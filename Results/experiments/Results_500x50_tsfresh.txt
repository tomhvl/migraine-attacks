


StandardScaler, lagged allx1, CC, SMOTE(), poly 2 & 0, cid2


pre/post: 50/0  win/stride: 500/50  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-20 23:02:23.024000 
pca_target: 0 	 poly degree: 0 	 kselect: 80 
Imbalance: ClusterCentroids(estimator=None, n_jobs=1, random_state=None, ratio='auto') 
Extended target (count):  25141 13
('Total : Processed (count): ', (493L, 438L), 13)
Final feature (count):  (493L, 438L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.784 	-0.100 	-0.080 	0.411 	0.000 	0.000
[[116  25]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.94      0.82      0.88       141
        1.0       0.00      0.00      0.00         7

avg / total       0.90      0.78      0.84       148


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.001, class_weight={1: 3}, dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.595 	0.130 	0.063 	0.651 	0.648 	0.426
[[83 58]
 [ 2  5]]
             precision    recall  f1-score   support

        0.0       0.98      0.59      0.73       141
        1.0       0.08      0.71      0.14         7

avg / total       0.93      0.59      0.71       148


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.0001, average=False, class_weight={1: 15}, epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='invscaling', loss='perceptron', n_iter=5, n_jobs=4,
       penalty='l2', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.608 	0.137 	0.068 	0.659 	0.656 	0.435
[[85 56]
 [ 2  5]]
             precision    recall  f1-score   support

        0.0       0.98      0.60      0.75       141
        1.0       0.08      0.71      0.15         7

avg / total       0.93      0.61      0.72       148


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 500}, criterion='gini',
           max_depth=None, max_features='auto', max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=30, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.757 	0.034 	0.024 	0.533 	0.472 	0.212
[[110  31]
 [  5   2]]
             precision    recall  f1-score   support

        0.0       0.96      0.78      0.86       141
        1.0       0.06      0.29      0.10         7

avg / total       0.91      0.76      0.82       148


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3},
            criterion='entropy', max_depth=32, max_features='auto',
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=15, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.784 	0.050 	0.038 	0.547 	0.481 	0.219
[[114  27]
 [  5   2]]
             precision    recall  f1-score   support

        0.0       0.96      0.81      0.88       141
        1.0       0.07      0.29      0.11         7

avg / total       0.92      0.78      0.84       148


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.804 	0.064 	0.050 	0.558 	0.487 	0.224
[[117  24]
 [  5   2]]
             precision    recall  f1-score   support

        0.0       0.96      0.83      0.89       141
        1.0       0.08      0.29      0.12         7

avg / total       0.92      0.80      0.85       148


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 500}, criterion='gini', max_depth=16,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=1.0, n_estimators=50, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.622 	0.144 	0.073 	0.666 	0.664 	0.445
[[87 54]
 [ 2  5]]
             precision    recall  f1-score   support

        0.0       0.98      0.62      0.76       141
        1.0       0.08      0.71      0.15         7

avg / total       0.94      0.62      0.73       148


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.01, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='linear',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.527 	0.156 	0.065 	0.684 	0.662 	0.453
[[72 69]
 [ 1  6]]
             precision    recall  f1-score   support

        0.0       0.99      0.51      0.67       141
        1.0       0.08      0.86      0.15         7

avg / total       0.94      0.53      0.65       148


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...wski',
           metric_params=None, n_jobs=4, n_neighbors=4, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.716 	-0.055 	-0.037 	0.444 	0.326 	0.100
[[105  36]
 [  6   1]]
             precision    recall  f1-score   support

        0.0       0.95      0.74      0.83       141
        1.0       0.03      0.14      0.05         7

avg / total       0.90      0.72      0.80       148


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=3, p=1,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.797 	0.060 	0.046 	0.554 	0.485 	0.222
[[116  25]
 [  5   2]]
             precision    recall  f1-score   support

        0.0       0.96      0.82      0.89       141
        1.0       0.07      0.29      0.12         7

avg / total       0.92      0.80      0.85       148


                estimator min_score mean_score max_score   sd_score       acc  \
7                     SVC         0   0.315539       0.5   0.203814  0.527027   
6      AdaBoostClassifier  -0.19245   0.500077         1   0.207672  0.621622   
2           SGDClassifier -0.833333   0.241891   0.69245   0.181938  0.608108   
1      LogisticRegression  -0.19245   0.212013   0.69245   0.194047  0.594595   
5           MLPClassifier       0.5   0.688441   0.69245  0.0274869  0.804054   
9    KNeighborsClassifier         0   0.397273   0.69245   0.166475  0.797297   
4  RandomForestClassifier  -0.19245   0.388198  0.833333   0.149148  0.783784   
3    ExtraTreesClassifier  0.140883   0.504982         1   0.160353  0.756757   
8        VotingClassifier  0.166667   0.555394   0.69245   0.106432  0.716216   
0              GaussianNB   0.69245    0.69245   0.69245          0  0.783784   

        auc          conf_matrix     f1_c0      f1_c1      kappa model_score  \
7  0.683891   [[72, 69], [1, 6]]  0.672897   0.146341   0.065488    0.156155   
6  0.665653   [[87, 54], [2, 5]]  0.756522   0.151515   0.073138    0.143638   
2  0.658561   [[85, 56], [2, 5]]  0.745614   0.147059  0.0679696    0.136761   
1  0.651469   [[83, 58], [2, 5]]  0.734513   0.142857  0.0630935    0.130057   
5  0.557751  [[117, 24], [5, 2]]  0.889734   0.121212  0.0504425   0.0644287   
9  0.554205  [[116, 25], [5, 2]]  0.885496   0.117647   0.045982   0.0595869   
4  0.547112  [[114, 27], [5, 2]]  0.876923   0.111111  0.0377895   0.0503909   
3  0.532928  [[110, 31], [5, 2]]  0.859375        0.1  0.0238182   0.0335853   
8  0.443769  [[105, 36], [6, 1]]  0.833333  0.0454545  -0.037037  -0.0551318   
0  0.411348  [[116, 25], [7, 0]]  0.878788          0 -0.0797994   -0.100452   

    prec_c0    prec_c1    rec_c0    rec_c1  
7  0.986301       0.08  0.510638  0.857143  
6  0.977528  0.0847458  0.617021  0.714286  
2  0.977011  0.0819672  0.602837  0.714286  
1  0.976471  0.0793651  0.588652  0.714286  
5  0.959016  0.0769231  0.829787  0.285714  
9  0.958678  0.0740741  0.822695  0.285714  
4  0.957983  0.0689655  0.808511  0.285714  
3  0.956522  0.0606061  0.780142  0.285714  
8  0.945946   0.027027  0.744681  0.142857  
0  0.943089          0  0.822695         0  
Elapsed time 14.09 mins 

************************************************************

pre/post: 50/0  win/stride: 500/50  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-20 23:16:28.567000 
pca_target: 0 	 poly degree: 0 	 kselect: 80 
Imbalance: SMOTE(k=None, k_neighbors=5, kind='regular', m=None, m_neighbors=10, n_jobs=1,
   out_step=0.5, random_state=None, ratio='auto', svm_estimator=None) 
Extended target (count):  25141 13
('Total : Processed (count): ', (493L, 438L), 13)
Final feature (count):  (493L, 438L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.932 	-0.032 	-0.029 	0.489 	0.000 	0.000
[[138   3]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.98      0.97       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.93      0.92       148


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=10, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.926 	0.116 	0.115 	0.554 	0.371 	0.126
[[136   5]
 [  6   1]]
             precision    recall  f1-score   support

        0.0       0.96      0.96      0.96       141
        1.0       0.17      0.14      0.15         7

avg / total       0.92      0.93      0.92       148


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.001, average=False, class_weight='balanced',
       epsilon=0.1, eta0=0.001, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='perceptron', n_iter=5, n_jobs=4,
       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.939 	0.159 	0.153 	0.561 	0.374 	0.128
[[138   3]
 [  6   1]]
             precision    recall  f1-score   support

        0.0       0.96      0.98      0.97       141
        1.0       0.25      0.14      0.18         7

avg / total       0.92      0.94      0.93       148


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=32, max_features=0.75, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=30, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.939 	-0.026 	-0.021 	0.493 	0.000 	0.000
[[139   2]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.99      0.97       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.94      0.92       148


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=50, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.939 	-0.026 	-0.021 	0.493 	0.000 	0.000
[[139   2]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.99      0.97       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.94      0.92       148


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.939 	-0.026 	-0.021 	0.493 	0.000 	0.000
[[139   2]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.99      0.97       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.94      0.92       148


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 50}, criterion='entropy', max_depth=8,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=1.0, n_estimators=15, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.939 	-0.026 	-0.021 	0.493 	0.000 	0.000
[[139   2]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.99      0.97       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.94      0.92       148


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.1, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.946 	-0.018 	-0.012 	0.496 	0.000 	0.000
[[140   1]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.99      0.97       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.95      0.93       148


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=10.0, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', ...owski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='uniform'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.946 	0.194 	0.177 	0.564 	0.375 	0.129
[[139   2]
 [  6   1]]
             precision    recall  f1-score   support

        0.0       0.96      0.99      0.97       141
        1.0       0.33      0.14      0.20         7

avg / total       0.93      0.95      0.94       148


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=3,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.912 	0.088 	0.087 	0.547 	0.368 	0.125
[[134   7]
 [  6   1]]
             precision    recall  f1-score   support

        0.0       0.96      0.95      0.95       141
        1.0       0.12      0.14      0.13         7

avg / total       0.92      0.91      0.91       148


                estimator min_score mean_score max_score    sd_score  \
8        VotingClassifier  0.877902   0.935382  0.976779     0.02369   
2           SGDClassifier         0   0.653599   0.97108    0.250437   
1      LogisticRegression  0.210302    0.79256  0.942645    0.154997   
9    KNeighborsClassifier  0.791681   0.861968  0.918336   0.0387657   
7                     SVC         0   0.810166         1    0.318241   
3    ExtraTreesClassifier  0.836621   0.986433         1   0.0226535   
4  RandomForestClassifier  0.970795   0.988605  0.997072  0.00454178   
5           MLPClassifier  0.937134   0.965278  0.985481   0.0139862   
6      AdaBoostClassifier  0.908054   0.971952  0.997072   0.0165069   
0              GaussianNB  0.951368   0.951368  0.951368           0   

        acc       auc         conf_matrix     f1_c0     f1_c1      kappa  \
8  0.945946  0.564336  [[139, 2], [6, 1]]  0.972028       0.2   0.176634   
2  0.939189   0.56079  [[138, 3], [6, 1]]  0.968421  0.181818   0.152672   
1  0.925676  0.553698  [[136, 5], [6, 1]]  0.961131  0.153846   0.115217   
9  0.912162  0.546606  [[134, 7], [6, 1]]  0.953737  0.133333  0.0872865   
7  0.945946  0.496454  [[140, 1], [7, 0]]  0.972222         0 -0.0119658   
3  0.939189  0.492908  [[139, 2], [7, 0]]  0.968641         0 -0.0214724   
4  0.939189  0.492908  [[139, 2], [7, 0]]  0.968641         0 -0.0214724   
5  0.939189  0.492908  [[139, 2], [7, 0]]  0.968641         0 -0.0214724   
6  0.939189  0.492908  [[139, 2], [7, 0]]  0.968641         0 -0.0214724   
0  0.932432  0.489362  [[138, 3], [7, 0]]  0.965035         0 -0.0292072   

  model_score   prec_c0   prec_c1    rec_c0    rec_c1  
8    0.193821  0.958621  0.333333  0.985816  0.142857  
2    0.159152  0.958333      0.25  0.978723  0.142857  
1    0.115592  0.957746  0.166667  0.964539  0.142857  
9   0.0875025  0.957143     0.125  0.950355  0.142857  
7  -0.0183773  0.952381         0  0.992908         0  
3  -0.0260782  0.952055         0  0.985816         0  
4  -0.0260782  0.952055         0  0.985816         0  
5  -0.0260782  0.952055         0  0.985816         0  
6  -0.0260782  0.952055         0  0.985816         0  
0  -0.0320491  0.951724         0  0.978723         0  
Elapsed time 22.74 mins 

************************************************************

pre/post: 50/0  win/stride: 500/50  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-20 23:39:13.220000 
pca_target: 0 	 poly degree: 0 	 kselect: 80 
Imbalance: None 
Extended target (count):  25141 13
('Total : Processed (count): ', (493L, 438L), 13)
Final feature (count):  (493L, 438L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.905 	0.180 	0.175 	0.611 	0.517 	0.250
[[132   9]
 [  5   2]]
             precision    recall  f1-score   support

        0.0       0.96      0.94      0.95       141
        1.0       0.18      0.29      0.22         7

avg / total       0.93      0.91      0.92       148


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.01, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=10, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='sag', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.872 	0.209 	0.184 	0.661 	0.619 	0.365
[[126  15]
 [  4   3]]
             precision    recall  f1-score   support

        0.0       0.97      0.89      0.93       141
        1.0       0.17      0.43      0.24         7

avg / total       0.93      0.87      0.90       148


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=1, average=False, class_weight='balanced', epsilon=0.1,
       eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='perceptron', n_iter=5, n_jobs=4,
       penalty='l2', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.365 	0.028 	0.009 	0.531 	0.498 	0.257
[[49 92]
 [ 2  5]]
             precision    recall  f1-score   support

        0.0       0.96      0.35      0.51       141
        1.0       0.05      0.71      0.10         7

avg / total       0.92      0.36      0.49       148


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 500}, criterion='gini',
           max_depth=8, max_features=0.33, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.919 	0.100 	0.100 	0.550 	0.370 	0.126
[[135   6]
 [  6   1]]
             precision    recall  f1-score   support

        0.0       0.96      0.96      0.96       141
        1.0       0.14      0.14      0.14         7

avg / total       0.92      0.92      0.92       148


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=32, max_features=0.75, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.953 	0.000 	0.000 	0.500 	0.000 	0.000
[[141   0]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      1.00      0.98       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.95      0.93       148


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.01, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.946 	-0.018 	-0.012 	0.496 	0.000 	0.000
[[140   1]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.99      0.97       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.95      0.93       148


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=32,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=0.5, n_estimators=15, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.946 	0.311 	0.306 	0.632 	0.529 	0.260
[[138   3]
 [  5   2]]
             precision    recall  f1-score   support

        0.0       0.97      0.98      0.97       141
        1.0       0.40      0.29      0.33         7

avg / total       0.94      0.95      0.94       148


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='linear',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.905 	0.268 	0.254 	0.679 	0.631 	0.378
[[131  10]
 [  4   3]]
             precision    recall  f1-score   support

        0.0       0.97      0.93      0.95       141
        1.0       0.23      0.43      0.30         7

avg / total       0.94      0.91      0.92       148


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...owski',
           metric_params=None, n_jobs=4, n_neighbors=4, p=2,
           weights='uniform'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.953 	0.000 	0.000 	0.500 	0.000 	0.000
[[141   0]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      1.00      0.98       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.95      0.93       148


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=4,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.946 	0.311 	0.306 	0.632 	0.529 	0.260
[[138   3]
 [  5   2]]
             precision    recall  f1-score   support

        0.0       0.97      0.98      0.97       141
        1.0       0.40      0.29      0.33         7

avg / total       0.94      0.95      0.94       148


                estimator   min_score   mean_score  max_score    sd_score  \
7                     SVC  -0.0336583 -0.000512397   0.217171   0.0457888   
1      LogisticRegression  -0.0449002    0.0406531   0.222541   0.0699931   
6      AdaBoostClassifier   -0.030201  -0.00461502   0.194117   0.0351751   
9    KNeighborsClassifier  -0.0244336   0.00133434  0.0437761   0.0171677   
0              GaussianNB    0.186475     0.186475   0.186475           0   
3    ExtraTreesClassifier  -0.0159544   0.00106265   0.189926   0.0147219   
2           SGDClassifier   -0.102146    0.0703396   0.337024   0.0617538   
4  RandomForestClassifier -0.00713022  1.41607e-05  0.0785401  0.00424841   
8        VotingClassifier  -0.0209728  -0.00917915          0  0.00529997   
5           MLPClassifier  -0.0235879   -0.0139198  0.0544906   0.0112137   

        acc       auc          conf_matrix     f1_c0      f1_c1       kappa  \
7  0.905405  0.678825  [[131, 10], [4, 3]]  0.949275        0.3     0.25414   
1  0.871622  0.661094  [[126, 15], [4, 3]]  0.929889       0.24    0.184455   
6  0.945946  0.632219   [[138, 3], [5, 2]]  0.971831   0.333333    0.305979   
9  0.945946  0.632219   [[138, 3], [5, 2]]  0.971831   0.333333    0.305979   
0  0.905405  0.610942   [[132, 9], [5, 2]]   0.94964   0.222222    0.174502   
3  0.918919  0.550152   [[135, 6], [6, 1]]  0.957447   0.142857    0.100304   
2  0.364865  0.530902   [[49, 92], [2, 5]]  0.510417  0.0961538  0.00869317   
4  0.952703       0.5   [[141, 0], [7, 0]]  0.975779          0           0   
8  0.952703       0.5   [[141, 0], [7, 0]]  0.975779          0           0   
5  0.945946  0.496454   [[140, 1], [7, 0]]  0.972222          0  -0.0119658   

  model_score   prec_c0    prec_c1    rec_c0    rec_c1  
7    0.268212   0.97037   0.230769  0.929078  0.428571  
1    0.209248  0.969231   0.166667  0.893617  0.428571  
6    0.310691  0.965035        0.4  0.978723  0.285714  
9    0.310691  0.965035        0.4  0.978723  0.285714  
0    0.179568  0.963504   0.181818   0.93617  0.285714  
3    0.100304  0.957447   0.142857  0.957447  0.142857  
2   0.0276058  0.960784  0.0515464  0.347518  0.714286  
4           0  0.952703          0         1         0  
8           0  0.952703          0         1         0  
5  -0.0183773  0.952381          0  0.992908         0  
Elapsed time 17.17 mins 

************************************************************

pre/post: 50/0  win/stride: 500/50  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-20 23:56:23.147000 
pca_target: 0 	 poly degree: 0 	 kselect: 40 
Imbalance: ClusterCentroids(estimator=None, n_jobs=1, random_state=None, ratio='auto') 
Extended target (count):  25141 13
('Total : Processed (count): ', (493L, 438L), 13)
Final feature (count):  (493L, 438L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.770 	0.042 	0.030 	0.540 	0.476 	0.215
[[112  29]
 [  5   2]]
             precision    recall  f1-score   support

        0.0       0.96      0.79      0.87       141
        1.0       0.06      0.29      0.11         7

avg / total       0.92      0.77      0.83       148


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.1, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=5, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.784 	0.050 	0.038 	0.547 	0.481 	0.219
[[114  27]
 [  5   2]]
             precision    recall  f1-score   support

        0.0       0.96      0.81      0.88       141
        1.0       0.07      0.29      0.11         7

avg / total       0.92      0.78      0.84       148


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.0001, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='invscaling', loss='perceptron', n_iter=5, n_jobs=4,
       penalty='l1', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.608 	0.137 	0.068 	0.659 	0.656 	0.435
[[85 56]
 [ 2  5]]
             precision    recall  f1-score   support

        0.0       0.98      0.60      0.75       141
        1.0       0.08      0.71      0.15         7

avg / total       0.93      0.61      0.72       148


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=8, max_features='auto', max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.649 	0.039 	0.022 	0.544 	0.532 	0.276
[[93 48]
 [ 4  3]]
             precision    recall  f1-score   support

        0.0       0.96      0.66      0.78       141
        1.0       0.06      0.43      0.10         7

avg / total       0.92      0.65      0.75       148


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=50, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.554 	0.111 	0.050 	0.630 	0.625 	0.397
[[77 64]
 [ 2  5]]
             precision    recall  f1-score   support

        0.0       0.97      0.55      0.70       141
        1.0       0.07      0.71      0.13         7

avg / total       0.93      0.55      0.67       148


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.791 	0.055 	0.042 	0.551 	0.483 	0.221
[[115  26]
 [  5   2]]
             precision    recall  f1-score   support

        0.0       0.96      0.82      0.88       141
        1.0       0.07      0.29      0.11         7

avg / total       0.92      0.79      0.84       148


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='entropy', max_depth=8,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=2.0, n_estimators=50, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.703 	0.004 	0.003 	0.505 	0.455 	0.198
[[102  39]
 [  5   2]]
             precision    recall  f1-score   support

        0.0       0.95      0.72      0.82       141
        1.0       0.05      0.29      0.08         7

avg / total       0.91      0.70      0.79       148


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='linear',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.696 	0.186 	0.108 	0.705 	0.705 	0.497
[[98 43]
 [ 2  5]]
             precision    recall  f1-score   support

        0.0       0.98      0.70      0.81       141
        1.0       0.10      0.71      0.18         7

avg / total       0.94      0.70      0.78       148


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.777 	0.115 	0.083 	0.611 	0.583 	0.328
[[112  29]
 [  4   3]]
             precision    recall  f1-score   support

        0.0       0.97      0.79      0.87       141
        1.0       0.09      0.43      0.15         7

avg / total       0.92      0.78      0.84       148


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=3, p=2,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.851 	0.020 	0.018 	0.515 	0.356 	0.117
[[125  16]
 [  6   1]]
             precision    recall  f1-score   support

        0.0       0.95      0.89      0.92       141
        1.0       0.06      0.14      0.08         7

avg / total       0.91      0.85      0.88       148


                estimator  min_score mean_score max_score   sd_score  \
7                     SVC          0   0.348084  0.666667   0.218308   
2           SGDClassifier  -0.359117   0.412927  0.859117   0.175764   
4  RandomForestClassifier   0.166667   0.702896         1   0.173402   
8        VotingClassifier    0.30755   0.725382  0.859117  0.0832577   
5           MLPClassifier -0.0257834   0.116578  0.140883  0.0588232   
1      LogisticRegression          0   0.549652         1   0.378754   
3    ExtraTreesClassifier   0.474217   0.866335         1   0.102561   
0              GaussianNB    0.69245    0.69245   0.69245          0   
9    KNeighborsClassifier          0   0.412734  0.833333   0.247993   
6      AdaBoostClassifier  -0.166667   0.531322         1   0.195911   

        acc       auc          conf_matrix     f1_c0      f1_c1       kappa  \
7  0.695946  0.704661   [[98, 43], [2, 5]]  0.813278   0.181818    0.108195   
2  0.608108  0.658561   [[85, 56], [2, 5]]  0.745614   0.147059   0.0679696   
4  0.554054  0.630193   [[77, 64], [2, 5]]       0.7   0.131579   0.0499903   
8  0.777027  0.611449  [[112, 29], [4, 3]]  0.871595   0.153846   0.0826446   
5  0.790541  0.550659  [[115, 26], [5, 2]]  0.881226   0.114286   0.0417711   
1  0.783784  0.547112  [[114, 27], [5, 2]]  0.876923   0.111111   0.0377895   
3  0.648649  0.544073   [[93, 48], [4, 3]]  0.781513   0.103448   0.0221093   
0   0.77027   0.54002  [[112, 29], [5, 2]]  0.868217   0.105263   0.0304432   
9  0.851351  0.514691  [[125, 16], [6, 1]]  0.919118  0.0833333   0.0175015   
6  0.702703  0.504559  [[102, 39], [5, 2]]  0.822581  0.0833333  0.00275651   

  model_score   prec_c0    prec_c1    rec_c0    rec_c1  
7     0.18561      0.98   0.104167  0.695035  0.714286  
2    0.136761  0.977011  0.0819672  0.602837  0.714286  
4    0.110799  0.974684  0.0724638  0.546099  0.714286  
8    0.114937  0.965517    0.09375  0.794326  0.428571  
5   0.0549126  0.958333  0.0714286  0.815603  0.285714  
1   0.0503909  0.957983  0.0689655  0.808511  0.285714  
3   0.0393722  0.958763  0.0588235  0.659574  0.428571  
0   0.0417537  0.957265  0.0645161  0.794326  0.285714  
9   0.0195605  0.954198  0.0588235  0.886525  0.142857  
6  0.00432514  0.953271  0.0487805  0.723404  0.285714  
Elapsed time 13.53 mins 

************************************************************

pre/post: 50/0  win/stride: 500/50  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-21 00:09:54.881000 
pca_target: 0 	 poly degree: 0 	 kselect: 40 
Imbalance: SMOTE(k=None, k_neighbors=5, kind='regular', m=None, m_neighbors=10, n_jobs=1,
   out_step=0.5, random_state=None, ratio='auto', svm_estimator=None) 
Extended target (count):  25141 13
('Total : Processed (count): ', (493L, 438L), 13)
Final feature (count):  (493L, 438L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.872 	0.127 	0.116 	0.593 	0.507 	0.242
[[127  14]
 [  5   2]]
             precision    recall  f1-score   support

        0.0       0.96      0.90      0.93       141
        1.0       0.12      0.29      0.17         7

avg / total       0.92      0.87      0.89       148


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=5, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=5, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.885 	0.050 	0.048 	0.532 	0.363 	0.121
[[130  11]
 [  6   1]]
             precision    recall  f1-score   support

        0.0       0.96      0.92      0.94       141
        1.0       0.08      0.14      0.11         7

avg / total       0.91      0.89      0.90       148


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.001, average=False, class_weight='balanced',
       epsilon=0.1, eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='modified_huber', n_iter=5, n_jobs=4,
       penalty='none', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.926 	0.228 	0.228 	0.622 	0.523 	0.255
[[135   6]
 [  5   2]]
             precision    recall  f1-score   support

        0.0       0.96      0.96      0.96       141
        1.0       0.25      0.29      0.27         7

avg / total       0.93      0.93      0.93       148


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=32, max_features='auto', max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=30, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.939 	-0.026 	-0.021 	0.493 	0.000 	0.000
[[139   2]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.99      0.97       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.94      0.92       148


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight='balanced',
            criterion='gini', max_depth=None, max_features='auto',
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.946 	-0.018 	-0.012 	0.496 	0.000 	0.000
[[140   1]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.99      0.97       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.95      0.93       148


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(500,), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.939 	-0.026 	-0.021 	0.493 	0.000 	0.000
[[139   2]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.99      0.97       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.94      0.92       148


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 50}, criterion='entropy', max_depth=8,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=0.5, n_estimators=50, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.939 	-0.026 	-0.021 	0.493 	0.000 	0.000
[[139   2]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.99      0.97       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.94      0.92       148


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.5, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.939 	-0.026 	-0.021 	0.493 	0.000 	0.000
[[139   2]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.99      0.97       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.94      0.92       148


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=10.0, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', ...owski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='uniform'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.939 	0.277 	0.276 	0.629 	0.527 	0.259
[[137   4]
 [  5   2]]
             precision    recall  f1-score   support

        0.0       0.96      0.97      0.97       141
        1.0       0.33      0.29      0.31         7

avg / total       0.93      0.94      0.94       148


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=4,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.899 	0.067 	0.066 	0.540 	0.366 	0.123
[[132   9]
 [  6   1]]
             precision    recall  f1-score   support

        0.0       0.96      0.94      0.95       141
        1.0       0.10      0.14      0.12         7

avg / total       0.92      0.90      0.91       148


                estimator  min_score mean_score max_score    sd_score  \
8        VotingClassifier   0.865093   0.922077  0.959724   0.0219282   
2           SGDClassifier -0.0556336   0.642281  0.959573    0.244456   
0              GaussianNB   0.893935   0.893935  0.893935           0   
9    KNeighborsClassifier   0.828982   0.873396  0.918374   0.0288673   
1      LogisticRegression  0.0344016   0.759098  0.931556    0.185196   
4  RandomForestClassifier   0.962291   0.978273  0.994143  0.00619971   
3    ExtraTreesClassifier   0.806751   0.982303         1   0.0285044   
5           MLPClassifier   0.948263   0.964541  0.982671   0.0106027   
6      AdaBoostClassifier   0.904473   0.967479  0.994185   0.0156297   
7                     SVC          0   0.785699  0.988328    0.315843   

        acc       auc          conf_matrix     f1_c0     f1_c1      kappa  \
8  0.939189  0.628673   [[137, 4], [5, 2]]  0.968198  0.307692   0.276087   
2  0.925676  0.621581   [[135, 6], [5, 2]]  0.960854  0.266667   0.227704   
0  0.871622  0.593212  [[127, 14], [5, 2]]  0.930403  0.173913   0.115723   
9  0.898649  0.539514   [[132, 9], [6, 1]]  0.946237  0.117647  0.0656566   
1  0.885135  0.532421  [[130, 11], [6, 1]]  0.938628  0.105263  0.0484115   
4  0.945946  0.496454   [[140, 1], [7, 0]]  0.972222         0 -0.0119658   
3  0.939189  0.492908   [[139, 2], [7, 0]]  0.968641         0 -0.0214724   
5  0.939189  0.492908   [[139, 2], [7, 0]]  0.968641         0 -0.0214724   
6  0.939189  0.492908   [[139, 2], [7, 0]]  0.968641         0 -0.0214724   
7  0.939189  0.492908   [[139, 2], [7, 0]]  0.968641         0 -0.0214724   

  model_score   prec_c0    prec_c1    rec_c0    rec_c1  
8    0.276984  0.964789   0.333333  0.971631  0.285714  
2    0.228267  0.964286       0.25  0.957447  0.285714  
0    0.127442  0.962121      0.125  0.900709  0.285714  
9   0.0668339  0.956522        0.1   0.93617  0.142857  
1   0.0504268  0.955882  0.0833333  0.921986  0.142857  
4  -0.0183773  0.952381          0  0.992908         0  
3  -0.0260782  0.952055          0  0.985816         0  
5  -0.0260782  0.952055          0  0.985816         0  
6  -0.0260782  0.952055          0  0.985816         0  
7  -0.0260782  0.952055          0  0.985816         0  
Elapsed time 20.39 mins 

************************************************************

pre/post: 50/0  win/stride: 500/50  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-21 00:30:18.266000 
pca_target: 0 	 poly degree: 0 	 kselect: 40 
Imbalance: None 
Extended target (count):  25141 13
('Total : Processed (count): ', (493L, 438L), 13)
Final feature (count):  (493L, 438L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.845 	0.175 	0.146 	0.647 	0.609 	0.355
[[122  19]
 [  4   3]]
             precision    recall  f1-score   support

        0.0       0.97      0.87      0.91       141
        1.0       0.14      0.43      0.21         7

avg / total       0.93      0.84      0.88       148


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.1, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=0.01, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='sag', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.757 	0.165 	0.111 	0.669 	0.662 	0.429
[[108  33]
 [  3   4]]
             precision    recall  f1-score   support

        0.0       0.97      0.77      0.86       141
        1.0       0.11      0.57      0.18         7

avg / total       0.93      0.76      0.83       148


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.0001, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='perceptron', n_iter=5, n_jobs=4,
       penalty='l2', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.878 	0.136 	0.125 	0.597 	0.509 	0.243
[[128  13]
 [  5   2]]
             precision    recall  f1-score   support

        0.0       0.96      0.91      0.93       141
        1.0       0.13      0.29      0.18         7

avg / total       0.92      0.88      0.90       148


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 500}, criterion='gini',
           max_depth=8, max_features=0.75, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.899 	0.067 	0.066 	0.540 	0.366 	0.123
[[132   9]
 [  6   1]]
             precision    recall  f1-score   support

        0.0       0.96      0.94      0.95       141
        1.0       0.10      0.14      0.12         7

avg / total       0.92      0.90      0.91       148


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 50}, criterion='gini',
            max_depth=None, max_features=0.75, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.953 	0.000 	0.000 	0.500 	0.000 	0.000
[[141   0]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      1.00      0.98       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.95      0.93       148


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.5, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(500,), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.939 	-0.026 	-0.021 	0.493 	0.000 	0.000
[[139   2]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.99      0.97       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.94      0.92       148


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight='balanced', criterion='gini',
            max_depth=16, max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=2.0, n_estimators=15, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.939 	-0.026 	-0.021 	0.493 	0.000 	0.000
[[139   2]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.99      0.97       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.94      0.92       148


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.01, cache_size=200, class_weight={1: 50}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='linear',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.872 	0.209 	0.184 	0.661 	0.619 	0.365
[[126  15]
 [  4   3]]
             precision    recall  f1-score   support

        0.0       0.97      0.89      0.93       141
        1.0       0.17      0.43      0.24         7

avg / total       0.93      0.87      0.90       148


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...wski',
           metric_params=None, n_jobs=4, n_neighbors=4, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.946 	-0.018 	-0.012 	0.496 	0.000 	0.000
[[140   1]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.99      0.97       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.95      0.93       148


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=4,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.946 	0.311 	0.306 	0.632 	0.529 	0.260
[[138   3]
 [  5   2]]
             precision    recall  f1-score   support

        0.0       0.97      0.98      0.97       141
        1.0       0.40      0.29      0.33         7

avg / total       0.94      0.95      0.94       148


                estimator   min_score  mean_score   max_score    sd_score  \
1      LogisticRegression   -0.042902    0.062673     0.27771   0.0823525   
7                     SVC  -0.0380098  0.00382469    0.143454    0.046242   
0              GaussianNB    0.132982    0.132982    0.132982           0   
9    KNeighborsClassifier  -0.0197561 -0.00108838   0.0412875   0.0127817   
2           SGDClassifier   -0.113122   0.0821934    0.329249   0.0653987   
3    ExtraTreesClassifier   -0.029983   0.0052159     0.33048   0.0320724   
4  RandomForestClassifier -0.00713086  0.00170133         0.2   0.0196646   
8        VotingClassifier  -0.0174365 -0.00808023           0  0.00450677   
5           MLPClassifier  -0.0276952  -0.0159191 -0.00713022  0.00522486   
6      AdaBoostClassifier  -0.0310467   0.0356147    0.303176   0.0683789   

        acc       auc          conf_matrix     f1_c0     f1_c1      kappa  \
1  0.756757  0.668693  [[108, 33], [3, 4]]  0.857143  0.181818   0.111111   
7  0.871622  0.661094  [[126, 15], [4, 3]]  0.929889      0.24   0.184455   
0  0.844595   0.64691  [[122, 19], [4, 3]]  0.913858  0.206897   0.145582   
9  0.945946  0.632219   [[138, 3], [5, 2]]  0.971831  0.333333   0.305979   
2  0.878378  0.596758  [[128, 13], [5, 2]]  0.934307  0.181818    0.12541   
3  0.898649  0.539514   [[132, 9], [6, 1]]  0.946237  0.117647  0.0656566   
4  0.952703       0.5   [[141, 0], [7, 0]]  0.975779         0          0   
8  0.945946  0.496454   [[140, 1], [7, 0]]  0.972222         0 -0.0119658   
5  0.939189  0.492908   [[139, 2], [7, 0]]  0.968641         0 -0.0214724   
6  0.939189  0.492908   [[139, 2], [7, 0]]  0.968641         0 -0.0214724   

  model_score   prec_c0   prec_c1    rec_c0    rec_c1  
1    0.165395  0.972973  0.108108  0.765957  0.571429  
7    0.209248  0.969231  0.166667  0.893617  0.428571  
0    0.175325  0.968254  0.136364  0.865248  0.428571  
9    0.310691  0.965035       0.4  0.978723  0.285714  
2    0.136114  0.962406  0.133333  0.907801  0.285714  
3   0.0668339  0.956522       0.1   0.93617  0.142857  
4           0  0.952703         0         1         0  
8  -0.0183773  0.952381         0  0.992908         0  
5  -0.0260782  0.952055         0  0.985816         0  
6  -0.0260782  0.952055         0  0.985816         0  
Elapsed time 16.84 mins 

************************************************************

pre/post: 50/0  win/stride: 500/50  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-21 00:47:08.737000 
pca_target: 0 	 poly degree: 0 	 kselect: 100 
Imbalance: ClusterCentroids(estimator=None, n_jobs=1, random_state=None, ratio='auto') 
Extended target (count):  25141 13
('Total : Processed (count): ', (493L, 438L), 13)
Final feature (count):  (493L, 438L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.791 	-0.019 	-0.015 	0.483 	0.343 	0.110
[[116  25]
 [  6   1]]
             precision    recall  f1-score   support

        0.0       0.95      0.82      0.88       141
        1.0       0.04      0.14      0.06         7

avg / total       0.91      0.79      0.84       148


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=1, class_weight={1: 15}, dual=False, fit_intercept=True,
          intercept_scaling=5, max_iter=100, multi_class='ovr', n_jobs=4,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.757 	0.034 	0.024 	0.533 	0.472 	0.212
[[110  31]
 [  5   2]]
             precision    recall  f1-score   support

        0.0       0.96      0.78      0.86       141
        1.0       0.06      0.29      0.10         7

avg / total       0.91      0.76      0.82       148


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.1, average=False, class_weight={1: 50}, epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='squared_hinge', n_iter=5, n_jobs=4,
       penalty='l1', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.561 	0.114 	0.052 	0.634 	0.629 	0.402
[[78 63]
 [ 2  5]]
             precision    recall  f1-score   support

        0.0       0.97      0.55      0.71       141
        1.0       0.07      0.71      0.13         7

avg / total       0.93      0.56      0.68       148


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=32, max_features=0.75, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=30, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.520 	-0.020 	-0.009 	0.477 	0.474 	0.223
[[74 67]
 [ 4  3]]
             precision    recall  f1-score   support

        0.0       0.95      0.52      0.68       141
        1.0       0.04      0.43      0.08         7

avg / total       0.91      0.52      0.65       148


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 15},
            criterion='entropy', max_depth=None, max_features=0.75,
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=15, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.568 	0.059 	0.028 	0.569 	0.569 	0.324
[[80 61]
 [ 3  4]]
             precision    recall  f1-score   support

        0.0       0.96      0.57      0.71       141
        1.0       0.06      0.57      0.11         7

avg / total       0.92      0.57      0.69       148


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.804 	-0.012 	-0.009 	0.490 	0.346 	0.111
[[118  23]
 [  6   1]]
             precision    recall  f1-score   support

        0.0       0.95      0.84      0.89       141
        1.0       0.04      0.14      0.06         7

avg / total       0.91      0.80      0.85       148


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=0.5, n_estimators=80, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.338 	-0.166 	-0.054 	0.313 	0.312 	0.097
[[48 93]
 [ 5  2]]
             precision    recall  f1-score   support

        0.0       0.91      0.34      0.49       141
        1.0       0.02      0.29      0.04         7

avg / total       0.86      0.34      0.47       148


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=1, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.257 	0.115 	0.026 	0.610 	0.469 	0.237
[[ 31 110]
 [  0   7]]
             precision    recall  f1-score   support

        0.0       1.00      0.22      0.36       141
        1.0       0.06      1.00      0.11         7

avg / total       0.96      0.26      0.35       148


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 500}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Ran...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.682 	-0.006 	-0.003 	0.494 	0.448 	0.192
[[99 42]
 [ 5  2]]
             precision    recall  f1-score   support

        0.0       0.95      0.70      0.81       141
        1.0       0.05      0.29      0.08         7

avg / total       0.91      0.68      0.77       148


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=2,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.818 	-0.004 	-0.003 	0.497 	0.349 	0.113
[[120  21]
 [  6   1]]
             precision    recall  f1-score   support

        0.0       0.95      0.85      0.90       141
        1.0       0.05      0.14      0.07         7

avg / total       0.91      0.82      0.86       148


                estimator  min_score mean_score max_score   sd_score  \
2           SGDClassifier       -0.5   0.340974  0.859117    0.19076   
7                     SVC -0.0257834   0.337333   0.69245   0.233943   
4  RandomForestClassifier  -0.166667   0.318705  0.859117     0.1343   
1      LogisticRegression   -0.19245   0.331848   0.69245   0.215907   
9    KNeighborsClassifier   -0.19245   0.337343   0.69245   0.202864   
8        VotingClassifier  -0.359117   0.164509       0.5   0.160343   
5           MLPClassifier   0.166667   0.345899  0.666667  0.0642455   
0              GaussianNB    0.69245    0.69245   0.69245          0   
3    ExtraTreesClassifier   0.166667   0.642657         1   0.190003   
6      AdaBoostClassifier  -0.333333    0.48244         1   0.212659   

        acc       auc          conf_matrix     f1_c0      f1_c1       kappa  \
2  0.560811  0.633739   [[78, 63], [2, 5]]  0.705882   0.133333     0.05203   
7  0.256757  0.609929  [[31, 110], [0, 7]]  0.360465   0.112903   0.0259663   
4  0.567568  0.569402   [[80, 61], [3, 4]]  0.714286   0.111111   0.0281141   
1  0.756757  0.532928  [[110, 31], [5, 2]]  0.859375        0.1   0.0238182   
9  0.817568   0.49696  [[120, 21], [6, 1]]  0.898876  0.0689655 -0.00301205   
8  0.682432  0.493921   [[99, 42], [5, 2]]  0.808163  0.0784314  -0.0034622   
5  0.804054  0.489868  [[118, 23], [6, 1]]  0.890566  0.0645161 -0.00940734   
0  0.790541  0.482776  [[116, 25], [6, 1]]  0.882129  0.0606061  -0.0150442   
3   0.52027  0.476697   [[74, 67], [4, 3]]  0.675799  0.0779221 -0.00883257   
6  0.337838   0.31307   [[48, 93], [5, 2]]  0.494845  0.0392157  -0.0536103   

  model_score   prec_c0    prec_c1    rec_c0    rec_c1  
2    0.113932     0.975  0.0735294  0.553191  0.714286  
7     0.11469         1  0.0598291  0.219858         1  
4   0.0593699  0.963855  0.0615385  0.567376  0.571429  
1   0.0335853  0.956522  0.0606061  0.780142  0.285714  
9 -0.00362741  0.952381  0.0454545  0.851064  0.142857  
8  -0.0056465  0.951923  0.0454545  0.702128  0.285714  
5  -0.0116696  0.951613  0.0416667  0.836879  0.142857  
0  -0.0192156   0.95082  0.0384615  0.822695  0.142857  
3  -0.0198154  0.948718  0.0428571  0.524823  0.428571  
6   -0.165527   0.90566  0.0210526  0.340426  0.285714  
Elapsed time 14.24 mins 

************************************************************

pre/post: 50/0  win/stride: 500/50  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-21 01:01:22.945000 
pca_target: 0 	 poly degree: 0 	 kselect: 100 
Imbalance: SMOTE(k=None, k_neighbors=5, kind='regular', m=None, m_neighbors=10, n_jobs=1,
   out_step=0.5, random_state=None, ratio='auto', svm_estimator=None) 
Extended target (count):  25141 13
('Total : Processed (count): ', (493L, 438L), 13)
Final feature (count):  (493L, 438L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.892 	-0.057 	-0.056 	0.468 	0.000 	0.000
[[132   9]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.94      0.94       141
        1.0       0.00      0.00      0.00         7

avg / total       0.90      0.89      0.90       148


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=5, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=5, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.932 	0.135 	0.132 	0.557 	0.373 	0.127
[[137   4]
 [  6   1]]
             precision    recall  f1-score   support

        0.0       0.96      0.97      0.96       141
        1.0       0.20      0.14      0.17         7

avg / total       0.92      0.93      0.93       148


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.001, average=False, class_weight='balanced',
       epsilon=0.1, eta0=0.001, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='perceptron', n_iter=5, n_jobs=4,
       penalty='l1', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.919 	-0.042 	-0.041 	0.482 	0.000 	0.000
[[136   5]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.96      0.96       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.92      0.91       148


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3},
           criterion='entropy', max_depth=None, max_features='auto',
           max_leaf_nodes=None, min_impurity_split=1e-07,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=4,
           oob_score=False, random_state=None, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.939 	-0.026 	-0.021 	0.493 	0.000 	0.000
[[139   2]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.99      0.97       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.94      0.92       148


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3},
            criterion='entropy', max_depth=32, max_features='auto',
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.946 	-0.018 	-0.012 	0.496 	0.000 	0.000
[[140   1]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.99      0.97       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.95      0.93       148


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.01, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.939 	-0.026 	-0.021 	0.493 	0.000 	0.000
[[139   2]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.99      0.97       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.94      0.92       148


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=0.5, n_estimators=15, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.932 	-0.032 	-0.029 	0.489 	0.000 	0.000
[[138   3]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.98      0.97       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.93      0.92       148


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.1, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.953 	0.000 	0.000 	0.500 	0.000 	0.000
[[141   0]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      1.00      0.98       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.95      0.93       148


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=10.0, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', ...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.939 	-0.026 	-0.021 	0.493 	0.000 	0.000
[[139   2]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.99      0.97       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.94      0.92       148


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=4,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.912 	0.194 	0.190 	0.614 	0.519 	0.252
[[133   8]
 [  5   2]]
             precision    recall  f1-score   support

        0.0       0.96      0.94      0.95       141
        1.0       0.20      0.29      0.24         7

avg / total       0.93      0.91      0.92       148


                estimator min_score mean_score max_score    sd_score  \
9    KNeighborsClassifier  0.786857    0.85789  0.915648   0.0372058   
1      LogisticRegression  0.309503   0.813017  0.954143    0.151461   
7                     SVC         0   0.816347         1    0.318383   
4  RandomForestClassifier  0.976571   0.989611         1   0.0044575   
3    ExtraTreesClassifier  0.886285   0.988038         1    0.017905   
5           MLPClassifier  0.956838   0.972716  0.988286  0.00842715   
8        VotingClassifier  0.875542   0.934308  0.965268   0.0201384   
6      AdaBoostClassifier  0.922648   0.971515  0.997072   0.0148111   
2           SGDClassifier -0.142236   0.646214  0.982594    0.254068   
0              GaussianNB  0.893992   0.893992  0.893992           0   

        acc       auc         conf_matrix     f1_c0     f1_c1      kappa  \
9  0.912162  0.614488  [[133, 8], [5, 2]]  0.953405  0.235294   0.190236   
1  0.932432  0.557244  [[137, 4], [6, 1]]  0.964789  0.166667   0.132474   
7  0.952703       0.5  [[141, 0], [7, 0]]  0.975779         0          0   
4  0.945946  0.496454  [[140, 1], [7, 0]]  0.972222         0 -0.0119658   
3  0.939189  0.492908  [[139, 2], [7, 0]]  0.968641         0 -0.0214724   
5  0.939189  0.492908  [[139, 2], [7, 0]]  0.968641         0 -0.0214724   
8  0.939189  0.492908  [[139, 2], [7, 0]]  0.968641         0 -0.0214724   
6  0.932432  0.489362  [[138, 3], [7, 0]]  0.965035         0 -0.0292072   
2  0.918919   0.48227  [[136, 5], [7, 0]]  0.957746         0 -0.0410317   
0  0.891892  0.468085  [[132, 9], [7, 0]]  0.942857         0 -0.0561998   

  model_score   prec_c0 prec_c1    rec_c0    rec_c1  
9    0.193647  0.963768     0.2  0.943262  0.285714  
1    0.134514  0.958042     0.2  0.971631  0.142857  
7           0  0.952703       0         1         0  
4  -0.0183773  0.952381       0  0.992908         0  
3  -0.0260782  0.952055       0  0.985816         0  
5  -0.0260782  0.952055       0  0.985816         0  
8  -0.0260782  0.952055       0  0.985816         0  
6  -0.0320491  0.951724       0  0.978723         0  
2  -0.0416636  0.951049       0  0.964539         0  
0  -0.0566961   0.94964       0   0.93617         0  
Elapsed time 23.73 mins 

************************************************************

pre/post: 50/0  win/stride: 500/50  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-21 01:25:06.844000 
pca_target: 0 	 poly degree: 0 	 kselect: 100 
Imbalance: None 
Extended target (count):  25141 13
('Total : Processed (count): ', (493L, 438L), 13)
Final feature (count):  (493L, 438L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.899 	0.167 	0.160 	0.607 	0.515 	0.248
[[131  10]
 [  5   2]]
             precision    recall  f1-score   support

        0.0       0.96      0.93      0.95       141
        1.0       0.17      0.29      0.21         7

avg / total       0.93      0.90      0.91       148


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.01, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=10, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='sag', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.838 	0.010 	0.008 	0.508 	0.353 	0.116
[[123  18]
 [  6   1]]
             precision    recall  f1-score   support

        0.0       0.95      0.87      0.91       141
        1.0       0.05      0.14      0.08         7

avg / total       0.91      0.84      0.87       148


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.001, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='constant', loss='perceptron', n_iter=5, n_jobs=4,
       penalty='l1', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.946 	-0.018 	-0.012 	0.496 	0.000 	0.000
[[140   1]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.99      0.97       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.95      0.93       148


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 500}, criterion='gini',
           max_depth=8, max_features=0.33, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=50, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.926 	-0.037 	-0.036 	0.486 	0.000 	0.000
[[137   4]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.97      0.96       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.93      0.92       148


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.953 	0.000 	0.000 	0.500 	0.000 	0.000
[[141   0]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      1.00      0.98       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.95      0.93       148


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.01, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(500,), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.946 	-0.018 	-0.012 	0.496 	0.000 	0.000
[[140   1]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.99      0.97       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.95      0.93       148


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 500}, criterion='entropy',
            max_depth=16, max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=2.0, n_estimators=50, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.939 	0.159 	0.153 	0.561 	0.374 	0.128
[[138   3]
 [  6   1]]
             precision    recall  f1-score   support

        0.0       0.96      0.98      0.97       141
        1.0       0.25      0.14      0.18         7

avg / total       0.92      0.94      0.93       148


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='linear',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.899 	0.167 	0.160 	0.607 	0.515 	0.248
[[131  10]
 [  5   2]]
             precision    recall  f1-score   support

        0.0       0.96      0.93      0.95       141
        1.0       0.17      0.29      0.21         7

avg / total       0.93      0.90      0.91       148


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...owski',
           metric_params=None, n_jobs=4, n_neighbors=4, p=2,
           weights='uniform'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.953 	0.000 	0.000 	0.500 	0.000 	0.000
[[141   0]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      1.00      0.98       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.95      0.93       148


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=4,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.953 	0.355 	0.341 	0.636 	0.531 	0.262
[[139   2]
 [  5   2]]
             precision    recall  f1-score   support

        0.0       0.97      0.99      0.98       141
        1.0       0.50      0.29      0.36         7

avg / total       0.94      0.95      0.95       148


                estimator   min_score   mean_score   max_score    sd_score  \
9    KNeighborsClassifier   -0.028136   -0.0031902   0.0395858   0.0140083   
0              GaussianNB    0.106272     0.106272    0.106272           0   
7                     SVC  -0.0305592  -0.00332903    0.144442   0.0319679   
6      AdaBoostClassifier  -0.0279705  -0.00558921    0.217214   0.0330784   
1      LogisticRegression  -0.0449592    0.0402586    0.204691   0.0623185   
4  RandomForestClassifier -0.00588299  -0.00010027           0  0.00061359   
8        VotingClassifier  -0.0203777  -0.00856628           0  0.00539318   
2           SGDClassifier  -0.0971905    0.0601204    0.244809    0.058182   
5           MLPClassifier   -0.023711   -0.0157379 -0.00713022   0.0044756   
3    ExtraTreesClassifier  -0.0338044  0.000804393    0.131015   0.0135811   

        acc       auc          conf_matrix     f1_c0      f1_c1       kappa  \
9  0.952703  0.635765   [[139, 2], [5, 2]]  0.975439   0.363636    0.340967   
0  0.898649  0.607396  [[131, 10], [5, 2]]  0.945848   0.210526    0.160363   
7  0.898649  0.607396  [[131, 10], [5, 2]]  0.945848   0.210526    0.160363   
6  0.939189   0.56079   [[138, 3], [6, 1]]  0.968421   0.181818    0.152672   
1  0.837838  0.507599  [[123, 18], [6, 1]]  0.911111  0.0769231  0.00837521   
4  0.952703       0.5   [[141, 0], [7, 0]]  0.975779          0           0   
8  0.952703       0.5   [[141, 0], [7, 0]]  0.975779          0           0   
2  0.945946  0.496454   [[140, 1], [7, 0]]  0.972222          0  -0.0119658   
5  0.945946  0.496454   [[140, 1], [7, 0]]  0.972222          0  -0.0119658   
3  0.925676  0.485816   [[137, 4], [7, 0]]  0.961404          0  -0.0356234   

  model_score   prec_c0    prec_c1    rec_c0    rec_c1  
9    0.355439  0.965278        0.5  0.985816  0.285714  
0    0.167039  0.963235   0.166667  0.929078  0.285714  
7    0.167039  0.963235   0.166667  0.929078  0.285714  
6    0.159152  0.958333       0.25  0.978723  0.142857  
1  0.00964408  0.953488  0.0526316   0.87234  0.142857  
4           0  0.952703          0         1         0  
8           0  0.952703          0         1         0  
2  -0.0183773  0.952381          0  0.992908         0  
5  -0.0183773  0.952381          0  0.992908         0  
3  -0.0371354  0.951389          0  0.971631         0  
Elapsed time 17.85 mins 

************************************************************

pre/post: 50/0  win/stride: 500/50  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-21 01:42:57.878000 
pca_target: 0 	 poly degree: 2 	 kselect: 80 
Imbalance: ClusterCentroids(estimator=None, n_jobs=1, random_state=None, ratio='auto') 
Extended target (count):  25141 13
('Total : Processed (count): ', (493L, 96580L), 13)
Final feature (count):  (493L, 96580L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.642 	0.036 	0.020 	0.541 	0.529 	0.273
[[92 49]
 [ 4  3]]
             precision    recall  f1-score   support

        0.0       0.96      0.65      0.78       141
        1.0       0.06      0.43      0.10         7

avg / total       0.92      0.64      0.74       148


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.001, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='sag', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.696 	0.125 	0.075 	0.637 	0.633 	0.396
[[99 42]
 [ 3  4]]
             precision    recall  f1-score   support

        0.0       0.97      0.70      0.81       141
        1.0       0.09      0.57      0.15         7

avg / total       0.93      0.70      0.78       148


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.0001, average=False, class_weight='balanced',
       epsilon=0.1, eta0=0.001, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='squared_hinge', n_iter=5, n_jobs=4,
       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.622 	-0.034 	-0.018 	0.462 	0.427 	0.176
[[90 51]
 [ 5  2]]
             precision    recall  f1-score   support

        0.0       0.95      0.64      0.76       141
        1.0       0.04      0.29      0.07         7

avg / total       0.90      0.62      0.73       148


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=8, max_features='auto', max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.500 	0.029 	0.012 	0.534 	0.533 	0.286
[[70 71]
 [ 3  4]]
             precision    recall  f1-score   support

        0.0       0.96      0.50      0.65       141
        1.0       0.05      0.57      0.10         7

avg / total       0.92      0.50      0.63       148


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=16, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.453 	0.008 	0.003 	0.509 	0.505 	0.259
[[63 78]
 [ 3  4]]
             precision    recall  f1-score   support

        0.0       0.95      0.45      0.61       141
        1.0       0.05      0.57      0.09         7

avg / total       0.91      0.45      0.58       148


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.01, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.676 	-0.009 	-0.005 	0.490 	0.446 	0.190
[[98 43]
 [ 5  2]]
             precision    recall  f1-score   support

        0.0       0.95      0.70      0.80       141
        1.0       0.04      0.29      0.08         7

avg / total       0.91      0.68      0.77       148


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=0.5, n_estimators=50, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.466 	0.014 	0.005 	0.516 	0.513 	0.266
[[65 76]
 [ 3  4]]
             precision    recall  f1-score   support

        0.0       0.96      0.46      0.62       141
        1.0       0.05      0.57      0.09         7

avg / total       0.91      0.47      0.60       148


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='linear',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.662 	0.046 	0.027 	0.551 	0.537 	0.282
[[95 46]
 [ 4  3]]
             precision    recall  f1-score   support

        0.0       0.96      0.67      0.79       141
        1.0       0.06      0.43      0.11         7

avg / total       0.92      0.66      0.76       148


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.601 	0.017 	0.009 	0.519 	0.511 	0.257
[[86 55]
 [ 4  3]]
             precision    recall  f1-score   support

        0.0       0.96      0.61      0.74       141
        1.0       0.05      0.43      0.09         7

avg / total       0.91      0.60      0.71       148


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=2,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.669 	0.110 	0.063 	0.623 	0.620 	0.381
[[95 46]
 [ 3  4]]
             precision    recall  f1-score   support

        0.0       0.97      0.67      0.79       141
        1.0       0.08      0.57      0.14         7

avg / total       0.93      0.67      0.76       148


                estimator min_score mean_score max_score    sd_score  \
1      LogisticRegression         0   0.581864         1    0.403609   
9    KNeighborsClassifier  0.833333   0.952463         1   0.0742408   
7                     SVC         0   0.579322         1    0.376982   
0              GaussianNB  0.666667   0.666667  0.666667           0   
3    ExtraTreesClassifier   0.69245   0.832942  0.833333  0.00741488   
8        VotingClassifier  0.859117   0.872814         1   0.0417381   
6      AdaBoostClassifier  0.333333   0.781058         1    0.170375   
4  RandomForestClassifier   0.69245   0.848649         1   0.0562193   
5           MLPClassifier  0.833333   0.961806         1   0.0700494   
2           SGDClassifier -0.166667   0.506855         1    0.200491   

        acc       auc         conf_matrix     f1_c0      f1_c1       kappa  \
1  0.695946  0.636778  [[99, 42], [3, 4]]  0.814815   0.150943       0.075   
9  0.668919  0.622594  [[95, 46], [3, 4]]  0.794979   0.140351   0.0625646   
7  0.662162  0.551165  [[95, 46], [4, 3]]  0.791667   0.107143    0.026572   
0  0.641892  0.540527  [[92, 49], [4, 3]]  0.776371   0.101695     0.01999   
3       0.5  0.533941  [[70, 71], [3, 4]]  0.654206   0.097561   0.0120873   
8  0.601351   0.51925  [[86, 55], [4, 3]]  0.744589  0.0923077  0.00862852   
6  0.466216  0.516211  [[65, 76], [3, 4]]   0.62201   0.091954  0.00544403   
4  0.452703  0.509119  [[63, 78], [3, 4]]  0.608696  0.0898876  0.00299401   
5  0.675676  0.490375  [[98, 43], [5, 2]]  0.803279  0.0769231 -0.00537787   
2  0.621622  0.462006  [[90, 51], [5, 2]]  0.762712  0.0666667   -0.018432   

  model_score   prec_c0    prec_c1    rec_c0    rec_c1  
1    0.125466  0.970588  0.0869565  0.702128  0.571429  
9    0.110042  0.969388       0.08  0.673759  0.571429  
7    0.046158  0.959596  0.0612245  0.673759  0.428571  
0   0.0360408  0.958333  0.0576923  0.652482  0.428571  
3    0.028822  0.958904  0.0533333  0.496454  0.571429  
8   0.0167413  0.955556  0.0517241  0.609929  0.428571  
6   0.0138099  0.955882       0.05  0.460993  0.571429  
4  0.00778816  0.954545  0.0487805  0.446809  0.571429  
5 -0.00888321  0.951456  0.0444444  0.695035  0.285714  
2  -0.0336436  0.947368  0.0377358  0.638298  0.285714  
Elapsed time 22.07 mins 

************************************************************

pre/post: 50/0  win/stride: 500/50  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-21 02:05:02.135000 
pca_target: 0 	 poly degree: 2 	 kselect: 80 
Imbalance: SMOTE(k=None, k_neighbors=5, kind='regular', m=None, m_neighbors=10, n_jobs=1,
   out_step=0.5, random_state=None, ratio='auto', svm_estimator=None) 
Extended target (count):  25141 13
('Total : Processed (count): ', (493L, 96580L), 13)
Final feature (count):  (493L, 96580L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.865 	-0.069 	-0.066 	0.454 	0.000 	0.000
[[128  13]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.91      0.93       141
        1.0       0.00      0.00      0.00         7

avg / total       0.90      0.86      0.88       148


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=5, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=5, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.899 	0.067 	0.066 	0.540 	0.366 	0.123
[[132   9]
 [  6   1]]
             precision    recall  f1-score   support

        0.0       0.96      0.94      0.95       141
        1.0       0.10      0.14      0.12         7

avg / total       0.92      0.90      0.91       148


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.1, average=False, class_weight='balanced', epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='modified_huber', n_iter=5, n_jobs=4,
       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.926 	0.116 	0.115 	0.554 	0.371 	0.126
[[136   5]
 [  6   1]]
             precision    recall  f1-score   support

        0.0       0.96      0.96      0.96       141
        1.0       0.17      0.14      0.15         7

avg / total       0.92      0.93      0.92       148


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3},
           criterion='entropy', max_depth=16, max_features='auto',
           max_leaf_nodes=None, min_impurity_split=1e-07,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=4,
           oob_score=False, random_state=None, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.946 	-0.018 	-0.012 	0.496 	0.000 	0.000
[[140   1]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.99      0.97       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.95      0.93       148


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight='balanced',
            criterion='entropy', max_depth=16, max_features='auto',
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.953 	0.000 	0.000 	0.500 	0.000 	0.000
[[141   0]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      1.00      0.98       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.95      0.93       148


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.01, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.946 	0.194 	0.177 	0.564 	0.375 	0.129
[[139   2]
 [  6   1]]
             precision    recall  f1-score   support

        0.0       0.96      0.99      0.97       141
        1.0       0.33      0.14      0.20         7

avg / total       0.93      0.95      0.94       148


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=8,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=1.0, n_estimators=80, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.939 	-0.026 	-0.021 	0.493 	0.000 	0.000
[[139   2]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.99      0.97       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.94      0.92       148


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.5, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.953 	0.000 	0.000 	0.500 	0.000 	0.000
[[141   0]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      1.00      0.98       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.95      0.93       148


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=1.0, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', R...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.939 	0.159 	0.153 	0.561 	0.374 	0.128
[[138   3]
 [  6   1]]
             precision    recall  f1-score   support

        0.0       0.96      0.98      0.97       141
        1.0       0.25      0.14      0.18         7

avg / total       0.92      0.94      0.93       148


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=4,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.919 	0.100 	0.100 	0.550 	0.370 	0.126
[[135   6]
 [  6   1]]
             precision    recall  f1-score   support

        0.0       0.96      0.96      0.96       141
        1.0       0.14      0.14      0.14         7

avg / total       0.92      0.92      0.92       148


                estimator min_score mean_score max_score    sd_score  \
5           MLPClassifier  0.956878   0.976146  0.994143  0.00978488   
8        VotingClassifier  0.942898   0.968388  0.976779  0.00671428   
2           SGDClassifier -0.106722   0.691521  0.976859     0.23839   
9    KNeighborsClassifier  0.923744   0.953015   0.97108   0.0123148   
1      LogisticRegression  0.525998   0.859161  0.971045    0.138303   
4  RandomForestClassifier  0.965572   0.984422  0.997072  0.00431933   
7                     SVC         0   0.814737         1    0.309571   
3    ExtraTreesClassifier  0.843998   0.983479  0.997072   0.0183429   
6      AdaBoostClassifier  0.937051   0.979296         1   0.0110228   
0              GaussianNB  0.853505   0.853505  0.853505           0   

        acc       auc          conf_matrix     f1_c0     f1_c1      kappa  \
5  0.945946  0.564336   [[139, 2], [6, 1]]  0.972028       0.2   0.176634   
8  0.939189   0.56079   [[138, 3], [6, 1]]  0.968421  0.181818   0.152672   
2  0.925676  0.553698   [[136, 5], [6, 1]]  0.961131  0.153846   0.115217   
9  0.918919  0.550152   [[135, 6], [6, 1]]  0.957447  0.142857   0.100304   
1  0.898649  0.539514   [[132, 9], [6, 1]]  0.946237  0.117647  0.0656566   
4  0.952703       0.5   [[141, 0], [7, 0]]  0.975779         0          0   
7  0.952703       0.5   [[141, 0], [7, 0]]  0.975779         0          0   
3  0.945946  0.496454   [[140, 1], [7, 0]]  0.972222         0 -0.0119658   
6  0.939189  0.492908   [[139, 2], [7, 0]]  0.968641         0 -0.0214724   
0  0.864865  0.453901  [[128, 13], [7, 0]]  0.927536         0 -0.0655148   

  model_score   prec_c0   prec_c1    rec_c0    rec_c1  
5    0.193821  0.958621  0.333333  0.985816  0.142857  
8    0.159152  0.958333      0.25  0.978723  0.142857  
2    0.115592  0.957746  0.166667  0.964539  0.142857  
9    0.100304  0.957447  0.142857  0.957447  0.142857  
1   0.0668339  0.956522       0.1   0.93617  0.142857  
4           0  0.952703         0         1         0  
7           0  0.952703         0         1         0  
3  -0.0183773  0.952381         0  0.992908         0  
6  -0.0260782  0.952055         0  0.985816         0  
0  -0.0691424  0.948148         0  0.907801         0  
Elapsed time 21.98 mins 

************************************************************

pre/post: 50/0  win/stride: 500/50  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-21 02:27:00.965000 
pca_target: 0 	 poly degree: 2 	 kselect: 80 
Imbalance: None 
Extended target (count):  25141 13
('Total : Processed (count): ', (493L, 96580L), 13)
Final feature (count):  (493L, 96580L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.899 	0.167 	0.160 	0.607 	0.515 	0.248
[[131  10]
 [  5   2]]
             precision    recall  f1-score   support

        0.0       0.96      0.93      0.95       141
        1.0       0.17      0.29      0.21         7

avg / total       0.93      0.90      0.91       148


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.001, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=10, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.939 	-0.026 	-0.021 	0.493 	0.000 	0.000
[[139   2]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.99      0.97       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.94      0.92       148


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.0001, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='invscaling', loss='squared_hinge', n_iter=5,
       n_jobs=4, penalty='none', power_t=0.5, random_state=None,
       shuffle=True, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.939 	-0.026 	-0.021 	0.493 	0.000 	0.000
[[139   2]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.99      0.97       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.94      0.92       148


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=8, max_features='auto', max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=30, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.946 	-0.018 	-0.012 	0.496 	0.000 	0.000
[[140   1]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.99      0.97       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.95      0.93       148


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=50, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.953 	0.000 	0.000 	0.500 	0.000 	0.000
[[141   0]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      1.00      0.98       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.95      0.93       148


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.1, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.946 	-0.018 	-0.012 	0.496 	0.000 	0.000
[[140   1]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.99      0.97       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.95      0.93       148


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='entropy', max_depth=32,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=1.0, n_estimators=50, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.946 	-0.018 	-0.012 	0.496 	0.000 	0.000
[[140   1]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.99      0.97       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.95      0.93       148


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.01, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='linear',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.946 	-0.018 	-0.012 	0.496 	0.000 	0.000
[[140   1]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.99      0.97       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.95      0.93       148


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', R...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.946 	-0.018 	-0.012 	0.496 	0.000 	0.000
[[140   1]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.99      0.97       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.95      0.93       148


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=4,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.946 	-0.018 	-0.012 	0.496 	0.000 	0.000
[[140   1]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.99      0.97       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.95      0.93       148


                estimator   min_score mean_score max_score   sd_score  \
0              GaussianNB    0.238239   0.238239  0.238239          0   
4  RandomForestClassifier -0.00713022  0.0132819  0.339529  0.0504687   
3    ExtraTreesClassifier  -0.0222914  0.0894047  0.339529   0.110406   
5           MLPClassifier  -0.0184164   0.170766  0.388253  0.0926928   
6      AdaBoostClassifier  -0.0238573  0.0496901  0.456359  0.0979398   
7                     SVC  -0.0451663   0.058219  0.573381  0.0983049   
8        VotingClassifier -0.00837942  0.0909481  0.492626   0.114959   
9    KNeighborsClassifier           0  0.0713079  0.374309   0.138043   
1      LogisticRegression  -0.0670642   0.127615  0.514687  0.0870069   
2           SGDClassifier   -0.223899  0.0999895  0.571659  0.0758248   

        acc       auc          conf_matrix     f1_c0     f1_c1      kappa  \
0  0.898649  0.607396  [[131, 10], [5, 2]]  0.945848  0.210526   0.160363   
4  0.952703       0.5   [[141, 0], [7, 0]]  0.975779         0          0   
3  0.945946  0.496454   [[140, 1], [7, 0]]  0.972222         0 -0.0119658   
5  0.945946  0.496454   [[140, 1], [7, 0]]  0.972222         0 -0.0119658   
6  0.945946  0.496454   [[140, 1], [7, 0]]  0.972222         0 -0.0119658   
7  0.945946  0.496454   [[140, 1], [7, 0]]  0.972222         0 -0.0119658   
8  0.945946  0.496454   [[140, 1], [7, 0]]  0.972222         0 -0.0119658   
9  0.945946  0.496454   [[140, 1], [7, 0]]  0.972222         0 -0.0119658   
1  0.939189  0.492908   [[139, 2], [7, 0]]  0.968641         0 -0.0214724   
2  0.939189  0.492908   [[139, 2], [7, 0]]  0.968641         0 -0.0214724   

  model_score   prec_c0   prec_c1    rec_c0    rec_c1  
0    0.167039  0.963235  0.166667  0.929078  0.285714  
4           0  0.952703         0         1         0  
3  -0.0183773  0.952381         0  0.992908         0  
5  -0.0183773  0.952381         0  0.992908         0  
6  -0.0183773  0.952381         0  0.992908         0  
7  -0.0183773  0.952381         0  0.992908         0  
8  -0.0183773  0.952381         0  0.992908         0  
9  -0.0183773  0.952381         0  0.992908         0  
1  -0.0260782  0.952055         0  0.985816         0  
2  -0.0260782  0.952055         0  0.985816         0  
Elapsed time 17.85 mins 

************************************************************

pre/post: 50/0  win/stride: 500/50  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-21 02:44:51.695000 
pca_target: 0 	 poly degree: 2 	 kselect: 40 
Imbalance: ClusterCentroids(estimator=None, n_jobs=1, random_state=None, ratio='auto') 
Extended target (count):  25141 13
('Total : Processed (count): ', (493L, 96580L), 13)
Final feature (count):  (493L, 96580L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.601 	0.017 	0.009 	0.519 	0.511 	0.257
[[86 55]
 [ 4  3]]
             precision    recall  f1-score   support

        0.0       0.96      0.61      0.74       141
        1.0       0.05      0.43      0.09         7

avg / total       0.91      0.60      0.71       148


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.001, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.797 	0.060 	0.046 	0.554 	0.485 	0.222
[[116  25]
 [  5   2]]
             precision    recall  f1-score   support

        0.0       0.96      0.82      0.89       141
        1.0       0.07      0.29      0.12         7

avg / total       0.92      0.80      0.85       148


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.0001, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='constant', loss='modified_huber', n_iter=5, n_jobs=4,
       penalty='none', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.608 	-0.040 	-0.021 	0.455 	0.422 	0.172
[[88 53]
 [ 5  2]]
             precision    recall  f1-score   support

        0.0       0.95      0.62      0.75       141
        1.0       0.04      0.29      0.06         7

avg / total       0.90      0.61      0.72       148


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=8, max_features=0.75, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.365 	0.028 	0.009 	0.531 	0.498 	0.257
[[49 92]
 [ 2  5]]
             precision    recall  f1-score   support

        0.0       0.96      0.35      0.51       141
        1.0       0.05      0.71      0.10         7

avg / total       0.92      0.36      0.49       148


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.459 	0.011 	0.004 	0.513 	0.509 	0.262
[[64 77]
 [ 3  4]]
             precision    recall  f1-score   support

        0.0       0.96      0.45      0.62       141
        1.0       0.05      0.57      0.09         7

avg / total       0.91      0.46      0.59       148


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.588 	0.011 	0.005 	0.512 	0.505 	0.251
[[84 57]
 [ 4  3]]
             precision    recall  f1-score   support

        0.0       0.95      0.60      0.73       141
        1.0       0.05      0.43      0.09         7

avg / total       0.91      0.59      0.70       148


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=0.5, n_estimators=50, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.446 	0.005 	0.002 	0.506 	0.501 	0.255
[[62 79]
 [ 3  4]]
             precision    recall  f1-score   support

        0.0       0.95      0.44      0.60       141
        1.0       0.05      0.57      0.09         7

avg / total       0.91      0.45      0.58       148


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.696 	0.001 	0.001 	0.501 	0.452 	0.196
[[101  40]
 [  5   2]]
             precision    recall  f1-score   support

        0.0       0.95      0.72      0.82       141
        1.0       0.05      0.29      0.08         7

avg / total       0.91      0.70      0.78       148


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.527 	0.099 	0.042 	0.616 	0.608 	0.377
[[73 68]
 [ 2  5]]
             precision    recall  f1-score   support

        0.0       0.97      0.52      0.68       141
        1.0       0.07      0.71      0.12         7

avg / total       0.93      0.53      0.65       148


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=1,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.432 	-0.001 	-0.000 	0.498 	0.493 	0.247
[[60 81]
 [ 3  4]]
             precision    recall  f1-score   support

        0.0       0.95      0.43      0.59       141
        1.0       0.05      0.57      0.09         7

avg / total       0.91      0.43      0.56       148


                estimator min_score mean_score max_score   sd_score       acc  \
8        VotingClassifier  0.859117   0.859117  0.859117          0  0.527027   
1      LogisticRegression         0   0.584297         1   0.439821  0.797297   
3    ExtraTreesClassifier       0.5   0.840708         1   0.118894  0.364865   
0              GaussianNB  0.859117   0.859117  0.859117          0  0.601351   
4  RandomForestClassifier  0.833333   0.996759         1  0.0230135  0.459459   
5           MLPClassifier  0.833333   0.996528         1  0.0238044  0.587838   
6      AdaBoostClassifier  0.666667   0.942229         1  0.0877547  0.445946   
7                     SVC         0   0.654276         1   0.432463  0.695946   
9    KNeighborsClassifier  0.833333   0.951389         1  0.0757549  0.432432   
2           SGDClassifier         0   0.465849         1   0.257315  0.608108   

        auc          conf_matrix     f1_c0      f1_c1        kappa  \
8  0.616008   [[73, 68], [2, 5]]  0.675926      0.125    0.0423368   
1  0.554205  [[116, 25], [5, 2]]  0.885496   0.117647     0.045982   
3  0.530902   [[49, 92], [2, 5]]  0.510417  0.0961538   0.00869317   
0   0.51925   [[86, 55], [4, 3]]  0.744589  0.0923077   0.00862852   
4  0.512665   [[64, 77], [3, 4]]  0.615385  0.0909091   0.00420521   
5  0.512158   [[84, 57], [4, 3]]  0.733624  0.0895522   0.00528867   
6  0.505572   [[62, 79], [3, 4]]  0.601942  0.0888889   0.00180951   
7  0.501013  [[101, 40], [5, 2]]  0.817814  0.0816327   0.00060024   
9   0.49848   [[60, 81], [3, 4]]  0.588235  0.0869565 -0.000482859   
2  0.454914   [[88, 53], [5, 2]]  0.752137  0.0645161   -0.0211754   

  model_score   prec_c0    prec_c1    rec_c0    rec_c1  
8    0.098511  0.973333  0.0684932   0.51773  0.714286  
1   0.0595869  0.958678  0.0740741  0.822695  0.285714  
3   0.0276058  0.960784  0.0515464  0.347518  0.714286  
0   0.0167413  0.955556  0.0517241  0.609929  0.428571  
4   0.0108019  0.955224  0.0493827  0.453901  0.571429  
5   0.0105132  0.954545       0.05  0.595745  0.428571  
6  0.00476693  0.953846  0.0481928  0.439716  0.571429  
7   0.0009541   0.95283   0.047619  0.716312  0.285714  
9 -0.00130492  0.952381  0.0470588  0.425532  0.571429  
2  -0.0396103  0.946237  0.0363636  0.624113  0.285714  
Elapsed time 21.78 mins 

************************************************************

pre/post: 50/0  win/stride: 500/50  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-21 03:06:38.221000 
pca_target: 0 	 poly degree: 2 	 kselect: 40 
Imbalance: SMOTE(k=None, k_neighbors=5, kind='regular', m=None, m_neighbors=10, n_jobs=1,
   out_step=0.5, random_state=None, ratio='auto', svm_estimator=None) 
Extended target (count):  25141 13
('Total : Processed (count): ', (493L, 96580L), 13)
Final feature (count):  (493L, 96580L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.905 	0.180 	0.175 	0.611 	0.517 	0.250
[[132   9]
 [  5   2]]
             precision    recall  f1-score   support

        0.0       0.96      0.94      0.95       141
        1.0       0.18      0.29      0.22         7

avg / total       0.93      0.91      0.92       148


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=5, class_weight={1: 3}, dual=False, fit_intercept=True,
          intercept_scaling=0.1, max_iter=100, multi_class='ovr', n_jobs=4,
          penalty='l2', random_state=None, solver='lbfgs', tol=0.0001,
          verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.912 	0.088 	0.087 	0.547 	0.368 	0.125
[[134   7]
 [  6   1]]
             precision    recall  f1-score   support

        0.0       0.96      0.95      0.95       141
        1.0       0.12      0.14      0.13         7

avg / total       0.92      0.91      0.91       148


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.1, average=False, class_weight='balanced', epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='modified_huber', n_iter=5, n_jobs=4,
       penalty='l2', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.932 	0.135 	0.132 	0.557 	0.373 	0.127
[[137   4]
 [  6   1]]
             precision    recall  f1-score   support

        0.0       0.96      0.97      0.96       141
        1.0       0.20      0.14      0.17         7

avg / total       0.92      0.93      0.93       148


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3},
           criterion='entropy', max_depth=32, max_features=0.33,
           max_leaf_nodes=None, min_impurity_split=1e-07,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=4,
           oob_score=False, random_state=None, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.932 	-0.032 	-0.029 	0.489 	0.000 	0.000
[[138   3]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.98      0.97       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.93      0.92       148


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight='balanced',
            criterion='entropy', max_depth=16, max_features='auto',
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.939 	-0.026 	-0.021 	0.493 	0.000 	0.000
[[139   2]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.99      0.97       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.94      0.92       148


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.01, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.926 	-0.037 	-0.036 	0.486 	0.000 	0.000
[[137   4]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.97      0.96       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.93      0.92       148


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=0.5, n_estimators=15, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.939 	-0.026 	-0.021 	0.493 	0.000 	0.000
[[139   2]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.99      0.97       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.94      0.92       148


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.1, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.946 	-0.018 	-0.012 	0.496 	0.000 	0.000
[[140   1]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.99      0.97       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.95      0.93       148


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=10.0, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', ...owski',
           metric_params=None, n_jobs=4, n_neighbors=4, p=2,
           weights='uniform'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.919 	0.100 	0.100 	0.550 	0.370 	0.126
[[135   6]
 [  6   1]]
             precision    recall  f1-score   support

        0.0       0.96      0.96      0.96       141
        1.0       0.14      0.14      0.14         7

avg / total       0.92      0.92      0.92       148


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=2,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.926 	0.116 	0.115 	0.554 	0.371 	0.126
[[136   5]
 [  6   1]]
             precision    recall  f1-score   support

        0.0       0.96      0.96      0.96       141
        1.0       0.17      0.14      0.15         7

avg / total       0.92      0.93      0.92       148


                estimator min_score mean_score max_score    sd_score  \
0              GaussianNB  0.920915   0.920915  0.920915           0   
2           SGDClassifier -0.112272   0.704255  0.979706    0.244648   
9    KNeighborsClassifier  0.939906    0.96567  0.979665    0.012083   
8        VotingClassifier  0.939978   0.967109  0.979665  0.00667566   
1      LogisticRegression  0.407487   0.850591  0.971045    0.144673   
7                     SVC         0   0.835352         1    0.298785   
4  RandomForestClassifier   0.97071   0.979284  0.994143  0.00468933   
6      AdaBoostClassifier  0.935259   0.978188         1   0.0104877   
3    ExtraTreesClassifier  0.863229   0.984063         1   0.0186037   
5           MLPClassifier  0.965346   0.975401  0.985399  0.00428705   

        acc       auc         conf_matrix     f1_c0     f1_c1      kappa  \
0  0.905405  0.610942  [[132, 9], [5, 2]]   0.94964  0.222222   0.174502   
2  0.932432  0.557244  [[137, 4], [6, 1]]  0.964789  0.166667   0.132474   
9  0.925676  0.553698  [[136, 5], [6, 1]]  0.961131  0.153846   0.115217   
8  0.918919  0.550152  [[135, 6], [6, 1]]  0.957447  0.142857   0.100304   
1  0.912162  0.546606  [[134, 7], [6, 1]]  0.953737  0.133333  0.0872865   
7  0.945946  0.496454  [[140, 1], [7, 0]]  0.972222         0 -0.0119658   
4  0.939189  0.492908  [[139, 2], [7, 0]]  0.968641         0 -0.0214724   
6  0.939189  0.492908  [[139, 2], [7, 0]]  0.968641         0 -0.0214724   
3  0.932432  0.489362  [[138, 3], [7, 0]]  0.965035         0 -0.0292072   
5  0.925676  0.485816  [[137, 4], [7, 0]]  0.961404         0 -0.0356234   

  model_score   prec_c0   prec_c1    rec_c0    rec_c1  
0    0.179568  0.963504  0.181818   0.93617  0.285714  
2    0.134514  0.958042       0.2  0.971631  0.142857  
9    0.115592  0.957746  0.166667  0.964539  0.142857  
8    0.100304  0.957447  0.142857  0.957447  0.142857  
1   0.0875025  0.957143     0.125  0.950355  0.142857  
7  -0.0183773  0.952381         0  0.992908         0  
4  -0.0260782  0.952055         0  0.985816         0  
6  -0.0260782  0.952055         0  0.985816         0  
3  -0.0320491  0.951724         0  0.978723         0  
5  -0.0371354  0.951389         0  0.971631         0  
Elapsed time 20.02 mins 

************************************************************

pre/post: 50/0  win/stride: 500/50  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-21 03:26:39.186000 
pca_target: 0 	 poly degree: 2 	 kselect: 40 
Imbalance: None 
Extended target (count):  25141 13
('Total : Processed (count): ', (493L, 96580L), 13)
Final feature (count):  (493L, 96580L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.892 	0.156 	0.148 	0.604 	0.513 	0.247
[[130  11]
 [  5   2]]
             precision    recall  f1-score   support

        0.0       0.96      0.92      0.94       141
        1.0       0.15      0.29      0.20         7

avg / total       0.92      0.89      0.91       148


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.001, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='sag', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.946 	-0.018 	-0.012 	0.496 	0.000 	0.000
[[140   1]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.99      0.97       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.95      0.93       148


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=1, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='modified_huber', n_iter=5, n_jobs=4,
       penalty='l2', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.946 	-0.018 	-0.012 	0.496 	0.000 	0.000
[[140   1]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.99      0.97       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.95      0.93       148


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 15}, criterion='gini',
           max_depth=8, max_features=0.75, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.953 	0.000 	0.000 	0.500 	0.000 	0.000
[[141   0]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      1.00      0.98       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.95      0.93       148


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features=0.75, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=50, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.953 	0.000 	0.000 	0.500 	0.000 	0.000
[[141   0]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      1.00      0.98       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.95      0.93       148


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.5, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(500,), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.946 	-0.018 	-0.012 	0.496 	0.000 	0.000
[[140   1]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.99      0.97       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.95      0.93       148


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 50}, criterion='entropy',
            max_depth=16, max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=2.0, n_estimators=15, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.953 	0.000 	0.000 	0.500 	0.000 	0.000
[[141   0]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      1.00      0.98       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.95      0.93       148


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.1, cache_size=200, class_weight='balanced', coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.946 	-0.018 	-0.012 	0.496 	0.000 	0.000
[[140   1]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.99      0.97       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.95      0.93       148


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=1.0, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', R...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.946 	-0.018 	-0.012 	0.496 	0.000 	0.000
[[140   1]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.99      0.97       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.95      0.93       148


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=2,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.953 	0.250 	0.206 	0.568 	0.377 	0.130
[[140   1]
 [  6   1]]
             precision    recall  f1-score   support

        0.0       0.96      0.99      0.98       141
        1.0       0.50      0.14      0.22         7

avg / total       0.94      0.95      0.94       148


                estimator  min_score  mean_score max_score   sd_score  \
0              GaussianNB   0.269761    0.269761  0.269761          0   
9    KNeighborsClassifier -0.0160403    0.036171  0.206342  0.0784236   
3    ExtraTreesClassifier  -0.022026   0.0285909  0.292626  0.0566826   
4  RandomForestClassifier -0.0178699  0.00756126  0.142428  0.0333806   
6      AdaBoostClassifier -0.0251074   0.0534282  0.527686  0.0995672   
1      LogisticRegression -0.0375132    0.162131  0.498877   0.103611   
2           SGDClassifier  -0.193687    0.118939  0.653288  0.0852336   
5           MLPClassifier -0.0221923    0.131662  0.295524   0.105532   
7                     SVC -0.0496845   0.0785429  0.613078   0.107172   
8        VotingClassifier -0.0100714    0.123745  0.495567   0.148559   

        acc       auc          conf_matrix     f1_c0     f1_c1      kappa  \
0  0.891892   0.60385  [[130, 11], [5, 2]]  0.942029       0.2   0.147588   
9  0.952703  0.567882   [[140, 1], [6, 1]]   0.97561  0.222222   0.205521   
3  0.952703       0.5   [[141, 0], [7, 0]]  0.975779         0          0   
4  0.952703       0.5   [[141, 0], [7, 0]]  0.975779         0          0   
6  0.952703       0.5   [[141, 0], [7, 0]]  0.975779         0          0   
1  0.945946  0.496454   [[140, 1], [7, 0]]  0.972222         0 -0.0119658   
2  0.945946  0.496454   [[140, 1], [7, 0]]  0.972222         0 -0.0119658   
5  0.945946  0.496454   [[140, 1], [7, 0]]  0.972222         0 -0.0119658   
7  0.945946  0.496454   [[140, 1], [7, 0]]  0.972222         0 -0.0119658   
8  0.945946  0.496454   [[140, 1], [7, 0]]  0.972222         0 -0.0119658   

  model_score   prec_c0   prec_c1    rec_c0    rec_c1  
0     0.15576  0.962963  0.153846  0.921986  0.285714  
9    0.249606  0.958904       0.5  0.992908  0.142857  
3           0  0.952703         0         1         0  
4           0  0.952703         0         1         0  
6           0  0.952703         0         1         0  
1  -0.0183773  0.952381         0  0.992908         0  
2  -0.0183773  0.952381         0  0.992908         0  
5  -0.0183773  0.952381         0  0.992908         0  
7  -0.0183773  0.952381         0  0.992908         0  
8  -0.0183773  0.952381         0  0.992908         0  
Elapsed time 17.33 mins 

************************************************************

pre/post: 50/0  win/stride: 500/50  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-21 03:43:58.747000 
pca_target: 0 	 poly degree: 2 	 kselect: 100 
Imbalance: ClusterCentroids(estimator=None, n_jobs=1, random_state=None, ratio='auto') 
Extended target (count):  25141 13
('Total : Processed (count): ', (493L, 96580L), 13)
Final feature (count):  (493L, 96580L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.851 	0.020 	0.018 	0.515 	0.356 	0.117
[[125  16]
 [  6   1]]
             precision    recall  f1-score   support

        0.0       0.95      0.89      0.92       141
        1.0       0.06      0.14      0.08         7

avg / total       0.91      0.85      0.88       148


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.001, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.682 	0.118 	0.069 	0.630 	0.627 	0.389
[[97 44]
 [ 3  4]]
             precision    recall  f1-score   support

        0.0       0.97      0.69      0.80       141
        1.0       0.08      0.57      0.15         7

avg / total       0.93      0.68      0.77       148


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.001, average=False, class_weight='balanced',
       epsilon=0.1, eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='constant', loss='squared_hinge', n_iter=5, n_jobs=4,
       penalty='none', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.459 	0.069 	0.026 	0.581 	0.565 	0.328
[[63 78]
 [ 2  5]]
             precision    recall  f1-score   support

        0.0       0.97      0.45      0.61       141
        1.0       0.06      0.71      0.11         7

avg / total       0.93      0.46      0.59       148


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=8, max_features='auto', max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=30, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.439 	0.002 	0.001 	0.502 	0.497 	0.251
[[61 80]
 [ 3  4]]
             precision    recall  f1-score   support

        0.0       0.95      0.43      0.60       141
        1.0       0.05      0.57      0.09         7

avg / total       0.91      0.44      0.57       148


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 50}, criterion='gini',
            max_depth=16, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.486 	0.081 	0.032 	0.595 	0.583 	0.348
[[67 74]
 [ 2  5]]
             precision    recall  f1-score   support

        0.0       0.97      0.48      0.64       141
        1.0       0.06      0.71      0.12         7

avg / total       0.93      0.49      0.61       148


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.689 	-0.002 	-0.001 	0.497 	0.450 	0.194
[[100  41]
 [  5   2]]
             precision    recall  f1-score   support

        0.0       0.95      0.71      0.81       141
        1.0       0.05      0.29      0.08         7

avg / total       0.91      0.69      0.78       148


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=0.5, n_estimators=15, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.189 	0.008 	0.001 	0.507 	0.366 	0.143
[[ 22 119]
 [  1   6]]
             precision    recall  f1-score   support

        0.0       0.96      0.16      0.27       141
        1.0       0.05      0.86      0.09         7

avg / total       0.91      0.19      0.26       148


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.459 	0.069 	0.026 	0.581 	0.565 	0.328
[[63 78]
 [ 2  5]]
             precision    recall  f1-score   support

        0.0       0.97      0.45      0.61       141
        1.0       0.06      0.71      0.11         7

avg / total       0.93      0.46      0.59       148


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', R...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.466 	-0.044 	-0.018 	0.448 	0.448 	0.200
[[66 75]
 [ 4  3]]
             precision    recall  f1-score   support

        0.0       0.94      0.47      0.63       141
        1.0       0.04      0.43      0.07         7

avg / total       0.90      0.47      0.60       148


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=1,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.405 	0.046 	0.016 	0.552 	0.528 	0.288
[[55 86]
 [ 2  5]]
             precision    recall  f1-score   support

        0.0       0.96      0.39      0.56       141
        1.0       0.05      0.71      0.10         7

avg / total       0.92      0.41      0.53       148


                estimator  min_score mean_score max_score   sd_score  \
1      LogisticRegression          0   0.506419         1   0.309353   
4  RandomForestClassifier   0.666667   0.831019         1   0.023125   
2           SGDClassifier  -0.166667    0.41201         1   0.248434   
7                     SVC          0     0.6702         1   0.401418   
9    KNeighborsClassifier   0.859117   0.958909         1  0.0640356   
0              GaussianNB    0.69245    0.69245   0.69245          0   
6      AdaBoostClassifier  0.0257834   0.705901         1   0.189255   
3    ExtraTreesClassifier   0.833333   0.995833         1  0.0260208   
5           MLPClassifier   0.859117   0.973584         1  0.0549885   
8        VotingClassifier   0.833333   0.838735         1  0.0295133   

        acc       auc          conf_matrix     f1_c0      f1_c1       kappa  \
1  0.682432  0.629686   [[97, 44], [3, 4]]  0.804979   0.145455   0.0685592   
4  0.486486  0.594732   [[67, 74], [2, 5]]  0.638095   0.116279   0.0321803   
2  0.459459  0.580547   [[63, 78], [2, 5]]   0.61165   0.111111   0.0261556   
7  0.459459  0.580547   [[63, 78], [2, 5]]   0.61165   0.111111   0.0261556   
9  0.405405  0.552178   [[55, 86], [2, 5]]  0.555556   0.102041   0.0155707   
0  0.851351  0.514691  [[125, 16], [6, 1]]  0.919118  0.0833333   0.0175015   
6  0.189189  0.506586  [[22, 119], [1, 6]]  0.268293  0.0909091  0.00146182   
3  0.439189  0.502026   [[61, 80], [3, 4]]  0.595122  0.0879121  0.00065083   
5  0.689189  0.497467  [[100, 41], [5, 2]]  0.813008       0.08 -0.00147102   
8  0.466216  0.448328   [[66, 75], [4, 3]]  0.625592  0.0705882  -0.0177577   

  model_score   prec_c0    prec_c1    rec_c0    rec_c1  
1    0.117614      0.97  0.0833333  0.687943  0.571429  
4   0.0806204  0.971014  0.0632911  0.475177  0.714286  
2   0.0689037  0.969231   0.060241  0.446809  0.714286  
7   0.0689037  0.969231   0.060241  0.446809  0.714286  
9   0.0455219  0.964912  0.0549451  0.390071  0.714286  
0   0.0195605  0.954198  0.0588235  0.886525  0.142857  
6  0.00771731  0.956522      0.048  0.156028  0.857143  
3  0.00173649  0.953125   0.047619  0.432624  0.571429  
5 -0.00236855  0.952381  0.0465116   0.70922  0.285714  
8  -0.0439385  0.942857  0.0384615  0.468085  0.428571  
Elapsed time 22.39 mins 

************************************************************

pre/post: 50/0  win/stride: 500/50  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-21 04:06:21.904000 
pca_target: 0 	 poly degree: 2 	 kselect: 100 
Imbalance: SMOTE(k=None, k_neighbors=5, kind='regular', m=None, m_neighbors=10, n_jobs=1,
   out_step=0.5, random_state=None, ratio='auto', svm_estimator=None) 
Extended target (count):  25141 13
('Total : Processed (count): ', (493L, 96580L), 13)
Final feature (count):  (493L, 96580L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.851 	0.105 	0.091 	0.583 	0.501 	0.236
[[124  17]
 [  5   2]]
             precision    recall  f1-score   support

        0.0       0.96      0.88      0.92       141
        1.0       0.11      0.29      0.15         7

avg / total       0.92      0.85      0.88       148


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=10, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=5, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.885 	0.050 	0.048 	0.532 	0.363 	0.121
[[130  11]
 [  6   1]]
             precision    recall  f1-score   support

        0.0       0.96      0.92      0.94       141
        1.0       0.08      0.14      0.11         7

avg / total       0.91      0.89      0.90       148


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.1, average=False, class_weight='balanced', epsilon=0.1,
       eta0=0.001, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='modified_huber', n_iter=5, n_jobs=4,
       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.919 	0.100 	0.100 	0.550 	0.370 	0.126
[[135   6]
 [  6   1]]
             precision    recall  f1-score   support

        0.0       0.96      0.96      0.96       141
        1.0       0.14      0.14      0.14         7

avg / total       0.92      0.92      0.92       148


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=32, max_features='auto', max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.946 	-0.018 	-0.012 	0.496 	0.000 	0.000
[[140   1]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.99      0.97       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.95      0.93       148


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 50},
            criterion='entropy', max_depth=None, max_features='auto',
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.953 	0.000 	0.000 	0.500 	0.000 	0.000
[[141   0]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      1.00      0.98       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.95      0.93       148


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.01, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.932 	-0.032 	-0.029 	0.489 	0.000 	0.000
[[138   3]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.98      0.97       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.93      0.92       148


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='entropy', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=1.0, n_estimators=80, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.946 	0.194 	0.177 	0.564 	0.375 	0.129
[[139   2]
 [  6   1]]
             precision    recall  f1-score   support

        0.0       0.96      0.99      0.97       141
        1.0       0.33      0.14      0.20         7

avg / total       0.93      0.95      0.94       148


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.5, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.953 	0.000 	0.000 	0.500 	0.000 	0.000
[[141   0]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      1.00      0.98       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.95      0.93       148


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=10.0, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Ran...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.932 	0.135 	0.132 	0.557 	0.373 	0.127
[[137   4]
 [  6   1]]
             precision    recall  f1-score   support

        0.0       0.96      0.97      0.96       141
        1.0       0.20      0.14      0.17         7

avg / total       0.92      0.93      0.93       148


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=4,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.932 	0.135 	0.132 	0.557 	0.373 	0.127
[[137   4]
 [  6   1]]
             precision    recall  f1-score   support

        0.0       0.96      0.97      0.96       141
        1.0       0.20      0.14      0.17         7

avg / total       0.92      0.93      0.93       148


                estimator min_score mean_score max_score    sd_score  \
0              GaussianNB  0.901696   0.901696  0.901696           0   
6      AdaBoostClassifier  0.932145   0.979054  0.997072   0.0105672   
8        VotingClassifier  0.937577   0.970092  0.982513   0.0103861   
9    KNeighborsClassifier   0.92621   0.949719  0.976737    0.013625   
2           SGDClassifier -0.105794   0.676824  0.982593    0.240228   
1      LogisticRegression  0.530664   0.863399   0.97405    0.132103   
4  RandomForestClassifier  0.970753   0.984291  0.994185  0.00335902   
7                     SVC         0   0.813824         1    0.313436   
3    ExtraTreesClassifier  0.885975   0.984119  0.997072   0.0139752   
5           MLPClassifier   0.96246   0.979038  0.991256   0.0069284   

        acc       auc          conf_matrix     f1_c0     f1_c1      kappa  \
0  0.851351  0.582573  [[124, 17], [5, 2]]  0.918519  0.153846  0.0910106   
6  0.945946  0.564336   [[139, 2], [6, 1]]  0.972028       0.2   0.176634   
8  0.932432  0.557244   [[137, 4], [6, 1]]  0.964789  0.166667   0.132474   
9  0.932432  0.557244   [[137, 4], [6, 1]]  0.964789  0.166667   0.132474   
2  0.918919  0.550152   [[135, 6], [6, 1]]  0.957447  0.142857   0.100304   
1  0.885135  0.532421  [[130, 11], [6, 1]]  0.938628  0.105263  0.0484115   
4  0.952703       0.5   [[141, 0], [7, 0]]  0.975779         0          0   
7  0.952703       0.5   [[141, 0], [7, 0]]  0.975779         0          0   
3  0.945946  0.496454   [[140, 1], [7, 0]]  0.972222         0 -0.0119658   
5  0.932432  0.489362   [[138, 3], [7, 0]]  0.965035         0 -0.0292072   

  model_score   prec_c0    prec_c1    rec_c0    rec_c1  
0    0.104799   0.96124   0.105263  0.879433  0.285714  
6    0.193821  0.958621   0.333333  0.985816  0.142857  
8    0.134514  0.958042        0.2  0.971631  0.142857  
9    0.134514  0.958042        0.2  0.971631  0.142857  
2    0.100304  0.957447   0.142857  0.957447  0.142857  
1   0.0504268  0.955882  0.0833333  0.921986  0.142857  
4           0  0.952703          0         1         0  
7           0  0.952703          0         1         0  
3  -0.0183773  0.952381          0  0.992908         0  
5  -0.0320491  0.951724          0  0.978723         0  
Elapsed time 22.88 mins 

************************************************************

pre/post: 50/0  win/stride: 500/50  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-21 04:29:14.697000 
pca_target: 0 	 poly degree: 2 	 kselect: 100 
Imbalance: None 
Extended target (count):  25141 13
('Total : Processed (count): ', (493L, 96580L), 13)
Final feature (count):  (493L, 96580L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.899 	0.167 	0.160 	0.607 	0.515 	0.248
[[131  10]
 [  5   2]]
             precision    recall  f1-score   support

        0.0       0.96      0.93      0.95       141
        1.0       0.17      0.29      0.21         7

avg / total       0.93      0.90      0.91       148


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.001, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=10, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.946 	-0.018 	-0.012 	0.496 	0.000 	0.000
[[140   1]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.99      0.97       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.95      0.93       148


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.1, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='perceptron', n_iter=5, n_jobs=4,
       penalty='l2', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.953 	0.000 	0.000 	0.500 	0.000 	0.000
[[141   0]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      1.00      0.98       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.95      0.93       148


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 15}, criterion='gini',
           max_depth=8, max_features='auto', max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.946 	-0.018 	-0.012 	0.496 	0.000 	0.000
[[140   1]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.99      0.97       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.95      0.93       148


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 15}, criterion='gini',
            max_depth=32, max_features=0.75, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.953 	0.000 	0.000 	0.500 	0.000 	0.000
[[141   0]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      1.00      0.98       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.95      0.93       148


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.1, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.939 	-0.026 	-0.021 	0.493 	0.000 	0.000
[[139   2]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.99      0.97       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.94      0.92       148


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=16,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=2.0, n_estimators=15, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.946 	-0.018 	-0.012 	0.496 	0.000 	0.000
[[140   1]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.99      0.97       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.95      0.93       148


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.01, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='linear',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.939 	-0.026 	-0.021 	0.493 	0.000 	0.000
[[139   2]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.99      0.97       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.94      0.92       148


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 500}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Ran...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.946 	-0.018 	-0.012 	0.496 	0.000 	0.000
[[140   1]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.99      0.97       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.95      0.93       148


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=2,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.953 	0.000 	0.000 	0.500 	0.000 	0.000
[[141   0]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      1.00      0.98       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.95      0.93       148


                estimator   min_score  mean_score max_score   sd_score  \
0              GaussianNB    0.231156    0.231156  0.231156          0   
2           SGDClassifier   -0.174114    0.111767  0.616019  0.0778059   
4  RandomForestClassifier -0.00713022  0.00460437       0.2   0.032125   
9    KNeighborsClassifier -0.00418904   0.0840796  0.416019   0.153661   
1      LogisticRegression -0.00905223    0.145805  0.517628   0.097499   
3    ExtraTreesClassifier  -0.0227423   0.0326583  0.275642    0.07418   
6      AdaBoostClassifier  -0.0248371   0.0691927  0.490351  0.0937566   
8        VotingClassifier -0.00418904   0.0913535  0.495567   0.129819   
5           MLPClassifier  -0.0113206    0.254484  0.489685      0.124   
7                     SVC  -0.0167615   0.0802624  0.613078   0.126423   

        acc       auc          conf_matrix     f1_c0     f1_c1      kappa  \
0  0.898649  0.607396  [[131, 10], [5, 2]]  0.945848  0.210526   0.160363   
2  0.952703       0.5   [[141, 0], [7, 0]]  0.975779         0          0   
4  0.952703       0.5   [[141, 0], [7, 0]]  0.975779         0          0   
9  0.952703       0.5   [[141, 0], [7, 0]]  0.975779         0          0   
1  0.945946  0.496454   [[140, 1], [7, 0]]  0.972222         0 -0.0119658   
3  0.945946  0.496454   [[140, 1], [7, 0]]  0.972222         0 -0.0119658   
6  0.945946  0.496454   [[140, 1], [7, 0]]  0.972222         0 -0.0119658   
8  0.945946  0.496454   [[140, 1], [7, 0]]  0.972222         0 -0.0119658   
5  0.939189  0.492908   [[139, 2], [7, 0]]  0.968641         0 -0.0214724   
7  0.939189  0.492908   [[139, 2], [7, 0]]  0.968641         0 -0.0214724   

  model_score   prec_c0   prec_c1    rec_c0    rec_c1  
0    0.167039  0.963235  0.166667  0.929078  0.285714  
2           0  0.952703         0         1         0  
4           0  0.952703         0         1         0  
9           0  0.952703         0         1         0  
1  -0.0183773  0.952381         0  0.992908         0  
3  -0.0183773  0.952381         0  0.992908         0  
6  -0.0183773  0.952381         0  0.992908         0  
8  -0.0183773  0.952381         0  0.992908         0  
5  -0.0260782  0.952055         0  0.985816         0  
7  -0.0260782  0.952055         0  0.985816         0  
Elapsed time 18.43 mins 

************************************************************

pre/post: 50/0  win/stride: 500/50  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-21 04:47:40.747000 
pca_target: 100 	 poly degree: 0 	 kselect: 80 
Imbalance: ClusterCentroids(estimator=None, n_jobs=1, random_state=None, ratio='auto') 
Extended target (count):  25141 13
('Total : Processed (count): ', (493L, 438L), 13)
Final feature (count):  (493L, 438L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.953 	0.000 	0.000 	0.500 	0.000 	0.000
[[141   0]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      1.00      0.98       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.95      0.93       148


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.1, class_weight={1: 3}, dual=False, fit_intercept=True,
          intercept_scaling=0.1, max_iter=100, multi_class='ovr', n_jobs=4,
          penalty='l2', random_state=None, solver='lbfgs', tol=0.0001,
          verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.493 	0.026 	0.011 	0.530 	0.529 	0.282
[[69 72]
 [ 3  4]]
             precision    recall  f1-score   support

        0.0       0.96      0.49      0.65       141
        1.0       0.05      0.57      0.10         7

avg / total       0.92      0.49      0.62       148


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.5, average=False, class_weight='balanced', epsilon=0.1,
       eta0=0.001, fit_intercept=True, l1_ratio=0.15,
       learning_rate='constant', loss='perceptron', n_iter=5, n_jobs=4,
       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.851 	-0.075 	-0.069 	0.447 	0.000 	0.000
[[126  15]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.89      0.92       141
        1.0       0.00      0.00      0.00         7

avg / total       0.90      0.85      0.88       148


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 50},
           criterion='entropy', max_depth=16, max_features='auto',
           max_leaf_nodes=None, min_impurity_split=1e-07,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=15, n_jobs=4,
           oob_score=False, random_state=None, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.622 	0.026 	0.014 	0.530 	0.520 	0.265
[[89 52]
 [ 4  3]]
             precision    recall  f1-score   support

        0.0       0.96      0.63      0.76       141
        1.0       0.05      0.43      0.10         7

avg / total       0.91      0.62      0.73       148


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 500},
            criterion='entropy', max_depth=16, max_features=0.33,
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=15, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.541 	0.047 	0.021 	0.555 	0.555 	0.309
[[76 65]
 [ 3  4]]
             precision    recall  f1-score   support

        0.0       0.96      0.54      0.69       141
        1.0       0.06      0.57      0.11         7

avg / total       0.92      0.54      0.66       148


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.01, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.446 	-0.111 	-0.044 	0.370 	0.360 	0.128
[[64 77]
 [ 5  2]]
             precision    recall  f1-score   support

        0.0       0.93      0.45      0.61       141
        1.0       0.03      0.29      0.05         7

avg / total       0.88      0.45      0.58       148


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=2.0, n_estimators=80, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.439 	0.060 	0.022 	0.570 	0.551 	0.313
[[60 81]
 [ 2  5]]
             precision    recall  f1-score   support

        0.0       0.97      0.43      0.59       141
        1.0       0.06      0.71      0.11         7

avg / total       0.92      0.44      0.57       148


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.047 	0.000 	0.000 	0.500 	0.000 	0.000
[[  0 141]
 [  0   7]]
             precision    recall  f1-score   support

        0.0       0.00      0.00      0.00       141
        1.0       0.05      1.00      0.09         7

avg / total       0.00      0.05      0.00       148


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=1.0, class_weight={1: 500}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Ran...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.297 	-0.004 	-0.001 	0.495 	0.444 	0.206
[[ 39 102]
 [  2   5]]
             precision    recall  f1-score   support

        0.0       0.95      0.28      0.43       141
        1.0       0.05      0.71      0.09         7

avg / total       0.91      0.30      0.41       148


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=3, p=4,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.385 	-0.198 	-0.072 	0.270 	0.238 	0.055
[[56 85]
 [ 6  1]]
             precision    recall  f1-score   support

        0.0       0.90      0.40      0.55       141
        1.0       0.01      0.14      0.02         7

avg / total       0.86      0.39      0.53       148


                estimator  min_score mean_score max_score  sd_score  \
6      AdaBoostClassifier  -0.333333   0.357577         1   0.18259   
4  RandomForestClassifier -0.0257834   0.495935         1  0.177281   
1      LogisticRegression          0    0.26679  0.525783  0.192965   
3    ExtraTreesClassifier          0   0.279604  0.666667  0.127273   
0              GaussianNB    0.69245    0.69245   0.69245         0   
7                     SVC          0   0.376445   0.69245  0.233043   
8        VotingClassifier   0.140883   0.503619  0.666667  0.123121   
2           SGDClassifier  -0.359117   0.353565         1  0.200981   
5           MLPClassifier   0.140883   0.346647       0.5  0.134514   
9    KNeighborsClassifier  -0.166667   0.327751  0.833333  0.190716   

         acc       auc          conf_matrix     f1_c0      f1_c1       kappa  \
6   0.439189  0.569909   [[60, 81], [2, 5]]  0.591133   0.107527   0.0219745   
4   0.540541  0.555218   [[76, 65], [3, 4]]  0.690909   0.105263   0.0212021   
1   0.493243  0.530395   [[69, 72], [3, 4]]  0.647887  0.0963855   0.0106952   
3   0.621622  0.529889   [[89, 52], [4, 3]]  0.760684  0.0967742   0.0140376   
0   0.952703       0.5   [[141, 0], [7, 0]]  0.975779          0           0   
7  0.0472973       0.5   [[0, 141], [0, 7]]         0  0.0903226           0   
8   0.297297  0.495441  [[39, 102], [2, 5]]  0.428571  0.0877193 -0.00117081   
2   0.851351  0.446809  [[126, 15], [7, 0]]  0.919708          0  -0.0689429   
5   0.445946  0.369807   [[64, 77], [5, 2]]  0.609524  0.0465116  -0.0442265   
9   0.385135   0.27001   [[56, 85], [6, 1]]  0.551724  0.0215054   -0.072293   

  model_score   prec_c0    prec_c1    rec_c0    rec_c1  
6   0.0601555  0.967742  0.0581395  0.425532  0.714286  
4   0.0469926  0.962025   0.057971  0.539007  0.571429  
1   0.0258178  0.958333  0.0526316  0.489362  0.571429  
3   0.0262585  0.956989  0.0545455  0.631206  0.428571  
0           0  0.952703          0         1         0  
7           0         0  0.0472973         0         1  
8 -0.00432514   0.95122   0.046729  0.276596  0.714286  
2  -0.0748272  0.947368          0  0.893617         0  
5   -0.110799  0.927536  0.0253165  0.453901  0.285714  
9   -0.197903  0.903226  0.0116279  0.397163  0.142857  
Elapsed time 14.08 mins 

************************************************************

pre/post: 50/0  win/stride: 500/50  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-21 05:01:45.815000 
pca_target: 100 	 poly degree: 0 	 kselect: 80 
Imbalance: SMOTE(k=None, k_neighbors=5, kind='regular', m=None, m_neighbors=10, n_jobs=1,
   out_step=0.5, random_state=None, ratio='auto', svm_estimator=None) 
Extended target (count):  25141 13
('Total : Processed (count): ', (493L, 438L), 13)
Final feature (count):  (493L, 438L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.953 	0.000 	0.000 	0.500 	0.000 	0.000
[[141   0]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      1.00      0.98       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.95      0.93       148


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=10, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=5, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.892 	-0.057 	-0.056 	0.468 	0.000 	0.000
[[132   9]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.94      0.94       141
        1.0       0.00      0.00      0.00         7

avg / total       0.90      0.89      0.90       148


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.001, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='squared_hinge', n_iter=5, n_jobs=4,
       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.946 	-0.018 	-0.012 	0.496 	0.000 	0.000
[[140   1]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.99      0.97       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.95      0.93       148


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=8, max_features='auto', max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.953 	0.000 	0.000 	0.500 	0.000 	0.000
[[141   0]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      1.00      0.98       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.95      0.93       148


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=30, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.953 	0.000 	0.000 	0.500 	0.000 	0.000
[[141   0]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      1.00      0.98       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.95      0.93       148


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.953 	0.000 	0.000 	0.500 	0.000 	0.000
[[141   0]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      1.00      0.98       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.95      0.93       148


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=0.5, n_estimators=15, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.953 	0.000 	0.000 	0.500 	0.000 	0.000
[[141   0]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      1.00      0.98       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.95      0.93       148


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.953 	0.000 	0.000 	0.500 	0.000 	0.000
[[141   0]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      1.00      0.98       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.95      0.93       148


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=10.0, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', ...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.899 	-0.053 	-0.053 	0.472 	0.000 	0.000
[[133   8]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.94      0.95       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.90      0.90       148


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=1,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.845 	0.247 	0.199 	0.715 	0.700 	0.476
[[121  20]
 [  3   4]]
             precision    recall  f1-score   support

        0.0       0.98      0.86      0.91       141
        1.0       0.17      0.57      0.26         7

avg / total       0.94      0.84      0.88       148


                estimator  min_score mean_score max_score     sd_score  \
9    KNeighborsClassifier   0.382733   0.539583  0.672229    0.0853637   
0              GaussianNB          1          1         1            0   
3    ExtraTreesClassifier   0.997072   0.999902         1  0.000525678   
4  RandomForestClassifier   0.997072   0.999333         1    0.0012282   
5           MLPClassifier   0.921092   0.957509  0.991215    0.0202168   
6      AdaBoostClassifier   0.921675   0.978529         1    0.0110318   
7                     SVC          0   0.805429         1     0.335034   
2           SGDClassifier -0.0141247   0.679829  0.985481     0.253456   
8        VotingClassifier   0.831688   0.897203  0.937613    0.0287497   
1      LogisticRegression   0.390642   0.840046  0.951368     0.126911   

        acc       auc          conf_matrix     f1_c0     f1_c1      kappa  \
9  0.844595  0.714792  [[121, 20], [3, 4]]  0.913208  0.258065   0.199436   
0  0.952703       0.5   [[141, 0], [7, 0]]  0.975779         0          0   
3  0.952703       0.5   [[141, 0], [7, 0]]  0.975779         0          0   
4  0.952703       0.5   [[141, 0], [7, 0]]  0.975779         0          0   
5  0.952703       0.5   [[141, 0], [7, 0]]  0.975779         0          0   
6  0.952703       0.5   [[141, 0], [7, 0]]  0.975779         0          0   
7  0.952703       0.5   [[141, 0], [7, 0]]  0.975779         0          0   
2  0.945946  0.496454   [[140, 1], [7, 0]]  0.972222         0 -0.0119658   
8  0.898649  0.471631   [[133, 8], [7, 0]]  0.946619         0 -0.0531309   
1  0.891892  0.468085   [[132, 9], [7, 0]]  0.942857         0 -0.0561998   

  model_score   prec_c0   prec_c1    rec_c0    rec_c1  
9    0.247395  0.975806  0.166667  0.858156  0.571429  
0           0  0.952703         0         1         0  
3           0  0.952703         0         1         0  
4           0  0.952703         0         1         0  
5           0  0.952703         0         1         0  
6           0  0.952703         0         1         0  
7           0  0.952703         0         1         0  
2  -0.0183773  0.952381         0  0.992908         0  
8  -0.0532624      0.95         0  0.943262         0  
1  -0.0566961   0.94964         0   0.93617         0  
Elapsed time 24.54 mins 

************************************************************

pre/post: 50/0  win/stride: 500/50  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-21 05:26:18.303000 
pca_target: 100 	 poly degree: 0 	 kselect: 80 
Imbalance: None 
Extended target (count):  25141 13
('Total : Processed (count): ', (493L, 438L), 13)
Final feature (count):  (493L, 438L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.932 	-0.032 	-0.029 	0.489 	0.000 	0.000
[[138   3]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.98      0.97       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.93      0.92       148


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.01, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=10, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='sag', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.831 	0.005 	0.004 	0.504 	0.352 	0.115
[[122  19]
 [  6   1]]
             precision    recall  f1-score   support

        0.0       0.95      0.87      0.91       141
        1.0       0.05      0.14      0.07         7

avg / total       0.91      0.83      0.87       148


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.5, average=False, class_weight='balanced', epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='constant', loss='modified_huber', n_iter=5, n_jobs=4,
       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.953 	0.000 	0.000 	0.500 	0.000 	0.000
[[141   0]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      1.00      0.98       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.95      0.93       148


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 500}, criterion='gini',
           max_depth=8, max_features='auto', max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=50, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.946 	-0.018 	-0.012 	0.496 	0.000 	0.000
[[140   1]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.99      0.97       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.95      0.93       148


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.953 	0.000 	0.000 	0.500 	0.000 	0.000
[[141   0]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      1.00      0.98       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.95      0.93       148


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.01, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.946 	-0.018 	-0.012 	0.496 	0.000 	0.000
[[140   1]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.99      0.97       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.95      0.93       148


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight='balanced', criterion='gini',
            max_depth=16, max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=1.0, n_estimators=80, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.953 	0.250 	0.206 	0.568 	0.377 	0.130
[[140   1]
 [  6   1]]
             precision    recall  f1-score   support

        0.0       0.96      0.99      0.98       141
        1.0       0.50      0.14      0.22         7

avg / total       0.94      0.95      0.94       148


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.01, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.953 	0.000 	0.000 	0.500 	0.000 	0.000
[[141   0]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      1.00      0.98       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.95      0.93       148


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...owski',
           metric_params=None, n_jobs=4, n_neighbors=4, p=2,
           weights='uniform'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.946 	-0.018 	-0.012 	0.496 	0.000 	0.000
[[140   1]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.99      0.97       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.95      0.93       148


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=4,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.932 	0.135 	0.132 	0.557 	0.373 	0.127
[[137   4]
 [  6   1]]
             precision    recall  f1-score   support

        0.0       0.96      0.97      0.96       141
        1.0       0.20      0.14      0.17         7

avg / total       0.92      0.93      0.93       148


                estimator   min_score   mean_score max_score     sd_score  \
6      AdaBoostClassifier  -0.0268877  -0.00220272  0.303176    0.0419235   
9    KNeighborsClassifier  -0.0238566    0.0170768  0.256316    0.0635234   
1      LogisticRegression  -0.0561362   0.00350999  0.186664    0.0495522   
2           SGDClassifier   -0.140378    0.0354607  0.220775    0.0538404   
4  RandomForestClassifier -0.00713022 -0.000100268         0  0.000667024   
7                     SVC  -0.0212118   -0.0088788         0   0.00891237   
3    ExtraTreesClassifier -0.00713022  0.000782674  0.197058    0.0117981   
5           MLPClassifier  -0.0238114   -0.0074108  0.191091    0.0311734   
8        VotingClassifier  -0.0132461  -0.00647109         0   0.00277497   
0              GaussianNB    0.137436     0.137436  0.137436            0   

        acc       auc          conf_matrix     f1_c0      f1_c1       kappa  \
6  0.952703  0.567882   [[140, 1], [6, 1]]   0.97561   0.222222    0.205521   
9  0.932432  0.557244   [[137, 4], [6, 1]]  0.964789   0.166667    0.132474   
1  0.831081  0.504053  [[122, 19], [6, 1]]  0.907063  0.0740741  0.00430571   
2  0.952703       0.5   [[141, 0], [7, 0]]  0.975779          0           0   
4  0.952703       0.5   [[141, 0], [7, 0]]  0.975779          0           0   
7  0.952703       0.5   [[141, 0], [7, 0]]  0.975779          0           0   
3  0.945946  0.496454   [[140, 1], [7, 0]]  0.972222          0  -0.0119658   
5  0.945946  0.496454   [[140, 1], [7, 0]]  0.972222          0  -0.0119658   
8  0.945946  0.496454   [[140, 1], [7, 0]]  0.972222          0  -0.0119658   
0  0.932432  0.489362   [[138, 3], [7, 0]]  0.965035          0  -0.0292072   

  model_score   prec_c0 prec_c1    rec_c0    rec_c1  
6    0.249606  0.958904     0.5  0.992908  0.142857  
9    0.134514  0.958042     0.2  0.971631  0.142857  
1  0.00503282  0.953125    0.05  0.865248  0.142857  
2           0  0.952703       0         1         0  
4           0  0.952703       0         1         0  
7           0  0.952703       0         1         0  
3  -0.0183773  0.952381       0  0.992908         0  
5  -0.0183773  0.952381       0  0.992908         0  
8  -0.0183773  0.952381       0  0.992908         0  
0  -0.0320491  0.951724       0  0.978723         0  
Elapsed time 18.67 mins 

************************************************************

pre/post: 50/0  win/stride: 500/50  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-21 05:44:58.538000 
pca_target: 100 	 poly degree: 0 	 kselect: 40 
Imbalance: ClusterCentroids(estimator=None, n_jobs=1, random_state=None, ratio='auto') 
Extended target (count):  25141 13
('Total : Processed (count): ', (493L, 438L), 13)
Final feature (count):  (493L, 438L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.953 	0.000 	0.000 	0.500 	0.000 	0.000
[[141   0]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      1.00      0.98       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.95      0.93       148


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.001, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.473 	-0.214 	-0.094 	0.248 	0.000 	0.000
[[70 71]
 [ 7  0]]
             precision    recall  f1-score   support

        0.0       0.91      0.50      0.64       141
        1.0       0.00      0.00      0.00         7

avg / total       0.87      0.47      0.61       148


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.0001, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='perceptron', n_iter=5, n_jobs=4,
       penalty='l1', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.595 	0.188 	0.089 	0.719 	0.706 	0.512
[[82 59]
 [ 1  6]]
             precision    recall  f1-score   support

        0.0       0.99      0.58      0.73       141
        1.0       0.09      0.86      0.17         7

avg / total       0.95      0.59      0.71       148


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=8, max_features='auto', max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=50, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.716 	-0.055 	-0.037 	0.444 	0.326 	0.100
[[105  36]
 [  6   1]]
             precision    recall  f1-score   support

        0.0       0.95      0.74      0.83       141
        1.0       0.03      0.14      0.05         7

avg / total       0.90      0.72      0.80       148


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=50, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.676 	0.053 	0.031 	0.558 	0.543 	0.287
[[97 44]
 [ 4  3]]
             precision    recall  f1-score   support

        0.0       0.96      0.69      0.80       141
        1.0       0.06      0.43      0.11         7

avg / total       0.92      0.68      0.77       148


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.953 	0.000 	0.000 	0.500 	0.000 	0.000
[[141   0]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      1.00      0.98       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.95      0.93       148


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 50}, criterion='gini', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=0.5, n_estimators=80, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.257 	-0.092 	-0.023 	0.406 	0.371 	0.142
[[ 34 107]
 [  3   4]]
             precision    recall  f1-score   support

        0.0       0.92      0.24      0.38       141
        1.0       0.04      0.57      0.07         7

avg / total       0.88      0.26      0.37       148


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.1, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='linear',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.520 	0.038 	0.016 	0.545 	0.544 	0.297
[[73 68]
 [ 3  4]]
             precision    recall  f1-score   support

        0.0       0.96      0.52      0.67       141
        1.0       0.06      0.57      0.10         7

avg / total       0.92      0.52      0.65       148


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', R...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.426 	-0.120 	-0.046 	0.359 	0.352 	0.122
[[61 80]
 [ 5  2]]
             precision    recall  f1-score   support

        0.0       0.92      0.43      0.59       141
        1.0       0.02      0.29      0.04         7

avg / total       0.88      0.43      0.56       148


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=3, p=2,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.581 	0.181 	0.084 	0.712 	0.697 	0.500
[[80 61]
 [ 1  6]]
             precision    recall  f1-score   support

        0.0       0.99      0.57      0.72       141
        1.0       0.09      0.86      0.16         7

avg / total       0.95      0.58      0.69       148


                estimator min_score mean_score max_score  sd_score       acc  \
2           SGDClassifier -0.359117   0.425501  0.859117  0.198424  0.594595   
9    KNeighborsClassifier -0.166667   0.296252  0.666667  0.192781  0.581081   
4  RandomForestClassifier  0.166667   0.816196         1  0.161857  0.675676   
7                     SVC         0   0.601462         1  0.415796   0.52027   
0              GaussianNB   0.69245    0.69245   0.69245         0  0.952703   
5           MLPClassifier  0.140883   0.339741  0.525783  0.074519  0.952703   
3    ExtraTreesClassifier  0.525783   0.948527         1  0.089903  0.716216   
6      AdaBoostClassifier      -0.5   0.328112  0.859117  0.215684  0.256757   
8        VotingClassifier   0.30755   0.720185         1  0.151973  0.425676   
1      LogisticRegression  -0.19245   0.373027  0.833333  0.239581  0.472973   

        auc          conf_matrix     f1_c0      f1_c1      kappa model_score  \
2  0.719352   [[82, 59], [1, 6]]  0.732143   0.166667   0.088857    0.187644   
9  0.712259   [[80, 61], [1, 6]]  0.720721   0.162162  0.0836828     0.18104   
4  0.558257   [[97, 44], [4, 3]]  0.801653   0.111111  0.0313608   0.0531288   
7   0.54458   [[73, 68], [3, 4]]  0.672811   0.101266  0.0164732   0.0378661   
0       0.5   [[141, 0], [7, 0]]  0.975779          0          0           0   
5       0.5   [[141, 0], [7, 0]]  0.975779          0          0           0   
3  0.443769  [[105, 36], [6, 1]]  0.833333  0.0454545  -0.037037  -0.0551318   
6  0.406282  [[34, 107], [3, 4]]  0.382022  0.0677966 -0.0232558  -0.0918863   
8  0.359169   [[61, 80], [5, 2]]  0.589372  0.0449438 -0.0462409   -0.120284   
1  0.248227   [[70, 71], [7, 0]]  0.642202          0  -0.094218   -0.213955   

    prec_c0    prec_c1    rec_c0    rec_c1  
2  0.987952  0.0923077   0.58156  0.857143  
9  0.987654  0.0895522  0.567376  0.857143  
4  0.960396  0.0638298  0.687943  0.428571  
7  0.960526  0.0555556   0.51773  0.571429  
0  0.952703          0         1         0  
5  0.952703          0         1         0  
3  0.945946   0.027027  0.744681  0.142857  
6  0.918919   0.036036  0.241135  0.571429  
8  0.924242  0.0243902  0.432624  0.285714  
1  0.909091          0  0.496454         0  
Elapsed time 13.55 mins 

************************************************************

pre/post: 50/0  win/stride: 500/50  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-21 05:58:31.627000 
pca_target: 100 	 poly degree: 0 	 kselect: 40 
Imbalance: SMOTE(k=None, k_neighbors=5, kind='regular', m=None, m_neighbors=10, n_jobs=1,
   out_step=0.5, random_state=None, ratio='auto', svm_estimator=None) 
Extended target (count):  25141 13
('Total : Processed (count): ', (493L, 438L), 13)
Final feature (count):  (493L, 438L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.953 	0.000 	0.000 	0.500 	0.000 	0.000
[[141   0]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      1.00      0.98       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.95      0.93       148


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=5, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.892 	-0.057 	-0.056 	0.468 	0.000 	0.000
[[132   9]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.94      0.94       141
        1.0       0.00      0.00      0.00         7

avg / total       0.90      0.89      0.90       148


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.001, average=False, class_weight='balanced',
       epsilon=0.1, eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='perceptron', n_iter=5, n_jobs=4,
       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.946 	-0.018 	-0.012 	0.496 	0.000 	0.000
[[140   1]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.99      0.97       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.95      0.93       148


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=8, max_features='auto', max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=30, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.953 	0.000 	0.000 	0.500 	0.000 	0.000
[[141   0]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      1.00      0.98       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.95      0.93       148


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.953 	0.000 	0.000 	0.500 	0.000 	0.000
[[141   0]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      1.00      0.98       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.95      0.93       148


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.953 	0.000 	0.000 	0.500 	0.000 	0.000
[[141   0]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      1.00      0.98       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.95      0.93       148


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=0.5, n_estimators=15, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.953 	0.000 	0.000 	0.500 	0.000 	0.000
[[141   0]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      1.00      0.98       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.95      0.93       148


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.953 	0.000 	0.000 	0.500 	0.000 	0.000
[[141   0]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      1.00      0.98       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.95      0.93       148


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=10.0, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', ...owski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='uniform'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.912 	-0.046 	-0.046 	0.479 	0.000 	0.000
[[135   6]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.96      0.95       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.91      0.91       148


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=1,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.824 	0.224 	0.173 	0.704 	0.692 	0.466
[[118  23]
 [  3   4]]
             precision    recall  f1-score   support

        0.0       0.98      0.84      0.90       141
        1.0       0.15      0.57      0.24         7

avg / total       0.94      0.82      0.87       148


                estimator min_score mean_score max_score     sd_score  \
9    KNeighborsClassifier  0.274987   0.478059  0.644695      0.11372   
0              GaussianNB         1          1         1            0   
3    ExtraTreesClassifier  0.997072   0.999097         1   0.00135239   
4  RandomForestClassifier  0.997072   0.999943         1  0.000404361   
5           MLPClassifier  0.927006   0.958702  0.997072    0.0217635   
6      AdaBoostClassifier   0.85985   0.977903         1    0.0119432   
7                     SVC         0   0.811349         1     0.326178   
2           SGDClassifier -0.107516   0.688153  0.985399     0.254841   
8        VotingClassifier  0.819081   0.890342  0.932152    0.0315674   
1      LogisticRegression  0.139151   0.824451  0.948589      0.15734   

        acc       auc          conf_matrix     f1_c0     f1_c1      kappa  \
9  0.824324  0.704154  [[118, 23], [3, 4]]  0.900763  0.235294   0.173184   
0  0.952703       0.5   [[141, 0], [7, 0]]  0.975779         0          0   
3  0.952703       0.5   [[141, 0], [7, 0]]  0.975779         0          0   
4  0.952703       0.5   [[141, 0], [7, 0]]  0.975779         0          0   
5  0.952703       0.5   [[141, 0], [7, 0]]  0.975779         0          0   
6  0.952703       0.5   [[141, 0], [7, 0]]  0.975779         0          0   
7  0.952703       0.5   [[141, 0], [7, 0]]  0.975779         0          0   
2  0.945946  0.496454   [[140, 1], [7, 0]]  0.972222         0 -0.0119658   
8  0.912162  0.478723   [[135, 6], [7, 0]]  0.954064         0 -0.0456522   
1  0.891892  0.468085   [[132, 9], [7, 0]]  0.942857         0 -0.0561998   

  model_score   prec_c0   prec_c1    rec_c0    rec_c1  
9    0.224425  0.975207  0.148148  0.836879  0.571429  
0           0  0.952703         0         1         0  
3           0  0.952703         0         1         0  
4           0  0.952703         0         1         0  
5           0  0.952703         0         1         0  
6           0  0.952703         0         1         0  
7           0  0.952703         0         1         0  
2  -0.0183773  0.952381         0  0.992908         0  
8  -0.0458006  0.950704         0  0.957447         0  
1  -0.0566961   0.94964         0   0.93617         0  
Elapsed time 21.69 mins 

************************************************************

pre/post: 50/0  win/stride: 500/50  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-21 06:20:12.933000 
pca_target: 100 	 poly degree: 0 	 kselect: 40 
Imbalance: None 
Extended target (count):  25141 13
('Total : Processed (count): ', (493L, 438L), 13)
Final feature (count):  (493L, 438L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.946 	-0.018 	-0.012 	0.496 	0.000 	0.000
[[140   1]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.99      0.97       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.95      0.93       148


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.001, class_weight={1: 50}, dual=False,
          fit_intercept=True, intercept_scaling=0.01, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='sag', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.777 	-0.026 	-0.020 	0.476 	0.340 	0.108
[[114  27]
 [  6   1]]
             precision    recall  f1-score   support

        0.0       0.95      0.81      0.87       141
        1.0       0.04      0.14      0.06         7

avg / total       0.91      0.78      0.83       148


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.5, average=False, class_weight='balanced', epsilon=0.1,
       eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='constant', loss='squared_hinge', n_iter=5, n_jobs=4,
       penalty='l2', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.953 	0.000 	0.000 	0.500 	0.000 	0.000
[[141   0]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      1.00      0.98       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.95      0.93       148


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=8, max_features='auto', max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.953 	0.000 	0.000 	0.500 	0.000 	0.000
[[141   0]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      1.00      0.98       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.95      0.93       148


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.953 	0.000 	0.000 	0.500 	0.000 	0.000
[[141   0]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      1.00      0.98       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.95      0.93       148


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.01, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.946 	-0.018 	-0.012 	0.496 	0.000 	0.000
[[140   1]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.99      0.97       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.95      0.93       148


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 500}, criterion='entropy',
            max_depth=16, max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=2.0, n_estimators=50, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.946 	-0.018 	-0.012 	0.496 	0.000 	0.000
[[140   1]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.99      0.97       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.95      0.93       148


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.01, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.953 	0.000 	0.000 	0.500 	0.000 	0.000
[[141   0]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      1.00      0.98       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.95      0.93       148


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...wski',
           metric_params=None, n_jobs=4, n_neighbors=4, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.953 	0.000 	0.000 	0.500 	0.000 	0.000
[[141   0]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      1.00      0.98       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.95      0.93       148


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=4,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.939 	0.159 	0.153 	0.561 	0.374 	0.128
[[138   3]
 [  6   1]]
             precision    recall  f1-score   support

        0.0       0.96      0.98      0.97       141
        1.0       0.25      0.14      0.18         7

avg / total       0.92      0.94      0.93       148


                estimator   min_score   mean_score  max_score     sd_score  \
9    KNeighborsClassifier  -0.0225614    0.0054453  0.0563161    0.0213523   
2           SGDClassifier   -0.141681    0.0365327   0.220146    0.0553443   
3    ExtraTreesClassifier -0.00588299 -7.22991e-05          0   0.00053343   
4  RandomForestClassifier -0.00588299 -4.90249e-05          0  0.000435743   
7                     SVC  -0.0212118  -0.00786199          0   0.00794624   
8        VotingClassifier  -0.0118506  -0.00580803          0     0.002483   
0              GaussianNB    0.140378     0.140378   0.140378            0   
5           MLPClassifier  -0.0238573  -0.00914825   0.123884     0.020561   
6      AdaBoostClassifier  -0.0275844  -0.00568437   0.241037    0.0373025   
1      LogisticRegression  -0.0823156   0.00525834   0.219594    0.0497369   

        acc       auc          conf_matrix     f1_c0      f1_c1      kappa  \
9  0.939189   0.56079   [[138, 3], [6, 1]]  0.968421   0.181818   0.152672   
2  0.952703       0.5   [[141, 0], [7, 0]]  0.975779          0          0   
3  0.952703       0.5   [[141, 0], [7, 0]]  0.975779          0          0   
4  0.952703       0.5   [[141, 0], [7, 0]]  0.975779          0          0   
7  0.952703       0.5   [[141, 0], [7, 0]]  0.975779          0          0   
8  0.952703       0.5   [[141, 0], [7, 0]]  0.975779          0          0   
0  0.945946  0.496454   [[140, 1], [7, 0]]  0.972222          0 -0.0119658   
5  0.945946  0.496454   [[140, 1], [7, 0]]  0.972222          0 -0.0119658   
6  0.945946  0.496454   [[140, 1], [7, 0]]  0.972222          0 -0.0119658   
1  0.777027  0.475684  [[114, 27], [6, 1]]  0.873563  0.0571429 -0.0200501   

  model_score   prec_c0    prec_c1    rec_c0    rec_c1  
9    0.159152  0.958333       0.25  0.978723  0.142857  
2           0  0.952703          0         1         0  
3           0  0.952703          0         1         0  
4           0  0.952703          0         1         0  
7           0  0.952703          0         1         0  
8           0  0.952703          0         1         0  
0  -0.0183773  0.952381          0  0.992908         0  
5  -0.0183773  0.952381          0  0.992908         0  
6  -0.0183773  0.952381          0  0.992908         0  
1   -0.026358      0.95  0.0357143  0.808511  0.142857  
Elapsed time 17.58 mins 

************************************************************

pre/post: 50/0  win/stride: 500/50  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-21 06:37:47.946000 
pca_target: 100 	 poly degree: 0 	 kselect: 100 
Imbalance: ClusterCentroids(estimator=None, n_jobs=1, random_state=None, ratio='auto') 
Extended target (count):  25141 13
('Total : Processed (count): ', (493L, 438L), 13)
Final feature (count):  (493L, 438L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.047 	0.000 	0.000 	0.500 	0.000 	0.000
[[  0 141]
 [  0   7]]
             precision    recall  f1-score   support

        0.0       0.00      0.00      0.00       141
        1.0       0.05      1.00      0.09         7

avg / total       0.00      0.05      0.00       148


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.001, class_weight={1: 3}, dual=False,
          fit_intercept=True, intercept_scaling=5, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.399 	-0.248 	-0.095 	0.209 	0.000 	0.000
[[59 82]
 [ 7  0]]
             precision    recall  f1-score   support

        0.0       0.89      0.42      0.57       141
        1.0       0.00      0.00      0.00         7

avg / total       0.85      0.40      0.54       148


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.5, average=False, class_weight={1: 50}, epsilon=0.1,
       eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='invscaling', loss='perceptron', n_iter=5, n_jobs=4,
       penalty='l1', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.527 	-0.017 	-0.008 	0.480 	0.477 	0.226
[[75 66]
 [ 4  3]]
             precision    recall  f1-score   support

        0.0       0.95      0.53      0.68       141
        1.0       0.04      0.43      0.08         7

avg / total       0.91      0.53      0.65       148


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3},
           criterion='entropy', max_depth=8, max_features=0.75,
           max_leaf_nodes=None, min_impurity_split=1e-07,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=4,
           oob_score=False, random_state=None, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.541 	0.105 	0.046 	0.623 	0.616 	0.387
[[75 66]
 [ 2  5]]
             precision    recall  f1-score   support

        0.0       0.97      0.53      0.69       141
        1.0       0.07      0.71      0.13         7

avg / total       0.93      0.54      0.66       148


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features=0.33, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.669 	0.110 	0.063 	0.623 	0.620 	0.381
[[95 46]
 [ 3  4]]
             precision    recall  f1-score   support

        0.0       0.97      0.67      0.79       141
        1.0       0.08      0.57      0.14         7

avg / total       0.93      0.67      0.76       148


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.01, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.520 	0.095 	0.041 	0.612 	0.604 	0.372
[[72 69]
 [ 2  5]]
             precision    recall  f1-score   support

        0.0       0.97      0.51      0.67       141
        1.0       0.07      0.71      0.12         7

avg / total       0.93      0.52      0.64       148


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 50}, criterion='gini', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=2.0, n_estimators=50, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.520 	-0.020 	-0.009 	0.477 	0.474 	0.223
[[74 67]
 [ 4  3]]
             precision    recall  f1-score   support

        0.0       0.95      0.52      0.68       141
        1.0       0.04      0.43      0.08         7

avg / total       0.91      0.52      0.65       148


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=10, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.047 	0.000 	0.000 	0.500 	0.000 	0.000
[[  0 141]
 [  0   7]]
             precision    recall  f1-score   support

        0.0       0.00      0.00      0.00       141
        1.0       0.05      1.00      0.09         7

avg / total       0.00      0.05      0.00       148


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', R...wski',
           metric_params=None, n_jobs=4, n_neighbors=4, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.514 	-0.197 	-0.093 	0.270 	0.000 	0.000
[[76 65]
 [ 7  0]]
             precision    recall  f1-score   support

        0.0       0.92      0.54      0.68       141
        1.0       0.00      0.00      0.00         7

avg / total       0.87      0.51      0.65       148


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=4, p=4,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.953 	0.000 	0.000 	0.500 	0.000 	0.000
[[141   0]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      1.00      0.98       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.95      0.93       148


                estimator  min_score mean_score max_score  sd_score  \
3    ExtraTreesClassifier    0.30755   0.644289         1  0.126698   
4  RandomForestClassifier          0   0.570071         1  0.155078   
5           MLPClassifier  -0.333333   0.104051  0.333333  0.141865   
0              GaussianNB    0.69245    0.69245   0.69245         0   
7                     SVC          0   0.273573   0.69245  0.185204   
9    KNeighborsClassifier          0   0.251074   0.69245  0.141928   
2           SGDClassifier   -0.69245   0.180898   0.69245  0.186241   
6      AdaBoostClassifier       -0.5   0.110697  0.859117  0.216178   
8        VotingClassifier   0.166667   0.667341         1  0.116065   
1      LogisticRegression -0.0257834   0.229059  0.525783  0.157313   

         acc       auc         conf_matrix     f1_c0      f1_c1       kappa  \
3   0.540541    0.6231  [[75, 66], [2, 5]]  0.688073   0.128205   0.0460664   
4   0.668919  0.622594  [[95, 46], [3, 4]]  0.794979   0.140351   0.0625646   
5    0.52027  0.612462  [[72, 69], [2, 5]]  0.669767   0.123457   0.0405405   
0  0.0472973       0.5  [[0, 141], [0, 7]]         0  0.0903226           0   
7  0.0472973       0.5  [[0, 141], [0, 7]]         0  0.0903226           0   
9   0.952703       0.5  [[141, 0], [7, 0]]  0.975779          0           0   
2   0.527027  0.480243  [[75, 66], [4, 3]]  0.681818  0.0789474 -0.00758607   
6    0.52027  0.476697  [[74, 67], [4, 3]]  0.675799  0.0779221 -0.00883257   
8   0.513514  0.269504  [[76, 65], [7, 0]]  0.678571          0  -0.0933716   
1   0.398649   0.20922  [[59, 82], [7, 0]]  0.570048          0  -0.0954757   

  model_score   prec_c0    prec_c1    rec_c0    rec_c1  
3     0.10461  0.974026  0.0704225  0.531915  0.714286  
4    0.110042  0.969388       0.08  0.673759  0.571429  
5   0.0954911  0.972973  0.0675676  0.510638  0.714286  
0           0         0  0.0472973         0         1  
7           0         0  0.0472973         0         1  
9           0  0.952703          0         1         0  
2  -0.0168139  0.949367  0.0434783  0.531915  0.428571  
6  -0.0198154  0.948718  0.0428571  0.524823  0.428571  
8   -0.197177  0.915663          0  0.539007         0  
1   -0.248356  0.893939          0   0.41844         0  
Elapsed time 14.27 mins 

************************************************************

pre/post: 50/0  win/stride: 500/50  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-21 06:52:04.237000 
pca_target: 100 	 poly degree: 0 	 kselect: 100 
Imbalance: SMOTE(k=None, k_neighbors=5, kind='regular', m=None, m_neighbors=10, n_jobs=1,
   out_step=0.5, random_state=None, ratio='auto', svm_estimator=None) 
Extended target (count):  25141 13
('Total : Processed (count): ', (493L, 438L), 13)
Final feature (count):  (493L, 438L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.953 	0.000 	0.000 	0.500 	0.000 	0.000
[[141   0]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      1.00      0.98       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.95      0.93       148


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=1, class_weight={1: 3}, dual=False, fit_intercept=True,
          intercept_scaling=5, max_iter=100, multi_class='ovr', n_jobs=4,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.885 	0.050 	0.048 	0.532 	0.363 	0.121
[[130  11]
 [  6   1]]
             precision    recall  f1-score   support

        0.0       0.96      0.92      0.94       141
        1.0       0.08      0.14      0.11         7

avg / total       0.91      0.89      0.90       148


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.0001, average=False, class_weight='balanced',
       epsilon=0.1, eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='squared_hinge', n_iter=5, n_jobs=4,
       penalty='l2', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.953 	0.000 	0.000 	0.500 	0.000 	0.000
[[141   0]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      1.00      0.98       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.95      0.93       148


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=8, max_features='auto', max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.953 	0.000 	0.000 	0.500 	0.000 	0.000
[[141   0]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      1.00      0.98       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.95      0.93       148


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.953 	0.000 	0.000 	0.500 	0.000 	0.000
[[141   0]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      1.00      0.98       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.95      0.93       148


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.01, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.953 	0.000 	0.000 	0.500 	0.000 	0.000
[[141   0]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      1.00      0.98       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.95      0.93       148


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=1.0, n_estimators=15, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.953 	0.000 	0.000 	0.500 	0.000 	0.000
[[141   0]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      1.00      0.98       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.95      0.93       148


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.953 	0.000 	0.000 	0.500 	0.000 	0.000
[[141   0]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      1.00      0.98       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.95      0.93       148


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=10.0, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', ...owski',
           metric_params=None, n_jobs=4, n_neighbors=4, p=2,
           weights='uniform'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.899 	-0.053 	-0.053 	0.472 	0.000 	0.000
[[133   8]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.94      0.95       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.90      0.90       148


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=1,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.845 	0.175 	0.146 	0.647 	0.609 	0.355
[[122  19]
 [  4   3]]
             precision    recall  f1-score   support

        0.0       0.97      0.87      0.91       141
        1.0       0.14      0.43      0.21         7

avg / total       0.93      0.84      0.88       148


                estimator min_score mean_score max_score     sd_score  \
9    KNeighborsClassifier  0.387772   0.561807  0.697843    0.0860543   
1      LogisticRegression  0.400016    0.84075  0.948521     0.127259   
0              GaussianNB         1          1         1            0   
2           SGDClassifier -0.135554   0.679494    0.9854     0.253385   
3    ExtraTreesClassifier  0.997072   0.999935         1  0.000431674   
4  RandomForestClassifier  0.994185   0.999782         1   0.00102881   
5           MLPClassifier  0.926865   0.961561  0.994143    0.0194874   
6      AdaBoostClassifier  0.931992   0.978973         1   0.00919186   
7                     SVC         0   0.806413         1     0.333373   
8        VotingClassifier  0.829253   0.895849    0.9405    0.0282923   

        acc       auc          conf_matrix     f1_c0     f1_c1      kappa  \
9  0.844595   0.64691  [[122, 19], [4, 3]]  0.913858  0.206897   0.145582   
1  0.885135  0.532421  [[130, 11], [6, 1]]  0.938628  0.105263  0.0484115   
0  0.952703       0.5   [[141, 0], [7, 0]]  0.975779         0          0   
2  0.952703       0.5   [[141, 0], [7, 0]]  0.975779         0          0   
3  0.952703       0.5   [[141, 0], [7, 0]]  0.975779         0          0   
4  0.952703       0.5   [[141, 0], [7, 0]]  0.975779         0          0   
5  0.952703       0.5   [[141, 0], [7, 0]]  0.975779         0          0   
6  0.952703       0.5   [[141, 0], [7, 0]]  0.975779         0          0   
7  0.952703       0.5   [[141, 0], [7, 0]]  0.975779         0          0   
8  0.898649  0.471631   [[133, 8], [7, 0]]  0.946619         0 -0.0531309   

  model_score   prec_c0    prec_c1    rec_c0    rec_c1  
9    0.175325  0.968254   0.136364  0.865248  0.428571  
1   0.0504268  0.955882  0.0833333  0.921986  0.142857  
0           0  0.952703          0         1         0  
2           0  0.952703          0         1         0  
3           0  0.952703          0         1         0  
4           0  0.952703          0         1         0  
5           0  0.952703          0         1         0  
6           0  0.952703          0         1         0  
7           0  0.952703          0         1         0  
8  -0.0532624      0.95          0  0.943262         0  
Elapsed time 25.31 mins 

************************************************************

pre/post: 50/0  win/stride: 500/50  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-21 07:17:22.744000 
pca_target: 100 	 poly degree: 0 	 kselect: 100 
Imbalance: None 
Extended target (count):  25141 13
('Total : Processed (count): ', (493L, 438L), 13)
Final feature (count):  (493L, 438L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.932 	-0.032 	-0.029 	0.489 	0.000 	0.000
[[138   3]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.98      0.97       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.93      0.92       148


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.001, class_weight={1: 500}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.601 	0.133 	0.065 	0.655 	0.652 	0.431
[[84 57]
 [ 2  5]]
             precision    recall  f1-score   support

        0.0       0.98      0.60      0.74       141
        1.0       0.08      0.71      0.14         7

avg / total       0.93      0.60      0.71       148


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=1, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='constant', loss='perceptron', n_iter=5, n_jobs=4,
       penalty='l2', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.919 	0.100 	0.100 	0.550 	0.370 	0.126
[[135   6]
 [  6   1]]
             precision    recall  f1-score   support

        0.0       0.96      0.96      0.96       141
        1.0       0.14      0.14      0.14         7

avg / total       0.92      0.92      0.92       148


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=8, max_features='auto', max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.953 	0.000 	0.000 	0.500 	0.000 	0.000
[[141   0]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      1.00      0.98       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.95      0.93       148


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.953 	0.000 	0.000 	0.500 	0.000 	0.000
[[141   0]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      1.00      0.98       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.95      0.93       148


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.946 	0.194 	0.177 	0.564 	0.375 	0.129
[[139   2]
 [  6   1]]
             precision    recall  f1-score   support

        0.0       0.96      0.99      0.97       141
        1.0       0.33      0.14      0.20         7

avg / total       0.93      0.95      0.94       148


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=16,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=0.5, n_estimators=80, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.919 	-0.042 	-0.041 	0.482 	0.000 	0.000
[[136   5]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.96      0.96       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.92      0.91       148


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.01, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.953 	0.000 	0.000 	0.500 	0.000 	0.000
[[141   0]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      1.00      0.98       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.95      0.93       148


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...wski',
           metric_params=None, n_jobs=4, n_neighbors=4, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.953 	0.000 	0.000 	0.500 	0.000 	0.000
[[141   0]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      1.00      0.98       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.95      0.93       148


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=4,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.926 	0.116 	0.115 	0.554 	0.371 	0.126
[[136   5]
 [  6   1]]
             precision    recall  f1-score   support

        0.0       0.96      0.96      0.96       141
        1.0       0.17      0.14      0.15         7

avg / total       0.92      0.93      0.92       148


                estimator   min_score   mean_score max_score     sd_score  \
1      LogisticRegression  -0.0642185   0.00163173  0.149926    0.0475621   
5           MLPClassifier  -0.0247911   -0.0107691  0.099264      0.01745   
9    KNeighborsClassifier  -0.0226662    0.0130717  0.244364    0.0608449   
2           SGDClassifier   -0.138328    0.0342537  0.230862    0.0534744   
3    ExtraTreesClassifier -0.00713293 -6.75977e-05         0  0.000595329   
4  RandomForestClassifier -0.00588235 -0.000100272         0   0.00061359   
7                     SVC  -0.0221923   -0.0108556         0    0.0109049   
8        VotingClassifier  -0.0161873  -0.00647069         0   0.00301492   
0              GaussianNB    0.140378     0.140378  0.140378            0   
6      AdaBoostClassifier  -0.0279141  -0.00677168  0.333603    0.0360825   

        acc       auc         conf_matrix     f1_c0     f1_c1      kappa  \
1  0.601351  0.655015  [[84, 57], [2, 5]]  0.740088  0.144928  0.0654966   
5  0.945946  0.564336  [[139, 2], [6, 1]]  0.972028       0.2   0.176634   
9  0.925676  0.553698  [[136, 5], [6, 1]]  0.961131  0.153846   0.115217   
2  0.918919  0.550152  [[135, 6], [6, 1]]  0.957447  0.142857   0.100304   
3  0.952703       0.5  [[141, 0], [7, 0]]  0.975779         0          0   
4  0.952703       0.5  [[141, 0], [7, 0]]  0.975779         0          0   
7  0.952703       0.5  [[141, 0], [7, 0]]  0.975779         0          0   
8  0.952703       0.5  [[141, 0], [7, 0]]  0.975779         0          0   
0  0.932432  0.489362  [[138, 3], [7, 0]]  0.965035         0 -0.0292072   
6  0.918919   0.48227  [[136, 5], [7, 0]]  0.957746         0 -0.0410317   

  model_score   prec_c0    prec_c1    rec_c0    rec_c1  
1    0.133388  0.976744  0.0806452  0.595745  0.714286  
5    0.193821  0.958621   0.333333  0.985816  0.142857  
9    0.115592  0.957746   0.166667  0.964539  0.142857  
2    0.100304  0.957447   0.142857  0.957447  0.142857  
3           0  0.952703          0         1         0  
4           0  0.952703          0         1         0  
7           0  0.952703          0         1         0  
8           0  0.952703          0         1         0  
0  -0.0320491  0.951724          0  0.978723         0  
6  -0.0416636  0.951049          0  0.964539         0  
Elapsed time 19.08 mins 

************************************************************

pre/post: 50/0  win/stride: 500/50  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-21 07:36:27.266000 
pca_target: 100 	 poly degree: 2 	 kselect: 80 
Imbalance: ClusterCentroids(estimator=None, n_jobs=1, random_state=None, ratio='auto') 
Extended target (count):  25141 13
('Total : Processed (count): ', (493L, 96580L), 13)
Final feature (count):  (493L, 96580L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.953 	0.000 	0.000 	0.500 	0.000 	0.000
[[141   0]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      1.00      0.98       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.95      0.93       148


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.1, class_weight={1: 3}, dual=False, fit_intercept=True,
          intercept_scaling=0.1, max_iter=100, multi_class='ovr', n_jobs=4,
          penalty='l2', random_state=None, solver='lbfgs', tol=0.0001,
          verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.486 	-0.035 	-0.015 	0.459 	0.458 	0.208
[[69 72]
 [ 4  3]]
             precision    recall  f1-score   support

        0.0       0.95      0.49      0.64       141
        1.0       0.04      0.43      0.07         7

avg / total       0.90      0.49      0.62       148


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.0001, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='squared_hinge', n_iter=5, n_jobs=4,
       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.500 	-0.144 	-0.065 	0.330 	0.272 	0.071
[[73 68]
 [ 6  1]]
             precision    recall  f1-score   support

        0.0       0.92      0.52      0.66       141
        1.0       0.01      0.14      0.03         7

avg / total       0.88      0.50      0.63       148


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=8, max_features='auto', max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=50, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.459 	0.069 	0.026 	0.581 	0.565 	0.328
[[63 78]
 [ 2  5]]
             precision    recall  f1-score   support

        0.0       0.97      0.45      0.61       141
        1.0       0.06      0.71      0.11         7

avg / total       0.93      0.46      0.59       148


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=16, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=30, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.588 	0.069 	0.034 	0.580 	0.580 	0.336
[[83 58]
 [ 3  4]]
             precision    recall  f1-score   support

        0.0       0.97      0.59      0.73       141
        1.0       0.06      0.57      0.12         7

avg / total       0.92      0.59      0.70       148


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.520 	-0.020 	-0.009 	0.477 	0.474 	0.223
[[74 67]
 [ 4  3]]
             precision    recall  f1-score   support

        0.0       0.95      0.52      0.68       141
        1.0       0.04      0.43      0.08         7

avg / total       0.91      0.52      0.65       148


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=8,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=1.0, n_estimators=15, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.561 	0.056 	0.026 	0.566 	0.566 	0.321
[[79 62]
 [ 3  4]]
             precision    recall  f1-score   support

        0.0       0.96      0.56      0.71       141
        1.0       0.06      0.57      0.11         7

avg / total       0.92      0.56      0.68       148


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.1, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='linear',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.554 	0.168 	0.074 	0.698 	0.680 	0.477
[[76 65]
 [ 1  6]]
             precision    recall  f1-score   support

        0.0       0.99      0.54      0.70       141
        1.0       0.08      0.86      0.15         7

avg / total       0.94      0.55      0.67       148


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.581 	0.007 	0.004 	0.509 	0.502 	0.248
[[83 58]
 [ 4  3]]
             precision    recall  f1-score   support

        0.0       0.95      0.59      0.73       141
        1.0       0.05      0.43      0.09         7

avg / total       0.91      0.58      0.70       148


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=2,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.372 	-0.147 	-0.051 	0.331 	0.328 	0.106
[[53 88]
 [ 5  2]]
             precision    recall  f1-score   support

        0.0       0.91      0.38      0.53       141
        1.0       0.02      0.29      0.04         7

avg / total       0.87      0.37      0.51       148


                estimator min_score mean_score max_score   sd_score       acc  \
7                     SVC         0   0.654524         1   0.416287  0.554054   
3    ExtraTreesClassifier  0.833333   0.891527         1  0.0593931  0.459459   
4  RandomForestClassifier       0.5   0.785257         1  0.0858194  0.587838   
6      AdaBoostClassifier  0.166667   0.620441         1   0.200328  0.560811   
8        VotingClassifier  0.833333   0.930556         1  0.0821678  0.581081   
0              GaussianNB  0.525783   0.525783  0.525783          0  0.952703   
5           MLPClassifier  0.525783   0.674475  0.859117   0.098538   0.52027   
1      LogisticRegression         0   0.505148         1   0.361279  0.486486   
9    KNeighborsClassifier         0    0.47205   0.69245   0.180688  0.371622   
2           SGDClassifier -0.359117   0.424405         1   0.203284       0.5   

        auc         conf_matrix     f1_c0      f1_c1       kappa model_score  \
7  0.698075  [[76, 65], [1, 6]]  0.697248   0.153846   0.0741232    0.168323   
3  0.580547  [[63, 78], [2, 5]]   0.61165   0.111111   0.0261556   0.0689037   
4  0.580041  [[83, 58], [3, 4]]  0.731278   0.115942   0.0338185   0.0688737   
6  0.565856  [[79, 62], [3, 4]]   0.70852   0.109589   0.0263158   0.0562478   
8  0.508612  [[83, 58], [4, 3]]   0.72807  0.0882353  0.00369164   0.0074279   
0       0.5  [[141, 0], [7, 0]]  0.975779          0           0           0   
5  0.476697  [[74, 67], [4, 3]]  0.675799  0.0779221 -0.00883257  -0.0198154   
1  0.458967  [[69, 72], [4, 3]]   0.64486  0.0731707   -0.014613  -0.0348445   
9    0.3308  [[53, 88], [5, 2]]  0.532663  0.0412371  -0.0510079   -0.147147   
2  0.330294  [[73, 68], [6, 1]]  0.663636  0.0263158  -0.0651624   -0.144427   

    prec_c0    prec_c1    rec_c0    rec_c1  
7  0.987013   0.084507  0.539007  0.857143  
3  0.969231   0.060241  0.446809  0.714286  
4  0.965116  0.0645161  0.588652  0.571429  
6  0.963415  0.0606061  0.560284  0.571429  
8  0.954023  0.0491803  0.588652  0.428571  
0  0.952703          0         1         0  
5  0.948718  0.0428571  0.524823  0.428571  
1  0.945205       0.04  0.489362  0.428571  
9  0.913793  0.0222222  0.375887  0.285714  
2  0.924051  0.0144928   0.51773  0.142857  
Elapsed time 22.24 mins 

************************************************************

pre/post: 50/0  win/stride: 500/50  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-21 07:58:41.380000 
pca_target: 100 	 poly degree: 2 	 kselect: 80 
Imbalance: SMOTE(k=None, k_neighbors=5, kind='regular', m=None, m_neighbors=10, n_jobs=1,
   out_step=0.5, random_state=None, ratio='auto', svm_estimator=None) 
Extended target (count):  25141 13
('Total : Processed (count): ', (493L, 96580L), 13)
Final feature (count):  (493L, 96580L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.953 	0.000 	0.000 	0.500 	0.000 	0.000
[[141   0]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      1.00      0.98       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.95      0.93       148


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=10, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=5, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.919 	0.100 	0.100 	0.550 	0.370 	0.126
[[135   6]
 [  6   1]]
             precision    recall  f1-score   support

        0.0       0.96      0.96      0.96       141
        1.0       0.14      0.14      0.14         7

avg / total       0.92      0.92      0.92       148


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.001, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.001, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='squared_hinge', n_iter=5, n_jobs=4,
       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.905 	-0.050 	-0.050 	0.475 	0.000 	0.000
[[134   7]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.95      0.95       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.91      0.91       148


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=8, max_features='auto', max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.953 	0.000 	0.000 	0.500 	0.000 	0.000
[[141   0]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      1.00      0.98       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.95      0.93       148


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.953 	0.000 	0.000 	0.500 	0.000 	0.000
[[141   0]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      1.00      0.98       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.95      0.93       148


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.939 	-0.026 	-0.021 	0.493 	0.000 	0.000
[[139   2]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.99      0.97       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.94      0.92       148


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=0.5, n_estimators=15, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.953 	0.000 	0.000 	0.500 	0.000 	0.000
[[141   0]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      1.00      0.98       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.95      0.93       148


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.1, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.953 	0.000 	0.000 	0.500 	0.000 	0.000
[[141   0]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      1.00      0.98       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.95      0.93       148


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=10.0, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', ...wski',
           metric_params=None, n_jobs=4, n_neighbors=4, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.926 	-0.037 	-0.036 	0.486 	0.000 	0.000
[[137   4]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.97      0.96       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.93      0.92       148


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=4,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.865 	0.119 	0.107 	0.590 	0.505 	0.240
[[126  15]
 [  5   2]]
             precision    recall  f1-score   support

        0.0       0.96      0.89      0.93       141
        1.0       0.12      0.29      0.17         7

avg / total       0.92      0.86      0.89       148


                estimator  min_score mean_score max_score     sd_score  \
9    KNeighborsClassifier   0.764733   0.836725  0.920992     0.048911   
1      LogisticRegression   0.528249    0.88679  0.976778     0.104559   
0              GaussianNB          1          1         1            0   
3    ExtraTreesClassifier   0.997072   0.999984         1  0.000217657   
4  RandomForestClassifier   0.991172   0.999634         1   0.00112793   
6      AdaBoostClassifier   0.942634    0.97631         1    0.0105626   
7                     SVC          0   0.812458         1     0.341491   
5           MLPClassifier   0.951071   0.976164         1    0.0129724   
8        VotingClassifier   0.909786    0.94051  0.962534    0.0138406   
2           SGDClassifier -0.0924388   0.716193  0.991256     0.235958   

        acc       auc          conf_matrix     f1_c0     f1_c1      kappa  \
9  0.864865  0.589666  [[126, 15], [5, 2]]  0.926471  0.166667    0.10682   
1  0.918919  0.550152   [[135, 6], [6, 1]]  0.957447  0.142857   0.100304   
0  0.952703       0.5   [[141, 0], [7, 0]]  0.975779         0          0   
3  0.952703       0.5   [[141, 0], [7, 0]]  0.975779         0          0   
4  0.952703       0.5   [[141, 0], [7, 0]]  0.975779         0          0   
6  0.952703       0.5   [[141, 0], [7, 0]]  0.975779         0          0   
7  0.952703       0.5   [[141, 0], [7, 0]]  0.975779         0          0   
5  0.939189  0.492908   [[139, 2], [7, 0]]  0.968641         0 -0.0214724   
8  0.925676  0.485816   [[137, 4], [7, 0]]  0.961404         0 -0.0356234   
2  0.905405  0.475177   [[134, 7], [7, 0]]  0.950355         0 -0.0496454   

  model_score   prec_c0   prec_c1    rec_c0    rec_c1  
9    0.119386  0.961832  0.117647  0.893617  0.285714  
1    0.100304  0.957447  0.142857  0.957447  0.142857  
0           0  0.952703         0         1         0  
3           0  0.952703         0         1         0  
4           0  0.952703         0         1         0  
6           0  0.952703         0         1         0  
7           0  0.952703         0         1         0  
5  -0.0260782  0.952055         0  0.985816         0  
8  -0.0371354  0.951389         0  0.971631         0  
2  -0.0496454  0.950355         0  0.950355         0  
Elapsed time 26.62 mins 

************************************************************

pre/post: 50/0  win/stride: 500/50  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-21 08:25:18.588000 
pca_target: 100 	 poly degree: 2 	 kselect: 80 
Imbalance: None 
Extended target (count):  25141 13
('Total : Processed (count): ', (493L, 96580L), 13)
Final feature (count):  (493L, 96580L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.939 	0.159 	0.153 	0.561 	0.374 	0.128
[[138   3]
 [  6   1]]
             precision    recall  f1-score   support

        0.0       0.96      0.98      0.97       141
        1.0       0.25      0.14      0.18         7

avg / total       0.92      0.94      0.93       148


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.001, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=10, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.939 	-0.026 	-0.021 	0.493 	0.000 	0.000
[[139   2]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.99      0.97       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.94      0.92       148


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=1, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='modified_huber', n_iter=5, n_jobs=4,
       penalty='l2', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.953 	0.000 	0.000 	0.500 	0.000 	0.000
[[141   0]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      1.00      0.98       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.95      0.93       148


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 15}, criterion='gini',
           max_depth=8, max_features=0.33, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.946 	-0.018 	-0.012 	0.496 	0.000 	0.000
[[140   1]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.99      0.97       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.95      0.93       148


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features=0.33, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.946 	-0.018 	-0.012 	0.496 	0.000 	0.000
[[140   1]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.99      0.97       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.95      0.93       148


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.946 	-0.018 	-0.012 	0.496 	0.000 	0.000
[[140   1]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.99      0.97       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.95      0.93       148


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=16,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=2.0, n_estimators=80, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.932 	-0.032 	-0.029 	0.489 	0.000 	0.000
[[138   3]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.98      0.97       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.93      0.92       148


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.01, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='linear',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.946 	-0.018 	-0.012 	0.496 	0.000 	0.000
[[140   1]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.99      0.97       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.95      0.93       148


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', R...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.946 	-0.018 	-0.012 	0.496 	0.000 	0.000
[[140   1]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.99      0.97       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.95      0.93       148


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=3,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.939 	-0.026 	-0.021 	0.493 	0.000 	0.000
[[139   2]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.99      0.97       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.94      0.92       148


                estimator   min_score  mean_score max_score   sd_score  \
0              GaussianNB    0.459029    0.459029  0.459029          0   
2           SGDClassifier    -0.20129   0.0919493  0.495567  0.0615208   
3    ExtraTreesClassifier -0.00890878   0.0428313  0.295567  0.0866613   
4  RandomForestClassifier -0.00418904  0.00426016  0.295567  0.0280817   
5           MLPClassifier -0.00418904    0.173515  0.298465  0.0845429   
7                     SVC           0   0.0759367  0.263448  0.0778427   
8        VotingClassifier -0.00713086    0.109753   0.47854   0.110902   
1      LogisticRegression  -0.0029936    0.133429  0.541305  0.0794573   
9    KNeighborsClassifier           0   0.0778792  0.400927   0.138256   
6      AdaBoostClassifier  -0.0268868   0.0426304   0.47315  0.0844024   

        acc       auc         conf_matrix     f1_c0     f1_c1      kappa  \
0  0.939189   0.56079  [[138, 3], [6, 1]]  0.968421  0.181818   0.152672   
2  0.952703       0.5  [[141, 0], [7, 0]]  0.975779         0          0   
3  0.945946  0.496454  [[140, 1], [7, 0]]  0.972222         0 -0.0119658   
4  0.945946  0.496454  [[140, 1], [7, 0]]  0.972222         0 -0.0119658   
5  0.945946  0.496454  [[140, 1], [7, 0]]  0.972222         0 -0.0119658   
7  0.945946  0.496454  [[140, 1], [7, 0]]  0.972222         0 -0.0119658   
8  0.945946  0.496454  [[140, 1], [7, 0]]  0.972222         0 -0.0119658   
1  0.939189  0.492908  [[139, 2], [7, 0]]  0.968641         0 -0.0214724   
9  0.939189  0.492908  [[139, 2], [7, 0]]  0.968641         0 -0.0214724   
6  0.932432  0.489362  [[138, 3], [7, 0]]  0.965035         0 -0.0292072   

  model_score   prec_c0 prec_c1    rec_c0    rec_c1  
0    0.159152  0.958333    0.25  0.978723  0.142857  
2           0  0.952703       0         1         0  
3  -0.0183773  0.952381       0  0.992908         0  
4  -0.0183773  0.952381       0  0.992908         0  
5  -0.0183773  0.952381       0  0.992908         0  
7  -0.0183773  0.952381       0  0.992908         0  
8  -0.0183773  0.952381       0  0.992908         0  
1  -0.0260782  0.952055       0  0.985816         0  
9  -0.0260782  0.952055       0  0.985816         0  
6  -0.0320491  0.951724       0  0.978723         0  
Elapsed time 21.04 mins 

************************************************************

pre/post: 50/0  win/stride: 500/50  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-21 08:46:21.257000 
pca_target: 100 	 poly degree: 2 	 kselect: 40 
Imbalance: ClusterCentroids(estimator=None, n_jobs=1, random_state=None, ratio='auto') 
Extended target (count):  25141 13
('Total : Processed (count): ', (493L, 96580L), 13)
Final feature (count):  (493L, 96580L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.953 	0.000 	0.000 	0.500 	0.000 	0.000
[[141   0]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      1.00      0.98       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.95      0.93       148


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.001, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.365 	-0.209 	-0.073 	0.259 	0.232 	0.052
[[53 88]
 [ 6  1]]
             precision    recall  f1-score   support

        0.0       0.90      0.38      0.53       141
        1.0       0.01      0.14      0.02         7

avg / total       0.86      0.36      0.51       148


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.1, average=False, class_weight='balanced', epsilon=0.1,
       eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='constant', loss='modified_huber', n_iter=5, n_jobs=4,
       penalty='l2', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.378 	-0.085 	-0.029 	0.402 	0.401 	0.162
[[53 88]
 [ 4  3]]
             precision    recall  f1-score   support

        0.0       0.93      0.38      0.54       141
        1.0       0.03      0.43      0.06         7

avg / total       0.89      0.38      0.51       148


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 15}, criterion='gini',
           max_depth=8, max_features='auto', max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=30, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.534 	0.044 	0.020 	0.552 	0.551 	0.305
[[75 66]
 [ 3  4]]
             precision    recall  f1-score   support

        0.0       0.96      0.53      0.68       141
        1.0       0.06      0.57      0.10         7

avg / total       0.92      0.53      0.66       148


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=None, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.412 	-0.011 	-0.004 	0.488 	0.481 	0.235
[[57 84]
 [ 3  4]]
             precision    recall  f1-score   support

        0.0       0.95      0.40      0.57       141
        1.0       0.05      0.57      0.08         7

avg / total       0.91      0.41      0.54       148


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.01, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.520 	0.153 	0.063 	0.680 	0.657 	0.447
[[71 70]
 [ 1  6]]
             precision    recall  f1-score   support

        0.0       0.99      0.50      0.67       141
        1.0       0.08      0.86      0.14         7

avg / total       0.94      0.52      0.64       148


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=0.5, n_estimators=15, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.399 	-0.017 	-0.006 	0.481 	0.472 	0.227
[[55 86]
 [ 3  4]]
             precision    recall  f1-score   support

        0.0       0.95      0.39      0.55       141
        1.0       0.04      0.57      0.08         7

avg / total       0.91      0.40      0.53       148


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=10, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.047 	0.000 	0.000 	0.500 	0.000 	0.000
[[  0 141]
 [  0   7]]
             precision    recall  f1-score   support

        0.0       0.00      0.00      0.00       141
        1.0       0.05      1.00      0.09         7

avg / total       0.00      0.05      0.00       148


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 500}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Ran...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.466 	0.014 	0.005 	0.516 	0.513 	0.266
[[65 76]
 [ 3  4]]
             precision    recall  f1-score   support

        0.0       0.96      0.46      0.62       141
        1.0       0.05      0.57      0.09         7

avg / total       0.91      0.47      0.60       148


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=1,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.527 	0.099 	0.042 	0.616 	0.608 	0.377
[[73 68]
 [ 2  5]]
             precision    recall  f1-score   support

        0.0       0.97      0.52      0.68       141
        1.0       0.07      0.71      0.12         7

avg / total       0.93      0.53      0.65       148


                estimator min_score mean_score max_score   sd_score  \
5           MLPClassifier  0.359117   0.790996         1    0.15928   
9    KNeighborsClassifier  -0.19245   0.376113  0.833333   0.342532   
3    ExtraTreesClassifier   0.69245   0.857976         1    0.02345   
8        VotingClassifier  0.666667   0.896464         1   0.089937   
0              GaussianNB   0.69245    0.69245   0.69245          0   
7                     SVC         0   0.576773         1   0.365556   
4  RandomForestClassifier   0.69245   0.856196         1  0.0268145   
6      AdaBoostClassifier  0.166667   0.938905         1   0.115436   
2           SGDClassifier  -0.69245   0.187177         1   0.192525   
1      LogisticRegression         0   0.470274         1   0.404316   

         acc       auc         conf_matrix     f1_c0      f1_c1       kappa  \
5    0.52027  0.680344  [[71, 70], [1, 6]]  0.666667   0.144578   0.0634581   
9   0.527027  0.616008  [[73, 68], [2, 5]]  0.675926      0.125   0.0423368   
3   0.533784  0.551672  [[75, 66], [3, 4]]  0.684932   0.103896   0.0195853   
8   0.466216  0.516211  [[65, 76], [3, 4]]   0.62201   0.091954  0.00544403   
0   0.952703       0.5  [[141, 0], [7, 0]]  0.975779          0           0   
7  0.0472973       0.5  [[0, 141], [0, 7]]         0  0.0903226           0   
4   0.412162  0.487842  [[57, 84], [3, 4]]  0.567164  0.0842105 -0.00374181   
6   0.398649   0.48075  [[55, 86], [3, 4]]  0.552764  0.0824742  -0.0058033   
2   0.378378  0.402229  [[53, 88], [4, 3]]  0.535354  0.0612245  -0.0291761   
1   0.364865  0.259372  [[53, 88], [6, 1]]      0.53  0.0208333  -0.0732912   

  model_score   prec_c0    prec_c1    rec_c0    rec_c1  
5    0.153186  0.986111  0.0789474  0.503546  0.857143  
9    0.098511  0.973333  0.0684932   0.51773  0.714286  
3   0.0439385  0.961538  0.0571429  0.531915  0.571429  
8   0.0138099  0.955882       0.05  0.460993  0.571429  
0           0  0.952703          0         1         0  
7           0         0  0.0472973         0         1  
4  -0.0105132      0.95  0.0454545  0.404255  0.571429  
6  -0.0167413  0.948276  0.0444444  0.390071  0.571429  
2  -0.0852983  0.929825   0.032967  0.375887  0.428571  
1   -0.208648  0.898305   0.011236  0.375887  0.142857  
Elapsed time 22.05 mins 

************************************************************

pre/post: 50/0  win/stride: 500/50  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-21 09:08:24.128000 
pca_target: 100 	 poly degree: 2 	 kselect: 40 
Imbalance: SMOTE(k=None, k_neighbors=5, kind='regular', m=None, m_neighbors=10, n_jobs=1,
   out_step=0.5, random_state=None, ratio='auto', svm_estimator=None) 
Extended target (count):  25141 13
('Total : Processed (count): ', (493L, 96580L), 13)
Final feature (count):  (493L, 96580L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.953 	0.000 	0.000 	0.500 	0.000 	0.000
[[141   0]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      1.00      0.98       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.95      0.93       148


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=1, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.905 	0.076 	0.076 	0.543 	0.367 	0.124
[[133   8]
 [  6   1]]
             precision    recall  f1-score   support

        0.0       0.96      0.94      0.95       141
        1.0       0.11      0.14      0.12         7

avg / total       0.92      0.91      0.91       148


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.001, average=False, class_weight='balanced',
       epsilon=0.1, eta0=0.001, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='modified_huber', n_iter=5, n_jobs=4,
       penalty='l2', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.946 	-0.018 	-0.012 	0.496 	0.000 	0.000
[[140   1]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.99      0.97       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.95      0.93       148


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=8, max_features='auto', max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.953 	0.000 	0.000 	0.500 	0.000 	0.000
[[141   0]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      1.00      0.98       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.95      0.93       148


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.953 	0.000 	0.000 	0.500 	0.000 	0.000
[[141   0]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      1.00      0.98       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.95      0.93       148


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.953 	0.000 	0.000 	0.500 	0.000 	0.000
[[141   0]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      1.00      0.98       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.95      0.93       148


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=0.5, n_estimators=15, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.953 	0.000 	0.000 	0.500 	0.000 	0.000
[[141   0]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      1.00      0.98       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.95      0.93       148


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.1, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.946 	-0.018 	-0.012 	0.496 	0.000 	0.000
[[140   1]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.99      0.97       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.95      0.93       148


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=10.0, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', ...owski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='uniform'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.932 	-0.032 	-0.029 	0.489 	0.000 	0.000
[[138   3]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.98      0.97       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.93      0.92       148


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=4,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.885 	0.050 	0.048 	0.532 	0.363 	0.121
[[130  11]
 [  6   1]]
             precision    recall  f1-score   support

        0.0       0.96      0.92      0.94       141
        1.0       0.08      0.14      0.11         7

avg / total       0.91      0.89      0.90       148


                estimator  min_score mean_score max_score    sd_score  \
1      LogisticRegression   0.399579   0.880717  0.976778    0.122242   
9    KNeighborsClassifier   0.789121    0.85269   0.92416   0.0461172   
0              GaussianNB          1          1         1           0   
3    ExtraTreesClassifier   0.997072   0.999992         1  0.00015413   
4  RandomForestClassifier   0.991256   0.999765         1  0.00100522   
5           MLPClassifier   0.948338   0.976464  0.997072   0.0139893   
6      AdaBoostClassifier   0.934111   0.973045         1   0.0140358   
2           SGDClassifier -0.0919338   0.725649  0.994185    0.242759   
7                     SVC          0   0.813273         1    0.336169   
8        VotingClassifier    0.91007   0.939855   0.96246   0.0101275   

        acc       auc          conf_matrix     f1_c0     f1_c1      kappa  \
1  0.905405   0.54306   [[133, 8], [6, 1]]      0.95     0.125  0.0758252   
9  0.885135  0.532421  [[130, 11], [6, 1]]  0.938628  0.105263  0.0484115   
0  0.952703       0.5   [[141, 0], [7, 0]]  0.975779         0          0   
3  0.952703       0.5   [[141, 0], [7, 0]]  0.975779         0          0   
4  0.952703       0.5   [[141, 0], [7, 0]]  0.975779         0          0   
5  0.952703       0.5   [[141, 0], [7, 0]]  0.975779         0          0   
6  0.952703       0.5   [[141, 0], [7, 0]]  0.975779         0          0   
2  0.945946  0.496454   [[140, 1], [7, 0]]  0.972222         0 -0.0119658   
7  0.945946  0.496454   [[140, 1], [7, 0]]  0.972222         0 -0.0119658   
8  0.932432  0.489362   [[138, 3], [7, 0]]  0.965035         0 -0.0292072   

  model_score   prec_c0    prec_c1    rec_c0    rec_c1  
1   0.0764948  0.956835   0.111111  0.943262  0.142857  
9   0.0504268  0.955882  0.0833333  0.921986  0.142857  
0           0  0.952703          0         1         0  
3           0  0.952703          0         1         0  
4           0  0.952703          0         1         0  
5           0  0.952703          0         1         0  
6           0  0.952703          0         1         0  
2  -0.0183773  0.952381          0  0.992908         0  
7  -0.0183773  0.952381          0  0.992908         0  
8  -0.0320491  0.951724          0  0.978723         0  
Elapsed time 24.21 mins 

************************************************************

pre/post: 50/0  win/stride: 500/50  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-21 09:32:37.003000 
pca_target: 100 	 poly degree: 2 	 kselect: 40 
Imbalance: None 
Extended target (count):  25141 13
('Total : Processed (count): ', (493L, 96580L), 13)
Final feature (count):  (493L, 96580L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.939 	-0.026 	-0.021 	0.493 	0.000 	0.000
[[139   2]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.99      0.97       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.94      0.92       148


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.001, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=5, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.932 	-0.032 	-0.029 	0.489 	0.000 	0.000
[[138   3]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.98      0.97       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.93      0.92       148


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.1, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='squared_hinge', n_iter=5, n_jobs=4,
       penalty='l2', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.932 	-0.032 	-0.029 	0.489 	0.000 	0.000
[[138   3]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.98      0.97       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.93      0.92       148


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=16, max_features=0.33, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.953 	0.000 	0.000 	0.500 	0.000 	0.000
[[141   0]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      1.00      0.98       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.95      0.93       148


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=32, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.953 	0.000 	0.000 	0.500 	0.000 	0.000
[[141   0]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      1.00      0.98       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.95      0.93       148


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.01, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.946 	-0.018 	-0.012 	0.496 	0.000 	0.000
[[140   1]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.99      0.97       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.95      0.93       148


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight='balanced', criterion='entropy',
            max_depth=16, max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=1.0, n_estimators=80, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.953 	0.000 	0.000 	0.500 	0.000 	0.000
[[141   0]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      1.00      0.98       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.95      0.93       148


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.01, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='linear',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.939 	-0.026 	-0.021 	0.493 	0.000 	0.000
[[139   2]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.99      0.97       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.94      0.92       148


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 500}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Ran...owski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='uniform'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.946 	-0.018 	-0.012 	0.496 	0.000 	0.000
[[140   1]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.99      0.97       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.95      0.93       148


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=4,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.932 	-0.032 	-0.029 	0.489 	0.000 	0.000
[[138   3]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.98      0.97       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.93      0.92       148


                estimator   min_score  mean_score max_score   sd_score  \
3    ExtraTreesClassifier -0.00890878   0.0144194  0.298465   0.041185   
4  RandomForestClassifier -0.00418904  0.00506405  0.197101  0.0269902   
6      AdaBoostClassifier  -0.0264453    0.017649       0.4  0.0759107   
5           MLPClassifier  -0.0173905    0.157738  0.298465  0.0698862   
8        VotingClassifier  -0.0100714    0.111483  0.457905   0.118254   
0              GaussianNB    0.556397    0.556397  0.556397          0   
7                     SVC           0    0.073229  0.275599  0.0762267   
1      LogisticRegression -0.00419038    0.143624  0.461364  0.0836374   
2           SGDClassifier   -0.269881   0.0913898  0.597101  0.0642923   
9    KNeighborsClassifier -0.00294118   0.0826286  0.416019   0.148749   

        acc       auc         conf_matrix     f1_c0 f1_c1      kappa  \
3  0.952703       0.5  [[141, 0], [7, 0]]  0.975779     0          0   
4  0.952703       0.5  [[141, 0], [7, 0]]  0.975779     0          0   
6  0.952703       0.5  [[141, 0], [7, 0]]  0.975779     0          0   
5  0.945946  0.496454  [[140, 1], [7, 0]]  0.972222     0 -0.0119658   
8  0.945946  0.496454  [[140, 1], [7, 0]]  0.972222     0 -0.0119658   
0  0.939189  0.492908  [[139, 2], [7, 0]]  0.968641     0 -0.0214724   
7  0.939189  0.492908  [[139, 2], [7, 0]]  0.968641     0 -0.0214724   
1  0.932432  0.489362  [[138, 3], [7, 0]]  0.965035     0 -0.0292072   
2  0.932432  0.489362  [[138, 3], [7, 0]]  0.965035     0 -0.0292072   
9  0.932432  0.489362  [[138, 3], [7, 0]]  0.965035     0 -0.0292072   

  model_score   prec_c0 prec_c1    rec_c0 rec_c1  
3           0  0.952703       0         1      0  
4           0  0.952703       0         1      0  
6           0  0.952703       0         1      0  
5  -0.0183773  0.952381       0  0.992908      0  
8  -0.0183773  0.952381       0  0.992908      0  
0  -0.0260782  0.952055       0  0.985816      0  
7  -0.0260782  0.952055       0  0.985816      0  
1  -0.0320491  0.951724       0  0.978723      0  
2  -0.0320491  0.951724       0  0.978723      0  
9  -0.0320491  0.951724       0  0.978723      0  
Elapsed time 19.71 mins 

************************************************************

pre/post: 50/0  win/stride: 500/50  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-21 09:52:19.548000 
pca_target: 100 	 poly degree: 2 	 kselect: 100 
Imbalance: ClusterCentroids(estimator=None, n_jobs=1, random_state=None, ratio='auto') 
Extended target (count):  25141 13
('Total : Processed (count): ', (493L, 96580L), 13)
Final feature (count):  (493L, 96580L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.047 	0.000 	0.000 	0.500 	0.000 	0.000
[[  0 141]
 [  0   7]]
             precision    recall  f1-score   support

        0.0       0.00      0.00      0.00       141
        1.0       0.05      1.00      0.09         7

avg / total       0.00      0.05      0.00       148


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.001, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.520 	-0.020 	-0.009 	0.477 	0.474 	0.223
[[74 67]
 [ 4  3]]
             precision    recall  f1-score   support

        0.0       0.95      0.52      0.68       141
        1.0       0.04      0.43      0.08         7

avg / total       0.91      0.52      0.65       148


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.1, average=False, class_weight={1: 15}, epsilon=0.1,
       eta0=0.001, fit_intercept=True, l1_ratio=0.15,
       learning_rate='invscaling', loss='squared_hinge', n_iter=5,
       n_jobs=4, penalty='l2', power_t=0.5, random_state=None,
       shuffle=True, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.473 	-0.156 	-0.067 	0.316 	0.264 	0.067
[[69 72]
 [ 6  1]]
             precision    recall  f1-score   support

        0.0       0.92      0.49      0.64       141
        1.0       0.01      0.14      0.03         7

avg / total       0.88      0.47      0.61       148


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 500}, criterion='gini',
           max_depth=32, max_features='auto', max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.480 	0.020 	0.008 	0.523 	0.521 	0.274
[[67 74]
 [ 3  4]]
             precision    recall  f1-score   support

        0.0       0.96      0.48      0.64       141
        1.0       0.05      0.57      0.09         7

avg / total       0.91      0.48      0.61       148


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=30, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.635 	0.033 	0.018 	0.537 	0.526 	0.271
[[91 50]
 [ 4  3]]
             precision    recall  f1-score   support

        0.0       0.96      0.65      0.77       141
        1.0       0.06      0.43      0.10         7

avg / total       0.92      0.64      0.74       148


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.01, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.432 	-0.175 	-0.070 	0.295 	0.253 	0.062
[[63 78]
 [ 6  1]]
             precision    recall  f1-score   support

        0.0       0.91      0.45      0.60       141
        1.0       0.01      0.14      0.02         7

avg / total       0.87      0.43      0.57       148


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=1.0, n_estimators=15, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.297 	-0.004 	-0.001 	0.495 	0.444 	0.206
[[ 39 102]
 [  2   5]]
             precision    recall  f1-score   support

        0.0       0.95      0.28      0.43       141
        1.0       0.05      0.71      0.09         7

avg / total       0.91      0.30      0.41       148


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.953 	0.000 	0.000 	0.500 	0.000 	0.000
[[141   0]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      1.00      0.98       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.95      0.93       148


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.716 	0.138 	0.086 	0.647 	0.643 	0.407
[[102  39]
 [  3   4]]
             precision    recall  f1-score   support

        0.0       0.97      0.72      0.83       141
        1.0       0.09      0.57      0.16         7

avg / total       0.93      0.72      0.80       148


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=1,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.615 	0.082 	0.042 	0.594 	0.594 	0.351
[[87 54]
 [ 3  4]]
             precision    recall  f1-score   support

        0.0       0.97      0.62      0.75       141
        1.0       0.07      0.57      0.12         7

avg / total       0.92      0.61      0.72       148


                estimator min_score mean_score max_score   sd_score  \
8        VotingClassifier  0.666667   0.909722         1  0.0845779   
9    KNeighborsClassifier  0.359117   0.727344  0.833333   0.156033   
4  RandomForestClassifier       0.5   0.950072         1  0.0959871   
3    ExtraTreesClassifier       0.5   0.696759         1  0.0698675   
0              GaussianNB   0.69245    0.69245   0.69245          0   
7                     SVC         0   0.552895  0.859117   0.347086   
6      AdaBoostClassifier         0   0.705072         1    0.17852   
1      LogisticRegression         0   0.356288  0.833333   0.286225   
2           SGDClassifier      -0.5   0.412192         1   0.222828   
5           MLPClassifier       0.5   0.937251         1   0.139991   

         acc       auc          conf_matrix     f1_c0      f1_c1       kappa  \
8   0.716216  0.647416  [[102, 39], [3, 4]]  0.829268       0.16   0.0856134   
9   0.614865  0.594225   [[87, 54], [3, 4]]  0.753247   0.123077   0.0422343   
4   0.635135  0.536981   [[91, 50], [4, 3]]  0.771186        0.1   0.0179405   
3    0.47973  0.523303   [[67, 74], [3, 4]]  0.635071  0.0941176  0.00800836   
0  0.0472973       0.5   [[0, 141], [0, 7]]         0  0.0903226           0   
7   0.952703       0.5   [[141, 0], [7, 0]]  0.975779          0           0   
6   0.297297  0.495441  [[39, 102], [2, 5]]  0.428571  0.0877193 -0.00117081   
1    0.52027  0.476697   [[74, 67], [4, 3]]  0.675799  0.0779221 -0.00883257   
2   0.472973  0.316109   [[69, 72], [6, 1]]  0.638889      0.025  -0.0671104   
5   0.432432  0.294833   [[63, 78], [6, 1]]       0.6  0.0232558  -0.0696954   

  model_score   prec_c0    prec_c1    rec_c0    rec_c1  
8     0.13785  0.971429  0.0930233  0.723404  0.571429  
9   0.0819444  0.966667  0.0689655  0.617021  0.571429  
4   0.0327465  0.957895  0.0566038   0.64539  0.428571  
3   0.0198154  0.957143  0.0512821  0.475177  0.571429  
0           0         0  0.0472973         0         1  
7           0  0.952703          0         1         0  
6 -0.00432514   0.95122   0.046729  0.276596  0.714286  
1  -0.0198154  0.948718  0.0428571  0.524823  0.428571  
2   -0.156155      0.92  0.0136986  0.489362  0.142857  
5   -0.174606  0.913043  0.0126582  0.446809  0.142857  
Elapsed time 22.43 mins 

************************************************************

pre/post: 50/0  win/stride: 500/50  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-21 10:14:45.432000 
pca_target: 100 	 poly degree: 2 	 kselect: 100 
Imbalance: SMOTE(k=None, k_neighbors=5, kind='regular', m=None, m_neighbors=10, n_jobs=1,
   out_step=0.5, random_state=None, ratio='auto', svm_estimator=None) 
Extended target (count):  25141 13
('Total : Processed (count): ', (493L, 96580L), 13)
Final feature (count):  (493L, 96580L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.953 	0.000 	0.000 	0.500 	0.000 	0.000
[[141   0]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      1.00      0.98       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.95      0.93       148


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=10, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=10, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.905 	0.076 	0.076 	0.543 	0.367 	0.124
[[133   8]
 [  6   1]]
             precision    recall  f1-score   support

        0.0       0.96      0.94      0.95       141
        1.0       0.11      0.14      0.12         7

avg / total       0.92      0.91      0.91       148


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.001, average=False, class_weight='balanced',
       epsilon=0.1, eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='modified_huber', n_iter=5, n_jobs=4,
       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.939 	-0.026 	-0.021 	0.493 	0.000 	0.000
[[139   2]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.99      0.97       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.94      0.92       148


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=8, max_features='auto', max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.953 	0.000 	0.000 	0.500 	0.000 	0.000
[[141   0]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      1.00      0.98       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.95      0.93       148


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=30, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.953 	0.000 	0.000 	0.500 	0.000 	0.000
[[141   0]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      1.00      0.98       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.95      0.93       148


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.946 	-0.018 	-0.012 	0.496 	0.000 	0.000
[[140   1]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.99      0.97       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.95      0.93       148


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=0.5, n_estimators=15, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.953 	0.000 	0.000 	0.500 	0.000 	0.000
[[141   0]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      1.00      0.98       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.95      0.93       148


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.1, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.953 	0.000 	0.000 	0.500 	0.000 	0.000
[[141   0]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      1.00      0.98       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.95      0.93       148


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=10.0, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', ...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.932 	-0.032 	-0.029 	0.489 	0.000 	0.000
[[138   3]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.98      0.97       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.93      0.92       148


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=4,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.851 	0.183 	0.154 	0.650 	0.611 	0.357
[[123  18]
 [  4   3]]
             precision    recall  f1-score   support

        0.0       0.97      0.87      0.92       141
        1.0       0.14      0.43      0.21         7

avg / total       0.93      0.85      0.88       148


                estimator min_score mean_score max_score     sd_score  \
9    KNeighborsClassifier  0.745372   0.827722   0.90756    0.0534415   
1      LogisticRegression  0.553379   0.885776  0.965465    0.0982656   
0              GaussianNB         1          1         1            0   
3    ExtraTreesClassifier  0.997072   0.999984         1  0.000217657   
4  RandomForestClassifier  0.988243   0.998715         1   0.00168074   
6      AdaBoostClassifier  0.942752    0.98314         1    0.0095663   
7                     SVC         0   0.782054         1     0.357796   
5           MLPClassifier   0.94287   0.972574  0.997072    0.0160147   
2           SGDClassifier -0.157355   0.706637  0.994143     0.245985   
8        VotingClassifier  0.901969    0.93902  0.965271    0.0149854   

        acc       auc          conf_matrix     f1_c0     f1_c1      kappa  \
9  0.851351  0.650456  [[123, 18], [4, 3]]   0.91791  0.214286   0.154286   
1  0.905405   0.54306   [[133, 8], [6, 1]]      0.95     0.125  0.0758252   
0  0.952703       0.5   [[141, 0], [7, 0]]  0.975779         0          0   
3  0.952703       0.5   [[141, 0], [7, 0]]  0.975779         0          0   
4  0.952703       0.5   [[141, 0], [7, 0]]  0.975779         0          0   
6  0.952703       0.5   [[141, 0], [7, 0]]  0.975779         0          0   
7  0.952703       0.5   [[141, 0], [7, 0]]  0.975779         0          0   
5  0.945946  0.496454   [[140, 1], [7, 0]]  0.972222         0 -0.0119658   
2  0.939189  0.492908   [[139, 2], [7, 0]]  0.968641         0 -0.0214724   
8  0.932432  0.489362   [[138, 3], [7, 0]]  0.965035         0 -0.0292072   

  model_score   prec_c0   prec_c1    rec_c0    rec_c1  
9    0.183057  0.968504  0.142857   0.87234  0.428571  
1   0.0764948  0.956835  0.111111  0.943262  0.142857  
0           0  0.952703         0         1         0  
3           0  0.952703         0         1         0  
4           0  0.952703         0         1         0  
6           0  0.952703         0         1         0  
7           0  0.952703         0         1         0  
5  -0.0183773  0.952381         0  0.992908         0  
2  -0.0260782  0.952055         0  0.985816         0  
8  -0.0320491  0.951724         0  0.978723         0  
Elapsed time 28.76 mins 

************************************************************

pre/post: 50/0  win/stride: 500/50  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-21 10:43:30.813000 
pca_target: 100 	 poly degree: 2 	 kselect: 100 
Imbalance: None 
Extended target (count):  25141 13
('Total : Processed (count): ', (493L, 96580L), 13)
Final feature (count):  (493L, 96580L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.926 	0.116 	0.115 	0.554 	0.371 	0.126
[[136   5]
 [  6   1]]
             precision    recall  f1-score   support

        0.0       0.96      0.96      0.96       141
        1.0       0.17      0.14      0.15         7

avg / total       0.92      0.93      0.92       148


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.001, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=10, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.939 	-0.026 	-0.021 	0.493 	0.000 	0.000
[[139   2]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.99      0.97       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.94      0.92       148


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=1, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='modified_huber', n_iter=5, n_jobs=4,
       penalty='l2', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.946 	-0.018 	-0.012 	0.496 	0.000 	0.000
[[140   1]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.99      0.97       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.95      0.93       148


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=32, max_features='auto', max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.953 	0.000 	0.000 	0.500 	0.000 	0.000
[[141   0]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      1.00      0.98       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.95      0.93       148


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=30, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.953 	0.000 	0.000 	0.500 	0.000 	0.000
[[141   0]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      1.00      0.98       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.95      0.93       148


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(500,), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.946 	-0.018 	-0.012 	0.496 	0.000 	0.000
[[140   1]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.99      0.97       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.95      0.93       148


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=32,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=2.0, n_estimators=80, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.946 	0.194 	0.177 	0.564 	0.375 	0.129
[[139   2]
 [  6   1]]
             precision    recall  f1-score   support

        0.0       0.96      0.99      0.97       141
        1.0       0.33      0.14      0.20         7

avg / total       0.93      0.95      0.94       148


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.01, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='linear',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.946 	-0.018 	-0.012 	0.496 	0.000 	0.000
[[140   1]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.99      0.97       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.95      0.93       148


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.953 	0.000 	0.000 	0.500 	0.000 	0.000
[[141   0]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      1.00      0.98       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.95      0.93       148


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=3,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.953 	0.000 	0.000 	0.500 	0.000 	0.000
[[141   0]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      1.00      0.98       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.95      0.93       148


                estimator   min_score  mean_score max_score   sd_score  \
6      AdaBoostClassifier  -0.0274006    0.021833  0.434357   0.083357   
0              GaussianNB    0.459029    0.459029  0.459029          0   
3    ExtraTreesClassifier -0.00890878   0.0214122  0.295567   0.061587   
4  RandomForestClassifier  -0.0059676  0.00240737  0.197101  0.0229724   
8        VotingClassifier -0.00736313    0.134901  0.298465   0.129718   
9    KNeighborsClassifier -0.00418904   0.0816334  0.403869   0.146886   
2           SGDClassifier   -0.198008    0.093989  0.530116  0.0614546   
5           MLPClassifier -0.00418904    0.173972  0.298465  0.0700495   
7                     SVC           0   0.0972326  0.275599  0.0982157   
1      LogisticRegression           0    0.162604  0.541305   0.105559   

        acc       auc         conf_matrix     f1_c0     f1_c1      kappa  \
6  0.945946  0.564336  [[139, 2], [6, 1]]  0.972028       0.2   0.176634   
0  0.925676  0.553698  [[136, 5], [6, 1]]  0.961131  0.153846   0.115217   
3  0.952703       0.5  [[141, 0], [7, 0]]  0.975779         0          0   
4  0.952703       0.5  [[141, 0], [7, 0]]  0.975779         0          0   
8  0.952703       0.5  [[141, 0], [7, 0]]  0.975779         0          0   
9  0.952703       0.5  [[141, 0], [7, 0]]  0.975779         0          0   
2  0.945946  0.496454  [[140, 1], [7, 0]]  0.972222         0 -0.0119658   
5  0.945946  0.496454  [[140, 1], [7, 0]]  0.972222         0 -0.0119658   
7  0.945946  0.496454  [[140, 1], [7, 0]]  0.972222         0 -0.0119658   
1  0.939189  0.492908  [[139, 2], [7, 0]]  0.968641         0 -0.0214724   

  model_score   prec_c0   prec_c1    rec_c0    rec_c1  
6    0.193821  0.958621  0.333333  0.985816  0.142857  
0    0.115592  0.957746  0.166667  0.964539  0.142857  
3           0  0.952703         0         1         0  
4           0  0.952703         0         1         0  
8           0  0.952703         0         1         0  
9           0  0.952703         0         1         0  
2  -0.0183773  0.952381         0  0.992908         0  
5  -0.0183773  0.952381         0  0.992908         0  
7  -0.0183773  0.952381         0  0.992908         0  
1  -0.0260782  0.952055         0  0.985816         0  
Elapsed time 21.79 mins 

************************************************************

[4;33mReloaded modules[24m: migraine_processing, classifiers[0m
Finished.

lagged (3,4)x1

    pca = [0]
    poly = [0, 2]
    ksel = [40, 100]
    imb = [ClusterCentroids(), SMOTE(), None]
	
	

	
	
	









pre/post: 50/0  win/stride: 500/50  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-21 16:57:01.269000 
pca_target: 0 	 poly degree: 0 	 kselect: 40 
Imbalance: ClusterCentroids(estimator=None, n_jobs=1, random_state=None, ratio='auto') 
Extended target (count):  25141 13
('Total : Processed (count): ', (493L, 222L), 13)
Final feature (count):  (493L, 222L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.743 	-0.115 	-0.084 	0.390 	0.000 	0.000
[[110  31]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.94      0.78      0.85       141
        1.0       0.00      0.00      0.00         7

avg / total       0.90      0.74      0.81       148


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=1, class_weight={1: 3}, dual=False, fit_intercept=True,
          intercept_scaling=0.1, max_iter=100, multi_class='ovr', n_jobs=4,
          penalty='l2', random_state=None, solver='lbfgs', tol=0.0001,
          verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.676 	-0.072 	-0.045 	0.422 	0.317 	0.095
[[99 42]
 [ 6  1]]
             precision    recall  f1-score   support

        0.0       0.94      0.70      0.80       141
        1.0       0.02      0.14      0.04         7

avg / total       0.90      0.68      0.77       148


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.0001, average=False, class_weight={1: 500}, epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='invscaling', loss='squared_hinge', n_iter=5,
       n_jobs=4, penalty='l1', power_t=0.5, random_state=None,
       shuffle=True, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.486 	-0.150 	-0.066 	0.323 	0.268 	0.069
[[71 70]
 [ 6  1]]
             precision    recall  f1-score   support

        0.0       0.92      0.50      0.65       141
        1.0       0.01      0.14      0.03         7

avg / total       0.88      0.49      0.62       148


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 15}, criterion='gini',
           max_depth=8, max_features=0.33, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.378 	-0.026 	-0.009 	0.470 	0.459 	0.215
[[52 89]
 [ 3  4]]
             precision    recall  f1-score   support

        0.0       0.95      0.37      0.53       141
        1.0       0.04      0.57      0.08         7

avg / total       0.90      0.38      0.51       148


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=32, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.595 	0.072 	0.036 	0.584 	0.583 	0.340
[[84 57]
 [ 3  4]]
             precision    recall  f1-score   support

        0.0       0.97      0.60      0.74       141
        1.0       0.07      0.57      0.12         7

avg / total       0.92      0.59      0.71       148


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.01, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.730 	-0.119 	-0.085 	0.383 	0.000 	0.000
[[108  33]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.94      0.77      0.84       141
        1.0       0.00      0.00      0.00         7

avg / total       0.89      0.73      0.80       148


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=16,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=0.5, n_estimators=50, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.209 	0.019 	0.004 	0.517 	0.390 	0.162
[[ 25 116]
 [  1   6]]
             precision    recall  f1-score   support

        0.0       0.96      0.18      0.30       141
        1.0       0.05      0.86      0.09         7

avg / total       0.92      0.21      0.29       148


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=1, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.196 	-0.064 	-0.013 	0.442 	0.349 	0.128
[[ 24 117]
 [  2   5]]
             precision    recall  f1-score   support

        0.0       0.92      0.17      0.29       141
        1.0       0.04      0.71      0.08         7

avg / total       0.88      0.20      0.28       148


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 500}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Ran...wski',
           metric_params=None, n_jobs=4, n_neighbors=4, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.520 	-0.078 	-0.035 	0.409 	0.390 	0.148
[[75 66]
 [ 5  2]]
             precision    recall  f1-score   support

        0.0       0.94      0.53      0.68       141
        1.0       0.03      0.29      0.05         7

avg / total       0.89      0.52      0.65       148


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=2,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.757 	-0.036 	-0.027 	0.465 	0.335 	0.105
[[111  30]
 [  6   1]]
             precision    recall  f1-score   support

        0.0       0.95      0.79      0.86       141
        1.0       0.03      0.14      0.05         7

avg / total       0.91      0.76      0.82       148


                estimator min_score mean_score max_score  sd_score       acc  \
4  RandomForestClassifier         0   0.354602   0.69245  0.146641  0.594595   
6      AdaBoostClassifier         0   0.417944         1  0.202169  0.209459   
3    ExtraTreesClassifier  0.333333   0.687518         1  0.155744  0.378378   
9    KNeighborsClassifier -0.525783 -0.0411295  0.359117  0.284907  0.756757   
7                     SVC         0   0.413502  0.859117  0.313511  0.195946   
1      LogisticRegression -0.359117   0.249517   0.69245  0.234113  0.675676   
8        VotingClassifier  0.140883   0.430074  0.833333  0.148957   0.52027   
0              GaussianNB   0.69245    0.69245   0.69245         0  0.743243   
5           MLPClassifier         0   0.263889  0.333333  0.121875   0.72973   
2           SGDClassifier -0.666667   0.131658   0.69245  0.216704  0.486486   

        auc          conf_matrix     f1_c0      f1_c1       kappa model_score  \
4  0.583587   [[84, 57], [3, 4]]  0.736842   0.117647   0.0358306   0.0720943   
6  0.517224  [[25, 116], [1, 6]]  0.299401  0.0930233  0.00391164   0.0192156   
3  0.470111   [[52, 89], [3, 4]]  0.530612       0.08 -0.00874204  -0.0262585   
9  0.465046  [[111, 30], [6, 1]]  0.860465  0.0526316  -0.0265896  -0.0364684   
7  0.442249  [[24, 117], [2, 5]]  0.287425  0.0775194  -0.0131155  -0.0644287   
1  0.422492   [[99, 42], [6, 1]]  0.804878       0.04  -0.0450132  -0.0724776   
8  0.408815   [[75, 66], [5, 2]]  0.678733  0.0533333   -0.035475  -0.0776809   
0  0.390071  [[110, 31], [7, 0]]  0.852713          0  -0.0836224    -0.11469   
5  0.382979  [[108, 33], [7, 0]]   0.84375          0  -0.0846464   -0.119357   
2  0.323202   [[71, 70], [6, 1]]  0.651376   0.025641  -0.0661611   -0.150242   

    prec_c0    prec_c1    rec_c0    rec_c1  
4  0.965517  0.0655738  0.595745  0.571429  
6  0.961538  0.0491803  0.177305  0.857143  
3  0.945455  0.0430108  0.368794  0.571429  
9  0.948718  0.0322581  0.787234  0.142857  
7  0.923077  0.0409836  0.170213  0.714286  
1  0.942857  0.0232558  0.702128  0.142857  
8    0.9375  0.0294118  0.531915  0.285714  
0  0.940171          0  0.780142         0  
5   0.93913          0  0.765957         0  
2  0.922078  0.0140845  0.503546  0.142857  
Elapsed time 13.84 mins 

************************************************************

pre/post: 50/0  win/stride: 500/50  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-21 17:10:51.506000 
pca_target: 0 	 poly degree: 0 	 kselect: 40 
Imbalance: SMOTE(k=None, k_neighbors=5, kind='regular', m=None, m_neighbors=10, n_jobs=1,
   out_step=0.5, random_state=None, ratio='auto', svm_estimator=None) 
Extended target (count):  25141 13
('Total : Processed (count): ', (493L, 222L), 13)
Final feature (count):  (493L, 222L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.851 	0.020 	0.018 	0.515 	0.356 	0.117
[[125  16]
 [  6   1]]
             precision    recall  f1-score   support

        0.0       0.95      0.89      0.92       141
        1.0       0.06      0.14      0.08         7

avg / total       0.91      0.85      0.88       148


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=10, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.885 	-0.060 	-0.059 	0.465 	0.000 	0.000
[[131  10]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.93      0.94       141
        1.0       0.00      0.00      0.00         7

avg / total       0.90      0.89      0.89       148


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.001, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='perceptron', n_iter=5, n_jobs=4,
       penalty='l1', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.905 	-0.050 	-0.050 	0.475 	0.000 	0.000
[[134   7]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.95      0.95       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.91      0.91       148


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight='balanced',
           criterion='gini', max_depth=32, max_features=0.33,
           max_leaf_nodes=None, min_impurity_split=1e-07,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=15, n_jobs=4,
           oob_score=False, random_state=None, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.946 	-0.018 	-0.012 	0.496 	0.000 	0.000
[[140   1]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.99      0.97       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.95      0.93       148


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight='balanced',
            criterion='gini', max_depth=16, max_features='auto',
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=15, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.939 	-0.026 	-0.021 	0.493 	0.000 	0.000
[[139   2]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.99      0.97       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.94      0.92       148


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.939 	-0.026 	-0.021 	0.493 	0.000 	0.000
[[139   2]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.99      0.97       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.94      0.92       148


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight='balanced', criterion='entropy',
            max_depth=8, max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=0.5, n_estimators=15, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.939 	-0.026 	-0.021 	0.493 	0.000 	0.000
[[139   2]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.99      0.97       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.94      0.92       148


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.5, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.953 	0.000 	0.000 	0.500 	0.000 	0.000
[[141   0]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      1.00      0.98       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.95      0.93       148


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', R...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.905 	-0.050 	-0.050 	0.475 	0.000 	0.000
[[134   7]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.95      0.95       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.91      0.91       148


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=4,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.905 	0.076 	0.076 	0.543 	0.367 	0.124
[[133   8]
 [  6   1]]
             precision    recall  f1-score   support

        0.0       0.96      0.94      0.95       141
        1.0       0.11      0.14      0.12         7

avg / total       0.92      0.91      0.91       148


                estimator min_score mean_score max_score    sd_score  \
9    KNeighborsClassifier  0.821729   0.873559   0.91309   0.0281037   
0              GaussianNB  0.844246   0.844246  0.844246           0   
7                     SVC         0   0.777229  0.997072    0.288588   
3    ExtraTreesClassifier  0.811875   0.962438   0.98548   0.0278643   
4  RandomForestClassifier  0.956382   0.970107  0.982427  0.00364766   
5           MLPClassifier  0.937168   0.959134  0.979743  0.00982886   
6      AdaBoostClassifier  0.879396   0.959123  0.991215   0.0170284   
2           SGDClassifier -0.151424   0.583482  0.920306    0.241637   
8        VotingClassifier  0.859587   0.910075  0.934761   0.0166605   
1      LogisticRegression         0   0.700181  0.918058    0.230033   

        acc       auc          conf_matrix     f1_c0      f1_c1      kappa  \
9  0.905405   0.54306   [[133, 8], [6, 1]]      0.95      0.125  0.0758252   
0  0.851351  0.514691  [[125, 16], [6, 1]]  0.919118  0.0833333  0.0175015   
7  0.952703       0.5   [[141, 0], [7, 0]]  0.975779          0          0   
3  0.945946  0.496454   [[140, 1], [7, 0]]  0.972222          0 -0.0119658   
4  0.939189  0.492908   [[139, 2], [7, 0]]  0.968641          0 -0.0214724   
5  0.939189  0.492908   [[139, 2], [7, 0]]  0.968641          0 -0.0214724   
6  0.939189  0.492908   [[139, 2], [7, 0]]  0.968641          0 -0.0214724   
2  0.905405  0.475177   [[134, 7], [7, 0]]  0.950355          0 -0.0496454   
8  0.905405  0.475177   [[134, 7], [7, 0]]  0.950355          0 -0.0496454   
1  0.885135  0.464539  [[131, 10], [7, 0]]  0.939068          0 -0.0589226   

  model_score   prec_c0    prec_c1    rec_c0    rec_c1  
9   0.0764948  0.956835   0.111111  0.943262  0.142857  
0   0.0195605  0.954198  0.0588235  0.886525  0.142857  
7           0  0.952703          0         1         0  
3  -0.0183773  0.952381          0  0.992908         0  
4  -0.0260782  0.952055          0  0.985816         0  
5  -0.0260782  0.952055          0  0.985816         0  
6  -0.0260782  0.952055          0  0.985816         0  
2  -0.0496454  0.950355          0  0.950355         0  
8  -0.0496454  0.950355          0  0.950355         0  
1  -0.0599791  0.949275          0  0.929078         0  
Elapsed time 20.96 mins 

************************************************************

pre/post: 50/0  win/stride: 500/50  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-21 17:31:48.854000 
pca_target: 0 	 poly degree: 0 	 kselect: 40 
Imbalance: None 
Extended target (count):  25141 13
('Total : Processed (count): ', (493L, 222L), 13)
Final feature (count):  (493L, 222L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.872 	0.037 	0.034 	0.525 	0.360 	0.120
[[128  13]
 [  6   1]]
             precision    recall  f1-score   support

        0.0       0.96      0.91      0.93       141
        1.0       0.07      0.14      0.10         7

avg / total       0.91      0.87      0.89       148


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=0.01, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='sag', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.899 	-0.053 	-0.053 	0.472 	0.000 	0.000
[[133   8]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.94      0.95       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.90      0.90       148


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.001, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='invscaling', loss='perceptron', n_iter=5, n_jobs=4,
       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.926 	-0.037 	-0.036 	0.486 	0.000 	0.000
[[137   4]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.97      0.96       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.93      0.92       148


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight='balanced',
           criterion='gini', max_depth=8, max_features=0.75,
           max_leaf_nodes=None, min_impurity_split=1e-07,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=15, n_jobs=4,
           oob_score=False, random_state=None, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.939 	-0.026 	-0.021 	0.493 	0.000 	0.000
[[139   2]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.99      0.97       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.94      0.92       148


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.953 	0.000 	0.000 	0.500 	0.000 	0.000
[[141   0]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      1.00      0.98       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.95      0.93       148


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.01, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.939 	-0.026 	-0.021 	0.493 	0.000 	0.000
[[139   2]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.99      0.97       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.94      0.92       148


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight='balanced', criterion='gini', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=2.0, n_estimators=50, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.946 	-0.018 	-0.012 	0.496 	0.000 	0.000
[[140   1]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.99      0.97       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.95      0.93       148


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.1, cache_size=200, class_weight={1: 50}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.872 	0.037 	0.034 	0.525 	0.360 	0.120
[[128  13]
 [  6   1]]
             precision    recall  f1-score   support

        0.0       0.96      0.91      0.93       141
        1.0       0.07      0.14      0.10         7

avg / total       0.91      0.87      0.89       148


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 500}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Ran...wski',
           metric_params=None, n_jobs=4, n_neighbors=4, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.946 	-0.018 	-0.012 	0.496 	0.000 	0.000
[[140   1]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.99      0.97       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.95      0.93       148


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=4,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.926 	-0.037 	-0.036 	0.486 	0.000 	0.000
[[137   4]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.97      0.96       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.93      0.92       148


                estimator   min_score   mean_score  max_score    sd_score  \
0              GaussianNB    0.073132     0.073132   0.073132           0   
7                     SVC  -0.0332807    0.0392648   0.158691   0.0508928   
4  RandomForestClassifier -0.00588235 -0.000335728          0  0.00104742   
6      AdaBoostClassifier  -0.0307267   0.00748992   0.265117   0.0516821   
8        VotingClassifier  -0.0174359  0.000514795   0.113759   0.0222635   
3    ExtraTreesClassifier  -0.0155116    0.0121824   0.218714   0.0466946   
5           MLPClassifier  -0.0251065   -0.0119513  0.0913339   0.0185271   
2           SGDClassifier  -0.0935557    0.0690674   0.308886   0.0589011   
9    KNeighborsClassifier  -0.0186391 -0.000135196  0.0507738   0.0145547   
1      LogisticRegression  -0.0152446    0.0958198   0.214843    0.058256   

        acc       auc          conf_matrix     f1_c0      f1_c1      kappa  \
0  0.871622  0.525329  [[128, 13], [6, 1]]  0.930909  0.0952381  0.0343407   
7  0.871622  0.525329  [[128, 13], [6, 1]]  0.930909  0.0952381  0.0343407   
4  0.952703       0.5   [[141, 0], [7, 0]]  0.975779          0          0   
6  0.945946  0.496454   [[140, 1], [7, 0]]  0.972222          0 -0.0119658   
8  0.945946  0.496454   [[140, 1], [7, 0]]  0.972222          0 -0.0119658   
3  0.939189  0.492908   [[139, 2], [7, 0]]  0.968641          0 -0.0214724   
5  0.939189  0.492908   [[139, 2], [7, 0]]  0.968641          0 -0.0214724   
2  0.925676  0.485816   [[137, 4], [7, 0]]  0.961404          0 -0.0356234   
9  0.925676  0.485816   [[137, 4], [7, 0]]  0.961404          0 -0.0356234   
1  0.898649  0.471631   [[133, 8], [7, 0]]  0.946619          0 -0.0531309   

  model_score   prec_c0    prec_c1    rec_c0    rec_c1  
0   0.0367447  0.955224  0.0714286  0.907801  0.142857  
7   0.0367447  0.955224  0.0714286  0.907801  0.142857  
4           0  0.952703          0         1         0  
6  -0.0183773  0.952381          0  0.992908         0  
8  -0.0183773  0.952381          0  0.992908         0  
3  -0.0260782  0.952055          0  0.985816         0  
5  -0.0260782  0.952055          0  0.985816         0  
2  -0.0371354  0.951389          0  0.971631         0  
9  -0.0371354  0.951389          0  0.971631         0  
1  -0.0532624      0.95          0  0.943262         0  
Elapsed time 16.99 mins 

************************************************************

pre/post: 50/0  win/stride: 500/50  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-21 17:48:48.036000 
pca_target: 0 	 poly degree: 0 	 kselect: 100 
Imbalance: ClusterCentroids(estimator=None, n_jobs=1, random_state=None, ratio='auto') 
Extended target (count):  25141 13
('Total : Processed (count): ', (493L, 222L), 13)
Final feature (count):  (493L, 222L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.750 	-0.040 	-0.029 	0.461 	0.334 	0.104
[[110  31]
 [  6   1]]
             precision    recall  f1-score   support

        0.0       0.95      0.78      0.86       141
        1.0       0.03      0.14      0.05         7

avg / total       0.90      0.75      0.82       148


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=5, class_weight={1: 50}, dual=False, fit_intercept=True,
          intercept_scaling=0.1, max_iter=100, multi_class='ovr', n_jobs=4,
          penalty='l2', random_state=None, solver='lbfgs', tol=0.0001,
          verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.635 	-0.089 	-0.051 	0.401 	0.307 	0.089
[[93 48]
 [ 6  1]]
             precision    recall  f1-score   support

        0.0       0.94      0.66      0.78       141
        1.0       0.02      0.14      0.04         7

avg / total       0.90      0.64      0.74       148


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=1, average=False, class_weight={1: 50}, epsilon=0.1,
       eta0=0.001, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='squared_hinge', n_iter=5, n_jobs=4,
       penalty='none', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.500 	-0.029 	-0.012 	0.466 	0.465 	0.214
[[71 70]
 [ 4  3]]
             precision    recall  f1-score   support

        0.0       0.95      0.50      0.66       141
        1.0       0.04      0.43      0.07         7

avg / total       0.90      0.50      0.63       148


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=8, max_features=0.75, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=30, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.588 	0.069 	0.034 	0.580 	0.580 	0.336
[[83 58]
 [ 3  4]]
             precision    recall  f1-score   support

        0.0       0.97      0.59      0.73       141
        1.0       0.06      0.57      0.12         7

avg / total       0.92      0.59      0.70       148


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features=0.33, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.541 	0.105 	0.046 	0.623 	0.616 	0.387
[[75 66]
 [ 2  5]]
             precision    recall  f1-score   support

        0.0       0.97      0.53      0.69       141
        1.0       0.07      0.71      0.13         7

avg / total       0.93      0.54      0.66       148


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.01, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.723 	-0.052 	-0.035 	0.447 	0.328 	0.101
[[106  35]
 [  6   1]]
             precision    recall  f1-score   support

        0.0       0.95      0.75      0.84       141
        1.0       0.03      0.14      0.05         7

avg / total       0.90      0.72      0.80       148


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='entropy', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=2.0, n_estimators=15, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.209 	0.019 	0.004 	0.517 	0.390 	0.162
[[ 25 116]
 [  1   6]]
             precision    recall  f1-score   support

        0.0       0.96      0.18      0.30       141
        1.0       0.05      0.86      0.09         7

avg / total       0.92      0.21      0.29       148


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.01, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='linear',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.216 	0.100 	0.020 	0.589 	0.421 	0.192
[[ 25 116]
 [  0   7]]
             precision    recall  f1-score   support

        0.0       1.00      0.18      0.30       141
        1.0       0.06      1.00      0.11         7

avg / total       0.96      0.22      0.29       148


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...owski',
           metric_params=None, n_jobs=4, n_neighbors=4, p=2,
           weights='uniform'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.608 	-0.040 	-0.021 	0.455 	0.422 	0.172
[[88 53]
 [ 5  2]]
             precision    recall  f1-score   support

        0.0       0.95      0.62      0.75       141
        1.0       0.04      0.29      0.06         7

avg / total       0.90      0.61      0.72       148


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=6, p=1,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.899 	-0.053 	-0.053 	0.472 	0.000 	0.000
[[133   8]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.94      0.95       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.90      0.90       148


                estimator  min_score mean_score max_score  sd_score       acc  \
4  RandomForestClassifier   -0.69245   0.196514  0.833333  0.207193  0.540541   
7                     SVC  -0.359117 -0.0634152         0  0.101577  0.216216   
3    ExtraTreesClassifier   -0.19245   0.301105  0.666667  0.179039  0.587838   
6      AdaBoostClassifier  -0.666667  0.0626551   0.69245  0.257697  0.209459   
9    KNeighborsClassifier  -0.666667  -0.426873   0.19245  0.203044  0.898649   
2           SGDClassifier  -0.833333   0.101827  0.833333  0.281641       0.5   
0              GaussianNB        0.5        0.5       0.5         0      0.75   
8        VotingClassifier  -0.525783   0.134187   0.69245  0.169702  0.608108   
5           MLPClassifier  -0.525783  -0.156078  0.333333  0.195855  0.722973   
1      LogisticRegression -0.0257834   0.216454   0.69245  0.197572  0.635135   

        auc          conf_matrix     f1_c0      f1_c1       kappa model_score  \
4    0.6231   [[75, 66], [2, 5]]  0.688073   0.128205   0.0460664     0.10461   
7  0.588652  [[25, 116], [0, 7]]  0.301205   0.107692   0.0199794    0.100452   
3  0.580041   [[83, 58], [3, 4]]  0.731278   0.115942   0.0338185   0.0688737   
6  0.517224  [[25, 116], [1, 6]]  0.299401  0.0930233  0.00391164   0.0192156   
9  0.471631   [[133, 8], [7, 0]]  0.946619          0  -0.0531309  -0.0532624   
2  0.466059   [[71, 70], [4, 3]]  0.657407      0.075  -0.0123868   -0.028822   
0  0.461499  [[110, 31], [6, 1]]  0.856031  0.0512821    -0.02855  -0.0397055   
8  0.454914   [[88, 53], [5, 2]]  0.752137  0.0645161  -0.0211754  -0.0396103   
5  0.447315  [[106, 35], [6, 1]]  0.837945  0.0465116  -0.0354949  -0.0521332   
1  0.401216   [[93, 48], [6, 1]]     0.775  0.0357143  -0.0513023   -0.089117   

    prec_c0    prec_c1    rec_c0    rec_c1  
4  0.974026  0.0704225  0.531915  0.714286  
7         1  0.0569106  0.177305         1  
3  0.965116  0.0645161  0.588652  0.571429  
6  0.961538  0.0491803  0.177305  0.857143  
9      0.95          0  0.943262         0  
2  0.946667  0.0410959  0.503546  0.428571  
0  0.948276    0.03125  0.780142  0.142857  
8  0.946237  0.0363636  0.624113  0.285714  
5  0.946429  0.0277778  0.751773  0.142857  
1  0.939394  0.0204082  0.659574  0.142857  
Elapsed time 15.06 mins 

************************************************************

pre/post: 50/0  win/stride: 500/50  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-21 18:03:51.383000 
pca_target: 0 	 poly degree: 0 	 kselect: 100 
Imbalance: SMOTE(k=None, k_neighbors=5, kind='regular', m=None, m_neighbors=10, n_jobs=1,
   out_step=0.5, random_state=None, ratio='auto', svm_estimator=None) 
Extended target (count):  25141 13
('Total : Processed (count): ', (493L, 222L), 13)
Final feature (count):  (493L, 222L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.892 	-0.057 	-0.056 	0.468 	0.000 	0.000
[[132   9]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.94      0.94       141
        1.0       0.00      0.00      0.00         7

avg / total       0.90      0.89      0.90       148


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=5, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='sag', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.899 	-0.053 	-0.053 	0.472 	0.000 	0.000
[[133   8]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.94      0.95       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.90      0.90       148


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.001, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='perceptron', n_iter=5, n_jobs=4,
       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.892 	-0.057 	-0.056 	0.468 	0.000 	0.000
[[132   9]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.94      0.94       141
        1.0       0.00      0.00      0.00         7

avg / total       0.90      0.89      0.90       148


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=None, max_features='auto', max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=30, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.946 	-0.018 	-0.012 	0.496 	0.000 	0.000
[[140   1]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.99      0.97       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.95      0.93       148


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3},
            criterion='entropy', max_depth=16, max_features='auto',
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=15, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.953 	0.000 	0.000 	0.500 	0.000 	0.000
[[141   0]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      1.00      0.98       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.95      0.93       148


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.01, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.932 	-0.032 	-0.029 	0.489 	0.000 	0.000
[[138   3]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.98      0.97       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.93      0.92       148


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=8,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=1.0, n_estimators=80, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.946 	-0.018 	-0.012 	0.496 	0.000 	0.000
[[140   1]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.99      0.97       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.95      0.93       148


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.5, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.953 	0.000 	0.000 	0.500 	0.000 	0.000
[[141   0]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      1.00      0.98       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.95      0.93       148


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=10.0, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', ...owski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='uniform'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.939 	-0.026 	-0.021 	0.493 	0.000 	0.000
[[139   2]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.99      0.97       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.94      0.92       148


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=1,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.899 	-0.053 	-0.053 	0.472 	0.000 	0.000
[[133   8]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.94      0.95       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.90      0.90       148


                estimator  min_score mean_score max_score    sd_score  \
4  RandomForestClassifier   0.965136    0.97879  0.988409  0.00434313   
7                     SVC          0   0.790297         1    0.323628   
3    ExtraTreesClassifier   0.918374   0.983945  0.997072   0.0136211   
6      AdaBoostClassifier   0.910909   0.963301  0.997072   0.0166769   
8        VotingClassifier   0.870237   0.939855  0.973894   0.0240199   
5           MLPClassifier   0.945491   0.963603  0.985483   0.0109225   
1      LogisticRegression  0.0847583   0.755759  0.928922    0.198714   
9    KNeighborsClassifier   0.786551   0.861725  0.937276   0.0497693   
0              GaussianNB   0.934465   0.934465  0.934465           0   
2           SGDClassifier -0.0170064   0.609497  0.959574    0.260301   

        acc       auc         conf_matrix     f1_c0 f1_c1      kappa  \
4  0.952703       0.5  [[141, 0], [7, 0]]  0.975779     0          0   
7  0.952703       0.5  [[141, 0], [7, 0]]  0.975779     0          0   
3  0.945946  0.496454  [[140, 1], [7, 0]]  0.972222     0 -0.0119658   
6  0.945946  0.496454  [[140, 1], [7, 0]]  0.972222     0 -0.0119658   
8  0.939189  0.492908  [[139, 2], [7, 0]]  0.968641     0 -0.0214724   
5  0.932432  0.489362  [[138, 3], [7, 0]]  0.965035     0 -0.0292072   
1  0.898649  0.471631  [[133, 8], [7, 0]]  0.946619     0 -0.0531309   
9  0.898649  0.471631  [[133, 8], [7, 0]]  0.946619     0 -0.0531309   
0  0.891892  0.468085  [[132, 9], [7, 0]]  0.942857     0 -0.0561998   
2  0.891892  0.468085  [[132, 9], [7, 0]]  0.942857     0 -0.0561998   

  model_score   prec_c0 prec_c1    rec_c0 rec_c1  
4           0  0.952703       0         1      0  
7           0  0.952703       0         1      0  
3  -0.0183773  0.952381       0  0.992908      0  
6  -0.0183773  0.952381       0  0.992908      0  
8  -0.0260782  0.952055       0  0.985816      0  
5  -0.0320491  0.951724       0  0.978723      0  
1  -0.0532624      0.95       0  0.943262      0  
9  -0.0532624      0.95       0  0.943262      0  
0  -0.0566961   0.94964       0   0.93617      0  
2  -0.0566961   0.94964       0   0.93617      0  
Elapsed time 24.65 mins 

************************************************************

pre/post: 50/0  win/stride: 500/50  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-21 18:28:30.549000 
pca_target: 0 	 poly degree: 0 	 kselect: 100 
Imbalance: None 
Extended target (count):  25141 13
('Total : Processed (count): ', (493L, 222L), 13)
Final feature (count):  (493L, 222L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.845 	-0.078 	-0.070 	0.443 	0.000 	0.000
[[125  16]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.89      0.92       141
        1.0       0.00      0.00      0.00         7

avg / total       0.90      0.84      0.87       148


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.001, class_weight={1: 50}, dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.574 	0.004 	0.002 	0.505 	0.499 	0.245
[[82 59]
 [ 4  3]]
             precision    recall  f1-score   support

        0.0       0.95      0.58      0.72       141
        1.0       0.05      0.43      0.09         7

avg / total       0.91      0.57      0.69       148


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.5, average=False, class_weight={1: 15}, epsilon=0.1,
       eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='modified_huber', n_iter=5, n_jobs=4,
       penalty='l1', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.953 	0.000 	0.000 	0.500 	0.000 	0.000
[[141   0]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      1.00      0.98       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.95      0.93       148


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 500},
           criterion='entropy', max_depth=8, max_features=0.33,
           max_leaf_nodes=None, min_impurity_split=1e-07,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=4,
           oob_score=False, random_state=None, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.939 	-0.026 	-0.021 	0.493 	0.000 	0.000
[[139   2]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.99      0.97       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.94      0.92       148


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.953 	0.000 	0.000 	0.500 	0.000 	0.000
[[141   0]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      1.00      0.98       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.95      0.93       148


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.01, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.932 	-0.032 	-0.029 	0.489 	0.000 	0.000
[[138   3]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.98      0.97       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.93      0.92       148


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=0.5, n_estimators=50, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.953 	0.000 	0.000 	0.500 	0.000 	0.000
[[141   0]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      1.00      0.98       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.95      0.93       148


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.1, cache_size=200, class_weight='balanced', coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.845 	-0.078 	-0.070 	0.443 	0.000 	0.000
[[125  16]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.89      0.92       141
        1.0       0.00      0.00      0.00         7

avg / total       0.90      0.84      0.87       148


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=1.0, class_weight={1: 500}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Ran...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.946 	-0.018 	-0.012 	0.496 	0.000 	0.000
[[140   1]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.99      0.97       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.95      0.93       148


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=3,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.905 	-0.050 	-0.050 	0.475 	0.000 	0.000
[[134   7]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.95      0.95       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.91      0.91       148


                estimator   min_score   mean_score max_score     sd_score  \
1      LogisticRegression  -0.0563062    0.0250264  0.151287    0.0458747   
2           SGDClassifier  -0.0919019    0.0427749  0.257905    0.0514261   
4  RandomForestClassifier -0.00418904 -6.06558e-05         0  0.000435018   
6      AdaBoostClassifier  -0.0297364   0.00358563  0.195808     0.045885   
8        VotingClassifier  -0.0100734   0.00950074  0.197059    0.0393591   
3    ExtraTreesClassifier  -0.0195692   0.00167569  0.133245    0.0173648   
5           MLPClassifier  -0.0228768    0.0282717  0.194829    0.0695047   
9    KNeighborsClassifier  -0.0113219    0.0280389  0.190352    0.0654943   
0              GaussianNB     0.21001      0.21001   0.21001            0   
7                     SVC  -0.0316552 -0.000207285  0.146993    0.0296179   

        acc       auc          conf_matrix     f1_c0      f1_c1       kappa  \
1  0.574324  0.505066   [[82, 59], [4, 3]]  0.722467  0.0869565  0.00214041   
2  0.952703       0.5   [[141, 0], [7, 0]]  0.975779          0           0   
4  0.952703       0.5   [[141, 0], [7, 0]]  0.975779          0           0   
6  0.952703       0.5   [[141, 0], [7, 0]]  0.975779          0           0   
8  0.945946  0.496454   [[140, 1], [7, 0]]  0.972222          0  -0.0119658   
3  0.939189  0.492908   [[139, 2], [7, 0]]  0.968641          0  -0.0214724   
5  0.932432  0.489362   [[138, 3], [7, 0]]  0.965035          0  -0.0292072   
9  0.905405  0.475177   [[134, 7], [7, 0]]  0.950355          0  -0.0496454   
0  0.844595  0.443262  [[125, 16], [7, 0]]  0.915751          0  -0.0704403   
7  0.844595  0.443262  [[125, 16], [7, 0]]  0.915751          0  -0.0704403   

  model_score   prec_c0    prec_c1    rec_c0    rec_c1  
1   0.0043591  0.953488  0.0483871   0.58156  0.428571  
2           0  0.952703          0         1         0  
4           0  0.952703          0         1         0  
6           0  0.952703          0         1         0  
8  -0.0183773  0.952381          0  0.992908         0  
3  -0.0260782  0.952055          0  0.985816         0  
5  -0.0320491  0.951724          0  0.978723         0  
9  -0.0496454  0.950355          0  0.950355         0  
0  -0.0775733   0.94697          0  0.886525         0  
7  -0.0775733   0.94697          0  0.886525         0  
Elapsed time 17.90 mins 

************************************************************

pre/post: 50/0  win/stride: 500/50  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-21 18:46:24.545000 
pca_target: 0 	 poly degree: 2 	 kselect: 40 
Imbalance: ClusterCentroids(estimator=None, n_jobs=1, random_state=None, ratio='auto') 
Extended target (count):  25141 13
('Total : Processed (count): ', (493L, 24976L), 13)
Final feature (count):  (493L, 24976L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.784 	0.050 	0.038 	0.547 	0.481 	0.219
[[114  27]
 [  5   2]]
             precision    recall  f1-score   support

        0.0       0.96      0.81      0.88       141
        1.0       0.07      0.29      0.11         7

avg / total       0.92      0.78      0.84       148


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.001, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.730 	0.083 	0.055 	0.587 	0.565 	0.309
[[105  36]
 [  4   3]]
             precision    recall  f1-score   support

        0.0       0.96      0.74      0.84       141
        1.0       0.08      0.43      0.13         7

avg / total       0.92      0.73      0.81       148


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.0001, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='perceptron', n_iter=5, n_jobs=4,
       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.743 	0.092 	0.062 	0.594 	0.570 	0.314
[[107  34]
 [  4   3]]
             precision    recall  f1-score   support

        0.0       0.96      0.76      0.85       141
        1.0       0.08      0.43      0.14         7

avg / total       0.92      0.74      0.82       148


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=8, max_features='auto', max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=30, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.459 	0.011 	0.004 	0.513 	0.509 	0.262
[[64 77]
 [ 3  4]]
             precision    recall  f1-score   support

        0.0       0.96      0.45      0.62       141
        1.0       0.05      0.57      0.09         7

avg / total       0.91      0.46      0.59       148


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=30, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.453 	0.008 	0.003 	0.509 	0.505 	0.259
[[63 78]
 [ 3  4]]
             precision    recall  f1-score   support

        0.0       0.95      0.45      0.61       141
        1.0       0.05      0.57      0.09         7

avg / total       0.91      0.45      0.58       148


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.716 	0.075 	0.048 	0.580 	0.560 	0.304
[[103  38]
 [  4   3]]
             precision    recall  f1-score   support

        0.0       0.96      0.73      0.83       141
        1.0       0.07      0.43      0.12         7

avg / total       0.92      0.72      0.80       148


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=0.5, n_estimators=15, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.466 	-0.044 	-0.018 	0.448 	0.448 	0.200
[[66 75]
 [ 4  3]]
             precision    recall  f1-score   support

        0.0       0.94      0.47      0.63       141
        1.0       0.04      0.43      0.07         7

avg / total       0.90      0.47      0.60       148


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.1, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='linear',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.628 	0.029 	0.016 	0.533 	0.523 	0.268
[[90 51]
 [ 4  3]]
             precision    recall  f1-score   support

        0.0       0.96      0.64      0.77       141
        1.0       0.06      0.43      0.10         7

avg / total       0.91      0.63      0.73       148


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.486 	0.081 	0.032 	0.595 	0.583 	0.348
[[67 74]
 [ 2  5]]
             precision    recall  f1-score   support

        0.0       0.97      0.48      0.64       141
        1.0       0.06      0.71      0.12         7

avg / total       0.93      0.49      0.61       148


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=4,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.764 	0.105 	0.074 	0.604 	0.578 	0.323
[[110  31]
 [  4   3]]
             precision    recall  f1-score   support

        0.0       0.96      0.78      0.86       141
        1.0       0.09      0.43      0.15         7

avg / total       0.92      0.76      0.83       148


                estimator min_score mean_score max_score   sd_score       acc  \
9    KNeighborsClassifier  0.666667   0.837093         1   0.112407  0.763514   
8        VotingClassifier   0.69245   0.820941  0.833333  0.0399039  0.486486   
2           SGDClassifier  -0.19245   0.455295         1   0.247438  0.743243   
1      LogisticRegression         0   0.542961         1   0.421638   0.72973   
5           MLPClassifier  0.859117   0.973584         1  0.0549885  0.716216   
0              GaussianNB  0.859117   0.859117  0.859117          0  0.783784   
7                     SVC         0   0.641045         1   0.437761  0.628378   
3    ExtraTreesClassifier  0.666667    0.76771         1   0.120766  0.459459   
4  RandomForestClassifier   0.69245   0.989175         1  0.0421547  0.452703   
6      AdaBoostClassifier  0.333333   0.862392         1   0.141319  0.466216   

        auc          conf_matrix     f1_c0      f1_c1       kappa model_score  \
9  0.604357  [[110, 31], [4, 3]]  0.862745   0.146341   0.0736767    0.105321   
8  0.594732   [[67, 74], [2, 5]]  0.638095   0.116279   0.0321803   0.0806204   
2  0.593718  [[107, 34], [4, 3]]  0.849206   0.136364   0.0617284   0.0918863   
1  0.586626  [[105, 36], [4, 3]]      0.84   0.130435   0.0546151   0.0834818   
5  0.579534  [[103, 38], [4, 3]]  0.830645      0.125   0.0480858   0.0754497   
0  0.547112  [[114, 27], [5, 2]]  0.876923   0.111111   0.0377895   0.0503909   
7  0.533435   [[90, 51], [4, 3]]  0.765957  0.0983607   0.0159574   0.0294866   
3  0.512665   [[64, 77], [3, 4]]  0.615385  0.0909091  0.00420521   0.0108019   
4  0.509119   [[63, 78], [3, 4]]  0.608696  0.0898876  0.00299401  0.00778816   
6  0.448328   [[66, 75], [4, 3]]  0.625592  0.0705882  -0.0177577  -0.0439385   

    prec_c0    prec_c1    rec_c0    rec_c1  
9  0.964912  0.0882353  0.780142  0.428571  
8  0.971014  0.0632911  0.475177  0.714286  
2  0.963964  0.0810811  0.758865  0.428571  
1  0.963303  0.0769231  0.744681  0.428571  
5  0.962617  0.0731707  0.730496  0.428571  
0  0.957983  0.0689655  0.808511  0.285714  
7  0.957447  0.0555556  0.638298  0.428571  
3  0.955224  0.0493827  0.453901  0.571429  
4  0.954545  0.0487805  0.446809  0.571429  
6  0.942857  0.0384615  0.468085  0.428571  
Elapsed time 15.45 mins 

************************************************************

pre/post: 50/0  win/stride: 500/50  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-21 19:01:51.308000 
pca_target: 0 	 poly degree: 2 	 kselect: 40 
Imbalance: SMOTE(k=None, k_neighbors=5, kind='regular', m=None, m_neighbors=10, n_jobs=1,
   out_step=0.5, random_state=None, ratio='auto', svm_estimator=None) 
Extended target (count):  25141 13
('Total : Processed (count): ', (493L, 24976L), 13)
Final feature (count):  (493L, 24976L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.676 	0.053 	0.031 	0.558 	0.543 	0.287
[[97 44]
 [ 4  3]]
             precision    recall  f1-score   support

        0.0       0.96      0.69      0.80       141
        1.0       0.06      0.43      0.11         7

avg / total       0.92      0.68      0.77       148


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=5, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=5, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.804 	0.064 	0.050 	0.558 	0.487 	0.224
[[117  24]
 [  5   2]]
             precision    recall  f1-score   support

        0.0       0.96      0.83      0.89       141
        1.0       0.08      0.29      0.12         7

avg / total       0.92      0.80      0.85       148


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.001, average=False, class_weight='balanced',
       epsilon=0.1, eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='invscaling', loss='perceptron', n_iter=5, n_jobs=4,
       penalty='l2', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.750 	-0.112 	-0.083 	0.394 	0.000 	0.000
[[111  30]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.94      0.79      0.86       141
        1.0       0.00      0.00      0.00         7

avg / total       0.90      0.75      0.82       148


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 500}, criterion='gini',
           max_depth=32, max_features=0.33, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.926 	-0.037 	-0.036 	0.486 	0.000 	0.000
[[137   4]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.97      0.96       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.93      0.92       148


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight='balanced',
            criterion='entropy', max_depth=32, max_features='auto',
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.899 	-0.053 	-0.053 	0.472 	0.000 	0.000
[[133   8]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.94      0.95       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.90      0.90       148


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.01, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.919 	-0.042 	-0.041 	0.482 	0.000 	0.000
[[136   5]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.96      0.96       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.92      0.91       148


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 50}, criterion='gini', max_depth=8,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=1.0, n_estimators=50, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.926 	-0.037 	-0.036 	0.486 	0.000 	0.000
[[137   4]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.97      0.96       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.93      0.92       148


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=10, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.905 	-0.050 	-0.050 	0.475 	0.000 	0.000
[[134   7]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.95      0.95       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.91      0.91       148


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=10.0, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', ...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.885 	-0.060 	-0.059 	0.465 	0.000 	0.000
[[131  10]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.93      0.94       141
        1.0       0.00      0.00      0.00         7

avg / total       0.90      0.89      0.89       148


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=4,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.899 	-0.053 	-0.053 	0.472 	0.000 	0.000
[[133   8]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.94      0.95       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.90      0.90       148


                estimator min_score mean_score max_score   sd_score       acc  \
0              GaussianNB  0.737962   0.737962  0.737962          0  0.675676   
1      LogisticRegression  0.188801   0.648581  0.807265   0.117319  0.804054   
3    ExtraTreesClassifier  0.774187   0.953324  0.991337  0.0400067  0.925676   
6      AdaBoostClassifier   0.87937   0.946766  0.988328  0.0210307  0.925676   
5           MLPClassifier  0.934474   0.960599  0.982554   0.010978  0.918919   
7                     SVC         0   0.694627  0.962127   0.199326  0.905405   
4  RandomForestClassifier  0.922497   0.959802  0.982554  0.0103258  0.898649   
9    KNeighborsClassifier  0.816222   0.870286  0.937412  0.0368391  0.898649   
8        VotingClassifier  0.818674   0.896226  0.945925  0.0289324  0.885135   
2           SGDClassifier -0.185029    0.55734  0.834129   0.195138      0.75   

        auc          conf_matrix     f1_c0     f1_c1      kappa model_score  \
0  0.558257   [[97, 44], [4, 3]]  0.801653  0.111111  0.0313608   0.0531288   
1  0.557751  [[117, 24], [5, 2]]  0.889734  0.121212  0.0504425   0.0644287   
3  0.485816   [[137, 4], [7, 0]]  0.961404         0 -0.0356234  -0.0371354   
6  0.485816   [[137, 4], [7, 0]]  0.961404         0 -0.0356234  -0.0371354   
5   0.48227   [[136, 5], [7, 0]]  0.957746         0 -0.0410317  -0.0416636   
7  0.475177   [[134, 7], [7, 0]]  0.950355         0 -0.0496454  -0.0496454   
4  0.471631   [[133, 8], [7, 0]]  0.946619         0 -0.0531309  -0.0532624   
9  0.471631   [[133, 8], [7, 0]]  0.946619         0 -0.0531309  -0.0532624   
8  0.464539  [[131, 10], [7, 0]]  0.939068         0 -0.0589226  -0.0599791   
2  0.393617  [[111, 30], [7, 0]]  0.857143         0 -0.0830696   -0.112346   

    prec_c0    prec_c1    rec_c0    rec_c1  
0  0.960396  0.0638298  0.687943  0.428571  
1  0.959016  0.0769231  0.829787  0.285714  
3  0.951389          0  0.971631         0  
6  0.951389          0  0.971631         0  
5  0.951049          0  0.964539         0  
7  0.950355          0  0.950355         0  
4      0.95          0  0.943262         0  
9      0.95          0  0.943262         0  
8  0.949275          0  0.929078         0  
2  0.940678          0  0.787234         0  
Elapsed time 27.08 mins 

************************************************************

pre/post: 50/0  win/stride: 500/50  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-21 19:28:55.971000 
pca_target: 0 	 poly degree: 2 	 kselect: 40 
Imbalance: None 
Extended target (count):  25141 13
('Total : Processed (count): ', (493L, 24976L), 13)
Final feature (count):  (493L, 24976L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.831 	-0.083 	-0.073 	0.436 	0.000 	0.000
[[123  18]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.87      0.91       141
        1.0       0.00      0.00      0.00         7

avg / total       0.90      0.83      0.86       148


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.001, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.946 	-0.018 	-0.012 	0.496 	0.000 	0.000
[[140   1]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.99      0.97       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.95      0.93       148


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.1, average=False, class_weight='balanced', epsilon=0.1,
       eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='invscaling', loss='squared_hinge', n_iter=5,
       n_jobs=4, penalty='l2', power_t=0.5, random_state=None,
       shuffle=True, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.628 	-0.031 	-0.017 	0.466 	0.429 	0.178
[[91 50]
 [ 5  2]]
             precision    recall  f1-score   support

        0.0       0.95      0.65      0.77       141
        1.0       0.04      0.29      0.07         7

avg / total       0.90      0.63      0.73       148


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight='balanced',
           criterion='gini', max_depth=32, max_features=0.75,
           max_leaf_nodes=None, min_impurity_split=1e-07,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=15, n_jobs=4,
           oob_score=False, random_state=None, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.946 	-0.018 	-0.012 	0.496 	0.000 	0.000
[[140   1]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.99      0.97       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.95      0.93       148


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 50}, criterion='gini',
            max_depth=32, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.953 	0.000 	0.000 	0.500 	0.000 	0.000
[[141   0]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      1.00      0.98       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.95      0.93       148


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.926 	-0.037 	-0.036 	0.486 	0.000 	0.000
[[137   4]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.97      0.96       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.93      0.92       148


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='entropy', max_depth=32,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=1.0, n_estimators=50, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.926 	-0.037 	-0.036 	0.486 	0.000 	0.000
[[137   4]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.97      0.96       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.93      0.92       148


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=10, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='linear',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.939 	-0.026 	-0.021 	0.493 	0.000 	0.000
[[139   2]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.99      0.97       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.94      0.92       148


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 500}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Ran...owski',
           metric_params=None, n_jobs=4, n_neighbors=4, p=2,
           weights='uniform'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.946 	-0.018 	-0.012 	0.496 	0.000 	0.000
[[140   1]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.99      0.97       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.95      0.93       148


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=3,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.926 	-0.037 	-0.036 	0.486 	0.000 	0.000
[[137   4]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.97      0.96       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.93      0.92       148


                estimator   min_score   mean_score  max_score   sd_score  \
4  RandomForestClassifier  -0.0169874  0.000271984  0.0984655  0.0161714   
1      LogisticRegression  -0.0333575    0.0934959   0.275599  0.0712003   
3    ExtraTreesClassifier  -0.0344754  -0.00786277  0.0726577  0.0164632   
8        VotingClassifier  -0.0186857 -0.000638802   0.195811  0.0265563   
7                     SVC  -0.0454742    0.0324536   0.260507   0.054588   
5           MLPClassifier  -0.0279713   -0.0150453  0.0820984  0.0153175   
6      AdaBoostClassifier  -0.0289767    0.0388763   0.389358  0.0746123   
9    KNeighborsClassifier -0.00890942   0.00923722  0.0426604  0.0178294   
2           SGDClassifier   -0.116124    0.0581053   0.309552  0.0582867   
0              GaussianNB   0.0766593    0.0766593  0.0766593          0   

        acc       auc          conf_matrix     f1_c0      f1_c1      kappa  \
4  0.952703       0.5   [[141, 0], [7, 0]]  0.975779          0          0   
1  0.945946  0.496454   [[140, 1], [7, 0]]  0.972222          0 -0.0119658   
3  0.945946  0.496454   [[140, 1], [7, 0]]  0.972222          0 -0.0119658   
8  0.945946  0.496454   [[140, 1], [7, 0]]  0.972222          0 -0.0119658   
7  0.939189  0.492908   [[139, 2], [7, 0]]  0.968641          0 -0.0214724   
5  0.925676  0.485816   [[137, 4], [7, 0]]  0.961404          0 -0.0356234   
6  0.925676  0.485816   [[137, 4], [7, 0]]  0.961404          0 -0.0356234   
9  0.925676  0.485816   [[137, 4], [7, 0]]  0.961404          0 -0.0356234   
2  0.628378  0.465552   [[91, 50], [5, 2]]  0.767932  0.0677966 -0.0169915   
0  0.831081   0.43617  [[123, 18], [7, 0]]  0.907749          0 -0.0730858   

  model_score   prec_c0    prec_c1    rec_c0    rec_c1  
4           0  0.952703          0         1         0  
1  -0.0183773  0.952381          0  0.992908         0  
3  -0.0183773  0.952381          0  0.992908         0  
8  -0.0183773  0.952381          0  0.992908         0  
7  -0.0260782  0.952055          0  0.985816         0  
5  -0.0371354  0.951389          0  0.971631         0  
6  -0.0371354  0.951389          0  0.971631         0  
9  -0.0371354  0.951389          0  0.971631         0  
2  -0.0306347  0.947917  0.0384615   0.64539  0.285714  
0  -0.0829095  0.946154          0   0.87234         0  
Elapsed time 18.76 mins 

************************************************************

pre/post: 50/0  win/stride: 500/50  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-21 19:47:41.502000 
pca_target: 0 	 poly degree: 2 	 kselect: 100 
Imbalance: ClusterCentroids(estimator=None, n_jobs=1, random_state=None, ratio='auto') 
Extended target (count):  25141 13
('Total : Processed (count): ', (493L, 24976L), 13)
Final feature (count):  (493L, 24976L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.851 	0.020 	0.018 	0.515 	0.356 	0.117
[[125  16]
 [  6   1]]
             precision    recall  f1-score   support

        0.0       0.95      0.89      0.92       141
        1.0       0.06      0.14      0.08         7

avg / total       0.91      0.85      0.88       148


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=1, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.757 	0.165 	0.111 	0.669 	0.662 	0.429
[[108  33]
 [  3   4]]
             precision    recall  f1-score   support

        0.0       0.97      0.77      0.86       141
        1.0       0.11      0.57      0.18         7

avg / total       0.93      0.76      0.83       148


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.1, average=False, class_weight='balanced', epsilon=0.1,
       eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='constant', loss='modified_huber', n_iter=5, n_jobs=4,
       penalty='l2', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.770 	0.042 	0.030 	0.540 	0.476 	0.215
[[112  29]
 [  5   2]]
             precision    recall  f1-score   support

        0.0       0.96      0.79      0.87       141
        1.0       0.06      0.29      0.11         7

avg / total       0.92      0.77      0.83       148


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=8, max_features='auto', max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=30, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.466 	0.072 	0.028 	0.584 	0.569 	0.333
[[64 77]
 [ 2  5]]
             precision    recall  f1-score   support

        0.0       0.97      0.45      0.62       141
        1.0       0.06      0.71      0.11         7

avg / total       0.93      0.47      0.59       148


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.466 	0.014 	0.005 	0.516 	0.513 	0.266
[[65 76]
 [ 3  4]]
             precision    recall  f1-score   support

        0.0       0.96      0.46      0.62       141
        1.0       0.05      0.57      0.09         7

avg / total       0.91      0.47      0.60       148


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.696 	0.064 	0.039 	0.569 	0.551 	0.295
[[100  41]
 [  4   3]]
             precision    recall  f1-score   support

        0.0       0.96      0.71      0.82       141
        1.0       0.07      0.43      0.12         7

avg / total       0.92      0.70      0.78       148


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=1.0, n_estimators=50, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.453 	0.008 	0.003 	0.509 	0.505 	0.259
[[63 78]
 [ 3  4]]
             precision    recall  f1-score   support

        0.0       0.95      0.45      0.61       141
        1.0       0.05      0.57      0.09         7

avg / total       0.91      0.45      0.58       148


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.878 	0.043 	0.041 	0.529 	0.362 	0.121
[[129  12]
 [  6   1]]
             precision    recall  f1-score   support

        0.0       0.96      0.91      0.93       141
        1.0       0.08      0.14      0.10         7

avg / total       0.91      0.88      0.90       148


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.628 	0.205 	0.103 	0.737 	0.727 	0.542
[[87 54]
 [ 1  6]]
             precision    recall  f1-score   support

        0.0       0.99      0.62      0.76       141
        1.0       0.10      0.86      0.18         7

avg / total       0.95      0.63      0.73       148


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=1,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.662 	0.166 	0.091 	0.687 	0.686 	0.474
[[93 48]
 [ 2  5]]
             precision    recall  f1-score   support

        0.0       0.98      0.66      0.79       141
        1.0       0.09      0.71      0.17         7

avg / total       0.94      0.66      0.76       148


                estimator min_score mean_score max_score   sd_score       acc  \
8        VotingClassifier  0.666667   0.841049         1   0.156124  0.628378   
9    KNeighborsClassifier  0.525783   0.734865  0.859117  0.0923989  0.662162   
1      LogisticRegression         0   0.561832         1   0.358705  0.756757   
3    ExtraTreesClassifier  0.525783   0.840679         1  0.0839035  0.466216   
5           MLPClassifier  0.833333   0.996528         1  0.0238044  0.695946   
2           SGDClassifier  -0.19245   0.499594         1    0.17686   0.77027   
7                     SVC         0   0.555059         1   0.347639  0.878378   
4  RandomForestClassifier  0.666667   0.908873         1  0.0859376  0.466216   
0              GaussianNB       0.5        0.5       0.5          0  0.851351   
6      AdaBoostClassifier  0.140883   0.692304         1   0.204882  0.452703   

        auc          conf_matrix     f1_c0      f1_c1       kappa model_score  \
8  0.737082   [[87, 54], [1, 6]]  0.759825   0.179104    0.103129    0.205008   
9   0.68693   [[93, 48], [2, 5]]  0.788136   0.166667   0.0906857    0.165527   
1  0.668693  [[108, 33], [3, 4]]  0.857143   0.181818    0.111111    0.165395   
3  0.584093   [[64, 77], [2, 5]]  0.618357    0.11236   0.0276114   0.0718242   
5  0.568896  [[100, 41], [4, 3]]  0.816327   0.117647   0.0392383   0.0639937   
2   0.54002  [[112, 29], [5, 2]]  0.868217   0.105263   0.0304432   0.0417537   
7  0.528875  [[129, 12], [6, 1]]  0.934783        0.1   0.0410367    0.043309   
4  0.516211   [[65, 76], [3, 4]]   0.62201   0.091954  0.00544403   0.0138099   
0  0.514691  [[125, 16], [6, 1]]  0.919118  0.0833333   0.0175015   0.0195605   
6  0.509119   [[63, 78], [3, 4]]  0.608696  0.0898876  0.00299401  0.00778816   

    prec_c0    prec_c1    rec_c0    rec_c1  
8  0.988636        0.1  0.617021  0.857143  
9  0.978947  0.0943396  0.659574  0.714286  
1  0.972973   0.108108  0.765957  0.571429  
3  0.969697  0.0609756  0.453901  0.714286  
5  0.961538  0.0681818   0.70922  0.428571  
2  0.957265  0.0645161  0.794326  0.285714  
7  0.955556  0.0769231  0.914894  0.142857  
4  0.955882       0.05  0.460993  0.571429  
0  0.954198  0.0588235  0.886525  0.142857  
6  0.954545  0.0487805  0.446809  0.571429  
Elapsed time 15.81 mins 

************************************************************

pre/post: 50/0  win/stride: 500/50  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-21 20:03:30.216000 
pca_target: 0 	 poly degree: 2 	 kselect: 100 
Imbalance: SMOTE(k=None, k_neighbors=5, kind='regular', m=None, m_neighbors=10, n_jobs=1,
   out_step=0.5, random_state=None, ratio='auto', svm_estimator=None) 
Extended target (count):  25141 13
('Total : Processed (count): ', (493L, 24976L), 13)
Final feature (count):  (493L, 24976L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.689 	0.060 	0.037 	0.565 	0.549 	0.293
[[99 42]
 [ 4  3]]
             precision    recall  f1-score   support

        0.0       0.96      0.70      0.81       141
        1.0       0.07      0.43      0.12         7

avg / total       0.92      0.69      0.78       148


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=10, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=5, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.872 	0.037 	0.034 	0.525 	0.360 	0.120
[[128  13]
 [  6   1]]
             precision    recall  f1-score   support

        0.0       0.96      0.91      0.93       141
        1.0       0.07      0.14      0.10         7

avg / total       0.91      0.87      0.89       148


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.001, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='perceptron', n_iter=5, n_jobs=4,
       penalty='l1', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.858 	0.025 	0.023 	0.518 	0.357 	0.118
[[126  15]
 [  6   1]]
             precision    recall  f1-score   support

        0.0       0.95      0.89      0.92       141
        1.0       0.06      0.14      0.09         7

avg / total       0.91      0.86      0.88       148


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=None, max_features=0.33, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.946 	-0.018 	-0.012 	0.496 	0.000 	0.000
[[140   1]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.99      0.97       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.95      0.93       148


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight='balanced',
            criterion='entropy', max_depth=32, max_features=0.75,
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.912 	0.088 	0.087 	0.547 	0.368 	0.125
[[134   7]
 [  6   1]]
             precision    recall  f1-score   support

        0.0       0.96      0.95      0.95       141
        1.0       0.12      0.14      0.13         7

avg / total       0.92      0.91      0.91       148


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.932 	-0.032 	-0.029 	0.489 	0.000 	0.000
[[138   3]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.98      0.97       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.93      0.92       148


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight='balanced', criterion='gini', max_depth=8,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=0.5, n_estimators=50, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.926 	-0.037 	-0.036 	0.486 	0.000 	0.000
[[137   4]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.97      0.96       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.93      0.92       148


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=10, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.946 	-0.018 	-0.012 	0.496 	0.000 	0.000
[[140   1]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.99      0.97       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.95      0.93       148


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=10.0, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', ...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.912 	-0.046 	-0.046 	0.479 	0.000 	0.000
[[135   6]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.96      0.95       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.91      0.91       148


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=4,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.899 	-0.053 	-0.053 	0.472 	0.000 	0.000
[[133   8]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.94      0.95       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.90      0.90       148


                estimator min_score mean_score max_score    sd_score  \
0              GaussianNB  0.747448   0.747448  0.747448           0   
4  RandomForestClassifier    0.9423   0.971022  0.985399  0.00608762   
1      LogisticRegression  0.453853   0.721961   0.91807    0.135575   
2           SGDClassifier -0.168204   0.572953   0.88778    0.199221   
3    ExtraTreesClassifier   0.82361    0.96674  0.991256   0.0306289   
7                     SVC         0   0.751936  0.976739    0.285964   
5           MLPClassifier  0.942936   0.961291  0.982596    0.010307   
6      AdaBoostClassifier  0.907139   0.966098  0.988409   0.0137799   
8        VotingClassifier  0.862065   0.923221  0.957068    0.022295   
9    KNeighborsClassifier  0.838985   0.882255  0.932066   0.0311209   

        acc       auc          conf_matrix     f1_c0      f1_c1      kappa  \
0  0.689189   0.56535   [[99, 42], [4, 3]]  0.811475   0.115385  0.0365129   
4  0.912162  0.546606   [[134, 7], [6, 1]]  0.953737   0.133333  0.0872865   
1  0.871622  0.525329  [[128, 13], [6, 1]]  0.930909  0.0952381  0.0343407   
2  0.858108  0.518237  [[126, 15], [6, 1]]  0.923077  0.0869565  0.0226415   
3  0.945946  0.496454   [[140, 1], [7, 0]]  0.972222          0 -0.0119658   
7  0.945946  0.496454   [[140, 1], [7, 0]]  0.972222          0 -0.0119658   
5  0.932432  0.489362   [[138, 3], [7, 0]]  0.965035          0 -0.0292072   
6  0.925676  0.485816   [[137, 4], [7, 0]]  0.961404          0 -0.0356234   
8  0.912162  0.478723   [[135, 6], [7, 0]]  0.954064          0 -0.0456522   
9  0.898649  0.471631   [[133, 8], [7, 0]]  0.946619          0 -0.0531309   

  model_score   prec_c0    prec_c1    rec_c0    rec_c1  
0   0.0603124  0.961165  0.0666667  0.702128  0.428571  
4   0.0875025  0.957143      0.125  0.950355  0.142857  
1   0.0367447  0.955224  0.0714286  0.907801  0.142857  
2   0.0249343  0.954545     0.0625  0.893617  0.142857  
3  -0.0183773  0.952381          0  0.992908         0  
7  -0.0183773  0.952381          0  0.992908         0  
5  -0.0320491  0.951724          0  0.978723         0  
6  -0.0371354  0.951389          0  0.971631         0  
8  -0.0458006  0.950704          0  0.957447         0  
9  -0.0532624      0.95          0  0.943262         0  
Elapsed time 27.37 mins 

************************************************************

pre/post: 50/0  win/stride: 500/50  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-21 20:30:52.389000 
pca_target: 0 	 poly degree: 2 	 kselect: 100 
Imbalance: None 
Extended target (count):  25141 13
('Total : Processed (count): ', (493L, 24976L), 13)
Final feature (count):  (493L, 24976L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.831 	0.005 	0.004 	0.504 	0.352 	0.115
[[122  19]
 [  6   1]]
             precision    recall  f1-score   support

        0.0       0.95      0.87      0.91       141
        1.0       0.05      0.14      0.07         7

avg / total       0.91      0.83      0.87       148


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.001, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=5, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='sag', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.953 	0.000 	0.000 	0.500 	0.000 	0.000
[[141   0]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      1.00      0.98       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.95      0.93       148


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.5, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.001, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='perceptron', n_iter=5, n_jobs=4,
       penalty='l2', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.926 	-0.037 	-0.036 	0.486 	0.000 	0.000
[[137   4]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.97      0.96       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.93      0.92       148


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight='balanced',
           criterion='entropy', max_depth=8, max_features=0.75,
           max_leaf_nodes=None, min_impurity_split=1e-07,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=4,
           oob_score=False, random_state=None, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.953 	0.000 	0.000 	0.500 	0.000 	0.000
[[141   0]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      1.00      0.98       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.95      0.93       148


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 50},
            criterion='entropy', max_depth=32, max_features=0.33,
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=15, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.953 	0.000 	0.000 	0.500 	0.000 	0.000
[[141   0]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      1.00      0.98       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.95      0.93       148


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.946 	0.194 	0.177 	0.564 	0.375 	0.129
[[139   2]
 [  6   1]]
             precision    recall  f1-score   support

        0.0       0.96      0.99      0.97       141
        1.0       0.33      0.14      0.20         7

avg / total       0.93      0.95      0.94       148


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 50}, criterion='entropy',
            max_depth=32, max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=2.0, n_estimators=50, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.926 	-0.037 	-0.036 	0.486 	0.000 	0.000
[[137   4]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.97      0.96       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.93      0.92       148


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.1, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='linear',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.946 	0.194 	0.177 	0.564 	0.375 	0.129
[[139   2]
 [  6   1]]
             precision    recall  f1-score   support

        0.0       0.96      0.99      0.97       141
        1.0       0.33      0.14      0.20         7

avg / total       0.93      0.95      0.94       148


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=1.0, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.946 	-0.018 	-0.012 	0.496 	0.000 	0.000
[[140   1]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.99      0.97       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.95      0.93       148


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=3,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.932 	-0.032 	-0.029 	0.489 	0.000 	0.000
[[138   3]
 [  7   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.98      0.97       141
        1.0       0.00      0.00      0.00         7

avg / total       0.91      0.93      0.92       148


                estimator   min_score  mean_score  max_score   sd_score  \
5           MLPClassifier  -0.0248387  -0.0116596   0.126296  0.0228978   
7                     SVC   -0.036574   0.0180197   0.197059  0.0393219   
0              GaussianNB  -0.0383371  -0.0383371 -0.0383371          0   
1      LogisticRegression  -0.0785401   0.0638862   0.243993  0.0501779   
3    ExtraTreesClassifier  -0.0238106   0.0104516   0.238843  0.0379227   
4  RandomForestClassifier  -0.0118506  0.00183478        0.2  0.0204936   
8        VotingClassifier  -0.0147918   0.0756507        0.2   0.085964   
9    KNeighborsClassifier -0.00713022   0.0254573   0.203825  0.0565973   
2           SGDClassifier   -0.342428   0.0435344    0.27435  0.0509868   
6      AdaBoostClassifier  -0.0318926   0.0566135   0.403826  0.0820238   

        acc       auc          conf_matrix     f1_c0      f1_c1       kappa  \
5  0.945946  0.564336   [[139, 2], [6, 1]]  0.972028        0.2    0.176634   
7  0.945946  0.564336   [[139, 2], [6, 1]]  0.972028        0.2    0.176634   
0  0.831081  0.504053  [[122, 19], [6, 1]]  0.907063  0.0740741  0.00430571   
1  0.952703       0.5   [[141, 0], [7, 0]]  0.975779          0           0   
3  0.952703       0.5   [[141, 0], [7, 0]]  0.975779          0           0   
4  0.952703       0.5   [[141, 0], [7, 0]]  0.975779          0           0   
8  0.945946  0.496454   [[140, 1], [7, 0]]  0.972222          0  -0.0119658   
9  0.932432  0.489362   [[138, 3], [7, 0]]  0.965035          0  -0.0292072   
2  0.925676  0.485816   [[137, 4], [7, 0]]  0.961404          0  -0.0356234   
6  0.925676  0.485816   [[137, 4], [7, 0]]  0.961404          0  -0.0356234   

  model_score   prec_c0   prec_c1    rec_c0    rec_c1  
5    0.193821  0.958621  0.333333  0.985816  0.142857  
7    0.193821  0.958621  0.333333  0.985816  0.142857  
0  0.00503282  0.953125      0.05  0.865248  0.142857  
1           0  0.952703         0         1         0  
3           0  0.952703         0         1         0  
4           0  0.952703         0         1         0  
8  -0.0183773  0.952381         0  0.992908         0  
9  -0.0320491  0.951724         0  0.978723         0  
2  -0.0371354  0.951389         0  0.971631         0  
6  -0.0371354  0.951389         0  0.971631         0  
Elapsed time 19.20 mins 

************************************************************

[4;33mReloaded modules[24m: migraine_processing, classifiers[0m
Finished.





[4;33mReloaded modules[24m: migraine_processing, classifiers[0m
