

lagged (3,4)x1, Standard

    pca = [0,60]
    poly = [0,2]
    ksel = [20, 60]
    imb = [ClusterCentroids(), None]

    
	
[4;33mReloaded modules[24m: migraine_processing, classifiers[0m
pre/post: 25/0  win/stride: 500/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-25 12:41:57.365000 
pca_target: 0 	 poly degree: 2 	 kselect: 20 
Imbalance: ClusterCentroids(estimator=None, n_jobs=1, random_state=None, ratio='auto') 
Extended target (count):  25141 325
('Total : Processed (count): ', (986L, 276L), 13)
Final feature (count):  (986L, 276L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.605 	0.083 	0.023 	0.676 	0.672 	0.459
[[176 116]
 [  1   3]]
             precision    recall  f1-score   support

          0       0.99      0.60      0.75       292
          1       0.03      0.75      0.05         4

avg / total       0.98      0.60      0.74       296


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=1, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.588 	0.079 	0.021 	0.668 	0.663 	0.446
[[171 121]
 [  1   3]]
             precision    recall  f1-score   support

          0       0.99      0.59      0.74       292
          1       0.02      0.75      0.05         4

avg / total       0.98      0.59      0.73       296


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.0001, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='squared_hinge', n_iter=5, n_jobs=4,
       penalty='l1', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.493 	0.055 	0.012 	0.620 	0.606 	0.377
[[143 149]
 [  1   3]]
             precision    recall  f1-score   support

          0       0.99      0.49      0.66       292
          1       0.02      0.75      0.04         4

avg / total       0.98      0.49      0.65       296


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=8, max_features=0.75, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.578 	0.076 	0.020 	0.663 	0.657 	0.439
[[168 124]
 [  1   3]]
             precision    recall  f1-score   support

          0       0.99      0.58      0.73       292
          1       0.02      0.75      0.05         4

avg / total       0.98      0.58      0.72       296


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 15}, criterion='gini',
            max_depth=None, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=50, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.561 	0.072 	0.018 	0.654 	0.647 	0.427
[[163 129]
 [  1   3]]
             precision    recall  f1-score   support

          0       0.99      0.56      0.71       292
          1       0.02      0.75      0.04         4

avg / total       0.98      0.56      0.71       296


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.622 	0.088 	0.025 	0.685 	0.682 	0.471
[[181 111]
 [  1   3]]
             precision    recall  f1-score   support

          0       0.99      0.62      0.76       292
          1       0.03      0.75      0.05         4

avg / total       0.98      0.62      0.75       296


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=32,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=0.5, n_estimators=80, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.605 	0.083 	0.023 	0.676 	0.672 	0.459
[[176 116]
 [  1   3]]
             precision    recall  f1-score   support

          0       0.99      0.60      0.75       292
          1       0.03      0.75      0.05         4

avg / total       0.98      0.60      0.74       296


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.5, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='linear',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.551 	0.069 	0.017 	0.649 	0.641 	0.419
[[160 132]
 [  1   3]]
             precision    recall  f1-score   support

          0       0.99      0.55      0.71       292
          1       0.02      0.75      0.04         4

avg / total       0.98      0.55      0.70       296


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=10.0, class_weight={1: 500}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Ra...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.568 	0.073 	0.019 	0.658 	0.651 	0.432
[[165 127]
 [  1   3]]
             precision    recall  f1-score   support

          0       0.99      0.57      0.72       292
          1       0.02      0.75      0.04         4

avg / total       0.98      0.57      0.71       296


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=1,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.578 	0.076 	0.020 	0.663 	0.657 	0.439
[[168 124]
 [  1   3]]
             precision    recall  f1-score   support

          0       0.99      0.58      0.73       292
          1       0.02      0.75      0.05         4

avg / total       0.98      0.58      0.72       296


                estimator min_score mean_score max_score   sd_score       acc  \
5           MLPClassifier  0.607122   0.627048  0.718234  0.0389127  0.621622   
0              GaussianNB  0.701045   0.701045  0.701045          0   0.60473   
6      AdaBoostClassifier -0.273789   0.333169         1   0.241174   0.60473   
1      LogisticRegression         0   0.458834  0.812156   0.275058  0.587838   
3    ExtraTreesClassifier  0.461633   0.841657         1  0.0966184  0.577703   
9    KNeighborsClassifier    0.1283    0.47574  0.777778   0.178295  0.577703   
8        VotingClassifier  0.478822   0.663508  0.812156  0.0643777  0.567568   
4  RandomForestClassifier  0.145489   0.526866  0.906078   0.150112  0.560811   
7                     SVC         0    0.45294  0.812156   0.317252  0.550676   
2           SGDClassifier -0.145489   0.469214  0.906078     0.1699  0.493243   

        auc           conf_matrix     f1_c0      f1_c1      kappa model_score  \
5  0.684932  [[181, 111], [1, 3]]  0.763713  0.0508475  0.0253998   0.0877555   
0   0.67637  [[176, 116], [1, 3]]  0.750533  0.0487805  0.0232401   0.0830645   
6   0.67637  [[176, 116], [1, 3]]  0.750533  0.0487805  0.0232401   0.0830645   
1  0.667808  [[171, 121], [1, 3]]  0.737069   0.046875  0.0212489   0.0785398   
3  0.662671  [[168, 124], [1, 3]]   0.72885  0.0458015  0.0201271   0.0758957   
9  0.662671  [[168, 124], [1, 3]]   0.72885  0.0458015  0.0201271   0.0758957   
8  0.657534  [[165, 127], [1, 3]]  0.720524  0.0447761  0.0190555   0.0732994   
4   0.65411  [[163, 129], [1, 3]]  0.714912  0.0441176  0.0183673   0.0715933   
7  0.648973  [[160, 132], [1, 3]]  0.706402  0.0431655  0.0173722   0.0690682   
2  0.619863  [[143, 149], [1, 3]]  0.655963  0.0384615  0.0124555   0.0553775   

    prec_c0    prec_c1    rec_c0 rec_c1  
5  0.994505  0.0263158  0.619863   0.75  
0   0.99435  0.0252101   0.60274   0.75  
6   0.99435  0.0252101   0.60274   0.75  
1  0.994186  0.0241935  0.585616   0.75  
3  0.994083   0.023622  0.575342   0.75  
9  0.994083   0.023622  0.575342   0.75  
8  0.993976  0.0230769  0.565068   0.75  
4  0.993902  0.0227273  0.558219   0.75  
7  0.993789  0.0222222  0.547945   0.75  
2  0.993056  0.0197368  0.489726   0.75  
Elapsed time 14.00 mins 

************************************************************

pre/post: 25/0  win/stride: 500/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-25 12:55:57.360000 
pca_target: 0 	 poly degree: 2 	 kselect: 20 
Imbalance: SMOTE(k=None, k_neighbors=5, kind='regular', m=None, m_neighbors=10, n_jobs=1,
   out_step=0.5, random_state=None, ratio='auto', svm_estimator=None) 
Extended target (count):  25141 325
('Total : Processed (count): ', (986L, 276L), 13)
Final feature (count):  (986L, 276L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.530 	0.121 	0.029 	0.762 	0.724 	0.549
[[153 139]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.52      0.69       292
          1       0.03      1.00      0.05         4

avg / total       0.99      0.53      0.68       296


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=10, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.764 	0.006 	0.002 	0.510 	0.439 	0.183
[[225  67]
 [  3   1]]
             precision    recall  f1-score   support

          0       0.99      0.77      0.87       292
          1       0.01      0.25      0.03         4

avg / total       0.97      0.76      0.85       296


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=1, average=False, class_weight={1: 50}, epsilon=0.1,
       eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='invscaling', loss='squared_hinge', n_iter=5,
       n_jobs=4, penalty='l1', power_t=0.5, random_state=None,
       shuffle=True, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.649 	0.096 	0.029 	0.699 	0.697 	0.490
[[189 103]
 [  1   3]]
             precision    recall  f1-score   support

          0       0.99      0.65      0.78       292
          1       0.03      0.75      0.05         4

avg / total       0.98      0.65      0.77       296


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=32, max_features=0.75, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=50, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.953 	-0.022 	-0.020 	0.483 	0.000 	0.000
[[282  10]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.97      0.98       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.95      0.96       296


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3},
            criterion='entropy', max_depth=None, max_features=0.75,
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.943 	-0.025 	-0.021 	0.478 	0.000 	0.000
[[279  13]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.96      0.97       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.94      0.96       296


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.01, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(500,), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.949 	-0.023 	-0.020 	0.481 	0.000 	0.000
[[281  11]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.96      0.97       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.95      0.96       296


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 500}, criterion='gini', max_depth=16,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=1.0, n_estimators=80, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.966 	-0.017 	-0.016 	0.490 	0.000 	0.000
[[286   6]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.98      0.98       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.97      0.97       296


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=10, cache_size=200, class_weight='balanced', coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=10, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.946 	-0.024 	-0.021 	0.479 	0.000 	0.000
[[280  12]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.96      0.97       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.95      0.96       296


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=1.0, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', R...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.929 	-0.029 	-0.022 	0.471 	0.000 	0.000
[[275  17]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.94      0.96       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.93      0.95       296


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=1,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.939 	-0.026 	-0.021 	0.476 	0.000 	0.000
[[278  14]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.95      0.97       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.94      0.96       296


                estimator min_score mean_score max_score   sd_score       acc  \
0              GaussianNB  0.524473   0.524473  0.524473          0  0.530405   
2           SGDClassifier -0.174058   0.426271  0.653738   0.178313  0.648649   
1      LogisticRegression  0.168553   0.533829   0.69685    0.09791  0.763514   
6      AdaBoostClassifier  0.815986   0.912293  0.963906  0.0309594  0.966216   
3    ExtraTreesClassifier  0.603158   0.866435   0.96271   0.108393  0.952703   
5           MLPClassifier  0.921104   0.948482  0.965684  0.0122286  0.949324   
7                     SVC         0   0.605487  0.962379    0.21356  0.945946   
4  RandomForestClassifier  0.810458    0.91115  0.951533  0.0381816  0.942568   
9    KNeighborsClassifier  0.840337    0.90156   0.93866  0.0269115  0.939189   
8        VotingClassifier  0.838569   0.890406  0.924648   0.021674  0.929054   

        auc           conf_matrix     f1_c0      f1_c1       kappa  \
0  0.761986  [[153, 139], [0, 4]]   0.68764  0.0544218   0.0288897   
2   0.69863  [[189, 103], [1, 3]]  0.784232  0.0545455   0.0292634   
1  0.510274   [[225, 67], [3, 1]]  0.865385  0.0277778  0.00231125   
6  0.489726    [[286, 6], [4, 0]]  0.982818          0  -0.0164835   
3  0.482877   [[282, 10], [4, 0]]  0.975779          0   -0.019685   
5  0.481164   [[281, 11], [4, 0]]  0.974003          0  -0.0202206   
7  0.479452   [[280, 12], [4, 0]]  0.972222          0  -0.0206897   
4   0.47774   [[279, 13], [4, 0]]  0.970435          0  -0.0211039   
9  0.476027   [[278, 14], [4, 0]]  0.968641          0  -0.0214724   
8   0.47089   [[275, 17], [4, 0]]  0.963222          0  -0.0223684   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
0    0.121064         1   0.027972  0.523973      1  
2    0.095668  0.994737  0.0283019   0.64726   0.75  
1  0.00563986  0.986842  0.0147059  0.770548   0.25  
6  -0.0168351  0.986207          0  0.979452      0  
3  -0.0218855  0.986014          0  0.965753      0  
5  -0.0229939  0.985965          0  0.962329      0  
7  -0.0240586  0.985915          0  0.958904      0  
4  -0.0250852  0.985866          0  0.955479      0  
9  -0.0260782  0.985816          0  0.952055      0  
8  -0.0288909  0.985663          0  0.941781      0  
Elapsed time 38.43 mins 

************************************************************

pre/post: 25/0  win/stride: 500/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-25 13:34:22.975000 
pca_target: 0 	 poly degree: 2 	 kselect: 20 
Imbalance: None 
Extended target (count):  25141 325
('Total : Processed (count): ', (986L, 276L), 13)
Final feature (count):  (986L, 276L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.503 	0.115 	0.026 	0.748 	0.705 	0.522
[[145 147]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.50      0.66       292
          1       0.03      1.00      0.05         4

avg / total       0.99      0.50      0.66       296


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=1, class_weight={1: 500}, dual=False, fit_intercept=True,
          intercept_scaling=0.01, max_iter=100, multi_class='ovr',
          n_jobs=4, penalty='l2', random_state=None, solver='liblinear',
          tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.514 	0.117 	0.027 	0.753 	0.712 	0.532
[[148 144]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.51      0.67       292
          1       0.03      1.00      0.05         4

avg / total       0.99      0.51      0.66       296


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.001, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.001, fit_intercept=True, l1_ratio=0.15,
       learning_rate='invscaling', loss='perceptron', n_iter=5, n_jobs=4,
       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.980 	-0.010 	-0.009 	0.497 	0.000 	0.000
[[290   2]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.98       296


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 500}, criterion='gini',
           max_depth=16, max_features=0.75, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=30, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.929 	-0.029 	-0.022 	0.471 	0.000 	0.000
[[275  17]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.94      0.96       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.93      0.95       296


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 500},
            criterion='gini', max_depth=8, max_features=0.33,
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.929 	-0.029 	-0.022 	0.471 	0.000 	0.000
[[275  17]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.94      0.96       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.93      0.95       296


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.5, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(500,), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight='balanced', criterion='entropy',
            max_depth=4, max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=2.0, n_estimators=80, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.946 	-0.024 	-0.021 	0.479 	0.000 	0.000
[[280  12]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.96      0.97       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.95      0.96       296


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=10, cache_size=200, class_weight={1: 50}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='linear',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.831 	0.103 	0.050 	0.668 	0.646 	0.404
[[244  48]
 [  2   2]]
             precision    recall  f1-score   support

          0       0.99      0.84      0.91       292
          1       0.04      0.50      0.07         4

avg / total       0.98      0.83      0.90       296


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...owski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='uniform'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=1,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


                estimator  min_score  mean_score  max_score    sd_score  \
1      LogisticRegression -0.0898622   0.0281677   0.108152   0.0383861   
0              GaussianNB  0.0853453   0.0853453  0.0853453           0   
7                     SVC -0.0342461   0.0237862   0.150139   0.0445576   
5           MLPClassifier  -0.017785  -0.0118707          0  0.00459576   
8        VotingClassifier -0.0170486 -0.00692717          0  0.00480168   
9    KNeighborsClassifier -0.0136879 -0.00489699          0  0.00525969   
2           SGDClassifier  -0.145477   0.0250394   0.163452   0.0372532   
6      AdaBoostClassifier -0.0263068  -0.0123393  0.0422314  0.00576761   
3    ExtraTreesClassifier -0.0318851 -0.00287484  0.0520602   0.0111463   
4  RandomForestClassifier -0.0212146 -0.00119625  0.0321551  0.00359498   

        acc       auc           conf_matrix     f1_c0      f1_c1       kappa  \
1  0.513514  0.753425  [[148, 144], [0, 4]]  0.672727  0.0526316    0.027027   
0  0.503378  0.748288  [[145, 147], [0, 4]]  0.663616  0.0516129    0.025967   
7  0.831081  0.667808   [[244, 48], [2, 2]]  0.907063  0.0740741    0.050308   
5  0.986486       0.5    [[292, 0], [4, 0]]  0.993197          0           0   
8  0.986486       0.5    [[292, 0], [4, 0]]  0.993197          0           0   
9  0.986486       0.5    [[292, 0], [4, 0]]  0.993197          0           0   
2   0.97973  0.496575    [[290, 2], [4, 0]]  0.989761          0 -0.00909091   
6  0.945946  0.479452   [[280, 12], [4, 0]]  0.972222          0  -0.0206897   
3  0.929054   0.47089   [[275, 17], [4, 0]]  0.963222          0  -0.0223684   
4  0.929054   0.47089   [[275, 17], [4, 0]]  0.963222          0  -0.0223684   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
1    0.117041         1   0.027027  0.506849      1  
0    0.114692         1  0.0264901  0.496575      1  
7    0.103422   0.99187       0.04  0.835616    0.5  
5           0  0.986486          0         1      0  
8           0  0.986486          0         1      0  
9           0  0.986486          0         1      0  
2 -0.00965339  0.986395          0  0.993151      0  
6  -0.0240586  0.985915          0  0.958904      0  
3  -0.0288909  0.985663          0  0.941781      0  
4  -0.0288909  0.985663          0  0.941781      0  
Elapsed time 24.48 mins 

************************************************************

pre/post: 25/0  win/stride: 500/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-25 13:58:51.743000 
pca_target: 0 	 poly degree: 2 	 kselect: 60 
Imbalance: ClusterCentroids(estimator=None, n_jobs=1, random_state=None, ratio='auto') 
Extended target (count):  25141 325
('Total : Processed (count): ', (986L, 276L), 13)
Final feature (count):  (986L, 276L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.615 	0.086 	0.025 	0.682 	0.678 	0.466
[[179 113]
 [  1   3]]
             precision    recall  f1-score   support

          0       0.99      0.61      0.76       292
          1       0.03      0.75      0.05         4

avg / total       0.98      0.61      0.75       296


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.527 	0.063 	0.015 	0.637 	0.627 	0.402
[[153 139]
 [  1   3]]
             precision    recall  f1-score   support

          0       0.99      0.52      0.69       292
          1       0.02      0.75      0.04         4

avg / total       0.98      0.53      0.68       296


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.1, average=False, class_weight='balanced', epsilon=0.1,
       eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='constant', loss='modified_huber', n_iter=5, n_jobs=4,
       penalty='l1', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.622 	0.088 	0.025 	0.685 	0.682 	0.471
[[181 111]
 [  1   3]]
             precision    recall  f1-score   support

          0       0.99      0.62      0.76       292
          1       0.03      0.75      0.05         4

avg / total       0.98      0.62      0.75       296


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight='balanced',
           criterion='entropy', max_depth=8, max_features=0.33,
           max_leaf_nodes=None, min_impurity_split=1e-07,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=15, n_jobs=4,
           oob_score=False, random_state=None, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.584 	0.078 	0.021 	0.666 	0.661 	0.444
[[170 122]
 [  1   3]]
             precision    recall  f1-score   support

          0       0.99      0.58      0.73       292
          1       0.02      0.75      0.05         4

avg / total       0.98      0.58      0.73       296


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 50}, criterion='gini',
            max_depth=None, max_features=0.75, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.527 	0.063 	0.015 	0.637 	0.627 	0.402
[[153 139]
 [  1   3]]
             precision    recall  f1-score   support

          0       0.99      0.52      0.69       292
          1       0.02      0.75      0.04         4

avg / total       0.98      0.53      0.68       296


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.611 	0.027 	0.008 	0.557 	0.554 	0.303
[[179 113]
 [  2   2]]
             precision    recall  f1-score   support

          0       0.99      0.61      0.76       292
          1       0.02      0.50      0.03         4

avg / total       0.98      0.61      0.75       296


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=8,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=0.5, n_estimators=80, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.547 	0.125 	0.031 	0.771 	0.736 	0.566
[[158 134]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.54      0.70       292
          1       0.03      1.00      0.06         4

avg / total       0.99      0.55      0.69       296


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=10, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.551 	0.069 	0.017 	0.649 	0.641 	0.419
[[160 132]
 [  1   3]]
             precision    recall  f1-score   support

          0       0.99      0.55      0.71       292
          1       0.02      0.75      0.04         4

avg / total       0.98      0.55      0.70       296


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', R...owski',
           metric_params=None, n_jobs=4, n_neighbors=4, p=2,
           weights='uniform'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.547 	0.068 	0.017 	0.647 	0.639 	0.417
[[159 133]
 [  1   3]]
             precision    recall  f1-score   support

          0       0.99      0.54      0.70       292
          1       0.02      0.75      0.04         4

avg / total       0.98      0.55      0.69       296


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=5, p=1,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.419 	0.039 	0.007 	0.582 	0.557 	0.321
[[121 171]
 [  1   3]]
             precision    recall  f1-score   support

          0       0.99      0.41      0.58       292
          1       0.02      0.75      0.03         4

avg / total       0.98      0.42      0.58       296


                estimator  min_score mean_score max_score   sd_score  \
6      AdaBoostClassifier          0   0.603437         1   0.132078   
2           SGDClassifier    -0.3849   0.186769  0.812156   0.168722   
0              GaussianNB   0.701045   0.701045  0.701045          0   
3    ExtraTreesClassifier   0.111111   0.483362  0.777778   0.102271   
7                     SVC  -0.111111   0.233035  0.607122   0.228755   
8        VotingClassifier          0   0.316765  0.496011   0.116597   
1      LogisticRegression  -0.350522   0.232481  0.538367   0.162254   
4  RandomForestClassifier     0.1283   0.559356  0.906078   0.127326   
9    KNeighborsClassifier    -0.1283    0.12202  0.496011   0.134105   
5           MLPClassifier  0.0171889   0.206313  0.461633  0.0858396   

        acc       auc           conf_matrix     f1_c0      f1_c1       kappa  \
6  0.547297  0.770548  [[158, 134], [0, 4]]  0.702222   0.056338   0.0308835   
2  0.621622  0.684932  [[181, 111], [1, 3]]  0.763713  0.0508475   0.0253998   
0  0.614865  0.681507  [[179, 113], [1, 3]]  0.758475       0.05   0.0245143   
3  0.584459  0.666096  [[170, 122], [1, 3]]  0.734341  0.0465116   0.0208692   
7  0.550676  0.648973  [[160, 132], [1, 3]]  0.706402  0.0431655   0.0173722   
8  0.547297   0.64726  [[159, 133], [1, 3]]   0.70354  0.0428571     0.01705   
1  0.527027  0.636986  [[153, 139], [1, 3]]  0.686099  0.0410959   0.0152091   
4  0.527027  0.636986  [[153, 139], [1, 3]]  0.686099  0.0410959   0.0152091   
9  0.418919  0.582192  [[121, 171], [1, 3]]  0.584541  0.0337079  0.00748596   
5  0.611486  0.556507  [[179, 113], [2, 2]]  0.756871  0.0336134   0.0076959   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
6    0.125236         1  0.0289855  0.541096      1  
2   0.0877555  0.994505  0.0263158  0.619863   0.75  
0   0.0858577  0.994444  0.0258621  0.613014   0.75  
3   0.0776528  0.994152      0.024  0.582192   0.75  
7   0.0690682  0.993789  0.0222222  0.547945   0.75  
8   0.0682351   0.99375  0.0220588  0.544521   0.75  
1   0.0633175  0.993506  0.0211268  0.523973   0.75  
4   0.0633175  0.993506  0.0211268  0.523973   0.75  
9    0.038559  0.991803  0.0172414  0.414384   0.75  
5    0.026771   0.98895  0.0173913  0.613014    0.5  
Elapsed time 15.16 mins 

************************************************************

pre/post: 25/0  win/stride: 500/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-25 14:14:01.285000 
pca_target: 0 	 poly degree: 2 	 kselect: 60 
Imbalance: SMOTE(k=None, k_neighbors=5, kind='regular', m=None, m_neighbors=10, n_jobs=1,
   out_step=0.5, random_state=None, ratio='auto', svm_estimator=None) 
Extended target (count):  25141 325
('Total : Processed (count): ', (986L, 276L), 13)
Final feature (count):  (986L, 276L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.689 	-0.014 	-0.005 	0.473 	0.417 	0.166
[[203  89]
 [  3   1]]
             precision    recall  f1-score   support

          0       0.99      0.70      0.82       292
          1       0.01      0.25      0.02         4

avg / total       0.97      0.69      0.80       296


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=10, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.885 	0.053 	0.032 	0.572 	0.473 	0.209
[[261  31]
 [  3   1]]
             precision    recall  f1-score   support

          0       0.99      0.89      0.94       292
          1       0.03      0.25      0.06         4

avg / total       0.98      0.89      0.93       296


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.001, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.001, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='modified_huber', n_iter=5, n_jobs=4,
       penalty='none', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.818 	0.023 	0.011 	0.538 	0.454 	0.194
[[241  51]
 [  3   1]]
             precision    recall  f1-score   support

          0       0.99      0.83      0.90       292
          1       0.02      0.25      0.04         4

avg / total       0.97      0.82      0.89       296


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 500}, criterion='gini',
           max_depth=None, max_features=0.75, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=50, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.959 	-0.020 	-0.018 	0.486 	0.000 	0.000
[[284   8]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.97      0.98       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.96      0.97       296


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 50},
            criterion='entropy', max_depth=None, max_features=0.75,
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.956 	0.132 	0.116 	0.608 	0.491 	0.224
[[282  10]
 [  3   1]]
             precision    recall  f1-score   support

          0       0.99      0.97      0.98       292
          1       0.09      0.25      0.13         4

avg / total       0.98      0.96      0.97       296


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.963 	-0.018 	-0.018 	0.488 	0.000 	0.000
[[285   7]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.98      0.98       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.96      0.97       296


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight='balanced', criterion='gini', max_depth=8,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=0.5, n_estimators=80, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.966 	0.161 	0.151 	0.613 	0.494 	0.226
[[285   7]
 [  3   1]]
             precision    recall  f1-score   support

          0       0.99      0.98      0.98       292
          1       0.12      0.25      0.17         4

avg / total       0.98      0.97      0.97       296


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.5, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.959 	-0.020 	-0.018 	0.486 	0.000 	0.000
[[284   8]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.97      0.98       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.96      0.97       296


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=10.0, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', ...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.932 	-0.028 	-0.022 	0.473 	0.000 	0.000
[[276  16]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.95      0.97       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.93      0.95       296


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=4,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.949 	-0.023 	-0.020 	0.481 	0.000 	0.000
[[281  11]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.96      0.97       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.95      0.96       296


                estimator  min_score mean_score max_score    sd_score  \
6      AdaBoostClassifier   0.801068   0.930929  0.965324    0.025061   
4  RandomForestClassifier   0.834959   0.932431  0.966636   0.0251072   
1      LogisticRegression   0.132849   0.655567  0.878502    0.149631   
2           SGDClassifier -0.0554671   0.508796  0.827101    0.218153   
5           MLPClassifier   0.929291   0.950299  0.965404  0.00836636   
3    ExtraTreesClassifier   0.662337   0.897918  0.968388   0.0744779   
7                     SVC          0   0.735636  0.959484    0.251299   
9    KNeighborsClassifier   0.840108   0.898215  0.938991    0.028886   
0              GaussianNB   0.658839   0.658839  0.658839           0   
8        VotingClassifier   0.842566   0.901721   0.93887   0.0202081   

        acc       auc          conf_matrix     f1_c0      f1_c1       kappa  \
6  0.966216  0.613014   [[285, 7], [3, 1]]  0.982759   0.166667    0.151376   
4  0.956081  0.607877  [[282, 10], [3, 1]]   0.97747   0.133333    0.115809   
1  0.885135  0.571918  [[261, 31], [3, 1]]  0.938849  0.0555556   0.0323077   
2  0.817568  0.537671  [[241, 51], [3, 1]]  0.899254  0.0357143   0.0108911   
5  0.962838  0.488014   [[285, 7], [4, 0]]  0.981067          0     -0.0175   
3  0.959459  0.486301   [[284, 8], [4, 0]]   0.97931          0  -0.0183486   
7  0.959459  0.486301   [[284, 8], [4, 0]]   0.97931          0  -0.0183486   
9  0.949324  0.481164  [[281, 11], [4, 0]]  0.974003          0  -0.0202206   
0  0.689189  0.472603  [[203, 89], [3, 1]]  0.815261  0.0212766 -0.00472255   
8  0.932432  0.472603  [[276, 16], [4, 0]]  0.965035          0  -0.0220994   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
6    0.160932  0.989583      0.125  0.976027   0.25  
4    0.131692  0.989474  0.0909091  0.965753   0.25  
1   0.0534824  0.988636    0.03125  0.893836   0.25  
2   0.0228594  0.987705  0.0192308  0.825342   0.25  
5  -0.0182154  0.986159          0  0.976027      0  
3  -0.0195069  0.986111          0  0.972603      0  
7  -0.0195069  0.986111          0  0.972603      0  
9  -0.0229939  0.985965          0  0.962329      0  
0  -0.0137532  0.985437  0.0111111  0.695205   0.25  
8  -0.0279782  0.985714          0  0.945205      0  
Elapsed time 53.81 mins 

************************************************************

pre/post: 25/0  win/stride: 500/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-25 15:07:49.738000 
pca_target: 0 	 poly degree: 2 	 kselect: 60 
Imbalance: None 
Extended target (count):  25141 325
('Total : Processed (count): ', (986L, 276L), 13)
Final feature (count):  (986L, 276L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.551 	0.069 	0.017 	0.649 	0.641 	0.419
[[160 132]
 [  1   3]]
             precision    recall  f1-score   support

          0       0.99      0.55      0.71       292
          1       0.02      0.75      0.04         4

avg / total       0.98      0.55      0.70       296


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.001, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.564 	0.072 	0.019 	0.656 	0.649 	0.429
[[164 128]
 [  1   3]]
             precision    recall  f1-score   support

          0       0.99      0.56      0.72       292
          1       0.02      0.75      0.04         4

avg / total       0.98      0.56      0.71       296


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=1, average=False, class_weight={1: 15}, epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='constant', loss='perceptron', n_iter=5, n_jobs=4,
       penalty='l2', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 50}, criterion='gini',
           max_depth=8, max_features=0.75, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.970 	-0.015 	-0.015 	0.491 	0.000 	0.000
[[287   5]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.98      0.98       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.97      0.97       296


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight='balanced',
            criterion='gini', max_depth=8, max_features='auto',
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=15, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.5, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(500,), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 50}, criterion='entropy',
            max_depth=32, max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=0.5, n_estimators=15, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.976 	-0.012 	-0.012 	0.495 	0.000 	0.000
[[289   3]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.97       296


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.5, cache_size=200, class_weight={1: 50}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='linear',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.801 	0.088 	0.039 	0.652 	0.634 	0.390
[[235  57]
 [  2   2]]
             precision    recall  f1-score   support

          0       0.99      0.80      0.89       292
          1       0.03      0.50      0.06         4

avg / total       0.98      0.80      0.88       296


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...owski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='uniform'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=1,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


                estimator  min_score   mean_score   max_score    sd_score  \
1      LogisticRegression -0.0699499    0.0201029    0.099033   0.0325808   
7                     SVC  -0.033452   0.00561949   0.0553889   0.0225909   
0              GaussianNB  0.0960469    0.0960469   0.0960469           0   
2           SGDClassifier  -0.133987    0.0224221    0.180451   0.0345389   
4  RandomForestClassifier -0.0155011   -0.0001625   0.0585795   0.0062895   
5           MLPClassifier -0.0197135   -0.0143539 -0.00414424   0.0035523   
8        VotingClassifier -0.0176788  -0.00738515           0  0.00457616   
9    KNeighborsClassifier -0.0162349  -0.00526097           0  0.00612403   
6      AdaBoostClassifier -0.0225198  -0.00956163   0.0914483    0.013109   
3    ExtraTreesClassifier -0.0179519  0.000200155   0.0916105   0.0155283   

        acc       auc           conf_matrix     f1_c0      f1_c1      kappa  \
1  0.564189  0.655822  [[164, 128], [1, 3]]  0.717724  0.0444444  0.0187089   
7  0.800676  0.652397   [[235, 57], [2, 2]]  0.888469  0.0634921  0.0391725   
0  0.550676  0.648973  [[160, 132], [1, 3]]  0.706402  0.0431655  0.0173722   
2  0.986486       0.5    [[292, 0], [4, 0]]  0.993197          0          0   
4  0.986486       0.5    [[292, 0], [4, 0]]  0.993197          0          0   
5  0.986486       0.5    [[292, 0], [4, 0]]  0.993197          0          0   
8  0.986486       0.5    [[292, 0], [4, 0]]  0.993197          0          0   
9  0.986486       0.5    [[292, 0], [4, 0]]  0.993197          0          0   
6  0.976351  0.494863    [[289, 3], [4, 0]]  0.988034          0 -0.0117188   
3  0.969595  0.491438    [[287, 5], [4, 0]]  0.984563          0 -0.0152439   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
1    0.072444  0.993939  0.0229008  0.561644   0.75  
7   0.0880904  0.991561  0.0338983  0.804795    0.5  
0   0.0690682  0.993789  0.0222222  0.547945   0.75  
2           0  0.986486          0         1      0  
4           0  0.986486          0         1      0  
5           0  0.986486          0         1      0  
8           0  0.986486          0         1      0  
9           0  0.986486          0         1      0  
6  -0.0118431  0.986348          0  0.989726      0  
3  -0.0153418  0.986254          0  0.982877      0  
Elapsed time 28.42 mins 

************************************************************

pre/post: 25/0  win/stride: 500/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-25 15:36:15.028000 
pca_target: 60 	 poly degree: 2 	 kselect: 20 
Imbalance: ClusterCentroids(estimator=None, n_jobs=1, random_state=None, ratio='auto') 
Extended target (count):  25141 325
('Total : Processed (count): ', (986L, 276L), 13)
Final feature (count):  (986L, 276L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.014 	0.000 	0.000 	0.500 	0.000 	0.000
[[  0 292]
 [  0   4]]
             precision    recall  f1-score   support

          0       0.00      0.00      0.00       292
          1       0.01      1.00      0.03         4

avg / total       0.00      0.01      0.00       296


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=1, class_weight={1: 15}, dual=False, fit_intercept=True,
          intercept_scaling=0.1, max_iter=100, multi_class='ovr', n_jobs=4,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.486 	0.111 	0.024 	0.740 	0.692 	0.504
[[140 152]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.48      0.65       292
          1       0.03      1.00      0.05         4

avg / total       0.99      0.49      0.64       296


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.5, average=False, class_weight='balanced', epsilon=0.1,
       eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='invscaling', loss='modified_huber', n_iter=5,
       n_jobs=4, penalty='elasticnet', power_t=0.5, random_state=None,
       shuffle=True, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.524 	-0.109 	-0.027 	0.265 	0.000 	0.000
[[155 137]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.97      0.53      0.69       292
          1       0.00      0.00      0.00         4

avg / total       0.96      0.52      0.68       296


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=None, max_features=0.33, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=30, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.578 	0.076 	0.020 	0.663 	0.657 	0.439
[[168 124]
 [  1   3]]
             precision    recall  f1-score   support

          0       0.99      0.58      0.73       292
          1       0.02      0.75      0.05         4

avg / total       0.98      0.58      0.72       296


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 15}, criterion='gini',
            max_depth=32, max_features=0.75, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=30, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.578 	0.076 	0.020 	0.663 	0.657 	0.439
[[168 124]
 [  1   3]]
             precision    recall  f1-score   support

          0       0.99      0.58      0.73       292
          1       0.02      0.75      0.05         4

avg / total       0.98      0.58      0.72       296


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.524 	-0.051 	-0.013 	0.389 	0.363 	0.128
[[154 138]
 [  3   1]]
             precision    recall  f1-score   support

          0       0.98      0.53      0.69       292
          1       0.01      0.25      0.01         4

avg / total       0.97      0.52      0.68       296


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 50}, criterion='gini', max_depth=8,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=0.5, n_estimators=50, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.605 	0.083 	0.023 	0.676 	0.672 	0.459
[[176 116]
 [  1   3]]
             precision    recall  f1-score   support

          0       0.99      0.60      0.75       292
          1       0.03      0.75      0.05         4

avg / total       0.98      0.60      0.74       296


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.1, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='linear',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.520 	0.119 	0.028 	0.757 	0.717 	0.539
[[150 142]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.51      0.68       292
          1       0.03      1.00      0.05         4

avg / total       0.99      0.52      0.67       296


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', R...wski',
           metric_params=None, n_jobs=4, n_neighbors=4, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.537 	0.009 	0.002 	0.519 	0.518 	0.268
[[157 135]
 [  2   2]]
             precision    recall  f1-score   support

          0       0.99      0.54      0.70       292
          1       0.01      0.50      0.03         4

avg / total       0.97      0.54      0.69       296


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=1,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.720 	-0.006 	-0.002 	0.488 	0.426 	0.173
[[212  80]
 [  3   1]]
             precision    recall  f1-score   support

          0       0.99      0.73      0.84       292
          1       0.01      0.25      0.02         4

avg / total       0.97      0.72      0.83       296


                estimator min_score mean_score max_score   sd_score  \
7                     SVC         0   0.390017  0.683856   0.298818   
1      LogisticRegression         0   0.353019  0.683856   0.230365   
6      AdaBoostClassifier -0.316144   0.457039         1   0.237798   
3    ExtraTreesClassifier  0.350522   0.799235         1   0.129394   
4  RandomForestClassifier   -0.1283   0.347051  0.906078   0.163703   
8        VotingClassifier  0.350522   0.584244  0.812156  0.0878026   
0              GaussianNB  0.701045   0.701045  0.701045          0   
9    KNeighborsClassifier  0.111111   0.355344  0.496011   0.109848   
5           MLPClassifier  0.350522   0.522483  0.718234  0.0584903   
2           SGDClassifier   -0.2566    0.49707  0.888889   0.191588   

         acc       auc           conf_matrix     f1_c0      f1_c1       kappa  \
7    0.52027  0.756849  [[150, 142], [0, 4]]  0.678733  0.0533333   0.0277572   
1   0.486486  0.739726  [[140, 152], [0, 4]]  0.648148       0.05   0.0242887   
6    0.60473   0.67637  [[176, 116], [1, 3]]  0.750533  0.0487805   0.0232401   
3   0.577703  0.662671  [[168, 124], [1, 3]]   0.72885  0.0458015   0.0201271   
4   0.577703  0.662671  [[168, 124], [1, 3]]   0.72885  0.0458015   0.0201271   
8   0.537162  0.518836  [[157, 135], [2, 2]]  0.696231  0.0283688  0.00216535   
0  0.0135135       0.5    [[0, 292], [0, 4]]         0  0.0266667           0   
9   0.719595  0.488014   [[212, 80], [3, 1]]  0.836292  0.0235294  -0.0022846   
5   0.523649  0.388699  [[154, 138], [3, 1]]  0.685969   0.013986  -0.0126165   
2   0.523649  0.265411  [[155, 137], [4, 0]]  0.687361          0  -0.0269685   

  model_score   prec_c0     prec_c1    rec_c0 rec_c1  
7    0.118634         1   0.0273973  0.513699      1  
1    0.110877         1    0.025641  0.479452      1  
6   0.0830645   0.99435   0.0252101   0.60274   0.75  
3   0.0758957  0.994083    0.023622  0.575342   0.75  
4   0.0758957  0.994083    0.023622  0.575342   0.75  
8  0.00872313  0.987421   0.0145985  0.537671    0.5  
0           0         0   0.0135135         0      1  
9 -0.00620833  0.986047   0.0123457  0.726027   0.25  
5  -0.0514985  0.980892  0.00719424  0.527397   0.25  
2   -0.108643  0.974843           0  0.530822      0  
Elapsed time 13.98 mins 

************************************************************

pre/post: 25/0  win/stride: 500/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-25 15:50:13.769000 
pca_target: 60 	 poly degree: 2 	 kselect: 20 
Imbalance: SMOTE(k=None, k_neighbors=5, kind='regular', m=None, m_neighbors=10, n_jobs=1,
   out_step=0.5, random_state=None, ratio='auto', svm_estimator=None) 
Extended target (count):  25141 325
('Total : Processed (count): ', (986L, 276L), 13)
Final feature (count):  (986L, 276L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.902 	-0.036 	-0.024 	0.457 	0.000 	0.000
[[267  25]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.91      0.95       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.90      0.94       296


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=10, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.953 	-0.022 	-0.020 	0.483 	0.000 	0.000
[[282  10]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.97      0.98       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.95      0.96       296


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.0001, average=False, class_weight='balanced',
       epsilon=0.1, eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='modified_huber', n_iter=5, n_jobs=4,
       penalty='l1', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.949 	-0.023 	-0.020 	0.481 	0.000 	0.000
[[281  11]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.96      0.97       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.95      0.96       296


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=32, max_features=0.75, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3},
            criterion='entropy', max_depth=32, max_features='auto',
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.01, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.973 	-0.014 	-0.014 	0.493 	0.000 	0.000
[[288   4]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.97      0.97       296


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 500}, criterion='gini', max_depth=16,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=0.5, n_estimators=50, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.983 	-0.007 	-0.005 	0.498 	0.000 	0.000
[[291   1]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.98       296


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=10, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.976 	-0.012 	-0.012 	0.495 	0.000 	0.000
[[289   3]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.97       296


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=10.0, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', ...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.973 	-0.014 	-0.014 	0.493 	0.000 	0.000
[[288   4]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.97      0.97       296


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=1,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.973 	-0.014 	-0.014 	0.493 	0.000 	0.000
[[288   4]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.97      0.97       296


                estimator  min_score mean_score max_score    sd_score  \
3    ExtraTreesClassifier   0.819413   0.982727  0.997084   0.0296854   
4  RandomForestClassifier   0.985348    0.99245  0.997084  0.00239642   
6      AdaBoostClassifier   0.904786    0.98149  0.998537   0.0134788   
7                     SVC          0   0.829573  0.991295    0.286269   
5           MLPClassifier    0.94853   0.971426  0.988348  0.00901774   
8        VotingClassifier   0.950264   0.965286   0.97686  0.00499708   
9    KNeighborsClassifier   0.926592   0.953115  0.972641   0.0153732   
1      LogisticRegression   0.225999   0.794544  0.934784    0.178953   
2           SGDClassifier -0.0535426   0.634851  0.955597    0.280934   
0              GaussianNB   0.923409   0.923409  0.923409           0   

        acc       auc          conf_matrix     f1_c0 f1_c1       kappa  \
3  0.986486       0.5   [[292, 0], [4, 0]]  0.993197     0           0   
4  0.986486       0.5   [[292, 0], [4, 0]]  0.993197     0           0   
6  0.983108  0.498288   [[291, 1], [4, 0]]  0.991482     0 -0.00543478   
7  0.976351  0.494863   [[289, 3], [4, 0]]  0.988034     0  -0.0117188   
5  0.972973  0.493151   [[288, 4], [4, 0]]  0.986301     0  -0.0136986   
8  0.972973  0.493151   [[288, 4], [4, 0]]  0.986301     0  -0.0136986   
9  0.972973  0.493151   [[288, 4], [4, 0]]  0.986301     0  -0.0136986   
1  0.952703  0.482877  [[282, 10], [4, 0]]  0.975779     0   -0.019685   
2  0.949324  0.481164  [[281, 11], [4, 0]]  0.974003     0  -0.0202206   
0  0.902027  0.457192  [[267, 25], [4, 0]]   0.94849     0   -0.023855   

  model_score   prec_c0 prec_c1    rec_c0 rec_c1  
3           0  0.986486       0         1      0  
4           0  0.986486       0         1      0  
6  -0.0068144  0.986441       0  0.996575      0  
7  -0.0118431  0.986348       0  0.989726      0  
5  -0.0136986  0.986301       0  0.986301      0  
8  -0.0136986  0.986301       0  0.986301      0  
9  -0.0136986  0.986301       0  0.986301      0  
1  -0.0218855  0.986014       0  0.965753      0  
2  -0.0229939  0.985965       0  0.962329      0  
0  -0.0355487   0.98524       0  0.914384      0  
Elapsed time 39.16 mins 

************************************************************

pre/post: 25/0  win/stride: 500/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-25 16:29:23.308000 
pca_target: 60 	 poly degree: 2 	 kselect: 20 
Imbalance: None 
Extended target (count):  25141 325
('Total : Processed (count): ', (986L, 276L), 13)
Final feature (count):  (986L, 276L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.625 	0.030 	0.009 	0.563 	0.560 	0.309
[[183 109]
 [  2   2]]
             precision    recall  f1-score   support

          0       0.99      0.63      0.77       292
          1       0.02      0.50      0.03         4

avg / total       0.98      0.62      0.76       296


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.001, class_weight={1: 500}, dual=False,
          fit_intercept=True, intercept_scaling=5, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.470 	0.107 	0.023 	0.731 	0.680 	0.487
[[135 157]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.46      0.63       292
          1       0.02      1.00      0.05         4

avg / total       0.99      0.47      0.62       296


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.5, average=False, class_weight='balanced', epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='invscaling', loss='squared_hinge', n_iter=5,
       n_jobs=4, penalty='l1', power_t=0.5, random_state=None,
       shuffle=True, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.608 	0.084 	0.024 	0.678 	0.674 	0.461
[[177 115]
 [  1   3]]
             precision    recall  f1-score   support

          0       0.99      0.61      0.75       292
          1       0.03      0.75      0.05         4

avg / total       0.98      0.61      0.74       296


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 500}, criterion='gini',
           max_depth=8, max_features='auto', max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=50, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.801 	-0.056 	-0.026 	0.406 	0.000 	0.000
[[237  55]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.98      0.81      0.89       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.80      0.88       296


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.01, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(500,), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.976 	-0.012 	-0.012 	0.495 	0.000 	0.000
[[289   3]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.97       296


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 50}, criterion='entropy',
            max_depth=32, max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=2.0, n_estimators=50, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.980 	-0.010 	-0.009 	0.497 	0.000 	0.000
[[290   2]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.98       296


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.1, cache_size=200, class_weight='balanced', coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.787 	0.013 	0.006 	0.522 	0.446 	0.188
[[232  60]
 [  3   1]]
             precision    recall  f1-score   support

          0       0.99      0.79      0.88       292
          1       0.02      0.25      0.03         4

avg / total       0.97      0.79      0.87       296


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', R...owski',
           metric_params=None, n_jobs=4, n_neighbors=4, p=2,
           weights='uniform'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=1,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


                estimator   min_score   mean_score  max_score     sd_score  \
1      LogisticRegression  -0.0424507   0.00330726  0.0972406    0.0307915   
2           SGDClassifier   -0.170559    0.0146169   0.138589    0.0335438   
0              GaussianNB    0.108989     0.108989   0.108989            0   
7                     SVC  -0.0326315   -0.0119148  0.0577212    0.0156825   
4  RandomForestClassifier -0.00414424 -0.000377105          0  0.000854111   
8        VotingClassifier   -0.017273  -0.00951172          0   0.00460172   
9    KNeighborsClassifier  -0.0161235  -0.00501412          0    0.0063462   
6      AdaBoostClassifier   -0.022224  -0.00765774   0.130576    0.0167959   
5           MLPClassifier  -0.0255905   -0.0180353 -0.0119331   0.00331625   
3    ExtraTreesClassifier  -0.0291322  -0.00300064   0.070434     0.010446   

        acc       auc           conf_matrix     f1_c0      f1_c1       kappa  \
1  0.469595  0.731164  [[135, 157], [0, 4]]  0.632319  0.0484848    0.022712   
2  0.608108  0.678082  [[177, 115], [1, 3]]  0.753191  0.0491803   0.0236579   
0     0.625  0.563356  [[183, 109], [2, 2]]  0.767296  0.0347826  0.00892857   
7  0.787162   0.52226   [[232, 60], [3, 1]]  0.880455  0.0307692  0.00554608   
4  0.986486       0.5    [[292, 0], [4, 0]]  0.993197          0           0   
8  0.986486       0.5    [[292, 0], [4, 0]]  0.993197          0           0   
9  0.986486       0.5    [[292, 0], [4, 0]]  0.993197          0           0   
6   0.97973  0.496575    [[290, 2], [4, 0]]  0.989761          0 -0.00909091   
5  0.976351  0.494863    [[289, 3], [4, 0]]  0.988034          0  -0.0117188   
3  0.800676  0.405822   [[237, 55], [4, 0]]  0.889306          0  -0.0258459   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
1    0.107175         1  0.0248447  0.462329      1  
2   0.0839887  0.994382  0.0254237  0.606164   0.75  
0   0.0302199  0.989189   0.018018  0.626712    0.5  
7   0.0127082  0.987234  0.0163934  0.794521   0.25  
4           0  0.986486          0         1      0  
8           0  0.986486          0         1      0  
9           0  0.986486          0         1      0  
6 -0.00965339  0.986395          0  0.993151      0  
5  -0.0118431  0.986348          0  0.989726      0  
3  -0.0559128  0.983402          0  0.811644      0  
Elapsed time 26.09 mins 

************************************************************

pre/post: 25/0  win/stride: 500/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-25 16:55:28.599000 
pca_target: 60 	 poly degree: 2 	 kselect: 60 
Imbalance: ClusterCentroids(estimator=None, n_jobs=1, random_state=None, ratio='auto') 
Extended target (count):  25141 325
('Total : Processed (count): ', (986L, 276L), 13)
Final feature (count):  (986L, 276L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.1, class_weight={1: 500}, dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.493 	-0.002 	-0.000 	0.497 	0.497 	0.247
[[144 148]
 [  2   2]]
             precision    recall  f1-score   support

          0       0.99      0.49      0.66       292
          1       0.01      0.50      0.03         4

avg / total       0.97      0.49      0.65       296


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.001, average=False, class_weight={1: 500}, epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='invscaling', loss='squared_hinge', n_iter=5,
       n_jobs=4, penalty='elasticnet', power_t=0.5, random_state=None,
       shuffle=True, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.497 	-0.001 	-0.000 	0.498 	0.498 	0.248
[[145 147]
 [  2   2]]
             precision    recall  f1-score   support

          0       0.99      0.50      0.66       292
          1       0.01      0.50      0.03         4

avg / total       0.97      0.50      0.65       296


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=16, max_features=0.33, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=50, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.591 	0.079 	0.022 	0.670 	0.665 	0.449
[[172 120]
 [  1   3]]
             precision    recall  f1-score   support

          0       0.99      0.59      0.74       292
          1       0.02      0.75      0.05         4

avg / total       0.98      0.59      0.73       296


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 500},
            criterion='gini', max_depth=None, max_features='auto',
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=15, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.554 	0.070 	0.018 	0.651 	0.643 	0.422
[[161 131]
 [  1   3]]
             precision    recall  f1-score   support

          0       0.99      0.55      0.71       292
          1       0.02      0.75      0.04         4

avg / total       0.98      0.55      0.70       296


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.510 	-0.055 	-0.013 	0.382 	0.358 	0.125
[[150 142]
 [  3   1]]
             precision    recall  f1-score   support

          0       0.98      0.51      0.67       292
          1       0.01      0.25      0.01         4

avg / total       0.97      0.51      0.67       296


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=2.0, n_estimators=50, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.520 	0.062 	0.015 	0.634 	0.623 	0.397
[[151 141]
 [  1   3]]
             precision    recall  f1-score   support

          0       0.99      0.52      0.68       292
          1       0.02      0.75      0.04         4

avg / total       0.98      0.52      0.67       296


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...wski',
           metric_params=None, n_jobs=4, n_neighbors=4, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.463 	-0.066 	-0.014 	0.358 	0.341 	0.114
[[136 156]
 [  3   1]]
             precision    recall  f1-score   support

          0       0.98      0.47      0.63       292
          1       0.01      0.25      0.01         4

avg / total       0.97      0.46      0.62       296


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=4, p=1,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.625 	0.030 	0.009 	0.563 	0.560 	0.309
[[183 109]
 [  2   2]]
             precision    recall  f1-score   support

          0       0.99      0.63      0.77       292
          1       0.02      0.50      0.03         4

avg / total       0.98      0.62      0.76       296


                estimator  min_score mean_score max_score   sd_score  \
3    ExtraTreesClassifier   0.239411   0.663588  0.906078   0.129001   
4  RandomForestClassifier    -0.2566   0.311444  0.718234   0.161185   
6      AdaBoostClassifier  -0.239411   0.370018         1   0.269488   
9    KNeighborsClassifier  -0.367711  0.0226496  0.350522   0.144873   
0              GaussianNB   0.701045   0.701045  0.701045          0   
7                     SVC  -0.350522  0.0956535  0.367711     0.1155   
2           SGDClassifier  -0.333333   0.287654  0.718234    0.14065   
1      LogisticRegression -0.0343779   0.120558  0.444444  0.0968974   
5           MLPClassifier  0.0767332   0.278686  0.555556  0.0931669   
8        VotingClassifier    -0.1283   0.214955  0.461633   0.101218   

        acc       auc           conf_matrix     f1_c0      f1_c1        kappa  \
3  0.591216  0.669521  [[172, 120], [1, 3]]  0.739785  0.0472441    0.0216346   
4  0.554054  0.650685  [[161, 131], [1, 3]]  0.709251  0.0434783    0.0176991   
6   0.52027  0.633562  [[151, 141], [1, 3]]   0.68018  0.0405405    0.0146287   
9     0.625  0.563356  [[183, 109], [2, 2]]  0.767296  0.0347826   0.00892857   
0  0.986486       0.5    [[292, 0], [4, 0]]  0.993197          0            0   
7  0.986486       0.5    [[292, 0], [4, 0]]  0.993197          0            0   
2  0.496622  0.498288  [[145, 147], [2, 2]]  0.660592  0.0261438 -0.000181422   
1  0.493243  0.496575  [[144, 148], [2, 2]]  0.657534   0.025974  -0.00036049   
5  0.510135  0.381849  [[150, 142], [3, 1]]  0.674157  0.0136054   -0.0130287   
8  0.462838  0.357877  [[136, 156], [3, 1]]   0.63109  0.0124224   -0.0143103   

   model_score   prec_c0     prec_c1    rec_c0 rec_c1  
3    0.0794325   0.99422   0.0243902  0.589041   0.75  
4    0.0699055  0.993827   0.0223881   0.55137   0.75  
6    0.0617064  0.993421   0.0208333  0.517123   0.75  
9    0.0302199  0.989189    0.018018  0.626712    0.5  
0            0  0.986486           0         1      0  
7            0  0.986486           0         1      0  
2 -0.000790837  0.986395   0.0134228  0.496575    0.5  
1  -0.00158178  0.986301   0.0133333  0.493151    0.5  
5   -0.0545976  0.980392  0.00699301  0.513699   0.25  
8   -0.0657596  0.978417  0.00636943  0.465753   0.25  
Elapsed time 14.79 mins 

************************************************************

pre/post: 25/0  win/stride: 500/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-25 17:10:15.848000 
pca_target: 60 	 poly degree: 2 	 kselect: 60 
Imbalance: SMOTE(k=None, k_neighbors=5, kind='regular', m=None, m_neighbors=10, n_jobs=1,
   out_step=0.5, random_state=None, ratio='auto', svm_estimator=None) 
Extended target (count):  25141 325
('Total : Processed (count): ', (986L, 276L), 13)
Final feature (count):  (986L, 276L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.845 	-0.048 	-0.025 	0.428 	0.000 	0.000
[[250  42]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.98      0.86      0.92       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.84      0.90       296


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=10, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=10, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.956 	-0.021 	-0.019 	0.485 	0.000 	0.000
[[283   9]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.97      0.98       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.96      0.96       296


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.001, average=False, class_weight='balanced',
       epsilon=0.1, eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='squared_hinge', n_iter=5, n_jobs=4,
       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.956 	-0.021 	-0.019 	0.485 	0.000 	0.000
[[283   9]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.97      0.98       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.96      0.96       296


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=16, max_features=0.75, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=30, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.983 	-0.007 	-0.005 	0.498 	0.000 	0.000
[[291   1]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.98       296


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=None, max_features=0.33, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=50, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.983 	-0.007 	-0.005 	0.498 	0.000 	0.000
[[291   1]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.98       296


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.01, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.980 	-0.010 	-0.009 	0.497 	0.000 	0.000
[[290   2]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.98       296


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=8,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=0.5, n_estimators=80, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.976 	-0.012 	-0.012 	0.495 	0.000 	0.000
[[289   3]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.97       296


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=10, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.980 	-0.010 	-0.009 	0.497 	0.000 	0.000
[[290   2]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.98       296


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=10.0, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', ...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.973 	-0.014 	-0.014 	0.493 	0.000 	0.000
[[288   4]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.97      0.97       296


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=3,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.970 	-0.015 	-0.015 	0.491 	0.000 	0.000
[[287   5]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.98      0.98       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.97      0.97       296


                estimator  min_score mean_score max_score    sd_score  \
3    ExtraTreesClassifier   0.825209   0.980616  0.997084    0.033418   
4  RandomForestClassifier   0.983958   0.993299  0.998537  0.00240734   
5           MLPClassifier   0.951438   0.971388  0.984021  0.00935943   
7                     SVC          0   0.827913  0.992727    0.290706   
6      AdaBoostClassifier   0.895548   0.982405         1   0.0134218   
8        VotingClassifier   0.941959   0.963233  0.974015  0.00592041   
9    KNeighborsClassifier   0.898337   0.950188  0.971218   0.0186535   
1      LogisticRegression   0.242576   0.804301   0.94031    0.165959   
2           SGDClassifier -0.0366444   0.629378  0.955614    0.280961   
0              GaussianNB   0.874189   0.874189  0.874189           0   

        acc       auc          conf_matrix     f1_c0 f1_c1       kappa  \
3  0.983108  0.498288   [[291, 1], [4, 0]]  0.991482     0 -0.00543478   
4  0.983108  0.498288   [[291, 1], [4, 0]]  0.991482     0 -0.00543478   
5   0.97973  0.496575   [[290, 2], [4, 0]]  0.989761     0 -0.00909091   
7   0.97973  0.496575   [[290, 2], [4, 0]]  0.989761     0 -0.00909091   
6  0.976351  0.494863   [[289, 3], [4, 0]]  0.988034     0  -0.0117188   
8  0.972973  0.493151   [[288, 4], [4, 0]]  0.986301     0  -0.0136986   
9  0.969595  0.491438   [[287, 5], [4, 0]]  0.984563     0  -0.0152439   
1  0.956081  0.484589   [[283, 9], [4, 0]]  0.977547     0  -0.0190678   
2  0.956081  0.484589   [[283, 9], [4, 0]]  0.977547     0  -0.0190678   
0  0.844595  0.428082  [[250, 42], [4, 0]]  0.915751     0  -0.0253012   

  model_score   prec_c0 prec_c1    rec_c0 rec_c1  
3  -0.0068144  0.986441       0  0.996575      0  
4  -0.0068144  0.986441       0  0.996575      0  
5 -0.00965339  0.986395       0  0.993151      0  
7 -0.00965339  0.986395       0  0.993151      0  
6  -0.0118431  0.986348       0  0.989726      0  
8  -0.0136986  0.986301       0  0.986301      0  
9  -0.0153418  0.986254       0  0.982877      0  
1  -0.0207262  0.986063       0  0.969178      0  
2  -0.0207262  0.986063       0  0.969178      0  
0  -0.0475934  0.984252       0  0.856164      0  
Elapsed time 52.42 mins 

************************************************************

pre/post: 25/0  win/stride: 500/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-25 18:02:41.122000 
pca_target: 60 	 poly degree: 2 	 kselect: 60 
Imbalance: None 
Extended target (count):  25141 325
('Total : Processed (count): ', (986L, 276L), 13)
Final feature (count):  (986L, 276L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.615 	0.086 	0.025 	0.682 	0.678 	0.466
[[179 113]
 [  1   3]]
             precision    recall  f1-score   support

          0       0.99      0.61      0.76       292
          1       0.03      0.75      0.05         4

avg / total       0.98      0.61      0.75       296


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.001, class_weight={1: 500}, dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='sag', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.537 	0.066 	0.016 	0.642 	0.633 	0.409
[[156 136]
 [  1   3]]
             precision    recall  f1-score   support

          0       0.99      0.53      0.69       292
          1       0.02      0.75      0.04         4

avg / total       0.98      0.54      0.69       296


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.5, average=False, class_weight='balanced', epsilon=0.1,
       eta0=0.001, fit_intercept=True, l1_ratio=0.15,
       learning_rate='constant', loss='squared_hinge', n_iter=5, n_jobs=4,
       penalty='l1', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.527 	0.063 	0.015 	0.637 	0.627 	0.402
[[153 139]
 [  1   3]]
             precision    recall  f1-score   support

          0       0.99      0.52      0.69       292
          1       0.02      0.75      0.04         4

avg / total       0.98      0.53      0.68       296


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 500},
           criterion='entropy', max_depth=8, max_features='auto',
           max_leaf_nodes=None, min_impurity_split=1e-07,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=4,
           oob_score=False, random_state=None, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.875 	-0.041 	-0.025 	0.443 	0.000 	0.000
[[259  33]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.98      0.89      0.93       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.88      0.92       296


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.966 	-0.017 	-0.016 	0.490 	0.000 	0.000
[[286   6]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.98      0.98       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.97      0.97       296


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight='balanced', criterion='entropy',
            max_depth=32, max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=1.0, n_estimators=50, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.970 	-0.015 	-0.015 	0.491 	0.000 	0.000
[[287   5]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.98      0.98       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.97      0.97       296


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.1, cache_size=200, class_weight='balanced', coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.814 	0.022 	0.010 	0.536 	0.453 	0.194
[[240  52]
 [  3   1]]
             precision    recall  f1-score   support

          0       0.99      0.82      0.90       292
          1       0.02      0.25      0.04         4

avg / total       0.97      0.81      0.89       296


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...owski',
           metric_params=None, n_jobs=4, n_neighbors=4, p=2,
           weights='uniform'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.983 	-0.007 	-0.005 	0.498 	0.000 	0.000
[[291   1]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.98       296


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=1,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


                estimator   min_score   mean_score   max_score     sd_score  \
0              GaussianNB   0.0623903    0.0623903   0.0623903            0   
1      LogisticRegression  -0.0466852  0.000649881   0.0703235    0.0260821   
2           SGDClassifier  -0.0578744    0.0138298     0.17812     0.031757   
7                     SVC  -0.0314101   -0.0116456   0.0810155    0.0157254   
4  RandomForestClassifier -0.00588235 -0.000359855           0  0.000921438   
9    KNeighborsClassifier  -0.0170712  -0.00544065           0   0.00642647   
8        VotingClassifier  -0.0187657  -0.00974224 -0.00207212   0.00481673   
6      AdaBoostClassifier  -0.0235748  -0.00511759     0.19132    0.0224251   
5           MLPClassifier  -0.0247287   -0.0142673   0.0485612    0.0151711   
3    ExtraTreesClassifier  -0.0283335  -0.00310509   0.0739394    0.0115086   

        acc       auc           conf_matrix     f1_c0      f1_c1       kappa  \
0  0.614865  0.681507  [[179, 113], [1, 3]]  0.758475       0.05   0.0245143   
1  0.537162  0.642123  [[156, 136], [1, 3]]  0.694878   0.041958   0.0161102   
2  0.527027  0.636986  [[153, 139], [1, 3]]  0.686099  0.0410959   0.0152091   
7  0.814189  0.535959   [[240, 52], [3, 1]]  0.897196  0.0350877    0.010214   
4  0.986486       0.5    [[292, 0], [4, 0]]  0.993197          0           0   
9  0.986486       0.5    [[292, 0], [4, 0]]  0.993197          0           0   
8  0.983108  0.498288    [[291, 1], [4, 0]]  0.991482          0 -0.00543478   
6  0.969595  0.491438    [[287, 5], [4, 0]]  0.984563          0  -0.0152439   
5  0.966216  0.489726    [[286, 6], [4, 0]]  0.982818          0  -0.0164835   
3     0.875  0.443493   [[259, 33], [4, 0]]  0.933333          0  -0.0247006   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
0   0.0858577  0.994444  0.0258621  0.613014   0.75  
1   0.0657596  0.993631  0.0215827  0.534247   0.75  
2   0.0633175  0.993506  0.0211268  0.523973   0.75  
7   0.0216579  0.987654  0.0188679  0.821918   0.25  
4           0  0.986486          0         1      0  
9           0  0.986486          0         1      0  
8  -0.0068144  0.986441          0  0.996575      0  
6  -0.0153418  0.986254          0  0.982877      0  
5  -0.0168351  0.986207          0  0.979452      0  
3  -0.0414589  0.984791          0  0.886986      0  
Elapsed time 30.26 mins 

************************************************************

[4;33mReloaded modules[24m: migraine_processing, classifiers[0m
Finished.



lagged allx5, Standard




    pca = [0]
    poly = [0]
    ksel = [20, 40]
    imb = [ClusterCentroids(), None]






	

pre/post: 25/0  win/stride: 500/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-25 19:17:57.927000 
pca_target: 0 	 poly degree: 0 	 kselect: 20 
Imbalance: ClusterCentroids(estimator=None, n_jobs=1, random_state=None, ratio='auto') 
Extended target (count):  25141 325
('Total : Processed (count): ', (986L, 110L), 13)
Final feature (count):  (986L, 110L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.507 	0.115 	0.026 	0.750 	0.707 	0.525
[[146 146]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.50      0.67       292
          1       0.03      1.00      0.05         4

avg / total       0.99      0.51      0.66       296


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=5, class_weight={1: 50}, dual=False, fit_intercept=True,
          intercept_scaling=0.01, max_iter=100, multi_class='ovr',
          n_jobs=4, penalty='l2', random_state=None, solver='sag',
          tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.439 	0.101 	0.020 	0.716 	0.657 	0.456
[[126 166]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.43      0.60       292
          1       0.02      1.00      0.05         4

avg / total       0.99      0.44      0.60       296


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.5, average=False, class_weight='balanced', epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='modified_huber', n_iter=5, n_jobs=4,
       penalty='none', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.743 	0.065 	0.025 	0.623 	0.611 	0.364
[[218  74]
 [  2   2]]
             precision    recall  f1-score   support

          0       0.99      0.75      0.85       292
          1       0.03      0.50      0.05         4

avg / total       0.98      0.74      0.84       296


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=32, max_features='auto', max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.568 	0.073 	0.019 	0.658 	0.651 	0.432
[[165 127]
 [  1   3]]
             precision    recall  f1-score   support

          0       0.99      0.57      0.72       292
          1       0.02      0.75      0.04         4

avg / total       0.98      0.57      0.71       296


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 50},
            criterion='entropy', max_depth=None, max_features=0.75,
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=15, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.645 	0.036 	0.011 	0.574 	0.569 	0.319
[[189 103]
 [  2   2]]
             precision    recall  f1-score   support

          0       0.99      0.65      0.78       292
          1       0.02      0.50      0.04         4

avg / total       0.98      0.65      0.77       296


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.706 	0.053 	0.019 	0.604 	0.595 	0.347
[[207  85]
 [  2   2]]
             precision    recall  f1-score   support

          0       0.99      0.71      0.83       292
          1       0.02      0.50      0.04         4

avg / total       0.98      0.71      0.82       296


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight='balanced', criterion='gini',
            max_depth=16, max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=1.0, n_estimators=80, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.480 	0.052 	0.011 	0.613 	0.598 	0.367
[[139 153]
 [  1   3]]
             precision    recall  f1-score   support

          0       0.99      0.48      0.64       292
          1       0.02      0.75      0.04         4

avg / total       0.98      0.48      0.64       296


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.5, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='linear',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.439 	0.101 	0.020 	0.716 	0.657 	0.456
[[126 166]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.43      0.60       292
          1       0.02      1.00      0.05         4

avg / total       0.99      0.44      0.60       296


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', R...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.561 	0.072 	0.018 	0.654 	0.647 	0.427
[[163 129]
 [  1   3]]
             precision    recall  f1-score   support

          0       0.99      0.56      0.71       292
          1       0.02      0.75      0.04         4

avg / total       0.98      0.56      0.71       296


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=5, p=1,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.537 	0.066 	0.016 	0.642 	0.633 	0.409
[[156 136]
 [  1   3]]
             precision    recall  f1-score   support

          0       0.99      0.53      0.69       292
          1       0.02      0.75      0.04         4

avg / total       0.98      0.54      0.69       296


                estimator min_score mean_score max_score   sd_score       acc  \
0              GaussianNB  0.666667   0.666667  0.666667          0  0.506757   
1      LogisticRegression         0    0.26457  0.589933   0.174797  0.439189   
7                     SVC         0   0.296483  0.607122   0.231456  0.439189   
3    ExtraTreesClassifier  0.461633   0.586223  0.794967  0.0687371  0.567568   
8        VotingClassifier  0.350522   0.433134  0.607122   0.073829  0.560811   
9    KNeighborsClassifier   -0.1283   0.186145  0.478822   0.173503  0.537162   
2           SGDClassifier -0.367711   0.289308  0.718234   0.137878  0.743243   
6      AdaBoostClassifier  0.222222    0.63068  0.906078   0.109553   0.47973   
5           MLPClassifier    0.2566   0.536974  0.701045  0.0995525  0.706081   
4  RandomForestClassifier  0.350522   0.625432  0.906078   0.101807   0.64527   

        auc           conf_matrix     f1_c0      f1_c1      kappa model_score  \
0      0.75  [[146, 146], [0, 4]]  0.666667  0.0519481  0.0263158     0.11547   
1  0.715753  [[126, 166], [0, 4]]  0.602871   0.045977  0.0201021    0.100763   
7  0.715753  [[126, 166], [0, 4]]  0.602871   0.045977  0.0201021    0.100763   
3  0.657534  [[165, 127], [1, 3]]  0.720524  0.0447761  0.0190555   0.0732994   
8   0.65411  [[163, 129], [1, 3]]  0.714912  0.0441176  0.0183673   0.0715933   
9  0.642123  [[156, 136], [1, 3]]  0.694878   0.041958  0.0161102   0.0657596   
2  0.623288   [[218, 74], [2, 2]]  0.851562       0.05  0.0249653   0.0651708   
6  0.613014  [[139, 153], [1, 3]]  0.643519     0.0375  0.0114504   0.0522704   
5  0.604452   [[207, 85], [2, 2]]  0.826347   0.043956  0.0185976   0.0529463   
4   0.57363  [[189, 103], [2, 2]]  0.782609  0.0366972   0.010947   0.0355382   

    prec_c0    prec_c1    rec_c0 rec_c1  
0         1  0.0266667       0.5      1  
1         1  0.0235294  0.431507      1  
7         1  0.0235294  0.431507      1  
3  0.993976  0.0230769  0.565068   0.75  
8  0.993902  0.0227273  0.558219   0.75  
9  0.993631  0.0215827  0.534247   0.75  
2  0.990909  0.0263158  0.746575    0.5  
6  0.992857  0.0192308  0.476027   0.75  
5  0.990431  0.0229885  0.708904    0.5  
4  0.989529  0.0190476   0.64726    0.5  
Elapsed time 15.07 mins 

************************************************************

pre/post: 25/0  win/stride: 500/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-25 19:33:01.942000 
pca_target: 0 	 poly degree: 0 	 kselect: 20 
Imbalance: None 
Extended target (count):  25141 325
('Total : Processed (count): ', (986L, 110L), 13)
Final feature (count):  (986L, 110L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.520 	0.119 	0.028 	0.757 	0.717 	0.539
[[150 142]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.51      0.68       292
          1       0.03      1.00      0.05         4

avg / total       0.99      0.52      0.67       296


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.001, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.878 	0.050 	0.029 	0.568 	0.471 	0.208
[[259  33]
 [  3   1]]
             precision    recall  f1-score   support

          0       0.99      0.89      0.94       292
          1       0.03      0.25      0.05         4

avg / total       0.98      0.88      0.92       296


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.1, average=False, class_weight={1: 15}, epsilon=0.1,
       eta0=0.001, fit_intercept=True, l1_ratio=0.15,
       learning_rate='invscaling', loss='modified_huber', n_iter=5,
       n_jobs=4, penalty='l2', power_t=0.5, random_state=None,
       shuffle=True, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.878 	0.050 	0.029 	0.568 	0.471 	0.208
[[259  33]
 [  3   1]]
             precision    recall  f1-score   support

          0       0.99      0.89      0.94       292
          1       0.03      0.25      0.05         4

avg / total       0.98      0.88      0.92       296


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 50}, criterion='gini',
           max_depth=8, max_features='auto', max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=30, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.973 	-0.014 	-0.014 	0.493 	0.000 	0.000
[[288   4]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.97      0.97       296


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=50, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.5, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.983 	-0.007 	-0.005 	0.498 	0.000 	0.000
[[291   1]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.98       296


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 50}, criterion='gini', max_depth=16,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=0.5, n_estimators=80, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.980 	-0.010 	-0.009 	0.497 	0.000 	0.000
[[290   2]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.98       296


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=1, cache_size=200, class_weight={1: 50}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.970 	-0.015 	-0.015 	0.491 	0.000 	0.000
[[287   5]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.98      0.98       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.97      0.97       296


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=1.0, class_weight={1: 500}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Ran...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.983 	-0.007 	-0.005 	0.498 	0.000 	0.000
[[291   1]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.98       296


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=1,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.976 	-0.012 	-0.012 	0.495 	0.000 	0.000
[[289   3]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.97       296


                estimator   min_score   mean_score  max_score    sd_score  \
0              GaussianNB   0.0594198    0.0594198  0.0594198           0   
1      LogisticRegression   -0.033199    0.0454006   0.164862   0.0417167   
2           SGDClassifier   -0.187696    0.0309756   0.193531   0.0418424   
4  RandomForestClassifier  -0.0171122 -0.000809006          0  0.00183133   
5           MLPClassifier  -0.0155116   0.00262474   0.072985   0.0285578   
8        VotingClassifier  -0.0144729    0.0159476   0.212803   0.0445633   
6      AdaBoostClassifier  -0.0192826    0.0014896   0.233746   0.0337824   
9    KNeighborsClassifier -0.00708511     0.040867   0.190285   0.0755893   
3    ExtraTreesClassifier  -0.0212122    0.0108869   0.190797   0.0388009   
7                     SVC  -0.0266964    0.0414334   0.170829   0.0462679   

        acc       auc           conf_matrix     f1_c0      f1_c1       kappa  \
0   0.52027  0.756849  [[150, 142], [0, 4]]  0.678733  0.0533333   0.0277572   
1  0.878378  0.568493   [[259, 33], [3, 1]]  0.935018  0.0526316   0.0291545   
2  0.878378  0.568493   [[259, 33], [3, 1]]  0.935018  0.0526316   0.0291545   
4  0.986486       0.5    [[292, 0], [4, 0]]  0.993197          0           0   
5  0.983108  0.498288    [[291, 1], [4, 0]]  0.991482          0 -0.00543478   
8  0.983108  0.498288    [[291, 1], [4, 0]]  0.991482          0 -0.00543478   
6   0.97973  0.496575    [[290, 2], [4, 0]]  0.989761          0 -0.00909091   
9  0.976351  0.494863    [[289, 3], [4, 0]]  0.988034          0  -0.0117188   
3  0.972973  0.493151    [[288, 4], [4, 0]]  0.986301          0  -0.0136986   
7  0.969595  0.491438    [[287, 5], [4, 0]]  0.984563          0  -0.0152439   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
0    0.118634         1  0.0273973  0.513699      1  
1   0.0496031   0.98855  0.0294118  0.886986   0.25  
2   0.0496031   0.98855  0.0294118  0.886986   0.25  
4           0  0.986486          0         1      0  
5  -0.0068144  0.986441          0  0.996575      0  
8  -0.0068144  0.986441          0  0.996575      0  
6 -0.00965339  0.986395          0  0.993151      0  
9  -0.0118431  0.986348          0  0.989726      0  
3  -0.0136986  0.986301          0  0.986301      0  
7  -0.0153418  0.986254          0  0.982877      0  
Elapsed time 23.88 mins 

************************************************************

pre/post: 25/0  win/stride: 500/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-25 19:56:54.625000 
pca_target: 0 	 poly degree: 0 	 kselect: 40 
Imbalance: ClusterCentroids(estimator=None, n_jobs=1, random_state=None, ratio='auto') 
Extended target (count):  25141 325
('Total : Processed (count): ', (986L, 110L), 13)
Final feature (count):  (986L, 110L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.510 	0.116 	0.027 	0.752 	0.710 	0.528
[[147 145]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.50      0.67       292
          1       0.03      1.00      0.05         4

avg / total       0.99      0.51      0.66       296


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.001, class_weight={1: 3}, dual=False,
          fit_intercept=True, intercept_scaling=5, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.250 	0.065 	0.008 	0.620 	0.490 	0.258
[[ 70 222]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.24      0.39       292
          1       0.02      1.00      0.03         4

avg / total       0.99      0.25      0.38       296


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.1, average=False, class_weight='balanced', epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='perceptron', n_iter=5, n_jobs=4,
       penalty='l1', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.443 	0.101 	0.020 	0.717 	0.659 	0.460
[[127 165]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.43      0.61       292
          1       0.02      1.00      0.05         4

avg / total       0.99      0.44      0.60       296


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight='balanced',
           criterion='entropy', max_depth=8, max_features=0.33,
           max_leaf_nodes=None, min_impurity_split=1e-07,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=15, n_jobs=4,
           oob_score=False, random_state=None, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.601 	0.082 	0.023 	0.675 	0.670 	0.456
[[175 117]
 [  1   3]]
             precision    recall  f1-score   support

          0       0.99      0.60      0.75       292
          1       0.03      0.75      0.05         4

avg / total       0.98      0.60      0.74       296


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features=0.75, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.672 	0.043 	0.014 	0.587 	0.581 	0.331
[[197  95]
 [  2   2]]
             precision    recall  f1-score   support

          0       0.99      0.67      0.80       292
          1       0.02      0.50      0.04         4

avg / total       0.98      0.67      0.79       296


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.01, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.757 	0.070 	0.028 	0.630 	0.617 	0.370
[[222  70]
 [  2   2]]
             precision    recall  f1-score   support

          0       0.99      0.76      0.86       292
          1       0.03      0.50      0.05         4

avg / total       0.98      0.76      0.85       296


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='entropy', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=2.0, n_estimators=50, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.750 	-0.065 	-0.026 	0.380 	0.000 	0.000
[[222  70]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.98      0.76      0.86       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.75      0.85       296


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.301 	0.074 	0.011 	0.646 	0.540 	0.312
[[ 85 207]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.29      0.45       292
          1       0.02      1.00      0.04         4

avg / total       0.99      0.30      0.45       296


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=1.0, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', R...owski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='uniform'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.676 	-0.017 	-0.006 	0.466 	0.413 	0.163
[[199  93]
 [  3   1]]
             precision    recall  f1-score   support

          0       0.99      0.68      0.81       292
          1       0.01      0.25      0.02         4

avg / total       0.97      0.68      0.80       296


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=5, p=1,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.541 	0.010 	0.002 	0.521 	0.520 	0.269
[[158 134]
 [  2   2]]
             precision    recall  f1-score   support

          0       0.99      0.54      0.70       292
          1       0.01      0.50      0.03         4

avg / total       0.97      0.54      0.69       296


                estimator  min_score mean_score max_score   sd_score  \
0              GaussianNB   0.701045   0.701045  0.701045          0   
2           SGDClassifier  -0.478822   0.258125  0.718234   0.164499   
3    ExtraTreesClassifier     0.2566   0.533691  0.624311  0.0681147   
7                     SVC    -0.1283   0.225196    0.5132   0.194702   
5           MLPClassifier  0.0171889   0.248722  0.478822   0.116018   
1      LogisticRegression  -0.111111   0.245344  0.496011   0.161204   
4  RandomForestClassifier     0.1283   0.554181  0.812156   0.137718   
9    KNeighborsClassifier  -0.350522 -0.0235834  0.222222   0.141019   
8        VotingClassifier   0.145489   0.372176  0.624311   0.104524   
6      AdaBoostClassifier          0   0.576297  0.812156   0.118593   

        acc       auc           conf_matrix     f1_c0      f1_c1       kappa  \
0  0.510135  0.751712  [[147, 145], [0, 4]]  0.669704  0.0522876   0.0266691   
2  0.442568  0.717466  [[127, 165], [0, 4]]  0.606205  0.0462428   0.0203787   
3  0.601351  0.674658  [[175, 117], [1, 3]]  0.747863  0.0483871    0.022829   
7  0.300676  0.645548   [[85, 207], [0, 4]]  0.450928  0.0372093   0.0109762   
5  0.756757  0.630137   [[222, 70], [2, 2]]  0.860465  0.0526316   0.0277372   
1      0.25  0.619863   [[70, 222], [0, 4]]   0.38674  0.0347826  0.00845002   
4  0.672297  0.587329   [[197, 95], [2, 2]]  0.802444   0.039604    0.014011   
9  0.540541  0.520548  [[158, 134], [2, 2]]  0.699115  0.0285714  0.00237906   
8  0.675676  0.465753   [[199, 93], [3, 1]]  0.805668  0.0204082 -0.00566251   
6      0.75  0.380137   [[222, 70], [4, 0]]  0.857143          0  -0.0262369   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
0    0.116253         1  0.0268456  0.503425      1  
2    0.101461         1  0.0236686  0.434932      1  
3    0.082147  0.994318      0.025  0.599315   0.75  
7    0.074286         1  0.0189573  0.291096      1  
5   0.0700425  0.991071  0.0277778  0.760274    0.5  
1   0.0651378         1  0.0176991  0.239726      1  
4   0.0429632   0.98995  0.0206186  0.674658    0.5  
9  0.00952117    0.9875  0.0147059  0.541096    0.5  
8  -0.0169875  0.985149  0.0106383  0.681507   0.25  
6  -0.0651378  0.982301          0  0.760274      0  
Elapsed time 15.75 mins 

************************************************************

pre/post: 25/0  win/stride: 500/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-25 20:12:39.922000 
pca_target: 0 	 poly degree: 0 	 kselect: 40 
Imbalance: None 
Extended target (count):  25141 325
('Total : Processed (count): ', (986L, 110L), 13)
Final feature (count):  (986L, 110L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.547 	0.125 	0.031 	0.771 	0.736 	0.566
[[158 134]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.54      0.70       292
          1       0.03      1.00      0.06         4

avg / total       0.99      0.55      0.69       296


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=10, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=10, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.922 	0.082 	0.059 	0.591 	0.483 	0.217
[[272  20]
 [  3   1]]
             precision    recall  f1-score   support

          0       0.99      0.93      0.96       292
          1       0.05      0.25      0.08         4

avg / total       0.98      0.92      0.95       296


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.1, average=False, class_weight={1: 15}, epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='invscaling', loss='squared_hinge', n_iter=5,
       n_jobs=4, penalty='none', power_t=0.5, random_state=None,
       shuffle=True, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=16, max_features=0.75, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=50, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 500},
            criterion='gini', max_depth=8, max_features=0.33,
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.980 	-0.010 	-0.009 	0.497 	0.000 	0.000
[[290   2]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.98       296


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.1, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.980 	-0.010 	-0.009 	0.497 	0.000 	0.000
[[290   2]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.98       296


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='entropy', max_depth=16,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=0.5, n_estimators=15, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.983 	-0.007 	-0.005 	0.498 	0.000 	0.000
[[291   1]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.98       296


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.1, cache_size=200, class_weight={1: 500}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='linear',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.811 	0.020 	0.010 	0.534 	0.452 	0.193
[[239  53]
 [  3   1]]
             precision    recall  f1-score   support

          0       0.99      0.82      0.90       292
          1       0.02      0.25      0.03         4

avg / total       0.97      0.81      0.88       296


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...owski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='uniform'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


                estimator  min_score   mean_score  max_score    sd_score  \
0              GaussianNB  0.0368244    0.0368244  0.0368244           0   
1      LogisticRegression -0.0903126     0.052922   0.159855   0.0519835   
7                     SVC -0.0306043    0.0348421   0.129061   0.0488238   
2           SGDClassifier  -0.152575    0.0292131   0.228428   0.0400105   
3    ExtraTreesClassifier -0.0388567   -0.0020675  0.0942409   0.0134997   
8        VotingClassifier -0.0144729  -0.00572073          0  0.00341139   
9    KNeighborsClassifier -0.0155276  -0.00484277          0  0.00593288   
6      AdaBoostClassifier -0.0255982  -0.00189894   0.159849    0.026579   
4  RandomForestClassifier -0.0160238 -0.000795077  0.0682828  0.00414765   
5           MLPClassifier -0.0175832  -0.00769963  0.0707187   0.0119965   

        acc       auc           conf_matrix     f1_c0      f1_c1       kappa  \
0  0.547297  0.770548  [[158, 134], [0, 4]]  0.702222   0.056338   0.0308835   
1  0.922297  0.590753   [[272, 20], [3, 1]]  0.959436       0.08   0.0586283   
7  0.810811  0.534247   [[239, 53], [3, 1]]  0.895131  0.0344828  0.00956023   
2  0.986486       0.5    [[292, 0], [4, 0]]  0.993197          0           0   
3  0.986486       0.5    [[292, 0], [4, 0]]  0.993197          0           0   
8  0.986486       0.5    [[292, 0], [4, 0]]  0.993197          0           0   
9  0.986486       0.5    [[292, 0], [4, 0]]  0.993197          0           0   
6  0.983108  0.498288    [[291, 1], [4, 0]]  0.991482          0 -0.00543478   
4   0.97973  0.496575    [[290, 2], [4, 0]]  0.989761          0 -0.00909091   
5   0.97973  0.496575    [[290, 2], [4, 0]]  0.989761          0 -0.00909091   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
0    0.125236         1  0.0289855  0.541096      1  
1   0.0816279  0.989091   0.047619  0.931507   0.25  
7   0.0204769  0.987603  0.0185185  0.818493   0.25  
2           0  0.986486          0         1      0  
3           0  0.986486          0         1      0  
8           0  0.986486          0         1      0  
9           0  0.986486          0         1      0  
6  -0.0068144  0.986441          0  0.996575      0  
4 -0.00965339  0.986395          0  0.993151      0  
5 -0.00965339  0.986395          0  0.993151      0  
Elapsed time 23.65 mins 

************************************************************

[4;33mReloaded modules[24m: migraine_processing, classifiers[0m
Finished.

lagged (3,4)x2

    pca = [0, 20]
    poly = [0, 2]
    ksel = [20, 0]
    imb = [ClusterCentroids(), SMOTE(kind='borderline1'), None]
	




	
pre/post: 25/0  win/stride: 500/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-25 23:46:39.643000 
pca_target: 0 	 poly degree: 0 	 kselect: 20 
Imbalance: ClusterCentroids(estimator=None, n_jobs=1, random_state=None, ratio='auto') 
Extended target (count):  25141 325
('Total : Processed (count): ', (986L, 24L), 13)
Final feature (count):  (986L, 24L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.554 	0.070 	0.018 	0.651 	0.643 	0.422
[[161 131]
 [  1   3]]
             precision    recall  f1-score   support

          0       0.99      0.55      0.71       292
          1       0.02      0.75      0.04         4

avg / total       0.98      0.55      0.70       296


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.01, class_weight={1: 500}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.257 	0.066 	0.009 	0.623 	0.497 	0.265
[[ 72 220]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.25      0.40       292
          1       0.02      1.00      0.04         4

avg / total       0.99      0.26      0.39       296


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.5, average=False, class_weight='balanced', epsilon=0.1,
       eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='perceptron', n_iter=5, n_jobs=4,
       penalty='none', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.503 	0.058 	0.013 	0.625 	0.612 	0.384
[[146 146]
 [  1   3]]
             precision    recall  f1-score   support

          0       0.99      0.50      0.67       292
          1       0.02      0.75      0.04         4

avg / total       0.98      0.50      0.66       296


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=8, max_features=0.75, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.510 	0.059 	0.014 	0.628 	0.617 	0.389
[[148 144]
 [  1   3]]
             precision    recall  f1-score   support

          0       0.99      0.51      0.67       292
          1       0.02      0.75      0.04         4

avg / total       0.98      0.51      0.66       296


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=16, max_features=0.75, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=30, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.497 	0.056 	0.013 	0.622 	0.608 	0.379
[[144 148]
 [  1   3]]
             precision    recall  f1-score   support

          0       0.99      0.49      0.66       292
          1       0.02      0.75      0.04         4

avg / total       0.98      0.50      0.65       296


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.5, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(500,), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.649 	0.036 	0.011 	0.575 	0.570 	0.320
[[190 102]
 [  2   2]]
             precision    recall  f1-score   support

          0       0.99      0.65      0.79       292
          1       0.02      0.50      0.04         4

avg / total       0.98      0.65      0.78       296


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=8,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=1.0, n_estimators=50, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.456 	0.104 	0.022 	0.724 	0.670 	0.473
[[131 161]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.45      0.62       292
          1       0.02      1.00      0.05         4

avg / total       0.99      0.46      0.61       296


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=1, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='linear',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.476 	0.109 	0.023 	0.735 	0.685 	0.494
[[137 155]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.47      0.64       292
          1       0.03      1.00      0.05         4

avg / total       0.99      0.48      0.63       296


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 500}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Ran...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.446 	0.102 	0.021 	0.719 	0.662 	0.463
[[128 164]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.44      0.61       292
          1       0.02      1.00      0.05         4

avg / total       0.99      0.45      0.60       296


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=3, p=3,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.662 	0.040 	0.013 	0.582 	0.576 	0.327
[[194  98]
 [  2   2]]
             precision    recall  f1-score   support

          0       0.99      0.66      0.80       292
          1       0.02      0.50      0.04         4

avg / total       0.98      0.66      0.78       296


                estimator  min_score   mean_score max_score   sd_score  \
7                     SVC    -0.1283     0.023312    0.2566   0.102011   
6      AdaBoostClassifier -0.0171889     0.422915  0.906078   0.127623   
8        VotingClassifier          0     0.328011  0.496011    0.13433   
0              GaussianNB   0.572745     0.572745  0.572745          0   
3    ExtraTreesClassifier    -0.1283     0.327862  0.607122   0.124435   
2           SGDClassifier  -0.367711     0.170442  0.701045   0.154147   
1      LogisticRegression    -0.2566     0.155684    0.3849   0.137151   
4  RandomForestClassifier  -0.111111     0.429887  0.812156   0.186081   
9    KNeighborsClassifier  -0.461633 -0.000664785    0.3849   0.235687   
5           MLPClassifier    -0.2566   -0.0522179    0.1283  0.0806363   

        acc       auc           conf_matrix     f1_c0      f1_c1       kappa  \
7  0.476351  0.734589  [[137, 155], [0, 4]]  0.638695  0.0490798   0.0233311   
6  0.456081  0.724315  [[131, 161], [0, 4]]  0.619385  0.0473373   0.0215177   
8  0.445946  0.719178  [[128, 164], [0, 4]]  0.609524  0.0465116   0.0206585   
0  0.554054  0.650685  [[161, 131], [1, 3]]  0.709251  0.0434783   0.0176991   
3  0.510135  0.628425  [[148, 144], [1, 3]]  0.671202  0.0397351   0.0137868   
2  0.503378     0.625  [[146, 146], [1, 3]]  0.665148  0.0392157   0.0132438   
1  0.256757  0.623288   [[72, 220], [0, 4]]  0.395604  0.0350877  0.00876766   
4  0.496622  0.621575  [[144, 148], [1, 3]]  0.659039  0.0387097   0.0127149   
9  0.662162  0.582192   [[194, 98], [2, 2]]  0.795082  0.0384615   0.0128068   
5  0.648649  0.575342  [[190, 102], [2, 2]]  0.785124   0.037037   0.0113052   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
7    0.108643         1  0.0251572  0.469178      1  
6    0.104287         1  0.0242424   0.44863      1  
8    0.102162         1  0.0238095  0.438356      1  
0   0.0699055  0.993827  0.0223881   0.55137   0.75  
3   0.0593127  0.993289  0.0204082  0.506849   0.75  
2   0.0577311  0.993197  0.0201342       0.5   0.75  
1   0.0663561         1  0.0178571  0.246575      1  
4   0.0561597  0.993103  0.0198675  0.493151   0.75  
9   0.0401284  0.989796       0.02  0.664384    0.5  
5   0.0364438  0.989583  0.0192308  0.650685    0.5  
Elapsed time 15.07 mins 

************************************************************

pre/post: 25/0  win/stride: 500/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-26 00:01:43.947000 
pca_target: 0 	 poly degree: 0 	 kselect: 20 
Imbalance: SMOTE(k=None, k_neighbors=5, kind='borderline1', m=None, m_neighbors=10,
   n_jobs=1, out_step=0.5, random_state=None, ratio='auto',
   svm_estimator=None) 
Extended target (count):  25141 325
('Total : Processed (count): ', (986L, 24L), 13)
Final feature (count):  (986L, 24L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.554 	0.070 	0.018 	0.651 	0.643 	0.422
[[161 131]
 [  1   3]]
             precision    recall  f1-score   support

          0       0.99      0.55      0.71       292
          1       0.02      0.75      0.04         4

avg / total       0.98      0.55      0.70       296


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.1, class_weight={1: 3}, dual=False, fit_intercept=True,
          intercept_scaling=0.1, max_iter=100, multi_class='ovr', n_jobs=4,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.976 	-0.012 	-0.012 	0.495 	0.000 	0.000
[[289   3]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.97       296


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.001, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.001, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='squared_hinge', n_iter=5, n_jobs=4,
       penalty='l1', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.946 	-0.024 	-0.021 	0.479 	0.000 	0.000
[[280  12]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.96      0.97       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.95      0.96       296


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 500}, criterion='gini',
           max_depth=8, max_features='auto', max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=50, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.706 	0.053 	0.019 	0.604 	0.595 	0.347
[[207  85]
 [  2   2]]
             precision    recall  f1-score   support

          0       0.99      0.71      0.83       292
          1       0.02      0.50      0.04         4

avg / total       0.98      0.71      0.82       296


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight='balanced',
            criterion='gini', max_depth=8, max_features=0.75,
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=15, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(500,), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.973 	-0.014 	-0.014 	0.493 	0.000 	0.000
[[288   4]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.97      0.97       296


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=16,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=1.0, n_estimators=15, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.963 	-0.018 	-0.018 	0.488 	0.000 	0.000
[[285   7]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.98      0.98       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.96      0.97       296


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.1, cache_size=200, class_weight={1: 500}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.432 	0.099 	0.020 	0.712 	0.652 	0.449
[[124 168]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.42      0.60       292
          1       0.02      1.00      0.05         4

avg / total       0.99      0.43      0.59       296


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=1,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


                estimator  min_score   mean_score  max_score    sd_score  \
7                     SVC -0.0381152   0.00639303  0.0913259   0.0200867   
0              GaussianNB  0.0184332    0.0184332  0.0184332           0   
3    ExtraTreesClassifier -0.0269125  -0.00253851  0.0462465  0.00993463   
4  RandomForestClassifier  -0.024922  0.000418465  0.0971821  0.00857115   
8        VotingClassifier -0.0185633  -0.00510498          0   0.0055074   
9    KNeighborsClassifier -0.0170085  -0.00429527          0  0.00660825   
1      LogisticRegression -0.0299386    0.0302525   0.185991   0.0299935   
5           MLPClassifier -0.0202517   -0.0105999  0.0537201   0.0135711   
6      AdaBoostClassifier -0.0232374   -0.0108315  0.0888139  0.00779149   
2           SGDClassifier -0.0981743    0.0317434   0.231199    0.036697   

        acc       auc           conf_matrix     f1_c0      f1_c1      kappa  \
7  0.432432  0.712329  [[124, 168], [0, 4]]  0.596154  0.0454545  0.0195584   
0  0.554054  0.650685  [[161, 131], [1, 3]]  0.709251  0.0434783  0.0176991   
3  0.706081  0.604452   [[207, 85], [2, 2]]  0.826347   0.043956  0.0185976   
4  0.986486       0.5    [[292, 0], [4, 0]]  0.993197          0          0   
8  0.986486       0.5    [[292, 0], [4, 0]]  0.993197          0          0   
9  0.986486       0.5    [[292, 0], [4, 0]]  0.993197          0          0   
1  0.976351  0.494863    [[289, 3], [4, 0]]  0.988034          0 -0.0117188   
5  0.972973  0.493151    [[288, 4], [4, 0]]  0.986301          0 -0.0136986   
6  0.962838  0.488014    [[285, 7], [4, 0]]  0.981067          0    -0.0175   
2  0.945946  0.479452   [[280, 12], [4, 0]]  0.972222          0 -0.0206897   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
7   0.0993768         1  0.0232558  0.424658      1  
0   0.0699055  0.993827  0.0223881   0.55137   0.75  
3   0.0529463  0.990431  0.0229885  0.708904    0.5  
4           0  0.986486          0         1      0  
8           0  0.986486          0         1      0  
9           0  0.986486          0         1      0  
1  -0.0118431  0.986348          0  0.989726      0  
5  -0.0136986  0.986301          0  0.986301      0  
6  -0.0182154  0.986159          0  0.976027      0  
2  -0.0240586  0.985915          0  0.958904      0  
Elapsed time 23.64 mins 

************************************************************

pre/post: 25/0  win/stride: 500/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-26 00:25:22.102000 
pca_target: 0 	 poly degree: 0 	 kselect: 20 
Imbalance: None 
Extended target (count):  25141 325
('Total : Processed (count): ', (986L, 24L), 13)
Final feature (count):  (986L, 24L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.554 	0.070 	0.018 	0.651 	0.643 	0.422
[[161 131]
 [  1   3]]
             precision    recall  f1-score   support

          0       0.99      0.55      0.71       292
          1       0.02      0.75      0.04         4

avg / total       0.98      0.55      0.70       296


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.1, class_weight={1: 3}, dual=False, fit_intercept=True,
          intercept_scaling=0.1, max_iter=100, multi_class='ovr', n_jobs=4,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.976 	-0.012 	-0.012 	0.495 	0.000 	0.000
[[289   3]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.97       296


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.001, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.001, fit_intercept=True, l1_ratio=0.15,
       learning_rate='invscaling', loss='perceptron', n_iter=5, n_jobs=4,
       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.973 	-0.014 	-0.014 	0.493 	0.000 	0.000
[[288   4]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.97      0.97       296


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 500}, criterion='gini',
           max_depth=8, max_features=0.75, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=30, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.703 	0.113 	0.039 	0.726 	0.726 	0.529
[[205  87]
 [  1   3]]
             precision    recall  f1-score   support

          0       1.00      0.70      0.82       292
          1       0.03      0.75      0.06         4

avg / total       0.98      0.70      0.81       296


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 500},
            criterion='gini', max_depth=8, max_features=0.75,
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.922 	-0.031 	-0.023 	0.467 	0.000 	0.000
[[273  19]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.93      0.96       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.92      0.95       296


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.01, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.980 	-0.010 	-0.009 	0.497 	0.000 	0.000
[[290   2]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.98       296


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 500}, criterion='gini', max_depth=32,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=2.0, n_estimators=50, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.973 	-0.014 	-0.014 	0.493 	0.000 	0.000
[[288   4]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.97      0.97       296


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.1, cache_size=200, class_weight={1: 500}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.432 	0.099 	0.020 	0.712 	0.652 	0.449
[[124 168]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.42      0.60       292
          1       0.02      1.00      0.05         4

avg / total       0.99      0.43      0.59       296


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=1,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


                estimator  min_score   mean_score  max_score    sd_score  \
3    ExtraTreesClassifier -0.0265754  -0.00265864  0.0431759  0.00943055   
7                     SVC -0.0381152   0.00639303  0.0913259   0.0200867   
0              GaussianNB  0.0184332    0.0184332  0.0184332           0   
8        VotingClassifier -0.0176836  -0.00489511          0  0.00557414   
9    KNeighborsClassifier -0.0170085  -0.00429527          0  0.00660825   
5           MLPClassifier -0.0197946  -0.00835554  0.0580051   0.0179052   
1      LogisticRegression  -0.046962    0.0304624   0.185991   0.0303659   
2           SGDClassifier -0.0490787    0.0325586   0.256524   0.0366289   
6      AdaBoostClassifier -0.0253248   -0.0109219   0.072985  0.00715897   
4  RandomForestClassifier -0.0198219 -0.000125681   0.055063  0.00420634   

        acc       auc           conf_matrix     f1_c0      f1_c1       kappa  \
3  0.702703  0.726027   [[205, 87], [1, 3]]  0.823293  0.0638298    0.038961   
7  0.432432  0.712329  [[124, 168], [0, 4]]  0.596154  0.0454545   0.0195584   
0  0.554054  0.650685  [[161, 131], [1, 3]]  0.709251  0.0434783   0.0176991   
8  0.986486       0.5    [[292, 0], [4, 0]]  0.993197          0           0   
9  0.986486       0.5    [[292, 0], [4, 0]]  0.993197          0           0   
5   0.97973  0.496575    [[290, 2], [4, 0]]  0.989761          0 -0.00909091   
1  0.976351  0.494863    [[289, 3], [4, 0]]  0.988034          0  -0.0117188   
2  0.972973  0.493151    [[288, 4], [4, 0]]  0.986301          0  -0.0136986   
6  0.972973  0.493151    [[288, 4], [4, 0]]  0.986301          0  -0.0136986   
4  0.922297  0.467466   [[273, 19], [4, 0]]  0.959578          0  -0.0228365   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
3    0.113464  0.995146  0.0333333  0.702055   0.75  
7   0.0993768         1  0.0232558  0.424658      1  
0   0.0699055  0.993827  0.0223881   0.55137   0.75  
8           0  0.986486          0         1      0  
9           0  0.986486          0         1      0  
5 -0.00965339  0.986395          0  0.993151      0  
1  -0.0118431  0.986348          0  0.989726      0  
2  -0.0136986  0.986301          0  0.986301      0  
6  -0.0136986  0.986301          0  0.986301      0  
4  -0.0306532   0.98556          0  0.934932      0  
Elapsed time 23.40 mins 

************************************************************

pre/post: 25/0  win/stride: 500/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-26 00:48:46.320000 
pca_target: 0 	 poly degree: 0 	 kselect: 0 
Imbalance: ClusterCentroids(estimator=None, n_jobs=1, random_state=None, ratio='auto') 
Extended target (count):  25141 325
('Total : Processed (count): ', (986L, 24L), 13)
Final feature (count):  (986L, 24L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.530 	0.064 	0.016 	0.639 	0.629 	0.404
[[154 138]
 [  1   3]]
             precision    recall  f1-score   support

          0       0.99      0.53      0.69       292
          1       0.02      0.75      0.04         4

avg / total       0.98      0.53      0.68       296


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=1, class_weight={1: 50}, dual=False, fit_intercept=True,
          intercept_scaling=0.1, max_iter=100, multi_class='ovr', n_jobs=4,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.470 	0.107 	0.023 	0.731 	0.680 	0.487
[[135 157]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.46      0.63       292
          1       0.02      1.00      0.05         4

avg / total       0.99      0.47      0.62       296


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.5, average=False, class_weight='balanced', epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='invscaling', loss='perceptron', n_iter=5, n_jobs=4,
       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.527 	0.063 	0.015 	0.637 	0.627 	0.402
[[153 139]
 [  1   3]]
             precision    recall  f1-score   support

          0       0.99      0.52      0.69       292
          1       0.02      0.75      0.04         4

avg / total       0.98      0.53      0.68       296


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=None, max_features=0.33, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.615 	0.028 	0.008 	0.558 	0.555 	0.305
[[180 112]
 [  2   2]]
             precision    recall  f1-score   support

          0       0.99      0.62      0.76       292
          1       0.02      0.50      0.03         4

avg / total       0.98      0.61      0.75       296


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features=0.75, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.497 	0.113 	0.025 	0.745 	0.700 	0.515
[[143 149]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.49      0.66       292
          1       0.03      1.00      0.05         4

avg / total       0.99      0.50      0.65       296


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(500,), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.743 	0.129 	0.049 	0.747 	0.747 	0.558
[[217  75]
 [  1   3]]
             precision    recall  f1-score   support

          0       1.00      0.74      0.85       292
          1       0.04      0.75      0.07         4

avg / total       0.98      0.74      0.84       296


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=32,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=1.0, n_estimators=50, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.622 	-0.029 	-0.009 	0.438 	0.396 	0.151
[[183 109]
 [  3   1]]
             precision    recall  f1-score   support

          0       0.98      0.63      0.77       292
          1       0.01      0.25      0.02         4

avg / total       0.97      0.62      0.76       296


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=10, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='linear',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.632 	0.091 	0.027 	0.690 	0.687 	0.478
[[184 108]
 [  1   3]]
             precision    recall  f1-score   support

          0       0.99      0.63      0.77       292
          1       0.03      0.75      0.05         4

avg / total       0.98      0.63      0.76       296


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...owski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='uniform'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.497 	0.113 	0.025 	0.745 	0.700 	0.515
[[143 149]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.49      0.66       292
          1       0.03      1.00      0.05         4

avg / total       0.99      0.50      0.65       296


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=3, p=1,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.476 	-0.006 	-0.001 	0.488 	0.488 	0.239
[[139 153]
 [  2   2]]
             precision    recall  f1-score   support

          0       0.99      0.48      0.64       292
          1       0.01      0.50      0.03         4

avg / total       0.97      0.48      0.63       296


                estimator min_score  mean_score max_score  sd_score       acc  \
5           MLPClassifier -0.461633   -0.148008    0.1283  0.147729  0.743243   
4  RandomForestClassifier   -0.1283    0.402381  0.683856  0.175303  0.496622   
8        VotingClassifier -0.367711     0.10499  0.350522   0.13247  0.496622   
1      LogisticRegression -0.496011  0.00362457  0.461633  0.131305  0.469595   
7                     SVC -0.333333  -0.0149976    0.2566  0.137744  0.631757   
0              GaussianNB  0.683856    0.683856  0.683856         0  0.530405   
2           SGDClassifier -0.812156  0.00561285  0.572745  0.176901  0.527027   
3    ExtraTreesClassifier -0.367711    0.217359  0.683856  0.142095  0.614865   
9    KNeighborsClassifier   -0.2566   0.0106917    0.2566  0.160476  0.476351   
6      AdaBoostClassifier -0.111111    0.551949  0.906078  0.180076  0.621622   

        auc           conf_matrix     f1_c0      f1_c1       kappa  \
5  0.746575   [[217, 75], [1, 3]]   0.85098  0.0731707   0.0487145   
4  0.744863  [[143, 149], [0, 4]]  0.657471  0.0509554   0.0252829   
8  0.744863  [[143, 149], [0, 4]]  0.657471  0.0509554   0.0252829   
1  0.731164  [[135, 157], [0, 4]]  0.632319  0.0484848    0.022712   
7  0.690068  [[184, 108], [1, 3]]  0.771488  0.0521739   0.0267857   
0  0.638699  [[154, 138], [1, 3]]  0.689038  0.0413793   0.0155054   
2  0.636986  [[153, 139], [1, 3]]  0.686099  0.0410959   0.0152091   
3  0.558219  [[180, 112], [2, 2]]  0.759494  0.0338983  0.00799624   
9  0.488014  [[139, 153], [2, 2]]  0.642032  0.0251572 -0.00122207   
6  0.438356  [[183, 109], [3, 1]]   0.76569  0.0175439 -0.00876339   

  model_score   prec_c0     prec_c1    rec_c0 rec_c1  
5    0.129249  0.995413   0.0384615  0.743151   0.75  
4    0.113152         1   0.0261438  0.489726      1  
8    0.113152         1   0.0261438  0.489726      1  
1    0.107175         1   0.0248447  0.462329      1  
7   0.0906597  0.994595    0.027027  0.630137   0.75  
0   0.0641281  0.993548   0.0212766  0.527397   0.75  
2   0.0633175  0.993506   0.0211268  0.523973   0.75  
3   0.0276267  0.989011   0.0175439  0.616438    0.5  
9 -0.00554193  0.985816   0.0129032  0.476027    0.5  
6   -0.029457  0.983871  0.00909091  0.626712   0.25  
Elapsed time 15.00 mins 

************************************************************

pre/post: 25/0  win/stride: 500/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-26 01:03:46.579000 
pca_target: 0 	 poly degree: 0 	 kselect: 0 
Imbalance: SMOTE(k=None, k_neighbors=5, kind='borderline1', m=None, m_neighbors=10,
   n_jobs=1, out_step=0.5, random_state=None, ratio='auto',
   svm_estimator=None) 
Extended target (count):  25141 325
('Total : Processed (count): ', (986L, 24L), 13)
Final feature (count):  (986L, 24L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.574 	0.075 	0.020 	0.661 	0.655 	0.437
[[167 125]
 [  1   3]]
             precision    recall  f1-score   support

          0       0.99      0.57      0.73       292
          1       0.02      0.75      0.05         4

avg / total       0.98      0.57      0.72       296


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=1, class_weight={1: 50}, dual=False, fit_intercept=True,
          intercept_scaling=5, max_iter=100, multi_class='ovr', n_jobs=4,
          penalty='l2', random_state=None, solver='sag', tol=0.0001,
          verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.764 	0.138 	0.055 	0.757 	0.757 	0.572
[[223  69]
 [  1   3]]
             precision    recall  f1-score   support

          0       1.00      0.76      0.86       292
          1       0.04      0.75      0.08         4

avg / total       0.98      0.76      0.85       296


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=1, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='invscaling', loss='modified_huber', n_iter=5,
       n_jobs=4, penalty='none', power_t=0.5, random_state=None,
       shuffle=True, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.980 	-0.010 	-0.009 	0.497 	0.000 	0.000
[[290   2]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.98       296


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 500}, criterion='gini',
           max_depth=8, max_features=0.75, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=50, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.720 	0.057 	0.021 	0.611 	0.601 	0.353
[[211  81]
 [  2   2]]
             precision    recall  f1-score   support

          0       0.99      0.72      0.84       292
          1       0.02      0.50      0.05         4

avg / total       0.98      0.72      0.82       296


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight='balanced',
            criterion='gini', max_depth=8, max_features=0.75,
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=15, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.966 	-0.017 	-0.016 	0.490 	0.000 	0.000
[[286   6]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.98      0.98       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.97      0.97       296


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.5, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(500,), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 500}, criterion='entropy',
            max_depth=16, max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=2.0, n_estimators=80, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.959 	-0.020 	-0.018 	0.486 	0.000 	0.000
[[284   8]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.97      0.98       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.96      0.97       296


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.1, cache_size=200, class_weight={1: 500}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.486 	0.054 	0.012 	0.616 	0.602 	0.372
[[141 151]
 [  1   3]]
             precision    recall  f1-score   support

          0       0.99      0.48      0.65       292
          1       0.02      0.75      0.04         4

avg / total       0.98      0.49      0.64       296


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=1,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


                estimator   min_score   mean_score   max_score    sd_score  \
1      LogisticRegression  -0.0308918    0.0245996    0.123869   0.0294054   
0              GaussianNB  0.00157827   0.00157827  0.00157827           0   
7                     SVC  -0.0305365    0.0062218   0.0759845   0.0190836   
3    ExtraTreesClassifier  -0.0255374 -0.000738473   0.0551182   0.0120616   
5           MLPClassifier  -0.0191384   -0.0129422 -0.00207212   0.0040941   
8        VotingClassifier  -0.0166983  -0.00577377           0  0.00508469   
9    KNeighborsClassifier  -0.0143621  -0.00449418           0  0.00571764   
2           SGDClassifier  -0.0952331    0.0266594    0.269586   0.0346071   
4  RandomForestClassifier  -0.0187075 -0.000762607   0.0491091  0.00399943   
6      AdaBoostClassifier  -0.0261578   -0.0106057   0.0828505  0.00914646   

        acc       auc           conf_matrix     f1_c0      f1_c1       kappa  \
1  0.763514  0.756849   [[223, 69], [1, 3]]  0.864341  0.0789474   0.0547445   
0  0.574324  0.660959  [[167, 125], [1, 3]]  0.726087  0.0454545   0.0197645   
7  0.486486  0.616438  [[141, 151], [1, 3]]   0.64977  0.0379747   0.0119466   
3  0.719595  0.611301   [[211, 81], [2, 2]]  0.835644   0.045977    0.020727   
5  0.986486       0.5    [[292, 0], [4, 0]]  0.993197          0           0   
8  0.986486       0.5    [[292, 0], [4, 0]]  0.993197          0           0   
9  0.986486       0.5    [[292, 0], [4, 0]]  0.993197          0           0   
2   0.97973  0.496575    [[290, 2], [4, 0]]  0.989761          0 -0.00909091   
4  0.966216  0.489726    [[286, 6], [4, 0]]  0.982818          0  -0.0164835   
6  0.959459  0.486301    [[284, 8], [4, 0]]   0.97931          0  -0.0183486   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
1    0.138242  0.995536  0.0416667  0.763699   0.75  
0   0.0750251  0.994048  0.0234375  0.571918   0.75  
7   0.0538199  0.992958  0.0194805  0.482877   0.75  
3   0.0572167   0.99061  0.0240964  0.722603    0.5  
5           0  0.986486          0         1      0  
8           0  0.986486          0         1      0  
9           0  0.986486          0         1      0  
2 -0.00965339  0.986395          0  0.993151      0  
4  -0.0168351  0.986207          0  0.979452      0  
6  -0.0195069  0.986111          0  0.972603      0  
Elapsed time 23.44 mins 

************************************************************

pre/post: 25/0  win/stride: 500/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-26 01:27:13.105000 
pca_target: 0 	 poly degree: 0 	 kselect: 0 
Imbalance: None 
Extended target (count):  25141 325
('Total : Processed (count): ', (986L, 24L), 13)
Final feature (count):  (986L, 24L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.574 	0.075 	0.020 	0.661 	0.655 	0.437
[[167 125]
 [  1   3]]
             precision    recall  f1-score   support

          0       0.99      0.57      0.73       292
          1       0.02      0.75      0.05         4

avg / total       0.98      0.57      0.72       296


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.1, class_weight={1: 50}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='sag', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.672 	0.103 	0.033 	0.711 	0.710 	0.507
[[196  96]
 [  1   3]]
             precision    recall  f1-score   support

          0       0.99      0.67      0.80       292
          1       0.03      0.75      0.06         4

avg / total       0.98      0.67      0.79       296


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=1, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='constant', loss='perceptron', n_iter=5, n_jobs=4,
       penalty='none', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.926 	0.085 	0.062 	0.592 	0.483 	0.218
[[273  19]
 [  3   1]]
             precision    recall  f1-score   support

          0       0.99      0.93      0.96       292
          1       0.05      0.25      0.08         4

avg / total       0.98      0.93      0.95       296


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 500}, criterion='gini',
           max_depth=8, max_features=0.33, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.726 	0.059 	0.022 	0.615 	0.604 	0.356
[[213  79]
 [  2   2]]
             precision    recall  f1-score   support

          0       0.99      0.73      0.84       292
          1       0.02      0.50      0.05         4

avg / total       0.98      0.73      0.83       296


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight='balanced',
            criterion='gini', max_depth=8, max_features=0.75,
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.959 	-0.020 	-0.018 	0.486 	0.000 	0.000
[[284   8]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.97      0.98       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.96      0.97       296


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.01, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(500,), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.970 	-0.015 	-0.015 	0.491 	0.000 	0.000
[[287   5]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.98      0.98       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.97      0.97       296


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight='balanced', criterion='entropy',
            max_depth=8, max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=2.0, n_estimators=50, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.980 	-0.010 	-0.009 	0.497 	0.000 	0.000
[[290   2]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.98       296


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.1, cache_size=200, class_weight={1: 500}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.486 	0.054 	0.012 	0.616 	0.602 	0.372
[[141 151]
 [  1   3]]
             precision    recall  f1-score   support

          0       0.99      0.48      0.65       292
          1       0.02      0.75      0.04         4

avg / total       0.98      0.49      0.64       296


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=1,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


                estimator   min_score   mean_score   max_score    sd_score  \
1      LogisticRegression  -0.0425746    0.0246634    0.107916   0.0289581   
0              GaussianNB  0.00157827   0.00157827  0.00157827           0   
7                     SVC  -0.0305365    0.0062218   0.0759845   0.0190836   
3    ExtraTreesClassifier  -0.0214746 -0.000339715   0.0697259   0.0118193   
2           SGDClassifier  -0.0758719    0.0265101    0.194467   0.0330818   
8        VotingClassifier  -0.0177413  -0.00574073           0  0.00523722   
9    KNeighborsClassifier  -0.0143621  -0.00449418           0  0.00571764   
6      AdaBoostClassifier  -0.0247694   -0.0110689   0.0339317   0.0058806   
5           MLPClassifier  -0.0206169   -0.0110154   0.0391395   0.0110305   
4  RandomForestClassifier  -0.0201236 -0.000334209   0.0606517  0.00533454   

        acc       auc           conf_matrix     f1_c0      f1_c1       kappa  \
1  0.672297  0.710616   [[196, 96], [1, 3]]  0.801636  0.0582524   0.0331358   
0  0.574324  0.660959  [[167, 125], [1, 3]]  0.726087  0.0454545   0.0197645   
7  0.486486  0.616438  [[141, 151], [1, 3]]   0.64977  0.0379747   0.0119466   
3  0.726351  0.614726   [[213, 79], [2, 2]]  0.840237  0.0470588   0.0218668   
2  0.925676  0.592466   [[273, 19], [3, 1]]  0.961268  0.0833333    0.062212   
8  0.986486       0.5    [[292, 0], [4, 0]]  0.993197          0           0   
9  0.986486       0.5    [[292, 0], [4, 0]]  0.993197          0           0   
6   0.97973  0.496575    [[290, 2], [4, 0]]  0.989761          0 -0.00909091   
5  0.969595  0.491438    [[287, 5], [4, 0]]  0.984563          0  -0.0152439   
4  0.959459  0.486301    [[284, 8], [4, 0]]   0.97931          0  -0.0183486   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
1    0.103084  0.994924   0.030303  0.671233   0.75  
0   0.0750251  0.994048  0.0234375  0.571918   0.75  
7   0.0538199  0.992958  0.0194805  0.482877   0.75  
3   0.0594226  0.990698  0.0246914  0.729452    0.5  
2   0.0850673   0.98913       0.05  0.934932   0.25  
8           0  0.986486          0         1      0  
9           0  0.986486          0         1      0  
6 -0.00965339  0.986395          0  0.993151      0  
5  -0.0153418  0.986254          0  0.982877      0  
4  -0.0195069  0.986111          0  0.972603      0  
Elapsed time 23.51 mins 

************************************************************

pre/post: 25/0  win/stride: 500/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-26 01:50:43.464000 
pca_target: 0 	 poly degree: 2 	 kselect: 20 
Imbalance: ClusterCentroids(estimator=None, n_jobs=1, random_state=None, ratio='auto') 
Extended target (count):  25141 325
('Total : Processed (count): ', (986L, 325L), 13)
Final feature (count):  (986L, 325L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.622 	0.088 	0.025 	0.685 	0.682 	0.471
[[181 111]
 [  1   3]]
             precision    recall  f1-score   support

          0       0.99      0.62      0.76       292
          1       0.03      0.75      0.05         4

avg / total       0.98      0.62      0.75       296


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=5, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.598 	0.081 	0.022 	0.673 	0.669 	0.454
[[174 118]
 [  1   3]]
             precision    recall  f1-score   support

          0       0.99      0.60      0.75       292
          1       0.02      0.75      0.05         4

avg / total       0.98      0.60      0.74       296


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.0001, average=False, class_weight='balanced',
       epsilon=0.1, eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='modified_huber', n_iter=5, n_jobs=4,
       penalty='none', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.584 	0.078 	0.021 	0.666 	0.661 	0.444
[[170 122]
 [  1   3]]
             precision    recall  f1-score   support

          0       0.99      0.58      0.73       292
          1       0.02      0.75      0.05         4

avg / total       0.98      0.58      0.73       296


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=16, max_features='auto', max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=30, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.578 	0.076 	0.020 	0.663 	0.657 	0.439
[[168 124]
 [  1   3]]
             precision    recall  f1-score   support

          0       0.99      0.58      0.73       292
          1       0.02      0.75      0.05         4

avg / total       0.98      0.58      0.72       296


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 50},
            criterion='entropy', max_depth=None, max_features='auto',
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=15, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.544 	0.067 	0.017 	0.646 	0.637 	0.414
[[158 134]
 [  1   3]]
             precision    recall  f1-score   support

          0       0.99      0.54      0.70       292
          1       0.02      0.75      0.04         4

avg / total       0.98      0.54      0.69       296


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(500,), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.598 	0.081 	0.022 	0.673 	0.669 	0.454
[[174 118]
 [  1   3]]
             precision    recall  f1-score   support

          0       0.99      0.60      0.75       292
          1       0.02      0.75      0.05         4

avg / total       0.98      0.60      0.74       296


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=1.0, n_estimators=80, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.595 	0.080 	0.022 	0.671 	0.667 	0.451
[[173 119]
 [  1   3]]
             precision    recall  f1-score   support

          0       0.99      0.59      0.74       292
          1       0.02      0.75      0.05         4

avg / total       0.98      0.59      0.73       296


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=10, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='linear',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.591 	0.079 	0.022 	0.670 	0.665 	0.449
[[172 120]
 [  1   3]]
             precision    recall  f1-score   support

          0       0.99      0.59      0.74       292
          1       0.02      0.75      0.05         4

avg / total       0.98      0.59      0.73       296


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', R...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.568 	0.073 	0.019 	0.658 	0.651 	0.432
[[165 127]
 [  1   3]]
             precision    recall  f1-score   support

          0       0.99      0.57      0.72       292
          1       0.02      0.75      0.04         4

avg / total       0.98      0.57      0.71       296


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=1,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.618 	0.087 	0.025 	0.683 	0.680 	0.469
[[180 112]
 [  1   3]]
             precision    recall  f1-score   support

          0       0.99      0.62      0.76       292
          1       0.03      0.75      0.05         4

avg / total       0.98      0.62      0.75       296


                estimator min_score mean_score max_score   sd_score       acc  \
0              GaussianNB  0.701045   0.701045  0.701045          0  0.621622   
9    KNeighborsClassifier  0.367711   0.489654  0.777778   0.120321  0.618243   
1      LogisticRegression         0   0.465516  0.812156   0.280202  0.597973   
5           MLPClassifier  0.478822   0.691785  0.906078  0.0784554  0.597973   
6      AdaBoostClassifier  0.239411    0.62416         1   0.153539  0.594595   
7                     SVC         0   0.465697  0.906078   0.315509  0.591216   
2           SGDClassifier -0.222222   0.465882  0.906078   0.179319  0.584459   
3    ExtraTreesClassifier  0.572745   0.874342         1  0.0980406  0.577703   
8        VotingClassifier  0.444444   0.676071  0.812156   0.063043  0.567568   
4  RandomForestClassifier  0.222222   0.505725  0.812156   0.123472  0.543919   

        auc           conf_matrix     f1_c0      f1_c1      kappa model_score  \
0  0.684932  [[181, 111], [1, 3]]  0.763713  0.0508475  0.0253998   0.0877555   
9  0.683219  [[180, 112], [1, 3]]  0.761099  0.0504202  0.0249534   0.0868029   
1  0.672945  [[174, 118], [1, 3]]  0.745182      0.048  0.0224245   0.0812359   
5  0.672945  [[174, 118], [1, 3]]  0.745182      0.048  0.0224245   0.0812359   
6  0.671233  [[173, 119], [1, 3]]  0.742489   0.047619  0.0220264   0.0803312   
7  0.669521  [[172, 120], [1, 3]]  0.739785  0.0472441  0.0216346   0.0794325   
2  0.666096  [[170, 122], [1, 3]]  0.734341  0.0465116  0.0208692   0.0776528   
3  0.662671  [[168, 124], [1, 3]]   0.72885  0.0458015  0.0201271   0.0758957   
8  0.657534  [[165, 127], [1, 3]]  0.720524  0.0447761  0.0190555   0.0732994   
4  0.645548  [[158, 134], [1, 3]]  0.700665  0.0425532  0.0167323    0.067406   

    prec_c0    prec_c1    rec_c0 rec_c1  
0  0.994505  0.0263158  0.619863   0.75  
9  0.994475   0.026087  0.616438   0.75  
1  0.994286  0.0247934   0.59589   0.75  
5  0.994286  0.0247934   0.59589   0.75  
6  0.994253  0.0245902  0.592466   0.75  
7   0.99422  0.0243902  0.589041   0.75  
2  0.994152      0.024  0.582192   0.75  
3  0.994083   0.023622  0.575342   0.75  
8  0.993976  0.0230769  0.565068   0.75  
4  0.993711  0.0218978  0.541096   0.75  
Elapsed time 14.15 mins 

************************************************************

pre/post: 25/0  win/stride: 500/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-26 02:04:52.253000 
pca_target: 0 	 poly degree: 2 	 kselect: 20 
Imbalance: SMOTE(k=None, k_neighbors=5, kind='borderline1', m=None, m_neighbors=10,
   n_jobs=1, out_step=0.5, random_state=None, ratio='auto',
   svm_estimator=None) 
Extended target (count):  25141 325
('Total : Processed (count): ', (986L, 325L), 13)
Final feature (count):  (986L, 325L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.500 	0.114 	0.026 	0.747 	0.702 	0.518
[[144 148]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.49      0.66       292
          1       0.03      1.00      0.05         4

avg / total       0.99      0.50      0.65       296


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=1, class_weight={1: 500}, dual=False, fit_intercept=True,
          intercept_scaling=0.01, max_iter=100, multi_class='ovr',
          n_jobs=4, penalty='l2', random_state=None, solver='liblinear',
          tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.497 	0.113 	0.025 	0.745 	0.700 	0.515
[[143 149]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.49      0.66       292
          1       0.03      1.00      0.05         4

avg / total       0.99      0.50      0.65       296


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.0001, average=False, class_weight={1: 15}, epsilon=0.1,
       eta0=0.001, fit_intercept=True, l1_ratio=0.15,
       learning_rate='constant', loss='perceptron', n_iter=5, n_jobs=4,
       penalty='l2', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.936 	-0.027 	-0.022 	0.474 	0.000 	0.000
[[277  15]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.95      0.97       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.94      0.95       296


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight='balanced',
           criterion='entropy', max_depth=8, max_features='auto',
           max_leaf_nodes=None, min_impurity_split=1e-07,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=15, n_jobs=4,
           oob_score=False, random_state=None, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.929 	-0.029 	-0.022 	0.471 	0.000 	0.000
[[275  17]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.94      0.96       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.93      0.95       296


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 500},
            criterion='gini', max_depth=8, max_features=0.33,
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.926 	-0.030 	-0.023 	0.469 	0.000 	0.000
[[274  18]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.94      0.96       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.93      0.95       296


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.01, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.980 	-0.010 	-0.009 	0.497 	0.000 	0.000
[[290   2]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.98       296


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 500}, criterion='gini', max_depth=16,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=0.5, n_estimators=15, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.973 	-0.014 	-0.014 	0.493 	0.000 	0.000
[[288   4]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.97      0.97       296


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.5, cache_size=200, class_weight='balanced', coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.449 	0.103 	0.021 	0.721 	0.665 	0.466
[[129 163]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.44      0.61       292
          1       0.02      1.00      0.05         4

avg / total       0.99      0.45      0.61       296


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...owski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='uniform'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=1,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


                estimator  min_score   mean_score  max_score    sd_score  \
0              GaussianNB   0.084346     0.084346   0.084346           0   
1      LogisticRegression -0.0778017    0.0320524   0.113462   0.0369013   
7                     SVC  -0.026445    0.0148003   0.106329   0.0324949   
8        VotingClassifier -0.0155486  -0.00453897          0  0.00454468   
9    KNeighborsClassifier -0.0133312  -0.00397469          0  0.00488445   
5           MLPClassifier -0.0187657  -0.00796138  0.0687786   0.0120386   
6      AdaBoostClassifier -0.0259952   -0.0114049  0.0942409  0.00883604   
2           SGDClassifier  -0.139879     0.027393   0.181969   0.0376613   
3    ExtraTreesClassifier -0.0215169 -5.80824e-05  0.0744467     0.01209   
4  RandomForestClassifier -0.0163967 -0.000744838   0.033091  0.00355796   

        acc       auc           conf_matrix     f1_c0      f1_c1       kappa  \
0       0.5  0.746575  [[144, 148], [0, 4]]   0.66055  0.0512821   0.0256228   
1  0.496622  0.744863  [[143, 149], [0, 4]]  0.657471  0.0509554   0.0252829   
7  0.449324   0.72089  [[129, 163], [0, 4]]  0.612827  0.0467836   0.0209416   
8  0.986486       0.5    [[292, 0], [4, 0]]  0.993197          0           0   
9  0.986486       0.5    [[292, 0], [4, 0]]  0.993197          0           0   
5   0.97973  0.496575    [[290, 2], [4, 0]]  0.989761          0 -0.00909091   
6  0.972973  0.493151    [[288, 4], [4, 0]]  0.986301          0  -0.0136986   
2  0.935811  0.474315   [[277, 15], [4, 0]]  0.966841          0  -0.0218023   
3  0.929054   0.47089   [[275, 17], [4, 0]]  0.963222          0  -0.0223684   
4  0.925676  0.469178   [[274, 18], [4, 0]]  0.961404          0  -0.0226131   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
0    0.113919         1  0.0263158  0.493151      1  
1    0.113152         1  0.0261438  0.489726      1  
7    0.102867         1  0.0239521  0.441781      1  
8           0  0.986486          0         1      0  
9           0  0.986486          0         1      0  
5 -0.00965339  0.986395          0  0.993151      0  
6  -0.0136986  0.986301          0  0.986301      0  
2  -0.0270415  0.985765          0   0.94863      0  
3  -0.0288909  0.985663          0  0.941781      0  
4  -0.0297819  0.985612          0  0.938356      0  
Elapsed time 24.32 mins 

************************************************************

pre/post: 25/0  win/stride: 500/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-26 02:29:11.669000 
pca_target: 0 	 poly degree: 2 	 kselect: 20 
Imbalance: None 
Extended target (count):  25141 325
('Total : Processed (count): ', (986L, 325L), 13)
Final feature (count):  (986L, 325L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.500 	0.114 	0.026 	0.747 	0.702 	0.518
[[144 148]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.49      0.66       292
          1       0.03      1.00      0.05         4

avg / total       0.99      0.50      0.65       296


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=1, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=0.01, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='sag', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.807 	0.019 	0.009 	0.533 	0.451 	0.192
[[238  54]
 [  3   1]]
             precision    recall  f1-score   support

          0       0.99      0.82      0.89       292
          1       0.02      0.25      0.03         4

avg / total       0.97      0.81      0.88       296


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.0001, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='constant', loss='perceptron', n_iter=5, n_jobs=4,
       penalty='none', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.858 	0.120 	0.064 	0.682 	0.657 	0.416
[[252  40]
 [  2   2]]
             precision    recall  f1-score   support

          0       0.99      0.86      0.92       292
          1       0.05      0.50      0.09         4

avg / total       0.98      0.86      0.91       296


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 500}, criterion='gini',
           max_depth=16, max_features=0.33, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.963 	-0.018 	-0.018 	0.488 	0.000 	0.000
[[285   7]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.98      0.98       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.96      0.97       296


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 500},
            criterion='gini', max_depth=8, max_features='auto',
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.922 	0.082 	0.059 	0.591 	0.483 	0.217
[[272  20]
 [  3   1]]
             precision    recall  f1-score   support

          0       0.99      0.93      0.96       292
          1       0.05      0.25      0.08         4

avg / total       0.98      0.92      0.95       296


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.970 	-0.015 	-0.015 	0.491 	0.000 	0.000
[[287   5]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.98      0.98       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.97      0.97       296


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight='balanced', criterion='gini',
            max_depth=32, max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=1.0, n_estimators=50, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.976 	-0.012 	-0.012 	0.495 	0.000 	0.000
[[289   3]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.97       296


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.5, cache_size=200, class_weight='balanced', coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.449 	0.103 	0.021 	0.721 	0.665 	0.466
[[129 163]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.44      0.61       292
          1       0.02      1.00      0.05         4

avg / total       0.99      0.45      0.61       296


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=1,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


                estimator  min_score   mean_score  max_score    sd_score  \
0              GaussianNB   0.084346     0.084346   0.084346           0   
7                     SVC  -0.026445    0.0148003   0.106329   0.0324949   
2           SGDClassifier   -0.13425     0.027303   0.206709   0.0376506   
4  RandomForestClassifier -0.0209764 -0.000657678  0.0364943   0.0038136   
1      LogisticRegression  -0.047901    0.0323733   0.120159   0.0370995   
8        VotingClassifier -0.0151553  -0.00443843          0  0.00446139   
9    KNeighborsClassifier -0.0133312  -0.00397469          0  0.00488445   
6      AdaBoostClassifier  -0.024118   -0.0113019    0.08586  0.00903206   
5           MLPClassifier -0.0167608  -0.00663046  0.0696633   0.0157219   
3    ExtraTreesClassifier -0.0410039  -0.00131258  0.0504604   0.0108838   

        acc       auc           conf_matrix     f1_c0      f1_c1       kappa  \
0       0.5  0.746575  [[144, 148], [0, 4]]   0.66055  0.0512821   0.0256228   
7  0.449324   0.72089  [[129, 163], [0, 4]]  0.612827  0.0467836   0.0209416   
2  0.858108  0.681507   [[252, 40], [2, 2]]  0.923077  0.0869565   0.0638554   
4  0.922297  0.590753   [[272, 20], [3, 1]]  0.959436       0.08   0.0586283   
1  0.807432  0.532534   [[238, 54], [3, 1]]  0.893058  0.0338983  0.00892857   
8  0.986486       0.5    [[292, 0], [4, 0]]  0.993197          0           0   
9  0.986486       0.5    [[292, 0], [4, 0]]  0.993197          0           0   
6  0.976351  0.494863    [[289, 3], [4, 0]]  0.988034          0  -0.0117188   
5  0.969595  0.491438    [[287, 5], [4, 0]]  0.984563          0  -0.0152439   
3  0.962838  0.488014    [[285, 7], [4, 0]]  0.981067          0     -0.0175   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
0    0.113919         1  0.0263158  0.493151      1  
7    0.102867         1  0.0239521  0.441781      1  
2    0.120117  0.992126   0.047619  0.863014    0.5  
4   0.0816279  0.989091   0.047619  0.931507   0.25  
1   0.0193153  0.987552  0.0181818  0.815068   0.25  
8           0  0.986486          0         1      0  
9           0  0.986486          0         1      0  
6  -0.0118431  0.986348          0  0.989726      0  
5  -0.0153418  0.986254          0  0.982877      0  
3  -0.0182154  0.986159          0  0.976027      0  
Elapsed time 24.43 mins 

************************************************************

pre/post: 25/0  win/stride: 500/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-26 02:53:37.674000 
pca_target: 0 	 poly degree: 2 	 kselect: 0 
Imbalance: ClusterCentroids(estimator=None, n_jobs=1, random_state=None, ratio='auto') 
Extended target (count):  25141 325
('Total : Processed (count): ', (986L, 325L), 13)
Final feature (count):  (986L, 325L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.615 	0.086 	0.025 	0.682 	0.678 	0.466
[[179 113]
 [  1   3]]
             precision    recall  f1-score   support

          0       0.99      0.61      0.76       292
          1       0.03      0.75      0.05         4

avg / total       0.98      0.61      0.75       296


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=10, class_weight={1: 500}, dual=False,
          fit_intercept=True, intercept_scaling=10, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='sag', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.453 	0.046 	0.010 	0.599 	0.580 	0.347
[[131 161]
 [  1   3]]
             precision    recall  f1-score   support

          0       0.99      0.45      0.62       292
          1       0.02      0.75      0.04         4

avg / total       0.98      0.45      0.61       296


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.1, average=False, class_weight='balanced', epsilon=0.1,
       eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='invscaling', loss='perceptron', n_iter=5, n_jobs=4,
       penalty='l1', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.230 	-0.008 	-0.001 	0.486 	0.409 	0.176
[[ 65 227]
 [  1   3]]
             precision    recall  f1-score   support

          0       0.98      0.22      0.36       292
          1       0.01      0.75      0.03         4

avg / total       0.97      0.23      0.36       296


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 15},
           criterion='entropy', max_depth=32, max_features=0.33,
           max_leaf_nodes=None, min_impurity_split=1e-07,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=15, n_jobs=4,
           oob_score=False, random_state=None, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.588 	0.079 	0.021 	0.668 	0.663 	0.446
[[171 121]
 [  1   3]]
             precision    recall  f1-score   support

          0       0.99      0.59      0.74       292
          1       0.02      0.75      0.05         4

avg / total       0.98      0.59      0.73       296


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features=0.33, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.547 	0.068 	0.017 	0.647 	0.639 	0.417
[[159 133]
 [  1   3]]
             precision    recall  f1-score   support

          0       0.99      0.54      0.70       292
          1       0.02      0.75      0.04         4

avg / total       0.98      0.55      0.69       296


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.01, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(500,), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.750 	0.002 	0.001 	0.503 	0.435 	0.180
[[221  71]
 [  3   1]]
             precision    recall  f1-score   support

          0       0.99      0.76      0.86       292
          1       0.01      0.25      0.03         4

avg / total       0.97      0.75      0.85       296


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight='balanced', criterion='gini',
            max_depth=32, max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=0.5, n_estimators=50, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.588 	0.079 	0.021 	0.668 	0.663 	0.446
[[171 121]
 [  1   3]]
             precision    recall  f1-score   support

          0       0.99      0.59      0.74       292
          1       0.02      0.75      0.05         4

avg / total       0.98      0.59      0.73       296


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.916 	-0.032 	-0.023 	0.464 	0.000 	0.000
[[271  21]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.93      0.96       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.92      0.94       296


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 500}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Ran...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.544 	0.067 	0.017 	0.646 	0.637 	0.414
[[158 134]
 [  1   3]]
             precision    recall  f1-score   support

          0       0.99      0.54      0.70       292
          1       0.02      0.75      0.04         4

avg / total       0.98      0.54      0.69       296


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=3, p=3,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.639 	0.034 	0.010 	0.570 	0.566 	0.316
[[187 105]
 [  2   2]]
             precision    recall  f1-score   support

          0       0.99      0.64      0.78       292
          1       0.02      0.50      0.04         4

avg / total       0.98      0.64      0.77       296


                estimator  min_score  mean_score max_score  sd_score  \
0              GaussianNB   0.607122    0.607122  0.607122         0   
3    ExtraTreesClassifier    -0.2566    0.356141  0.794967  0.160651   
6      AdaBoostClassifier -0.0343779    0.474838         1  0.167164   
4  RandomForestClassifier  -0.222222    0.329658  0.701045  0.137331   
8        VotingClassifier  -0.496011    -0.22014  0.222222  0.167854   
1      LogisticRegression  -0.461633    0.037097    0.3849  0.193656   
9    KNeighborsClassifier  -0.461633  -0.0512069  0.239411  0.194604   
5           MLPClassifier  -0.589933   -0.181157  0.239411  0.253921   
2           SGDClassifier    -0.3849    0.242074  0.718234  0.145134   
7                     SVC    -0.2566 -0.00842947  0.350522  0.106328   

        acc       auc           conf_matrix     f1_c0      f1_c1        kappa  \
0  0.614865  0.681507  [[179, 113], [1, 3]]  0.758475       0.05    0.0245143   
3  0.587838  0.667808  [[171, 121], [1, 3]]  0.737069   0.046875    0.0212489   
6  0.587838  0.667808  [[171, 121], [1, 3]]  0.737069   0.046875    0.0212489   
4  0.547297   0.64726  [[159, 133], [1, 3]]   0.70354  0.0428571      0.01705   
8  0.543919  0.645548  [[158, 134], [1, 3]]  0.700665  0.0425532    0.0167323   
1  0.452703  0.599315  [[131, 161], [1, 3]]  0.617925  0.0357143   0.00958361   
9  0.638514  0.570205  [[187, 105], [2, 2]]  0.777547   0.036036      0.01025   
5      0.75  0.503425   [[221, 71], [3, 1]]  0.856589  0.0263158  0.000729927   
2   0.22973  0.486301   [[65, 227], [1, 3]]  0.363128   0.025641 -0.000949217   
7  0.915541  0.464041   [[271, 21], [4, 0]]  0.955908          0   -0.0232301   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
0   0.0858577  0.994444  0.0258621  0.613014   0.75  
3   0.0785398  0.994186  0.0241935  0.585616   0.75  
6   0.0785398  0.994186  0.0241935  0.585616   0.75  
4   0.0682351   0.99375  0.0220588  0.544521   0.75  
8    0.067406  0.993711  0.0218978  0.541096   0.75  
1   0.0461379  0.992424  0.0182927   0.44863   0.75  
9   0.0337442  0.989418  0.0186916  0.640411    0.5  
5  0.00184322  0.986607  0.0138889  0.756849   0.25  
2 -0.00759963  0.984848  0.0130435  0.222603   0.75  
7  -0.0323431  0.985455          0  0.928082      0  
Elapsed time 23.19 mins 

************************************************************

pre/post: 25/0  win/stride: 500/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-26 03:16:48.817000 
pca_target: 0 	 poly degree: 2 	 kselect: 0 
Imbalance: SMOTE(k=None, k_neighbors=5, kind='borderline1', m=None, m_neighbors=10,
   n_jobs=1, out_step=0.5, random_state=None, ratio='auto',
   svm_estimator=None) 
Extended target (count):  25141 325
('Total : Processed (count): ', (986L, 325L), 13)
Final feature (count):  (986L, 325L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.672 	0.043 	0.014 	0.587 	0.581 	0.331
[[197  95]
 [  2   2]]
             precision    recall  f1-score   support

          0       0.99      0.67      0.80       292
          1       0.02      0.50      0.04         4

avg / total       0.98      0.67      0.79       296


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.01, class_weight={1: 50}, dual=False,
          fit_intercept=True, intercept_scaling=10, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='sag', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.885 	-0.039 	-0.024 	0.449 	0.000 	0.000
[[262  30]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.98      0.90      0.94       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.89      0.93       296


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.0001, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='invscaling', loss='squared_hinge', n_iter=5,
       n_jobs=4, penalty='none', power_t=0.5, random_state=None,
       shuffle=True, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.858 	0.039 	0.021 	0.558 	0.465 	0.203
[[253  39]
 [  3   1]]
             precision    recall  f1-score   support

          0       0.99      0.87      0.92       292
          1       0.03      0.25      0.05         4

avg / total       0.98      0.86      0.91       296


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 50}, criterion='gini',
           max_depth=16, max_features=0.75, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.976 	-0.012 	-0.012 	0.495 	0.000 	0.000
[[289   3]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.97       296


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=30, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.01, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.956 	-0.021 	-0.019 	0.485 	0.000 	0.000
[[283   9]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.97      0.98       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.96      0.96       296


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 500}, criterion='gini', max_depth=16,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=2.0, n_estimators=15, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.970 	-0.015 	-0.015 	0.491 	0.000 	0.000
[[287   5]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.98      0.98       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.97      0.97       296


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.01, cache_size=200, class_weight={1: 500}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='linear',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.791 	0.014 	0.006 	0.524 	0.447 	0.189
[[233  59]
 [  3   1]]
             precision    recall  f1-score   support

          0       0.99      0.80      0.88       292
          1       0.02      0.25      0.03         4

avg / total       0.97      0.79      0.87       296


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...wski',
           metric_params=None, n_jobs=4, n_neighbors=4, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=1,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


                estimator   min_score   mean_score  max_score    sd_score  \
0              GaussianNB   0.0470019    0.0470019  0.0470019           0   
2           SGDClassifier   -0.127963    0.0209767   0.185483   0.0344144   
7                     SVC  -0.0308882  -0.00097039  0.0646927   0.0241844   
4  RandomForestClassifier -0.00795416 -0.000711792          0  0.00133658   
8        VotingClassifier  -0.0182974  -0.00768378          0  0.00502681   
9    KNeighborsClassifier  -0.0150364  -0.00464787          0  0.00594157   
3    ExtraTreesClassifier  -0.0240772   0.00294464  0.0759427   0.0158501   
6      AdaBoostClassifier  -0.0235002  0.000425582    0.19014   0.0296799   
5           MLPClassifier  -0.0192013   -0.0144836 -0.0100264  0.00196034   
1      LogisticRegression  -0.0336827     0.011927   0.107478   0.0302637   

        acc       auc          conf_matrix     f1_c0      f1_c1       kappa  \
0  0.672297  0.587329  [[197, 95], [2, 2]]  0.802444   0.039604    0.014011   
2  0.858108  0.558219  [[253, 39], [3, 1]]  0.923358  0.0454545   0.0214106   
7  0.790541  0.523973  [[233, 59], [3, 1]]  0.882576    0.03125  0.00606586   
4  0.986486       0.5   [[292, 0], [4, 0]]  0.993197          0           0   
8  0.986486       0.5   [[292, 0], [4, 0]]  0.993197          0           0   
9  0.986486       0.5   [[292, 0], [4, 0]]  0.993197          0           0   
3  0.976351  0.494863   [[289, 3], [4, 0]]  0.988034          0  -0.0117188   
6  0.969595  0.491438   [[287, 5], [4, 0]]  0.984563          0  -0.0152439   
5  0.956081  0.484589   [[283, 9], [4, 0]]  0.977547          0  -0.0190678   
1  0.885135   0.44863  [[262, 30], [4, 0]]  0.939068          0    -0.02443   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
0   0.0429632   0.98995  0.0206186  0.674658    0.5  
2   0.0393249  0.988281      0.025  0.866438   0.25  
7     0.01377  0.987288  0.0166667  0.797945   0.25  
4           0  0.986486          0         1      0  
8           0  0.986486          0         1      0  
9           0  0.986486          0         1      0  
3  -0.0118431  0.986348          0  0.989726      0  
6  -0.0153418  0.986254          0  0.982877      0  
5  -0.0207262  0.986063          0  0.969178      0  
1   -0.039306  0.984962          0   0.89726      0  
Elapsed time 52.38 mins 

************************************************************

pre/post: 25/0  win/stride: 500/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-26 04:09:11.531000 
pca_target: 0 	 poly degree: 2 	 kselect: 0 
Imbalance: None 
Extended target (count):  25141 325
('Total : Processed (count): ', (986L, 325L), 13)
Final feature (count):  (986L, 325L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.672 	0.043 	0.014 	0.587 	0.581 	0.331
[[197  95]
 [  2   2]]
             precision    recall  f1-score   support

          0       0.99      0.67      0.80       292
          1       0.02      0.50      0.04         4

avg / total       0.98      0.67      0.79       296


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.01, class_weight={1: 50}, dual=False,
          fit_intercept=True, intercept_scaling=0.01, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='sag', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.767 	0.007 	0.003 	0.512 	0.440 	0.183
[[226  66]
 [  3   1]]
             precision    recall  f1-score   support

          0       0.99      0.77      0.87       292
          1       0.01      0.25      0.03         4

avg / total       0.97      0.77      0.86       296


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=1, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='invscaling', loss='perceptron', n_iter=5, n_jobs=4,
       penalty='none', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.953 	-0.022 	-0.020 	0.483 	0.000 	0.000
[[282  10]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.97      0.98       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.95      0.96       296


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 500},
           criterion='entropy', max_depth=16, max_features=0.33,
           max_leaf_nodes=None, min_impurity_split=1e-07,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=15, n_jobs=4,
           oob_score=False, random_state=None, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.966 	-0.017 	-0.016 	0.490 	0.000 	0.000
[[286   6]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.98      0.98       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.97      0.97       296


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 500},
            criterion='gini', max_depth=8, max_features='auto',
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=15, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.956 	-0.021 	-0.019 	0.485 	0.000 	0.000
[[283   9]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.97      0.98       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.96      0.96       296


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.966 	-0.017 	-0.016 	0.490 	0.000 	0.000
[[286   6]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.98      0.98       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.97      0.97       296


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight='balanced', criterion='gini', max_depth=8,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=2.0, n_estimators=50, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.976 	-0.012 	-0.012 	0.495 	0.000 	0.000
[[289   3]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.97       296


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.01, cache_size=200, class_weight={1: 500}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='linear',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.791 	0.014 	0.006 	0.524 	0.447 	0.189
[[233  59]
 [  3   1]]
             precision    recall  f1-score   support

          0       0.99      0.80      0.88       292
          1       0.02      0.25      0.03         4

avg / total       0.97      0.79      0.87       296


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=1.0, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...wski',
           metric_params=None, n_jobs=4, n_neighbors=4, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=1,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


                estimator   min_score  mean_score  max_score    sd_score  \
0              GaussianNB   0.0470019   0.0470019  0.0470019           0   
7                     SVC  -0.0308882 -0.00097039  0.0646927   0.0241844   
1      LogisticRegression  -0.0336827    0.012343   0.119904   0.0307033   
8        VotingClassifier  -0.0188094 -0.00765041          0   0.0049069   
9    KNeighborsClassifier  -0.0150364 -0.00464787          0  0.00594157   
6      AdaBoostClassifier   -0.023889  0.00279254   0.168917   0.0318631   
3    ExtraTreesClassifier  -0.0203727  0.00242889  0.0921227    0.015388   
5           MLPClassifier  -0.0208378   -0.012391  0.0562437   0.0129103   
4  RandomForestClassifier -0.00708526   -0.000588  0.0547693  0.00326313   
2           SGDClassifier  -0.0866332   0.0199267    0.17342   0.0323159   

        acc       auc          conf_matrix     f1_c0     f1_c1       kappa  \
0  0.672297  0.587329  [[197, 95], [2, 2]]  0.802444  0.039604    0.014011   
7  0.790541  0.523973  [[233, 59], [3, 1]]  0.882576   0.03125  0.00606586   
1  0.766892  0.511986  [[226, 66], [3, 1]]  0.867562  0.028169  0.00273438   
8  0.986486       0.5   [[292, 0], [4, 0]]  0.993197         0           0   
9  0.986486       0.5   [[292, 0], [4, 0]]  0.993197         0           0   
6  0.976351  0.494863   [[289, 3], [4, 0]]  0.988034         0  -0.0117188   
3  0.966216  0.489726   [[286, 6], [4, 0]]  0.982818         0  -0.0164835   
5  0.966216  0.489726   [[286, 6], [4, 0]]  0.982818         0  -0.0164835   
4  0.956081  0.484589   [[283, 9], [4, 0]]  0.977547         0  -0.0190678   
2  0.952703  0.482877  [[282, 10], [4, 0]]  0.975779         0   -0.019685   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
0   0.0429632   0.98995  0.0206186  0.674658    0.5  
7     0.01377  0.987288  0.0166667  0.797945   0.25  
1  0.00661426    0.9869  0.0149254  0.773973   0.25  
8           0  0.986486          0         1      0  
9           0  0.986486          0         1      0  
6  -0.0118431  0.986348          0  0.989726      0  
3  -0.0168351  0.986207          0  0.979452      0  
5  -0.0168351  0.986207          0  0.979452      0  
4  -0.0207262  0.986063          0  0.969178      0  
2  -0.0218855  0.986014          0  0.965753      0  
Elapsed time 52.65 mins 

************************************************************

pre/post: 25/0  win/stride: 500/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-26 05:01:50.578000 
pca_target: 20 	 poly degree: 0 	 kselect: 20 
Imbalance: ClusterCentroids(estimator=None, n_jobs=1, random_state=None, ratio='auto') 
Extended target (count):  25141 325
('Total : Processed (count): ', (986L, 24L), 13)
Final feature (count):  (986L, 24L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.001, class_weight={1: 500}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.470 	-0.121 	-0.027 	0.238 	0.000 	0.000
[[139 153]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.97      0.48      0.64       292
          1       0.00      0.00      0.00         4

avg / total       0.96      0.47      0.63       296


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.001, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='invscaling', loss='squared_hinge', n_iter=5,
       n_jobs=4, penalty='elasticnet', power_t=0.5, random_state=None,
       shuffle=True, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.530 	-0.107 	-0.027 	0.269 	0.000 	0.000
[[157 135]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.98      0.54      0.69       292
          1       0.00      0.00      0.00         4

avg / total       0.96      0.53      0.68       296


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight='balanced',
           criterion='entropy', max_depth=32, max_features=0.75,
           max_leaf_nodes=None, min_impurity_split=1e-07,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=15, n_jobs=4,
           oob_score=False, random_state=None, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.547 	0.068 	0.017 	0.647 	0.639 	0.417
[[159 133]
 [  1   3]]
             precision    recall  f1-score   support

          0       0.99      0.54      0.70       292
          1       0.02      0.75      0.04         4

avg / total       0.98      0.55      0.69       296


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 500},
            criterion='gini', max_depth=32, max_features=0.75,
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.473 	0.051 	0.011 	0.610 	0.593 	0.362
[[137 155]
 [  1   3]]
             precision    recall  f1-score   support

          0       0.99      0.47      0.64       292
          1       0.02      0.75      0.04         4

avg / total       0.98      0.47      0.63       296


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.524 	-0.109 	-0.027 	0.265 	0.000 	0.000
[[155 137]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.97      0.53      0.69       292
          1       0.00      0.00      0.00         4

avg / total       0.96      0.52      0.68       296


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=0.5, n_estimators=15, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.514 	0.060 	0.014 	0.630 	0.619 	0.392
[[149 143]
 [  1   3]]
             precision    recall  f1-score   support

          0       0.99      0.51      0.67       292
          1       0.02      0.75      0.04         4

avg / total       0.98      0.51      0.67       296


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.1, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='linear',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.483 	0.053 	0.012 	0.615 	0.600 	0.369
[[140 152]
 [  1   3]]
             precision    recall  f1-score   support

          0       0.99      0.48      0.65       292
          1       0.02      0.75      0.04         4

avg / total       0.98      0.48      0.64       296


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', R...owski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='uniform'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.517 	0.061 	0.014 	0.632 	0.621 	0.394
[[150 142]
 [  1   3]]
             precision    recall  f1-score   support

          0       0.99      0.51      0.68       292
          1       0.02      0.75      0.04         4

avg / total       0.98      0.52      0.67       296


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=3,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


                estimator min_score  mean_score max_score  sd_score       acc  \
3    ExtraTreesClassifier   -0.1283    0.288206  0.718234  0.160638  0.547297   
8        VotingClassifier -0.367711 -0.00550193  0.239411   0.10438  0.516892   
6      AdaBoostClassifier -0.718234    0.502842  0.812156  0.275709  0.513514   
7                     SVC -0.589933  0.00711303  0.222222  0.243795  0.483108   
4  RandomForestClassifier -0.239411      0.2878  0.812156   0.17924  0.472973   
0              GaussianNB    0.5132      0.5132    0.5132         0  0.986486   
9    KNeighborsClassifier -0.239411    0.047422    0.2566   0.15424  0.986486   
2           SGDClassifier -0.589933    0.122726  0.812156  0.135407  0.530405   
5           MLPClassifier   -0.1283    0.113503  0.496011  0.100863  0.523649   
1      LogisticRegression   -0.2566   0.0354192    0.3849  0.124804  0.469595   

        auc           conf_matrix     f1_c0      f1_c1      kappa model_score  \
3   0.64726  [[159, 133], [1, 3]]   0.70354  0.0428571    0.01705   0.0682351   
8  0.631849  [[150, 142], [1, 3]]  0.677201  0.0402685  0.0143443   0.0609055   
6  0.630137  [[149, 143], [1, 3]]  0.674208       0.04  0.0140637   0.0601077   
7  0.614726  [[140, 152], [1, 3]]  0.646651  0.0377358  0.0116969   0.0530442   
4  0.609589  [[137, 155], [1, 3]]  0.637209   0.037037  0.0109664   0.0507283   
0       0.5    [[292, 0], [4, 0]]  0.993197          0          0           0   
9       0.5    [[292, 0], [4, 0]]  0.993197          0          0           0   
2  0.268836  [[157, 135], [4, 0]]  0.693157          0 -0.0269569   -0.107175   
5  0.265411  [[155, 137], [4, 0]]  0.687361          0 -0.0269685   -0.108643   
1  0.238014  [[139, 153], [4, 0]]   0.63908          0 -0.0270509   -0.121064   

    prec_c0    prec_c1    rec_c0 rec_c1  
3   0.99375  0.0220588  0.544521   0.75  
8  0.993377  0.0206897  0.513699   0.75  
6  0.993333  0.0205479  0.510274   0.75  
7  0.992908  0.0193548  0.479452   0.75  
4  0.992754  0.0189873  0.469178   0.75  
0  0.986486          0         1      0  
9  0.986486          0         1      0  
2  0.975155          0  0.537671      0  
5  0.974843          0  0.530822      0  
1  0.972028          0  0.476027      0  
Elapsed time 14.09 mins 

************************************************************

pre/post: 25/0  win/stride: 500/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-26 05:15:55.948000 
pca_target: 20 	 poly degree: 0 	 kselect: 20 
Imbalance: SMOTE(k=None, k_neighbors=5, kind='borderline1', m=None, m_neighbors=10,
   n_jobs=1, out_step=0.5, random_state=None, ratio='auto',
   svm_estimator=None) 
Extended target (count):  25141 325
('Total : Processed (count): ', (986L, 24L), 13)
Final feature (count):  (986L, 24L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.618 	0.087 	0.025 	0.683 	0.680 	0.469
[[180 112]
 [  1   3]]
             precision    recall  f1-score   support

          0       0.99      0.62      0.76       292
          1       0.03      0.75      0.05         4

avg / total       0.98      0.62      0.75       296


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.01, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.980 	-0.010 	-0.009 	0.497 	0.000 	0.000
[[290   2]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.98       296


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.0001, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='constant', loss='squared_hinge', n_iter=5, n_jobs=4,
       penalty='none', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.885 	-0.039 	-0.024 	0.449 	0.000 	0.000
[[262  30]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.98      0.90      0.94       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.89      0.93       296


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 500}, criterion='gini',
           max_depth=8, max_features=0.33, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=30, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.733 	0.062 	0.023 	0.618 	0.607 	0.359
[[215  77]
 [  2   2]]
             precision    recall  f1-score   support

          0       0.99      0.74      0.84       292
          1       0.03      0.50      0.05         4

avg / total       0.98      0.73      0.83       296


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=30, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.01, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.973 	-0.014 	-0.014 	0.493 	0.000 	0.000
[[288   4]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.97      0.97       296


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 50}, criterion='gini', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=2.0, n_estimators=80, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.976 	-0.012 	-0.012 	0.495 	0.000 	0.000
[[289   3]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.97       296


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.5, cache_size=200, class_weight={1: 50}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.868 	0.044 	0.025 	0.563 	0.468 	0.205
[[256  36]
 [  3   1]]
             precision    recall  f1-score   support

          0       0.99      0.88      0.93       292
          1       0.03      0.25      0.05         4

avg / total       0.98      0.87      0.92       296


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.983 	-0.007 	-0.005 	0.498 	0.000 	0.000
[[291   1]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.98       296


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=1,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


                estimator   min_score   mean_score  max_score     sd_score  \
0              GaussianNB   0.0375346    0.0375346  0.0375346            0   
3    ExtraTreesClassifier  -0.0222274 -0.000946969  0.0743781    0.0138835   
7                     SVC  -0.0261321   0.00218781  0.0614377    0.0199552   
4  RandomForestClassifier -0.00915738 -0.000386201          0  0.000987497   
9    KNeighborsClassifier  -0.0150487  -0.00453235          0   0.00607093   
8        VotingClassifier  -0.0177852  -0.00620537          0   0.00548634   
1      LogisticRegression  -0.0293919    0.0239891    0.13676      0.02975   
6      AdaBoostClassifier  -0.0235649   0.00374191   0.185732    0.0332924   
5           MLPClassifier  -0.0233897 -0.000497417     0.1317    0.0339703   
2           SGDClassifier  -0.0720692    0.0242615    0.19095    0.0310074   

        acc       auc           conf_matrix     f1_c0      f1_c1       kappa  \
0  0.618243  0.683219  [[180, 112], [1, 3]]  0.761099  0.0504202   0.0249534   
3  0.733108  0.618151   [[215, 77], [2, 2]]  0.844794  0.0481928   0.0230615   
7  0.868243  0.563356   [[256, 36], [3, 1]]   0.92922  0.0487805       0.025   
4  0.986486       0.5    [[292, 0], [4, 0]]  0.993197          0           0   
9  0.986486       0.5    [[292, 0], [4, 0]]  0.993197          0           0   
8  0.983108  0.498288    [[291, 1], [4, 0]]  0.991482          0 -0.00543478   
1   0.97973  0.496575    [[290, 2], [4, 0]]  0.989761          0 -0.00909091   
6  0.976351  0.494863    [[289, 3], [4, 0]]  0.988034          0  -0.0117188   
5  0.972973  0.493151    [[288, 4], [4, 0]]  0.986301          0  -0.0136986   
2  0.885135   0.44863   [[262, 30], [4, 0]]  0.939068          0    -0.02443   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
0   0.0868029  0.994475   0.026087  0.616438   0.75  
3     0.06168  0.990783  0.0253165  0.736301    0.5  
7   0.0442374  0.988417   0.027027  0.876712   0.25  
4           0  0.986486          0         1      0  
9           0  0.986486          0         1      0  
8  -0.0068144  0.986441          0  0.996575      0  
1 -0.00965339  0.986395          0  0.993151      0  
6  -0.0118431  0.986348          0  0.989726      0  
5  -0.0136986  0.986301          0  0.986301      0  
2   -0.039306  0.984962          0   0.89726      0  
Elapsed time 22.70 mins 

************************************************************

pre/post: 25/0  win/stride: 500/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-26 05:38:37.948000 
pca_target: 20 	 poly degree: 0 	 kselect: 20 
Imbalance: None 
Extended target (count):  25141 325
('Total : Processed (count): ', (986L, 24L), 13)
Final feature (count):  (986L, 24L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.618 	0.087 	0.025 	0.683 	0.680 	0.469
[[180 112]
 [  1   3]]
             precision    recall  f1-score   support

          0       0.99      0.62      0.76       292
          1       0.03      0.75      0.05         4

avg / total       0.98      0.62      0.75       296


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.01, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.980 	-0.010 	-0.009 	0.497 	0.000 	0.000
[[290   2]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.98       296


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.0001, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='constant', loss='squared_hinge', n_iter=5, n_jobs=4,
       penalty='none', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.963 	-0.018 	-0.018 	0.488 	0.000 	0.000
[[285   7]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.98      0.98       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.96      0.97       296


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 500}, criterion='gini',
           max_depth=8, max_features=0.33, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=50, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.804 	0.018 	0.008 	0.531 	0.450 	0.192
[[237  55]
 [  3   1]]
             precision    recall  f1-score   support

          0       0.99      0.81      0.89       292
          1       0.02      0.25      0.03         4

avg / total       0.97      0.80      0.88       296


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.01, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.976 	-0.012 	-0.012 	0.495 	0.000 	0.000
[[289   3]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.97       296


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=16,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=0.5, n_estimators=80, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.970 	-0.015 	-0.015 	0.491 	0.000 	0.000
[[287   5]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.98      0.98       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.97      0.97       296


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.5, cache_size=200, class_weight={1: 50}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.868 	0.044 	0.025 	0.563 	0.468 	0.205
[[256  36]
 [  3   1]]
             precision    recall  f1-score   support

          0       0.99      0.88      0.93       292
          1       0.03      0.25      0.05         4

avg / total       0.98      0.87      0.92       296


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.983 	-0.007 	-0.005 	0.498 	0.000 	0.000
[[291   1]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.98       296


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=1,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


                estimator   min_score   mean_score  max_score     sd_score  \
0              GaussianNB   0.0375346    0.0375346  0.0375346            0   
7                     SVC  -0.0261321   0.00218781  0.0614377    0.0199552   
3    ExtraTreesClassifier  -0.0187075 -0.000135505  0.0800156    0.0143873   
4  RandomForestClassifier -0.00655668 -0.000385679          0  0.000962406   
9    KNeighborsClassifier  -0.0150487  -0.00453235          0   0.00607093   
8        VotingClassifier  -0.0172105  -0.00611995          0   0.00563062   
1      LogisticRegression  -0.0241855    0.0249949    0.13676    0.0302003   
5           MLPClassifier  -0.0215649  -0.00299631   0.130451    0.0346675   
6      AdaBoostClassifier    -0.02367   0.00389481   0.161253    0.0331545   
2           SGDClassifier   -0.124866    0.0243946   0.195989    0.0315922   

        acc       auc           conf_matrix     f1_c0      f1_c1       kappa  \
0  0.618243  0.683219  [[180, 112], [1, 3]]  0.761099  0.0504202   0.0249534   
7  0.868243  0.563356   [[256, 36], [3, 1]]   0.92922  0.0487805       0.025   
3  0.804054  0.530822   [[237, 55], [3, 1]]  0.890977  0.0333333  0.00831793   
4  0.986486       0.5    [[292, 0], [4, 0]]  0.993197          0           0   
9  0.986486       0.5    [[292, 0], [4, 0]]  0.993197          0           0   
8  0.983108  0.498288    [[291, 1], [4, 0]]  0.991482          0 -0.00543478   
1   0.97973  0.496575    [[290, 2], [4, 0]]  0.989761          0 -0.00909091   
5  0.976351  0.494863    [[289, 3], [4, 0]]  0.988034          0  -0.0117188   
6  0.969595  0.491438    [[287, 5], [4, 0]]  0.984563          0  -0.0152439   
2  0.962838  0.488014    [[285, 7], [4, 0]]  0.981067          0     -0.0175   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
0   0.0868029  0.994475   0.026087  0.616438   0.75  
7   0.0442374  0.988417   0.027027  0.876712   0.25  
3   0.0181724    0.9875  0.0178571  0.811644   0.25  
4           0  0.986486          0         1      0  
9           0  0.986486          0         1      0  
8  -0.0068144  0.986441          0  0.996575      0  
1 -0.00965339  0.986395          0  0.993151      0  
5  -0.0118431  0.986348          0  0.989726      0  
6  -0.0153418  0.986254          0  0.982877      0  
2  -0.0182154  0.986159          0  0.976027      0  
Elapsed time 22.59 mins 

************************************************************

pre/post: 25/0  win/stride: 500/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-26 06:01:13.437000 
pca_target: 20 	 poly degree: 0 	 kselect: 0 
Imbalance: ClusterCentroids(estimator=None, n_jobs=1, random_state=None, ratio='auto') 
Extended target (count):  25141 325
('Total : Processed (count): ', (986L, 24L), 13)
Final feature (count):  (986L, 24L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.001, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=10, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='sag', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.480 	-0.062 	-0.014 	0.366 	0.347 	0.118
[[141 151]
 [  3   1]]
             precision    recall  f1-score   support

          0       0.98      0.48      0.65       292
          1       0.01      0.25      0.01         4

avg / total       0.97      0.48      0.64       296


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.5, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='constant', loss='squared_hinge', n_iter=5, n_jobs=4,
       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.473 	-0.006 	-0.001 	0.486 	0.486 	0.237
[[138 154]
 [  2   2]]
             precision    recall  f1-score   support

          0       0.99      0.47      0.64       292
          1       0.01      0.50      0.03         4

avg / total       0.97      0.47      0.63       296


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 50},
           criterion='entropy', max_depth=32, max_features=0.75,
           max_leaf_nodes=None, min_impurity_split=1e-07,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=4,
           oob_score=False, random_state=None, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.912 	0.072 	0.049 	0.586 	0.480 	0.215
[[269  23]
 [  3   1]]
             precision    recall  f1-score   support

          0       0.99      0.92      0.95       292
          1       0.04      0.25      0.07         4

avg / total       0.98      0.91      0.94       296


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 500},
            criterion='entropy', max_depth=None, max_features=0.33,
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=15, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.861 	0.041 	0.023 	0.560 	0.466 	0.204
[[254  38]
 [  3   1]]
             precision    recall  f1-score   support

          0       0.99      0.87      0.93       292
          1       0.03      0.25      0.05         4

avg / total       0.98      0.86      0.91       296


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.554 	-0.102 	-0.027 	0.281 	0.000 	0.000
[[164 128]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.98      0.56      0.71       292
          1       0.00      0.00      0.00         4

avg / total       0.96      0.55      0.70       296


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight='balanced', criterion='gini',
            max_depth=32, max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=0.5, n_estimators=50, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.480 	0.109 	0.024 	0.736 	0.687 	0.498
[[138 154]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.47      0.64       292
          1       0.03      1.00      0.05         4

avg / total       0.99      0.48      0.63       296


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=10, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=10.0, class_weight={1: 500}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Ra...owski',
           metric_params=None, n_jobs=4, n_neighbors=4, p=2,
           weights='uniform'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.541 	0.010 	0.002 	0.521 	0.520 	0.269
[[158 134]
 [  2   2]]
             precision    recall  f1-score   support

          0       0.99      0.54      0.70       292
          1       0.01      0.50      0.03         4

avg / total       0.97      0.54      0.69       296


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=4,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.541 	-0.048 	-0.012 	0.397 	0.369 	0.132
[[159 133]
 [  3   1]]
             precision    recall  f1-score   support

          0       0.98      0.54      0.70       292
          1       0.01      0.25      0.01         4

avg / total       0.97      0.54      0.69       296


                estimator min_score mean_score  max_score   sd_score  \
6      AdaBoostClassifier -0.777778   -0.27062   0.555556   0.241242   
3    ExtraTreesClassifier -0.718234  -0.208809     0.3849   0.210294   
4  RandomForestClassifier -0.718234  -0.159802     0.3849   0.195484   
8        VotingClassifier -0.496011  -0.115312   0.496011   0.174832   
0              GaussianNB -0.350522  -0.350522  -0.350522          0   
7                     SVC -0.239411 -0.0305365   0.461633   0.141973   
2           SGDClassifier -0.906078    -0.1663   0.478822   0.151015   
9    KNeighborsClassifier -0.589933 -0.0707107   0.350522   0.288169   
1      LogisticRegression -0.145489  0.0385417     0.2566  0.0977368   
5           MLPClassifier -0.718234  -0.357415 -0.0939222   0.126119   

        acc       auc           conf_matrix     f1_c0      f1_c1       kappa  \
6   0.47973  0.736301  [[138, 154], [0, 4]]   0.64186  0.0493827   0.0236463   
3  0.912162  0.585616   [[269, 23], [3, 1]]  0.953901  0.0714286   0.0494071   
4  0.861486  0.559932   [[254, 38], [3, 1]]  0.925319  0.0465116   0.0225515   
8  0.540541  0.520548  [[158, 134], [2, 2]]  0.699115  0.0285714  0.00237906   
0  0.986486       0.5    [[292, 0], [4, 0]]  0.993197          0           0   
7  0.986486       0.5    [[292, 0], [4, 0]]  0.993197          0           0   
2  0.472973  0.486301  [[138, 154], [2, 2]]  0.638889      0.025 -0.00138793   
9  0.540541   0.39726  [[159, 133], [3, 1]]  0.700441  0.0144928  -0.0120676   
1   0.47973  0.366438  [[141, 151], [3, 1]]  0.646789  0.0128205   -0.013879   
5  0.554054  0.280822  [[164, 128], [4, 0]]  0.713043          0  -0.0269134   

  model_score   prec_c0     prec_c1    rec_c0 rec_c1  
6    0.109383         1   0.0253165  0.472603      1  
3     0.07243  0.988971   0.0416667  0.921233   0.25  
4   0.0409174  0.988327    0.025641  0.869863   0.25  
8  0.00952117    0.9875   0.0147059  0.541096    0.5  
0           0  0.986486           0         1      0  
7           0  0.986486           0         1      0  
2 -0.00633581  0.985714   0.0128205  0.472603    0.5  
9  -0.0476628  0.981481  0.00746269  0.544521   0.25  
1  -0.0617064  0.979167  0.00657895  0.482877   0.25  
5   -0.102162   0.97619           0  0.561644      0  
Elapsed time 13.90 mins 

************************************************************

pre/post: 25/0  win/stride: 500/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-26 06:15:07.616000 
pca_target: 20 	 poly degree: 0 	 kselect: 0 
Imbalance: SMOTE(k=None, k_neighbors=5, kind='borderline1', m=None, m_neighbors=10,
   n_jobs=1, out_step=0.5, random_state=None, ratio='auto',
   svm_estimator=None) 
Extended target (count):  25141 325
('Total : Processed (count): ', (986L, 24L), 13)
Final feature (count):  (986L, 24L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.932 	-0.028 	-0.022 	0.473 	0.000 	0.000
[[276  16]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.95      0.97       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.93      0.95       296


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.001, class_weight={1: 50}, dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.966 	-0.017 	-0.016 	0.490 	0.000 	0.000
[[286   6]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.98      0.98       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.97      0.97       296


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.1, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='perceptron', n_iter=5, n_jobs=4,
       penalty='none', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.963 	-0.018 	-0.018 	0.488 	0.000 	0.000
[[285   7]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.98      0.98       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.96      0.97       296


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 500}, criterion='gini',
           max_depth=8, max_features=0.75, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.821 	0.024 	0.012 	0.539 	0.455 	0.195
[[242  50]
 [  3   1]]
             precision    recall  f1-score   support

          0       0.99      0.83      0.90       292
          1       0.02      0.25      0.04         4

avg / total       0.97      0.82      0.89       296


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.01, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(500,), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.980 	-0.010 	-0.009 	0.497 	0.000 	0.000
[[290   2]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.98       296


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=32,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=2.0, n_estimators=15, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.976 	-0.012 	-0.012 	0.495 	0.000 	0.000
[[289   3]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.97       296


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.01, cache_size=200, class_weight={1: 50}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='linear',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.821 	0.098 	0.046 	0.663 	0.642 	0.399
[[241  51]
 [  2   2]]
             precision    recall  f1-score   support

          0       0.99      0.83      0.90       292
          1       0.04      0.50      0.07         4

avg / total       0.98      0.82      0.89       296


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=1,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


                estimator   min_score   mean_score  max_score    sd_score  \
7                     SVC  -0.0290276   0.00186979  0.0674996   0.0221439   
3    ExtraTreesClassifier  -0.0247662  -0.00222099  0.0733673   0.0109798   
4  RandomForestClassifier -0.00714756 -0.000528858          0  0.00114077   
8        VotingClassifier  -0.0172105  -0.00554524          0  0.00504505   
9    KNeighborsClassifier  -0.0169442  -0.00441992          0  0.00657313   
5           MLPClassifier  -0.0200119    0.0124473   0.132888   0.0460432   
6      AdaBoostClassifier  -0.0222743   -0.0071409   0.120317   0.0166511   
1      LogisticRegression  -0.0611414    0.0242159   0.133145    0.032866   
2           SGDClassifier   -0.100038    0.0208386   0.211131   0.0343519   
0              GaussianNB   0.0149935    0.0149935  0.0149935           0   

        acc       auc          conf_matrix     f1_c0      f1_c1       kappa  \
7  0.820946  0.662671  [[241, 51], [2, 2]]  0.900935  0.0701754   0.0462062   
3  0.820946  0.539384  [[242, 50], [3, 1]]  0.901304  0.0363636   0.0115927   
4  0.986486       0.5   [[292, 0], [4, 0]]  0.993197          0           0   
8  0.986486       0.5   [[292, 0], [4, 0]]  0.993197          0           0   
9  0.986486       0.5   [[292, 0], [4, 0]]  0.993197          0           0   
5   0.97973  0.496575   [[290, 2], [4, 0]]  0.989761          0 -0.00909091   
6  0.976351  0.494863   [[289, 3], [4, 0]]  0.988034          0  -0.0117188   
1  0.966216  0.489726   [[286, 6], [4, 0]]  0.982818          0  -0.0164835   
2  0.962838  0.488014   [[285, 7], [4, 0]]  0.981067          0     -0.0175   
0  0.932432  0.472603  [[276, 16], [4, 0]]  0.965035          0  -0.0220994   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
7   0.0979763   0.99177  0.0377358  0.825342    0.5  
3   0.0240823  0.987755  0.0196078  0.828767   0.25  
4           0  0.986486          0         1      0  
8           0  0.986486          0         1      0  
9           0  0.986486          0         1      0  
5 -0.00965339  0.986395          0  0.993151      0  
6  -0.0118431  0.986348          0  0.989726      0  
1  -0.0168351  0.986207          0  0.979452      0  
2  -0.0182154  0.986159          0  0.976027      0  
0  -0.0279782  0.985714          0  0.945205      0  
Elapsed time 20.71 mins 

************************************************************

pre/post: 25/0  win/stride: 500/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-26 06:35:50.067000 
pca_target: 20 	 poly degree: 0 	 kselect: 0 
Imbalance: None 
Extended target (count):  25141 325
('Total : Processed (count): ', (986L, 24L), 13)
Final feature (count):  (986L, 24L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.932 	-0.028 	-0.022 	0.473 	0.000 	0.000
[[276  16]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.95      0.97       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.93      0.95       296


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.001, class_weight={1: 50}, dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.966 	-0.017 	-0.016 	0.490 	0.000 	0.000
[[286   6]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.98      0.98       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.97      0.97       296


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.001, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='constant', loss='squared_hinge', n_iter=5, n_jobs=4,
       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.980 	-0.010 	-0.009 	0.497 	0.000 	0.000
[[290   2]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.98       296


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight='balanced',
           criterion='gini', max_depth=8, max_features=0.75,
           max_leaf_nodes=None, min_impurity_split=1e-07,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=15, n_jobs=4,
           oob_score=False, random_state=None, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.966 	-0.017 	-0.016 	0.490 	0.000 	0.000
[[286   6]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.98      0.98       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.97      0.97       296


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.01, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.980 	-0.010 	-0.009 	0.497 	0.000 	0.000
[[290   2]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.98       296


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight='balanced', criterion='gini',
            max_depth=32, max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=1.0, n_estimators=80, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.970 	-0.015 	-0.015 	0.491 	0.000 	0.000
[[287   5]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.98      0.98       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.97      0.97       296


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.01, cache_size=200, class_weight={1: 50}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='linear',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.821 	0.098 	0.046 	0.663 	0.642 	0.399
[[241  51]
 [  2   2]]
             precision    recall  f1-score   support

          0       0.99      0.83      0.90       292
          1       0.04      0.50      0.07         4

avg / total       0.98      0.82      0.89       296


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=1,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


                estimator   min_score  mean_score  max_score    sd_score  \
7                     SVC  -0.0290276  0.00186979  0.0674996   0.0221439   
4  RandomForestClassifier -0.00507544 -0.00044756          0  0.00104292   
8        VotingClassifier  -0.0171667 -0.00540864          0  0.00495308   
9    KNeighborsClassifier  -0.0169442 -0.00441992          0  0.00657313   
2           SGDClassifier   -0.139879   0.0192698   0.187393   0.0338308   
5           MLPClassifier  -0.0187354    0.015401   0.132888   0.0447202   
6      AdaBoostClassifier  -0.0255843  -0.0060091   0.186089   0.0222522   
1      LogisticRegression  -0.0337591   0.0247264   0.133145   0.0324605   
3    ExtraTreesClassifier  -0.0170687 -0.00105969   0.131757   0.0147908   
0              GaussianNB   0.0149935   0.0149935  0.0149935           0   

        acc       auc          conf_matrix     f1_c0      f1_c1       kappa  \
7  0.820946  0.662671  [[241, 51], [2, 2]]  0.900935  0.0701754   0.0462062   
4  0.986486       0.5   [[292, 0], [4, 0]]  0.993197          0           0   
8  0.986486       0.5   [[292, 0], [4, 0]]  0.993197          0           0   
9  0.986486       0.5   [[292, 0], [4, 0]]  0.993197          0           0   
2   0.97973  0.496575   [[290, 2], [4, 0]]  0.989761          0 -0.00909091   
5   0.97973  0.496575   [[290, 2], [4, 0]]  0.989761          0 -0.00909091   
6  0.969595  0.491438   [[287, 5], [4, 0]]  0.984563          0  -0.0152439   
1  0.966216  0.489726   [[286, 6], [4, 0]]  0.982818          0  -0.0164835   
3  0.966216  0.489726   [[286, 6], [4, 0]]  0.982818          0  -0.0164835   
0  0.932432  0.472603  [[276, 16], [4, 0]]  0.965035          0  -0.0220994   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
7   0.0979763   0.99177  0.0377358  0.825342    0.5  
4           0  0.986486          0         1      0  
8           0  0.986486          0         1      0  
9           0  0.986486          0         1      0  
2 -0.00965339  0.986395          0  0.993151      0  
5 -0.00965339  0.986395          0  0.993151      0  
6  -0.0153418  0.986254          0  0.982877      0  
1  -0.0168351  0.986207          0  0.979452      0  
3  -0.0168351  0.986207          0  0.979452      0  
0  -0.0279782  0.985714          0  0.945205      0  
Elapsed time 20.79 mins 

************************************************************

pre/post: 25/0  win/stride: 500/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-26 06:56:37.261000 
pca_target: 20 	 poly degree: 2 	 kselect: 20 
Imbalance: ClusterCentroids(estimator=None, n_jobs=1, random_state=None, ratio='auto') 
Extended target (count):  25141 325
('Total : Processed (count): ', (986L, 325L), 13)
Final feature (count):  (986L, 325L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=5, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.510 	0.059 	0.014 	0.628 	0.617 	0.389
[[148 144]
 [  1   3]]
             precision    recall  f1-score   support

          0       0.99      0.51      0.67       292
          1       0.02      0.75      0.04         4

avg / total       0.98      0.51      0.66       296


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.1, average=False, class_weight={1: 500}, epsilon=0.1,
       eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='invscaling', loss='squared_hinge', n_iter=5,
       n_jobs=4, penalty='none', power_t=0.5, random_state=None,
       shuffle=True, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.476 	0.051 	0.011 	0.611 	0.595 	0.364
[[138 154]
 [  1   3]]
             precision    recall  f1-score   support

          0       0.99      0.47      0.64       292
          1       0.02      0.75      0.04         4

avg / total       0.98      0.48      0.63       296


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=16, max_features=0.75, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=30, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.595 	0.080 	0.022 	0.671 	0.667 	0.451
[[173 119]
 [  1   3]]
             precision    recall  f1-score   support

          0       0.99      0.59      0.74       292
          1       0.02      0.75      0.05         4

avg / total       0.98      0.59      0.73       296


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3},
            criterion='entropy', max_depth=16, max_features='auto',
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.578 	0.076 	0.020 	0.663 	0.657 	0.439
[[168 124]
 [  1   3]]
             precision    recall  f1-score   support

          0       0.99      0.58      0.73       292
          1       0.02      0.75      0.05         4

avg / total       0.98      0.58      0.72       296


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.527 	0.006 	0.002 	0.514 	0.514 	0.263
[[154 138]
 [  2   2]]
             precision    recall  f1-score   support

          0       0.99      0.53      0.69       292
          1       0.01      0.50      0.03         4

avg / total       0.97      0.53      0.68       296


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 50}, criterion='gini', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=2.0, n_estimators=15, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.591 	0.079 	0.022 	0.670 	0.665 	0.449
[[172 120]
 [  1   3]]
             precision    recall  f1-score   support

          0       0.99      0.59      0.74       292
          1       0.02      0.75      0.05         4

avg / total       0.98      0.59      0.73       296


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.5, cache_size=200, class_weight='balanced', coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.486 	0.111 	0.024 	0.740 	0.692 	0.504
[[140 152]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.48      0.65       292
          1       0.03      1.00      0.05         4

avg / total       0.99      0.49      0.64       296


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=1,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.757 	0.004 	0.001 	0.507 	0.437 	0.181
[[223  69]
 [  3   1]]
             precision    recall  f1-score   support

          0       0.99      0.76      0.86       292
          1       0.01      0.25      0.03         4

avg / total       0.97      0.76      0.85       296


                estimator min_score mean_score max_score   sd_score       acc  \
8        VotingClassifier    0.2566   0.500922  0.701045  0.0987581  0.486486   
3    ExtraTreesClassifier  0.205033   0.772533         1   0.125492  0.594595   
6      AdaBoostClassifier -0.572745   0.333571         1   0.311501  0.591216   
4  RandomForestClassifier   -0.1283    0.36164  0.812156    0.15519  0.577703   
1      LogisticRegression         0   0.379386  0.701045   0.253311  0.510135   
2           SGDClassifier -0.205033   0.470922  0.812156    0.16558  0.476351   
5           MLPClassifier  0.496011   0.601341  0.718234  0.0420514  0.527027   
9    KNeighborsClassifier    0.1283   0.520873  0.812156    0.14797  0.756757   
0              GaussianNB  0.701045   0.701045  0.701045          0  0.986486   
7                     SVC         0   0.431987  0.812156   0.261635  0.986486   

        auc           conf_matrix     f1_c0      f1_c1       kappa  \
8  0.739726  [[140, 152], [0, 4]]  0.648148       0.05   0.0242887   
3  0.671233  [[173, 119], [1, 3]]  0.742489   0.047619   0.0220264   
6  0.669521  [[172, 120], [1, 3]]  0.739785  0.0472441   0.0216346   
4  0.662671  [[168, 124], [1, 3]]   0.72885  0.0458015   0.0201271   
1  0.628425  [[148, 144], [1, 3]]  0.671202  0.0397351   0.0137868   
2  0.611301  [[138, 154], [1, 3]]  0.640371  0.0372671   0.0112069   
5  0.513699  [[154, 138], [2, 2]]    0.6875  0.0277778  0.00154202   
9  0.506849   [[223, 69], [3, 1]]  0.861004   0.027027  0.00149925   
0       0.5    [[292, 0], [4, 0]]  0.993197          0           0   
7       0.5    [[292, 0], [4, 0]]  0.993197          0           0   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
8    0.110877         1   0.025641  0.479452      1  
3   0.0803312  0.994253  0.0245902  0.592466   0.75  
6   0.0794325   0.99422  0.0243902  0.589041   0.75  
4   0.0758957  0.994083   0.023622  0.575342   0.75  
1   0.0593127  0.993289  0.0204082  0.506849   0.75  
2   0.0514985  0.992806  0.0191083  0.472603   0.75  
5  0.00633581  0.987179  0.0142857  0.527397    0.5  
9  0.00372216  0.986726  0.0142857  0.763699   0.25  
0           0  0.986486          0         1      0  
7           0  0.986486          0         1      0  
Elapsed time 14.11 mins 

************************************************************

pre/post: 25/0  win/stride: 500/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-26 07:10:43.765000 
pca_target: 20 	 poly degree: 2 	 kselect: 20 
Imbalance: SMOTE(k=None, k_neighbors=5, kind='borderline1', m=None, m_neighbors=10,
   n_jobs=1, out_step=0.5, random_state=None, ratio='auto',
   svm_estimator=None) 
Extended target (count):  25141 325
('Total : Processed (count): ', (986L, 325L), 13)
Final feature (count):  (986L, 325L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.595 	0.023 	0.006 	0.548 	0.546 	0.295
[[174 118]
 [  2   2]]
             precision    recall  f1-score   support

          0       0.99      0.60      0.74       292
          1       0.02      0.50      0.03         4

avg / total       0.98      0.59      0.73       296


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.1, class_weight={1: 50}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='sag', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.953 	0.124 	0.107 	0.606 	0.490 	0.223
[[281  11]
 [  3   1]]
             precision    recall  f1-score   support

          0       0.99      0.96      0.98       292
          1       0.08      0.25      0.12         4

avg / total       0.98      0.95      0.96       296


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.0001, average=False, class_weight={1: 15}, epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='squared_hinge', n_iter=5, n_jobs=4,
       penalty='l1', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.932 	-0.028 	-0.022 	0.473 	0.000 	0.000
[[276  16]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.95      0.97       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.93      0.95       296


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 500}, criterion='gini',
           max_depth=16, max_features=0.75, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=30, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.939 	-0.026 	-0.021 	0.476 	0.000 	0.000
[[278  14]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.95      0.97       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.94      0.96       296


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.01, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.980 	-0.010 	-0.009 	0.497 	0.000 	0.000
[[290   2]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.98       296


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 500}, criterion='entropy',
            max_depth=4, max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=2.0, n_estimators=15, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.980 	-0.010 	-0.009 	0.497 	0.000 	0.000
[[290   2]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.98       296


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.1, cache_size=200, class_weight='balanced', coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.524 	0.063 	0.015 	0.635 	0.625 	0.399
[[152 140]
 [  1   3]]
             precision    recall  f1-score   support

          0       0.99      0.52      0.68       292
          1       0.02      0.75      0.04         4

avg / total       0.98      0.52      0.67       296


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...owski',
           metric_params=None, n_jobs=4, n_neighbors=4, p=2,
           weights='uniform'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=1,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


                estimator   min_score   mean_score  max_score    sd_score  \
7                     SVC  -0.0280405   0.00667297  0.0708375     0.01952   
1      LogisticRegression  -0.0435646    0.0263233   0.126541   0.0359991   
0              GaussianNB     0.05335      0.05335    0.05335           0   
4  RandomForestClassifier -0.00568763 -0.000555959          0   0.0010408   
8        VotingClassifier  -0.0176788  -0.00765629          0  0.00503954   
9    KNeighborsClassifier  -0.0159176  -0.00516306          0  0.00643333   
5           MLPClassifier  -0.0207381  -0.00223829  0.0657416   0.0256746   
6      AdaBoostClassifier  -0.0263563  -0.00880864   0.127635   0.0146581   
3    ExtraTreesClassifier  -0.0223011   0.00212098   0.102516   0.0187649   
2           SGDClassifier   -0.187936    0.0252773   0.261833   0.0369963   

        acc       auc           conf_matrix     f1_c0      f1_c1       kappa  \
7  0.523649  0.635274  [[152, 140], [1, 3]]  0.683146  0.0408163   0.0149169   
1  0.952703  0.606164   [[281, 11], [3, 1]]  0.975694      0.125    0.106897   
0  0.594595  0.547945  [[174, 118], [2, 2]]   0.74359  0.0322581  0.00626679   
4  0.986486       0.5    [[292, 0], [4, 0]]  0.993197          0           0   
8  0.986486       0.5    [[292, 0], [4, 0]]  0.993197          0           0   
9  0.986486       0.5    [[292, 0], [4, 0]]  0.993197          0           0   
5   0.97973  0.496575    [[290, 2], [4, 0]]  0.989761          0 -0.00909091   
6   0.97973  0.496575    [[290, 2], [4, 0]]  0.989761          0 -0.00909091   
3  0.939189  0.476027   [[278, 14], [4, 0]]  0.968641          0  -0.0214724   
2  0.932432  0.472603   [[276, 16], [4, 0]]  0.965035          0  -0.0220994   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
7   0.0625103  0.993464   0.020979  0.520548   0.75  
1    0.124303  0.989437  0.0833333  0.962329   0.25  
0   0.0225502  0.988636  0.0166667   0.59589    0.5  
4           0  0.986486          0         1      0  
8           0  0.986486          0         1      0  
9           0  0.986486          0         1      0  
5 -0.00965339  0.986395          0  0.993151      0  
6 -0.00965339  0.986395          0  0.993151      0  
3  -0.0260782  0.985816          0  0.952055      0  
2  -0.0279782  0.985714          0  0.945205      0  
Elapsed time 24.37 mins 

************************************************************

pre/post: 25/0  win/stride: 500/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-26 07:35:05.937000 
pca_target: 20 	 poly degree: 2 	 kselect: 20 
Imbalance: None 
Extended target (count):  25141 325
('Total : Processed (count): ', (986L, 325L), 13)
Final feature (count):  (986L, 325L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.595 	0.023 	0.006 	0.548 	0.546 	0.295
[[174 118]
 [  2   2]]
             precision    recall  f1-score   support

          0       0.99      0.60      0.74       292
          1       0.02      0.50      0.03         4

avg / total       0.98      0.59      0.73       296


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=10, class_weight={1: 50}, dual=False, fit_intercept=True,
          intercept_scaling=0.01, max_iter=100, multi_class='ovr',
          n_jobs=4, penalty='l2', random_state=None, solver='liblinear',
          tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.655 	0.098 	0.030 	0.702 	0.700 	0.495
[[191 101]
 [  1   3]]
             precision    recall  f1-score   support

          0       0.99      0.65      0.79       292
          1       0.03      0.75      0.06         4

avg / total       0.98      0.66      0.78       296


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.5, average=False, class_weight={1: 15}, epsilon=0.1,
       eta0=0.001, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='modified_huber', n_iter=5, n_jobs=4,
       penalty='none', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.895 	-0.037 	-0.024 	0.454 	0.000 	0.000
[[265  27]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.91      0.94       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.90      0.93       296


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight='balanced',
           criterion='gini', max_depth=8, max_features='auto',
           max_leaf_nodes=None, min_impurity_split=1e-07,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=15, n_jobs=4,
           oob_score=False, random_state=None, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.905 	-0.035 	-0.024 	0.459 	0.000 	0.000
[[268  24]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.92      0.95       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.91      0.94       296


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.01, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(500,), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.970 	-0.015 	-0.015 	0.491 	0.000 	0.000
[[287   5]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.98      0.98       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.97      0.97       296


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight='balanced', criterion='gini',
            max_depth=32, max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=1.0, n_estimators=80, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.973 	0.191 	0.187 	0.616 	0.496 	0.228
[[287   5]
 [  3   1]]
             precision    recall  f1-score   support

          0       0.99      0.98      0.99       292
          1       0.17      0.25      0.20         4

avg / total       0.98      0.97      0.98       296


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.1, cache_size=200, class_weight='balanced', coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.524 	0.063 	0.015 	0.635 	0.625 	0.399
[[152 140]
 [  1   3]]
             precision    recall  f1-score   support

          0       0.99      0.52      0.68       292
          1       0.02      0.75      0.04         4

avg / total       0.98      0.52      0.67       296


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...owski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='uniform'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=1,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


                estimator  min_score   mean_score  max_score    sd_score  \
1      LogisticRegression -0.0585336    0.0252954    0.11383   0.0348655   
7                     SVC -0.0280405   0.00667297  0.0708375     0.01952   
6      AdaBoostClassifier -0.0237576  -0.00907394     0.1333   0.0136239   
0              GaussianNB    0.05335      0.05335    0.05335           0   
4  RandomForestClassifier -0.0050133 -0.000579693          0  0.00107463   
8        VotingClassifier -0.0187655  -0.00769843          0  0.00514737   
9    KNeighborsClassifier -0.0159176  -0.00516306          0  0.00643333   
5           MLPClassifier  -0.021642  -0.00518922   0.084524   0.0237861   
3    ExtraTreesClassifier -0.0239329   0.00269091   0.140983   0.0200645   
2           SGDClassifier  -0.139879    0.0255153   0.150955   0.0358984   

        acc       auc           conf_matrix     f1_c0      f1_c1       kappa  \
1  0.655405  0.702055  [[191, 101], [1, 3]]  0.789256  0.0555556   0.0303186   
7  0.523649  0.635274  [[152, 140], [1, 3]]  0.683146  0.0408163   0.0149169   
6  0.972973  0.616438    [[287, 5], [3, 1]]  0.986254        0.2    0.186813   
0  0.594595  0.547945  [[174, 118], [2, 2]]   0.74359  0.0322581  0.00626679   
4  0.986486       0.5    [[292, 0], [4, 0]]  0.993197          0           0   
8  0.986486       0.5    [[292, 0], [4, 0]]  0.993197          0           0   
9  0.986486       0.5    [[292, 0], [4, 0]]  0.993197          0           0   
5  0.969595  0.491438    [[287, 5], [4, 0]]  0.984563          0  -0.0152439   
3  0.905405  0.458904   [[268, 24], [4, 0]]  0.950355          0  -0.0237154   
2   0.89527  0.453767   [[265, 27], [4, 0]]  0.944742          0  -0.0241071   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
1   0.0977357  0.994792  0.0288462   0.65411   0.75  
7   0.0625103  0.993464   0.020979  0.520548   0.75  
6    0.190798  0.989655   0.166667  0.982877   0.25  
0   0.0225502  0.988636  0.0166667   0.59589    0.5  
4           0  0.986486          0         1      0  
8           0  0.986486          0         1      0  
9           0  0.986486          0         1      0  
5  -0.0153418  0.986254          0  0.982877      0  
3  -0.0347664  0.985294          0  0.917808      0  
2  -0.0370804   0.98513          0  0.907534      0  
Elapsed time 24.49 mins 

************************************************************

pre/post: 25/0  win/stride: 500/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-26 07:59:35.186000 
pca_target: 20 	 poly degree: 2 	 kselect: 0 
Imbalance: ClusterCentroids(estimator=None, n_jobs=1, random_state=None, ratio='auto') 
Extended target (count):  25141 325
('Total : Processed (count): ', (986L, 325L), 13)
Final feature (count):  (986L, 325L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.001, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=0.01, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='sag', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.486 	0.111 	0.024 	0.740 	0.692 	0.504
[[140 152]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.48      0.65       292
          1       0.03      1.00      0.05         4

avg / total       0.99      0.49      0.64       296


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.5, average=False, class_weight='balanced', epsilon=0.1,
       eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='invscaling', loss='squared_hinge', n_iter=5,
       n_jobs=4, penalty='l1', power_t=0.5, random_state=None,
       shuffle=True, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.534 	0.065 	0.016 	0.640 	0.631 	0.407
[[155 137]
 [  1   3]]
             precision    recall  f1-score   support

          0       0.99      0.53      0.69       292
          1       0.02      0.75      0.04         4

avg / total       0.98      0.53      0.68       296


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 15},
           criterion='entropy', max_depth=16, max_features=0.33,
           max_leaf_nodes=None, min_impurity_split=1e-07,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=15, n_jobs=4,
           oob_score=False, random_state=None, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.767 	0.007 	0.003 	0.512 	0.440 	0.183
[[226  66]
 [  3   1]]
             precision    recall  f1-score   support

          0       0.99      0.77      0.87       292
          1       0.01      0.25      0.03         4

avg / total       0.97      0.77      0.86       296


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 50},
            criterion='entropy', max_depth=8, max_features='auto',
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=15, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.696 	-0.012 	-0.004 	0.476 	0.419 	0.168
[[205  87]
 [  3   1]]
             precision    recall  f1-score   support

          0       0.99      0.70      0.82       292
          1       0.01      0.25      0.02         4

avg / total       0.97      0.70      0.81       296


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.486 	0.054 	0.012 	0.616 	0.602 	0.372
[[141 151]
 [  1   3]]
             precision    recall  f1-score   support

          0       0.99      0.48      0.65       292
          1       0.02      0.75      0.04         4

avg / total       0.98      0.49      0.64       296


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight='balanced', criterion='entropy',
            max_depth=16, max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=2.0, n_estimators=15, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.615 	0.028 	0.008 	0.558 	0.555 	0.305
[[180 112]
 [  2   2]]
             precision    recall  f1-score   support

          0       0.99      0.62      0.76       292
          1       0.02      0.50      0.03         4

avg / total       0.98      0.61      0.75       296


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.014 	0.000 	0.000 	0.500 	0.000 	0.000
[[  0 292]
 [  0   4]]
             precision    recall  f1-score   support

          0       0.00      0.00      0.00       292
          1       0.01      1.00      0.03         4

avg / total       0.00      0.01      0.00       296


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', R...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.483 	-0.061 	-0.014 	0.368 	0.349 	0.119
[[142 150]
 [  3   1]]
             precision    recall  f1-score   support

          0       0.98      0.49      0.65       292
          1       0.01      0.25      0.01         4

avg / total       0.97      0.48      0.64       296


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=3,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


                estimator  min_score mean_score max_score  sd_score  \
1      LogisticRegression -0.0171889  0.0621745  0.589933  0.102184   
2           SGDClassifier    -0.3849   0.295696  0.812156   0.14161   
5           MLPClassifier     0.1283   0.290248  0.607122  0.114908   
6      AdaBoostClassifier  -0.624311  -0.157375  0.683856  0.266866   
3    ExtraTreesClassifier  -0.496011  0.0565516  0.607122    0.1973   
0              GaussianNB     0.3849     0.3849    0.3849         0   
7                     SVC          0    0.26702  0.607122  0.196591   
9    KNeighborsClassifier  -0.111111   0.380552  0.812156  0.210084   
4  RandomForestClassifier  -0.718234  -0.167537  0.589933  0.222862   
8        VotingClassifier    -0.1283   0.286031  0.572745  0.144221   

         acc       auc           conf_matrix     f1_c0      f1_c1       kappa  \
1   0.486486  0.739726  [[140, 152], [0, 4]]  0.648148       0.05   0.0242887   
2   0.533784  0.640411  [[155, 137], [1, 3]]  0.691964  0.0416667   0.0158057   
5   0.486486  0.616438  [[141, 151], [1, 3]]   0.64977  0.0379747   0.0119466   
6   0.614865  0.558219  [[180, 112], [2, 2]]  0.759494  0.0338983  0.00799624   
3   0.766892  0.511986   [[226, 66], [3, 1]]  0.867562   0.028169  0.00273438   
0   0.986486       0.5    [[292, 0], [4, 0]]  0.993197          0           0   
7  0.0135135       0.5    [[0, 292], [0, 4]]         0  0.0266667           0   
9   0.986486       0.5    [[292, 0], [4, 0]]  0.993197          0           0   
4   0.695946  0.476027   [[205, 87], [3, 1]]      0.82  0.0217391 -0.00422195   
8   0.483108  0.368151  [[142, 150], [3, 1]]  0.649886  0.0129032  -0.0137894   

  model_score   prec_c0     prec_c1    rec_c0 rec_c1  
1    0.110877         1    0.025641  0.479452      1  
2   0.0649421   0.99359   0.0214286  0.530822   0.75  
5   0.0538199  0.992958   0.0194805  0.482877   0.75  
6   0.0276267  0.989011   0.0175439  0.616438    0.5  
3  0.00661426    0.9869   0.0149254  0.773973   0.25  
0           0  0.986486           0         1      0  
7           0         0   0.0135135         0      1  
9           0  0.986486           0         1      0  
4  -0.0121114  0.985577   0.0113636  0.702055   0.25  
8  -0.0609055   0.97931  0.00662252  0.486301   0.25  
Elapsed time 13.87 mins 

************************************************************

pre/post: 25/0  win/stride: 500/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-26 08:13:27.599000 
pca_target: 20 	 poly degree: 2 	 kselect: 0 
Imbalance: SMOTE(k=None, k_neighbors=5, kind='borderline1', m=None, m_neighbors=10,
   n_jobs=1, out_step=0.5, random_state=None, ratio='auto',
   svm_estimator=None) 
Extended target (count):  25141 325
('Total : Processed (count): ', (986L, 325L), 13)
Final feature (count):  (986L, 325L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.878 	-0.041 	-0.025 	0.445 	0.000 	0.000
[[260  32]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.98      0.89      0.94       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.88      0.92       296


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='sag', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.949 	-0.023 	-0.020 	0.481 	0.000 	0.000
[[281  11]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.96      0.97       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.95      0.96       296


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.5, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.001, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='modified_huber', n_iter=5, n_jobs=4,
       penalty='none', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.973 	-0.014 	-0.014 	0.493 	0.000 	0.000
[[288   4]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.97      0.97       296


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 500},
           criterion='entropy', max_depth=8, max_features='auto',
           max_leaf_nodes=None, min_impurity_split=1e-07,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=15, n_jobs=4,
           oob_score=False, random_state=None, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.720 	0.057 	0.021 	0.611 	0.601 	0.353
[[211  81]
 [  2   2]]
             precision    recall  f1-score   support

          0       0.99      0.72      0.84       292
          1       0.02      0.50      0.05         4

avg / total       0.98      0.72      0.82       296


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.01, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.973 	-0.014 	-0.014 	0.493 	0.000 	0.000
[[288   4]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.97      0.97       296


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 50}, criterion='gini', max_depth=8,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=2.0, n_estimators=15, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.976 	-0.012 	-0.012 	0.495 	0.000 	0.000
[[289   3]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.97       296


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.5, cache_size=200, class_weight={1: 50}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.936 	-0.027 	-0.022 	0.474 	0.000 	0.000
[[277  15]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.95      0.97       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.94      0.95       296


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...owski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='uniform'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=1,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


                estimator   min_score   mean_score  max_score    sd_score  \
3    ExtraTreesClassifier  -0.0229102 -0.000378942  0.0753276   0.0142205   
4  RandomForestClassifier -0.00828832 -0.000582849          0  0.00110561   
8        VotingClassifier  -0.0174841  -0.00598727          0  0.00493896   
9    KNeighborsClassifier  -0.0164925   -0.0051238          0  0.00642759   
6      AdaBoostClassifier  -0.0201839  -0.00679698   0.128458   0.0189264   
2           SGDClassifier  -0.0904202    0.0148391   0.154946   0.0303259   
5           MLPClassifier  -0.0195444  -0.00581241  0.0899008   0.0250323   
1      LogisticRegression   -0.049836    0.0128611  0.0845615    0.022289   
7                     SVC  -0.0249815   0.00832374  0.0856009   0.0190316   
0              GaussianNB   0.0375313    0.0375313  0.0375313           0   

        acc       auc          conf_matrix     f1_c0     f1_c1      kappa  \
3  0.719595  0.611301  [[211, 81], [2, 2]]  0.835644  0.045977   0.020727   
4  0.986486       0.5   [[292, 0], [4, 0]]  0.993197         0          0   
8  0.986486       0.5   [[292, 0], [4, 0]]  0.993197         0          0   
9  0.986486       0.5   [[292, 0], [4, 0]]  0.993197         0          0   
6  0.976351  0.494863   [[289, 3], [4, 0]]  0.988034         0 -0.0117188   
2  0.972973  0.493151   [[288, 4], [4, 0]]  0.986301         0 -0.0136986   
5  0.972973  0.493151   [[288, 4], [4, 0]]  0.986301         0 -0.0136986   
1  0.949324  0.481164  [[281, 11], [4, 0]]  0.974003         0 -0.0202206   
7  0.935811  0.474315  [[277, 15], [4, 0]]  0.966841         0 -0.0218023   
0  0.878378  0.445205  [[260, 32], [4, 0]]  0.935252         0 -0.0246154   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
3   0.0572167   0.99061  0.0240964  0.722603    0.5  
4           0  0.986486          0         1      0  
8           0  0.986486          0         1      0  
9           0  0.986486          0         1      0  
6  -0.0118431  0.986348          0  0.989726      0  
2  -0.0136986  0.986301          0  0.986301      0  
5  -0.0136986  0.986301          0  0.986301      0  
1  -0.0229939  0.985965          0  0.962329      0  
7  -0.0270415  0.985765          0   0.94863      0  
0  -0.0407485  0.984848          0  0.890411      0  
Elapsed time 22.12 mins 

************************************************************

pre/post: 25/0  win/stride: 500/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-26 08:35:34.546000 
pca_target: 20 	 poly degree: 2 	 kselect: 0 
Imbalance: None 
Extended target (count):  25141 325
('Total : Processed (count): ', (986L, 325L), 13)
Final feature (count):  (986L, 325L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.878 	-0.041 	-0.025 	0.445 	0.000 	0.000
[[260  32]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.98      0.89      0.94       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.88      0.92       296


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.1, class_weight={1: 50}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='sag', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.868 	-0.043 	-0.025 	0.440 	0.000 	0.000
[[257  35]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.98      0.88      0.93       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.87      0.92       296


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.001, average=False, class_weight={1: 15}, epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='constant', loss='perceptron', n_iter=5, n_jobs=4,
       penalty='none', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.831 	0.177 	0.084 	0.791 	0.790 	0.619
[[243  49]
 [  1   3]]
             precision    recall  f1-score   support

          0       1.00      0.83      0.91       292
          1       0.06      0.75      0.11         4

avg / total       0.98      0.83      0.90       296


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight='balanced',
           criterion='entropy', max_depth=8, max_features=0.33,
           max_leaf_nodes=None, min_impurity_split=1e-07,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=15, n_jobs=4,
           oob_score=False, random_state=None, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.949 	-0.023 	-0.020 	0.481 	0.000 	0.000
[[281  11]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.96      0.97       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.95      0.96       296


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.01, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(500,), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.976 	-0.012 	-0.012 	0.495 	0.000 	0.000
[[289   3]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.97       296


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight='balanced', criterion='gini', max_depth=8,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=2.0, n_estimators=50, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.970 	-0.015 	-0.015 	0.491 	0.000 	0.000
[[287   5]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.98      0.98       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.97      0.97       296


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.5, cache_size=200, class_weight={1: 50}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.936 	-0.027 	-0.022 	0.474 	0.000 	0.000
[[277  15]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.95      0.97       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.94      0.95       296


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...owski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='uniform'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.983 	-0.007 	-0.005 	0.498 	0.000 	0.000
[[291   1]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.98       296


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=1,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       292
          1       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


                estimator  min_score   mean_score  max_score    sd_score  \
2           SGDClassifier -0.0762044    0.0155308   0.156951   0.0309844   
4  RandomForestClassifier -0.0062162 -0.000553123          0  0.00102111   
9    KNeighborsClassifier -0.0164925   -0.0051238          0  0.00642759   
8        VotingClassifier -0.0176459  -0.00630669          0   0.0051175   
5           MLPClassifier -0.0197509   0.00568615   0.129272   0.0378783   
6      AdaBoostClassifier  -0.021072  -0.00721011   0.183447   0.0199024   
3    ExtraTreesClassifier -0.0214749  2.25599e-06   0.137023   0.0170275   
7                     SVC -0.0249815   0.00832374  0.0856009   0.0190316   
0              GaussianNB  0.0375313    0.0375313  0.0375313           0   
1      LogisticRegression  -0.037038    0.0125136  0.0888025   0.0226596   

        acc       auc          conf_matrix     f1_c0     f1_c1       kappa  \
2  0.831081  0.791096  [[243, 49], [1, 3]]  0.906716  0.107143   0.0841584   
4  0.986486       0.5   [[292, 0], [4, 0]]  0.993197         0           0   
9  0.986486       0.5   [[292, 0], [4, 0]]  0.993197         0           0   
8  0.983108  0.498288   [[291, 1], [4, 0]]  0.991482         0 -0.00543478   
5  0.976351  0.494863   [[289, 3], [4, 0]]  0.988034         0  -0.0117188   
6  0.969595  0.491438   [[287, 5], [4, 0]]  0.984563         0  -0.0152439   
3  0.949324  0.481164  [[281, 11], [4, 0]]  0.974003         0  -0.0202206   
7  0.935811  0.474315  [[277, 15], [4, 0]]  0.966841         0  -0.0218023   
0  0.878378  0.445205  [[260, 32], [4, 0]]  0.935252         0  -0.0246154   
1  0.868243  0.440068  [[257, 35], [4, 0]]  0.929476         0   -0.024858   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
2    0.176641  0.995902  0.0576923  0.832192   0.75  
4           0  0.986486          0         1      0  
9           0  0.986486          0         1      0  
8  -0.0068144  0.986441          0  0.996575      0  
5  -0.0118431  0.986348          0  0.989726      0  
6  -0.0153418  0.986254          0  0.982877      0  
3  -0.0229939  0.985965          0  0.962329      0  
7  -0.0270415  0.985765          0   0.94863      0  
0  -0.0407485  0.984848          0  0.890411      0  
1    -0.04286  0.984674          0  0.880137      0  
Elapsed time 22.28 mins 

************************************************************

[4;33mReloaded modules[24m: migraine_processing, classifiers[0m
Finished.
