



Standard, lagged(3,4)x1, filter(tukey & hp), NT+, truncated



    pca = [0, 80]
    poly = [2]
    ksel = [80, 40]
    imb = [None, ClusterCentroids() ]
	


	
	
pre/post: 25/0  win/stride: 500/25  label:start 
filename: stm_sb_modified.csv 
datetime: 2017-05-05 10:11:24.944000 
pca_target: 0 	 poly degree: 2 	 kselect: 60 
Imbalance: None 
Extended target (count):  31485 325
('Total : Processed (count): ', (1240L, 276L), 13)
Final feature (count):  (1240L, 276L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.511 	0.091 	0.016 	0.753 	0.712 	0.532
[[187 182]
 [  0   3]]
             precision    recall  f1-score   support

          0       1.00      0.51      0.67       369
          1       0.02      1.00      0.03         3

avg / total       0.99      0.51      0.67       372


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=5, class_weight={1: 500}, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=4,
          penalty='l2', random_state=None, solver='sag', tol=0.0001,
          verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.495 	0.088 	0.015 	0.745 	0.700 	0.516
[[181 188]
 [  0   3]]
             precision    recall  f1-score   support

          0       1.00      0.49      0.66       369
          1       0.02      1.00      0.03         3

avg / total       0.99      0.49      0.65       372


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.5, average=False, class_weight={1: 50}, epsilon=0.1,
       eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='invscaling', loss='squared_hinge', n_iter=5,
       n_jobs=4, penalty='none', power_t=0.5, random_state=None,
       shuffle=True, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.734 	0.081 	0.024 	0.701 	0.700 	0.486
[[271  98]
 [  1   2]]
             precision    recall  f1-score   support

          0       1.00      0.73      0.85       369
          1       0.02      0.67      0.04         3

avg / total       0.99      0.73      0.84       372


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 500},
           criterion='entropy', max_depth=8, max_features=0.33,
           max_leaf_nodes=None, min_impurity_split=1e-07,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=4,
           oob_score=False, random_state=None, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.887 	0.155 	0.073 	0.778 	0.770 	0.579
[[328  41]
 [  1   2]]
             precision    recall  f1-score   support

          0       1.00      0.89      0.94       369
          1       0.05      0.67      0.09         3

avg / total       0.99      0.89      0.93       372


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 500},
            criterion='gini', max_depth=8, max_features='auto',
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.949 	0.245 	0.162 	0.809 	0.796 	0.616
[[351  18]
 [  1   2]]
             precision    recall  f1-score   support

          0       1.00      0.95      0.97       369
          1       0.10      0.67      0.17         3

avg / total       0.99      0.95      0.97       372


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.01, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(500,), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.981 	-0.009 	-0.009 	0.495 	0.000 	0.000
[[365   4]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.98      0.98       372


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight='balanced', criterion='entropy',
            max_depth=32, max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=2.0, n_estimators=15, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	-0.007 	-0.006 	0.497 	0.000 	0.000
[[367   2]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.99      0.99       372


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=10, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.984 	-0.008 	-0.008 	0.496 	0.000 	0.000
[[366   3]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.98      0.98       372


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.992 	0.000 	0.000 	0.500 	0.000 	0.000
[[369   0]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      1.00       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.99      0.99       372


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=1,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.992 	0.000 	0.000 	0.500 	0.000 	0.000
[[369   0]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      1.00       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.99      0.99       372


                estimator   min_score   mean_score  max_score    sd_score  \
4  RandomForestClassifier  -0.0231433 -0.000218344  0.0739887  0.00657418   
3    ExtraTreesClassifier  -0.0214196 -0.000990998   0.117213   0.0150292   
0              GaussianNB   0.0932415    0.0932415  0.0932415           0   
1      LogisticRegression  -0.0580588    0.0101319   0.109114   0.0284851   
2           SGDClassifier   -0.168306     0.015055   0.139833   0.0368621   
8        VotingClassifier -0.00794902  -0.00138788          0  0.00199526   
9    KNeighborsClassifier  -0.0101247  -0.00206054          0  0.00368164   
6      AdaBoostClassifier  -0.0231877 -2.52722e-05   0.162332   0.0292424   
7                     SVC   -0.077988    0.0175721   0.137235   0.0365729   
5           MLPClassifier  -0.0125643    0.0196297   0.134904   0.0461588   

        acc       auc           conf_matrix     f1_c0      f1_c1       kappa  \
4  0.948925  0.808943   [[351, 18], [1, 2]]  0.973648   0.173913    0.162162   
3  0.887097  0.777778   [[328, 41], [1, 2]]  0.939828  0.0869565   0.0729797   
0  0.510753  0.753388  [[187, 182], [0, 3]]  0.672662  0.0319149    0.016302   
1  0.494624  0.745257  [[181, 188], [0, 3]]  0.658182  0.0309278    0.015291   
2  0.733871  0.700542   [[271, 98], [1, 2]]  0.845554   0.038835   0.0235444   
8  0.991935       0.5    [[369, 0], [3, 0]]  0.995951          0           0   
9  0.991935       0.5    [[369, 0], [3, 0]]  0.995951          0           0   
6  0.986559   0.49729    [[367, 2], [3, 0]]  0.993234          0 -0.00649351   
7  0.983871  0.495935    [[366, 3], [3, 0]]   0.99187          0 -0.00813008   
5  0.981183   0.49458    [[365, 4], [3, 0]]  0.990502          0 -0.00930233   

  model_score   prec_c0    prec_c1    rec_c0    rec_c1  
4    0.245017  0.997159        0.1   0.95122  0.666667  
3    0.155406   0.99696  0.0465116  0.888889  0.666667  
0    0.090653         1  0.0162162  0.506775         1  
1   0.0877748         1  0.0157068  0.490515         1  
2   0.0809142  0.996324       0.02  0.734417  0.666667  
8           0  0.991935          0         1         0  
9           0  0.991935          0         1         0  
6 -0.00662921  0.991892          0   0.99458         0  
7 -0.00813008   0.99187          0   0.99187         0  
5 -0.00940056  0.991848          0   0.98916         0  
Elapsed time 29.73 mins 

************************************************************

pre/post: 25/0  win/stride: 500/25  label:start 
filename: stm_sb_modified.csv 
datetime: 2017-05-05 10:41:08.745000 
pca_target: 0 	 poly degree: 2 	 kselect: 60 
Imbalance: SMOTE(k=None, k_neighbors=5, kind='regular', m=None, m_neighbors=10, n_jobs=1,
   out_step=0.5, random_state=None, ratio='auto', svm_estimator=None) 
Extended target (count):  31485 325
('Total : Processed (count): ', (1240L, 276L), 13)
Final feature (count):  (1240L, 276L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.554 	0.099 	0.019 	0.775 	0.742 	0.575
[[203 166]
 [  0   3]]
             precision    recall  f1-score   support

          0       1.00      0.55      0.71       369
          1       0.02      1.00      0.03         3

avg / total       0.99      0.55      0.70       372


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=10, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=5, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.879 	-0.032 	-0.015 	0.443 	0.000 	0.000
[[327  42]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.89      0.94       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.88      0.93       372


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.001, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.001, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='modified_huber', n_iter=5, n_jobs=4,
       penalty='none', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.833 	-0.039 	-0.016 	0.420 	0.000 	0.000
[[310  59]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.84      0.91       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.83      0.90       372


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=None, max_features=0.33, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=50, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.973 	-0.012 	-0.011 	0.491 	0.000 	0.000
[[362   7]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.98      0.99       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.97      0.98       372


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 50}, criterion='gini',
            max_depth=None, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=30, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.970 	-0.013 	-0.012 	0.489 	0.000 	0.000
[[361   8]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.98      0.98       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.97      0.98       372


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.01, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(500,), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.976 	-0.012 	-0.011 	0.492 	0.000 	0.000
[[363   6]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.98      0.99       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.98      0.98       372


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight='balanced', criterion='entropy',
            max_depth=4, max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=1.0, n_estimators=80, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.970 	-0.013 	-0.012 	0.489 	0.000 	0.000
[[361   8]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.98      0.98       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.97      0.98       372


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=10, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.978 	-0.011 	-0.010 	0.493 	0.000 	0.000
[[364   5]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.98      0.98       372


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=10.0, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', ...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.957 	-0.017 	-0.013 	0.482 	0.000 	0.000
[[356  13]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.96      0.98       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.96      0.97       372


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=2,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.941 	-0.021 	-0.014 	0.474 	0.000 	0.000
[[350  19]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.95      0.97       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.94      0.96       372


                estimator min_score mean_score max_score   sd_score       acc  \
0              GaussianNB  0.607894   0.607894  0.607894          0  0.553763   
7                     SVC         0   0.711731  0.974485   0.217858  0.978495   
5           MLPClassifier  0.929442    0.97451  0.987276  0.0108371  0.975806   
3    ExtraTreesClassifier  0.647646   0.905926  0.978117  0.0853291  0.973118   
4  RandomForestClassifier  0.760211   0.919191  0.968851  0.0561178   0.97043   
6      AdaBoostClassifier  0.718823   0.927515  0.972389  0.0330336   0.97043   
8        VotingClassifier  0.870481   0.916859  0.954382  0.0213075  0.956989   
9    KNeighborsClassifier  0.847992   0.899049  0.936514  0.0273459   0.94086   
1      LogisticRegression         0   0.589195   0.82716   0.144888  0.879032   
2           SGDClassifier -0.241433   0.428924  0.764877   0.205294  0.833333   

        auc           conf_matrix     f1_c0      f1_c1      kappa model_score  \
0  0.775068  [[203, 166], [0, 3]]   0.70979  0.0348837  0.0193425   0.0988217   
7  0.493225    [[364, 5], [3, 0]]   0.98913          0 -0.0101833  -0.0105245   
5   0.49187    [[363, 6], [3, 0]]  0.987755          0 -0.0108696  -0.0115447   
3  0.490515    [[362, 7], [3, 0]]  0.986376          0 -0.0114192  -0.0124868   
4   0.48916    [[361, 8], [3, 0]]  0.984993          0 -0.0118694  -0.0133672   
6   0.48916    [[361, 8], [3, 0]]  0.984993          0 -0.0118694  -0.0133672   
8  0.482385   [[356, 13], [3, 0]]  0.978022          0 -0.0132789  -0.0171582   
9  0.474255   [[350, 19], [3, 0]]  0.969529          0 -0.0141264  -0.0209188   
1  0.443089   [[327, 42], [3, 0]]  0.935622          0 -0.0152838  -0.0321673   
2  0.420054   [[310, 59], [3, 0]]  0.909091          0 -0.0155878  -0.0391473   

    prec_c0    prec_c1    rec_c0 rec_c1  
0         1  0.0177515  0.550136      1  
7  0.991826          0   0.98645      0  
5  0.991803          0   0.98374      0  
3  0.991781          0   0.98103      0  
4  0.991758          0   0.97832      0  
6  0.991758          0   0.97832      0  
8  0.991643          0   0.96477      0  
9  0.991501          0  0.948509      0  
1  0.990909          0  0.886179      0  
2  0.990415          0  0.840108      0  
Elapsed time 67.36 mins 

************************************************************

pre/post: 25/0  win/stride: 500/25  label:start 
filename: stm_sb_modified.csv 
datetime: 2017-05-05 11:48:30.631000 
pca_target: 0 	 poly degree: 2 	 kselect: 60 
Imbalance: ClusterCentroids(estimator=None, n_jobs=1, random_state=None, ratio='auto') 
Extended target (count):  31485 325
('Total : Processed (count): ', (1240L, 276L), 13)
Final feature (count):  (1240L, 276L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.524 	0.093 	0.017 	0.760 	0.721 	0.545
[[192 177]
 [  0   3]]
             precision    recall  f1-score   support

          0       1.00      0.52      0.68       369
          1       0.02      1.00      0.03         3

avg / total       0.99      0.52      0.68       372


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.001, class_weight={1: 50}, dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.492 	0.087 	0.015 	0.744 	0.698 	0.513
[[180 189]
 [  0   3]]
             precision    recall  f1-score   support

          0       1.00      0.49      0.66       369
          1       0.02      1.00      0.03         3

avg / total       0.99      0.49      0.65       372


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=1, average=False, class_weight='balanced', epsilon=0.1,
       eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='invscaling', loss='modified_huber', n_iter=5,
       n_jobs=4, penalty='l2', power_t=0.5, random_state=None,
       shuffle=True, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.858 	-0.036 	-0.015 	0.432 	0.000 	0.000
[[319  50]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.86      0.92       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.86      0.92       372


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight='balanced',
           criterion='entropy', max_depth=None, max_features=0.75,
           max_leaf_nodes=None, min_impurity_split=1e-07,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=15, n_jobs=4,
           oob_score=False, random_state=None, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.368 	0.068 	0.009 	0.682 	0.603 	0.386
[[134 235]
 [  0   3]]
             precision    recall  f1-score   support

          0       1.00      0.36      0.53       369
          1       0.01      1.00      0.02         3

avg / total       0.99      0.37      0.53       372


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.441 	-0.040 	-0.006 	0.388 	0.384 	0.146
[[163 206]
 [  2   1]]
             precision    recall  f1-score   support

          0       0.99      0.44      0.61       369
          1       0.00      0.33      0.01         3

avg / total       0.98      0.44      0.61       372


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.605 	0.050 	0.011 	0.636 	0.635 	0.405
[[223 146]
 [  1   2]]
             precision    recall  f1-score   support

          0       1.00      0.60      0.75       369
          1       0.01      0.67      0.03         3

avg / total       0.99      0.60      0.75       372


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight='balanced', criterion='entropy',
            max_depth=16, max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=0.5, n_estimators=50, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.462 	0.082 	0.013 	0.729 	0.677 	0.483
[[169 200]
 [  0   3]]
             precision    recall  f1-score   support

          0       1.00      0.46      0.63       369
          1       0.01      1.00      0.03         3

avg / total       0.99      0.46      0.62       372


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.1, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='linear',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.360 	0.066 	0.009 	0.678 	0.596 	0.378
[[131 238]
 [  0   3]]
             precision    recall  f1-score   support

          0       1.00      0.36      0.52       369
          1       0.01      1.00      0.02         3

avg / total       0.99      0.36      0.52       372


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', R...owski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='uniform'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.401 	0.072 	0.010 	0.698 	0.629 	0.420
[[146 223]
 [  0   3]]
             precision    recall  f1-score   support

          0       1.00      0.40      0.57       369
          1       0.01      1.00      0.03         3

avg / total       0.99      0.40      0.56       372


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=1,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.723 	-0.055 	-0.016 	0.364 	0.000 	0.000
[[269 100]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.73      0.84       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.72      0.83       372


                estimator min_score mean_score max_score   sd_score       acc  \
0              GaussianNB   0.91547    0.91547   0.91547          0  0.524194   
1      LogisticRegression  -0.11547   0.202547   0.54641   0.174254  0.491935   
6      AdaBoostClassifier   0.43094   0.702048   0.91547  0.0519458  0.462366   
8        VotingClassifier   0.23094   0.535409   0.83094    0.14371  0.400538   
3    ExtraTreesClassifier       0.4   0.548101   0.74641  0.0661792   0.36828   
7                     SVC  -0.11547   0.208947   0.54641   0.224458  0.360215   
5           MLPClassifier  -0.14641  0.0151585   0.23094   0.105505  0.604839   
2           SGDClassifier  -0.54641   0.272052   0.74641   0.207865  0.857527   
4  RandomForestClassifier   0.63094   0.781453   0.83094  0.0506766   0.44086   
9    KNeighborsClassifier  -0.11547   0.248458       0.6   0.186083  0.723118   

        auc           conf_matrix     f1_c0       f1_c1       kappa  \
0  0.760163  [[192, 177], [0, 3]]  0.684492   0.0327869   0.0171951   
1  0.743902  [[180, 189], [0, 3]]  0.655738   0.0307692   0.0151286   
6  0.728997  [[169, 200], [0, 3]]  0.628253   0.0291262   0.0134458   
8  0.697832  [[146, 223], [0, 3]]   0.56699   0.0262009   0.0104495   
3  0.681572  [[134, 235], [0, 3]]  0.532803   0.0248963  0.00911317   
7  0.677507  [[131, 238], [0, 3]]     0.524   0.0245902  0.00879962   
5  0.635501  [[223, 146], [1, 2]]  0.752108   0.0264901    0.010853   
2  0.432249   [[319, 50], [3, 0]]    0.9233           0  -0.0154512   
4  0.387534  [[163, 206], [2, 1]]  0.610487  0.00952381  -0.0064778   
9  0.364499  [[269, 100], [3, 0]]  0.839314           0  -0.0159084   

  model_score   prec_c0     prec_c1    rec_c0    rec_c1  
0    0.093124         1   0.0166667  0.520325         1  
1   0.0873038         1    0.015625  0.487805         1  
6   0.0822702         1   0.0147783  0.457995         1  
8   0.0724719         1   0.0132743  0.395664         1  
3   0.0676568         1    0.012605  0.363144         1  
7   0.0664775         1   0.0124481  0.355014         1  
5   0.0495214  0.995536   0.0135135  0.604336  0.666667  
2  -0.0355308  0.990683           0  0.864499         0  
4  -0.0404947  0.987879  0.00483092  0.441734  0.333333  
9  -0.0546718  0.988971           0  0.728997         0  
Elapsed time 16.04 mins 

************************************************************

pre/post: 25/0  win/stride: 500/25  label:start 
filename: stm_sb_modified.csv 
datetime: 2017-05-05 12:04:32.940000 
pca_target: 0 	 poly degree: 2 	 kselect: 40 
Imbalance: None 
Extended target (count):  31485 325
('Total : Processed (count): ', (1240L, 276L), 13)
Final feature (count):  (1240L, 276L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.812 	-0.042 	-0.016 	0.409 	0.000 	0.000
[[302  67]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.82      0.90       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.81      0.89       372


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.01, class_weight={1: 50}, dual=False,
          fit_intercept=True, intercept_scaling=0.01, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='sag', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.793 	0.101 	0.034 	0.730 	0.728 	0.523
[[293  76]
 [  1   2]]
             precision    recall  f1-score   support

          0       1.00      0.79      0.88       369
          1       0.03      0.67      0.05         3

avg / total       0.99      0.79      0.88       372


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.5, average=False, class_weight={1: 50}, epsilon=0.1,
       eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='constant', loss='squared_hinge', n_iter=5, n_jobs=4,
       penalty='l1', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.747 	0.085 	0.026 	0.707 	0.706 	0.495
[[276  93]
 [  1   2]]
             precision    recall  f1-score   support

          0       1.00      0.75      0.85       369
          1       0.02      0.67      0.04         3

avg / total       0.99      0.75      0.85       372


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=8, max_features='auto', max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.992 	0.000 	0.000 	0.500 	0.000 	0.000
[[369   0]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      1.00       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.99      0.99       372


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.992 	0.000 	0.000 	0.500 	0.000 	0.000
[[369   0]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      1.00       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.99      0.99       372


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.970 	-0.013 	-0.012 	0.489 	0.000 	0.000
[[361   8]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.98      0.98       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.97      0.98       372


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 500}, criterion='entropy',
            max_depth=4, max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=2.0, n_estimators=15, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.973 	-0.012 	-0.011 	0.491 	0.000 	0.000
[[362   7]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.98      0.99       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.97      0.98       372


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=10, cache_size=200, class_weight='balanced', coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.903 	0.074 	0.038 	0.621 	0.550 	0.285
[[335  34]
 [  2   1]]
             precision    recall  f1-score   support

          0       0.99      0.91      0.95       369
          1       0.03      0.33      0.05         3

avg / total       0.99      0.90      0.94       372


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.992 	0.000 	0.000 	0.500 	0.000 	0.000
[[369   0]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      1.00       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.99      0.99       372


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=1,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.992 	0.000 	0.000 	0.500 	0.000 	0.000
[[369   0]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      1.00       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.99      0.99       372


                estimator  min_score  mean_score  max_score    sd_score  \
1      LogisticRegression  -0.281443 -0.00472455   0.108562   0.0480895   
2           SGDClassifier  -0.195591 -0.00644031   0.113688   0.0376297   
7                     SVC   -0.11016   0.0164067   0.124037   0.0406825   
3    ExtraTreesClassifier -0.0339638 -0.00335213          0  0.00548316   
4  RandomForestClassifier -0.0101539 -0.00136935          0  0.00135968   
8        VotingClassifier -0.0101248 -0.00300133          0  0.00268838   
9    KNeighborsClassifier -0.0108123 -0.00275504          0  0.00400554   
6      AdaBoostClassifier -0.0225546 -0.00583172   0.214618   0.0187596   
5           MLPClassifier -0.0140017 -0.00522923  0.0890228    0.020235   
0              GaussianNB  0.0827839   0.0827839  0.0827839           0   

        acc       auc          conf_matrix     f1_c0      f1_c1      kappa  \
1  0.793011  0.730352  [[293, 76], [1, 2]]  0.883861  0.0493827  0.0343851   
2  0.747312  0.707317  [[276, 93], [1, 2]]  0.854489  0.0408163   0.025581   
7  0.903226  0.620596  [[335, 34], [2, 1]]  0.949008  0.0526316  0.0383455   
3  0.991935       0.5   [[369, 0], [3, 0]]  0.995951          0          0   
4  0.991935       0.5   [[369, 0], [3, 0]]  0.995951          0          0   
8  0.991935       0.5   [[369, 0], [3, 0]]  0.995951          0          0   
9  0.991935       0.5   [[369, 0], [3, 0]]  0.995951          0          0   
6  0.973118  0.490515   [[362, 7], [3, 0]]  0.986376          0 -0.0114192   
5   0.97043   0.48916   [[361, 8], [3, 0]]  0.984993          0 -0.0118694   
0  0.811828  0.409214  [[302, 67], [3, 0]]  0.896142          0 -0.0156799   

  model_score   prec_c0    prec_c1    rec_c0    rec_c1  
1    0.101222  0.996599   0.025641  0.794038  0.666667  
2   0.0850427   0.99639  0.0210526  0.747967  0.666667  
7   0.0738905  0.994065  0.0285714  0.907859  0.333333  
3           0  0.991935          0         1         0  
4           0  0.991935          0         1         0  
8           0  0.991935          0         1         0  
9           0  0.991935          0         1         0  
6  -0.0124868  0.991781          0   0.98103         0  
5  -0.0133672  0.991758          0   0.97832         0  
0  -0.0422605  0.990164          0  0.818428         0  
Elapsed time 27.39 mins 

************************************************************

pre/post: 25/0  win/stride: 500/25  label:start 
filename: stm_sb_modified.csv 
datetime: 2017-05-05 12:31:56.042000 
pca_target: 0 	 poly degree: 2 	 kselect: 40 
Imbalance: SMOTE(k=None, k_neighbors=5, kind='regular', m=None, m_neighbors=10, n_jobs=1,
   out_step=0.5, random_state=None, ratio='auto', svm_estimator=None) 
Extended target (count):  31485 325
('Total : Processed (count): ', (1240L, 276L), 13)
Final feature (count):  (1240L, 276L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.495 	0.088 	0.015 	0.745 	0.700 	0.516
[[181 188]
 [  0   3]]
             precision    recall  f1-score   support

          0       1.00      0.49      0.66       369
          1       0.02      1.00      0.03         3

avg / total       0.99      0.49      0.65       372


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=10, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.780 	-0.047 	-0.016 	0.393 	0.000 	0.000
[[290  79]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.79      0.88       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.78      0.87       372


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.001, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='squared_hinge', n_iter=5, n_jobs=4,
       penalty='l1', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.728 	-0.054 	-0.016 	0.367 	0.000 	0.000
[[271  98]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.73      0.84       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.73      0.84       372


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 15}, criterion='gini',
           max_depth=None, max_features=0.75, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=30, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.968 	-0.014 	-0.012 	0.488 	0.000 	0.000
[[360   9]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.98      0.98       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.97      0.98       372


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight='balanced',
            criterion='gini', max_depth=16, max_features='auto',
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.949 	-0.019 	-0.014 	0.478 	0.000 	0.000
[[353  16]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.96      0.97       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.95      0.97       372


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.1, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.965 	-0.015 	-0.013 	0.486 	0.000 	0.000
[[359  10]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.97      0.98       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.97      0.97       372


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 500}, criterion='entropy',
            max_depth=8, max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=1.0, n_estimators=80, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.954 	-0.018 	-0.013 	0.481 	0.000 	0.000
[[355  14]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.96      0.98       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.95      0.97       372


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=10, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.962 	-0.016 	-0.013 	0.485 	0.000 	0.000
[[358  11]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.97      0.98       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.96      0.97       372


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=10.0, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', ...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.946 	-0.020 	-0.014 	0.477 	0.000 	0.000
[[352  17]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.95      0.97       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.95      0.96       372


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=4,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.946 	0.116 	0.078 	0.642 	0.563 	0.297
[[351  18]
 [  2   1]]
             precision    recall  f1-score   support

          0       0.99      0.95      0.97       369
          1       0.05      0.33      0.09         3

avg / total       0.99      0.95      0.97       372


                estimator min_score mean_score max_score    sd_score  \
0              GaussianNB  0.561194   0.561194  0.561194           0   
9    KNeighborsClassifier  0.852607   0.898433  0.932655   0.0218346   
3    ExtraTreesClassifier  0.678591   0.897126  0.956096   0.0745664   
5           MLPClassifier  0.940364   0.968934  0.980402  0.00702384   
7                     SVC         0   0.682895  0.956101    0.190594   
6      AdaBoostClassifier  0.729491   0.914283  0.962225   0.0360553   
4  RandomForestClassifier  0.773752    0.90516  0.940358   0.0423578   
8        VotingClassifier  0.850333   0.892639  0.933464   0.0194755   
1      LogisticRegression         0    0.54278   0.78203    0.142306   
2           SGDClassifier -0.124312   0.391235  0.686495    0.186298   

        acc       auc           conf_matrix     f1_c0      f1_c1      kappa  \
0  0.494624  0.745257  [[181, 188], [0, 3]]  0.658182  0.0309278   0.015291   
9  0.946237  0.642276   [[351, 18], [2, 1]]  0.972299  0.0909091  0.0780669   
3  0.967742  0.487805    [[360, 9], [3, 0]]  0.983607          0 -0.0122449   
5  0.965054   0.48645   [[359, 10], [3, 0]]  0.982216          0 -0.0125628   
7  0.962366  0.485095   [[358, 11], [3, 0]]  0.980822          0 -0.0128355   
6  0.954301   0.48103   [[355, 14], [3, 0]]  0.976616          0 -0.0134615   
4  0.948925   0.47832   [[353, 16], [3, 0]]  0.973793          0 -0.0137694   
8  0.946237  0.476965   [[352, 17], [3, 0]]  0.972376          0 -0.0139002   
1   0.77957  0.392954   [[290, 79], [3, 0]]  0.876133          0 -0.0157842   
2  0.728495  0.367209   [[271, 98], [3, 0]]  0.842924          0 -0.0158988   

  model_score   prec_c0    prec_c1    rec_c0    rec_c1  
0   0.0877748         1  0.0157068  0.490515         1  
9    0.115604  0.994334  0.0526316   0.95122  0.333333  
3  -0.0141976  0.991736          0   0.97561         0  
5  -0.0149863  0.991713          0    0.9729         0  
7  -0.0157395   0.99169          0   0.97019         0  
6  -0.0178308   0.99162          0   0.96206         0  
4  -0.0191154  0.991573          0   0.95664         0  
8  -0.0197314  0.991549          0   0.95393         0  
1  -0.0468195  0.989761          0  0.785908         0  
2  -0.0539244  0.989051          0  0.734417         0  
Elapsed time 58.24 mins 

************************************************************

pre/post: 25/0  win/stride: 500/25  label:start 
filename: stm_sb_modified.csv 
datetime: 2017-05-05 13:30:10.678000 
pca_target: 0 	 poly degree: 2 	 kselect: 40 
Imbalance: ClusterCentroids(estimator=None, n_jobs=1, random_state=None, ratio='auto') 
Extended target (count):  31485 325
('Total : Processed (count): ', (1240L, 276L), 13)
Final feature (count):  (1240L, 276L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.465 	0.083 	0.014 	0.730 	0.679 	0.486
[[170 199]
 [  0   3]]
             precision    recall  f1-score   support

          0       1.00      0.46      0.63       369
          1       0.01      1.00      0.03         3

avg / total       0.99      0.47      0.63       372


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.001, class_weight={1: 50}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.438 	0.078 	0.012 	0.717 	0.658 	0.458
[[160 209]
 [  0   3]]
             precision    recall  f1-score   support

          0       1.00      0.43      0.60       369
          1       0.01      1.00      0.03         3

avg / total       0.99      0.44      0.60       372


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.0001, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='modified_huber', n_iter=5, n_jobs=4,
       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.360 	0.066 	0.009 	0.678 	0.596 	0.378
[[131 238]
 [  0   3]]
             precision    recall  f1-score   support

          0       1.00      0.36      0.52       369
          1       0.01      1.00      0.02         3

avg / total       0.99      0.36      0.52       372


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3},
           criterion='entropy', max_depth=8, max_features='auto',
           max_leaf_nodes=None, min_impurity_split=1e-07,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=15, n_jobs=4,
           oob_score=False, random_state=None, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.371 	0.068 	0.009 	0.683 	0.605 	0.389
[[135 234]
 [  0   3]]
             precision    recall  f1-score   support

          0       1.00      0.37      0.54       369
          1       0.01      1.00      0.02         3

avg / total       0.99      0.37      0.53       372


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3},
            criterion='entropy', max_depth=32, max_features=0.33,
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.358 	0.066 	0.009 	0.676 	0.594 	0.375
[[130 239]
 [  0   3]]
             precision    recall  f1-score   support

          0       1.00      0.35      0.52       369
          1       0.01      1.00      0.02         3

avg / total       0.99      0.36      0.52       372


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.465 	0.083 	0.014 	0.730 	0.679 	0.486
[[170 199]
 [  0   3]]
             precision    recall  f1-score   support

          0       1.00      0.46      0.63       369
          1       0.01      1.00      0.03         3

avg / total       0.99      0.47      0.63       372


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=32,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=0.5, n_estimators=50, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.481 	0.026 	0.004 	0.573 	0.565 	0.326
[[177 192]
 [  1   2]]
             precision    recall  f1-score   support

          0       0.99      0.48      0.65       369
          1       0.01      0.67      0.02         3

avg / total       0.99      0.48      0.64       372


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.5, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='linear',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.352 	0.065 	0.008 	0.673 	0.589 	0.370
[[128 241]
 [  0   3]]
             precision    recall  f1-score   support

          0       1.00      0.35      0.52       369
          1       0.01      1.00      0.02         3

avg / total       0.99      0.35      0.51       372


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', R...owski',
           metric_params=None, n_jobs=4, n_neighbors=4, p=2,
           weights='uniform'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.358 	0.066 	0.009 	0.676 	0.594 	0.375
[[130 239]
 [  0   3]]
             precision    recall  f1-score   support

          0       1.00      0.35      0.52       369
          1       0.01      1.00      0.02         3

avg / total       0.99      0.36      0.52       372


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=5, p=1,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.452 	0.081 	0.013 	0.724 	0.669 	0.472
[[165 204]
 [  0   3]]
             precision    recall  f1-score   support

          0       1.00      0.45      0.62       369
          1       0.01      1.00      0.03         3

avg / total       0.99      0.45      0.61       372


                estimator  min_score mean_score max_score    sd_score  \
0              GaussianNB    0.91547    0.91547   0.91547           0   
5           MLPClassifier  0.0845299    0.29261       0.4   0.0693341   
9    KNeighborsClassifier       -0.2   0.190942   0.66188    0.232627   
1      LogisticRegression       -0.2    0.15365   0.54641    0.183733   
3    ExtraTreesClassifier    0.54641   0.631645   0.71547  0.00993701   
2           SGDClassifier   -0.31547   0.331039   0.71547    0.184118   
4  RandomForestClassifier    0.43094   0.589496   0.83094   0.0703255   
8        VotingClassifier        0.2   0.487488   0.83094    0.200801   
7                     SVC       -0.2   0.148447   0.54641    0.195383   
6      AdaBoostClassifier    0.11547   0.548747   0.83094   0.0893979   

        acc       auc           conf_matrix     f1_c0      f1_c1       kappa  \
0  0.465054  0.730352  [[170, 199], [0, 3]]  0.630798  0.0292683   0.0135913   
5  0.465054  0.730352  [[170, 199], [0, 3]]  0.630798  0.0292683   0.0135913   
9  0.451613  0.723577  [[165, 204], [0, 3]]  0.617978  0.0285714   0.0128775   
1  0.438172  0.716802  [[160, 209], [0, 3]]  0.604915   0.027907    0.012197   
3  0.370968  0.682927  [[135, 234], [0, 3]]  0.535714      0.025  0.00921942   
2  0.360215  0.677507  [[131, 238], [0, 3]]     0.524  0.0245902  0.00879962   
4  0.357527  0.676152  [[130, 239], [0, 3]]  0.521042  0.0244898  0.00869682   
8  0.357527  0.676152  [[130, 239], [0, 3]]  0.521042  0.0244898  0.00869682   
7  0.352151  0.673442  [[128, 241], [0, 3]]  0.515091  0.0242915   0.0084937   
6  0.481183  0.573171  [[177, 192], [1, 2]]  0.647166  0.0203046  0.00449251   

  model_score   prec_c0    prec_c1    rec_c0    rec_c1  
0   0.0827173         1  0.0148515  0.460705         1  
5   0.0827173         1  0.0148515  0.460705         1  
9   0.0805016         1  0.0144928  0.447154         1  
1   0.0783321         1  0.0141509  0.433604         1  
3   0.0680519         1  0.0126582  0.365854         1  
2   0.0664775         1  0.0124481  0.355014         1  
4   0.0660863         1  0.0123967  0.352304         1  
8   0.0660863         1  0.0123967  0.352304         1  
7   0.0653067         1  0.0122951  0.346883         1  
6   0.0262018  0.994382  0.0103093  0.479675  0.666667  
Elapsed time 15.42 mins 

************************************************************

pre/post: 25/0  win/stride: 500/25  label:start 
filename: stm_sb_modified.csv 
datetime: 2017-05-05 13:45:35.851000 
pca_target: 0 	 poly degree: 2 	 kselect: 0 
Imbalance: None 
Extended target (count):  31485 325
('Total : Processed (count): ', (1240L, 276L), 13)
Final feature (count):  (1240L, 276L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.559 	0.100 	0.020 	0.778 	0.745 	0.580
[[205 164]
 [  0   3]]
             precision    recall  f1-score   support

          0       1.00      0.56      0.71       369
          1       0.02      1.00      0.04         3

avg / total       0.99      0.56      0.71       372


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=5, class_weight={1: 500}, dual=False, fit_intercept=True,
          intercept_scaling=5, max_iter=100, multi_class='ovr', n_jobs=4,
          penalty='l2', random_state=None, solver='sag', tol=0.0001,
          verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.672 	0.064 	0.016 	0.669 	0.669 	0.448
[[248 121]
 [  1   2]]
             precision    recall  f1-score   support

          0       1.00      0.67      0.80       369
          1       0.02      0.67      0.03         3

avg / total       0.99      0.67      0.80       372


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.1, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='invscaling', loss='squared_hinge', n_iter=5,
       n_jobs=4, penalty='l2', power_t=0.5, random_state=None,
       shuffle=True, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.992 	0.000 	0.000 	0.500 	0.000 	0.000
[[369   0]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      1.00       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.99      0.99       372


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 15}, criterion='gini',
           max_depth=8, max_features=0.33, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	-0.007 	-0.006 	0.497 	0.000 	0.000
[[367   2]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.99      0.99       372


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.992 	0.000 	0.000 	0.500 	0.000 	0.000
[[369   0]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      1.00       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.99      0.99       372


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.1, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.984 	-0.008 	-0.008 	0.496 	0.000 	0.000
[[366   3]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.98      0.98       372


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='entropy', max_depth=32,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=1.0, n_estimators=80, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	-0.007 	-0.006 	0.497 	0.000 	0.000
[[367   2]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.99      0.99       372


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.1, cache_size=200, class_weight='balanced', coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.984 	0.250 	0.242 	0.661 	0.574 	0.308
[[365   4]
 [  2   1]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       369
          1       0.20      0.33      0.25         3

avg / total       0.99      0.98      0.99       372


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.992 	0.000 	0.000 	0.500 	0.000 	0.000
[[369   0]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      1.00       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.99      0.99       372


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=1,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.992 	0.000 	0.000 	0.500 	0.000 	0.000
[[369   0]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      1.00       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.99      0.99       372


                estimator  min_score   mean_score  max_score    sd_score  \
0              GaussianNB  0.0371843    0.0371843  0.0371843           0   
1      LogisticRegression -0.0587553  -8.0879e-05  0.0817389   0.0270658   
7                     SVC -0.0297951   0.00369661   0.159079   0.0304307   
2           SGDClassifier -0.0773127   0.00359559   0.135158   0.0305625   
4  RandomForestClassifier -0.0146146 -0.000524539          0  0.00149696   
8        VotingClassifier   -0.01028  -0.00225685          0    0.001952   
9    KNeighborsClassifier -0.0121873  -0.00306196          0  0.00479149   
3    ExtraTreesClassifier -0.0419277  -0.00114584   0.136548   0.0147108   
6      AdaBoostClassifier -0.0206218  0.000729119   0.274825   0.0293356   
5           MLPClassifier -0.0142388  -0.00379086  0.0906952   0.0224353   

        acc       auc           conf_matrix     f1_c0      f1_c1       kappa  \
0   0.55914  0.777778  [[205, 164], [0, 3]]  0.714286  0.0352941   0.0197628   
1  0.672043  0.669377  [[248, 121], [1, 2]]  0.802589   0.031746    0.016257   
7  0.983871  0.661247    [[365, 4], [2, 1]]  0.991848       0.25    0.242363   
2  0.991935       0.5    [[369, 0], [3, 0]]  0.995951          0           0   
4  0.991935       0.5    [[369, 0], [3, 0]]  0.995951          0           0   
8  0.991935       0.5    [[369, 0], [3, 0]]  0.995951          0           0   
9  0.991935       0.5    [[369, 0], [3, 0]]  0.995951          0           0   
3  0.986559   0.49729    [[367, 2], [3, 0]]  0.993234          0 -0.00649351   
6  0.986559   0.49729    [[367, 2], [3, 0]]  0.993234          0 -0.00649351   
5  0.983871  0.495935    [[366, 3], [3, 0]]   0.99187          0 -0.00813008   

  model_score   prec_c0    prec_c1    rec_c0    rec_c1  
0   0.0999001         1  0.0179641  0.555556         1  
1   0.0644029  0.995984  0.0162602  0.672087  0.666667  
7    0.250482   0.99455        0.2   0.98916  0.333333  
2           0  0.991935          0         1         0  
4           0  0.991935          0         1         0  
8           0  0.991935          0         1         0  
9           0  0.991935          0         1         0  
3 -0.00662921  0.991892          0   0.99458         0  
6 -0.00662921  0.991892          0   0.99458         0  
5 -0.00813008   0.99187          0   0.99187         0  
Elapsed time 50.99 mins 

************************************************************

pre/post: 25/0  win/stride: 500/25  label:start 
filename: stm_sb_modified.csv 
datetime: 2017-05-05 14:36:35.074000 
pca_target: 0 	 poly degree: 2 	 kselect: 0 
Imbalance: SMOTE(k=None, k_neighbors=5, kind='regular', m=None, m_neighbors=10, n_jobs=1,
   out_step=0.5, random_state=None, ratio='auto', svm_estimator=None) 
Extended target (count):  31485 325
('Total : Processed (count): ', (1240L, 276L), 13)
Final feature (count):  (1240L, 276L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.594 	0.107 	0.023 	0.795 	0.769 	0.615
[[218 151]
 [  0   3]]
             precision    recall  f1-score   support

          0       1.00      0.59      0.74       369
          1       0.02      1.00      0.04         3

avg / total       0.99      0.59      0.74       372


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=10, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=5, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.922 	-0.025 	-0.015 	0.465 	0.000 	0.000
[[343  26]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.93      0.96       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.92      0.95       372


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.001, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.001, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='squared_hinge', n_iter=5, n_jobs=4,
       penalty='l1', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.863 	-0.035 	-0.015 	0.435 	0.000 	0.000
[[321  48]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.87      0.93       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.86      0.92       372


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight='balanced',
           criterion='gini', max_depth=None, max_features=0.75,
           max_leaf_nodes=None, min_impurity_split=1e-07,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=15, n_jobs=4,
           oob_score=False, random_state=None, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	-0.007 	-0.006 	0.497 	0.000 	0.000
[[367   2]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.99      0.99       372


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 500},
            criterion='gini', max_depth=32, max_features='auto',
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	-0.007 	-0.006 	0.497 	0.000 	0.000
[[367   2]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.99      0.99       372


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.1, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(500,), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.978 	-0.011 	-0.010 	0.493 	0.000 	0.000
[[364   5]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.98      0.98       372


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight='balanced', criterion='gini', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=1.0, n_estimators=80, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.976 	-0.012 	-0.011 	0.492 	0.000 	0.000
[[363   6]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.98      0.99       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.98      0.98       372


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=10, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.978 	0.209 	0.191 	0.659 	0.573 	0.307
[[363   6]
 [  2   1]]
             precision    recall  f1-score   support

          0       0.99      0.98      0.99       369
          1       0.14      0.33      0.20         3

avg / total       0.99      0.98      0.98       372


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=10.0, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', ...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.970 	-0.013 	-0.012 	0.489 	0.000 	0.000
[[361   8]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.98      0.98       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.97      0.98       372


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=1,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.944 	0.112 	0.074 	0.641 	0.562 	0.297
[[350  19]
 [  2   1]]
             precision    recall  f1-score   support

          0       0.99      0.95      0.97       369
          1       0.05      0.33      0.09         3

avg / total       0.99      0.94      0.96       372


                estimator min_score mean_score max_score    sd_score  \
0              GaussianNB  0.531887   0.531887  0.531887           0   
7                     SVC         0    0.75898  0.983796    0.279855   
9    KNeighborsClassifier  0.870311   0.908139   0.94831   0.0255398   
3    ExtraTreesClassifier  0.650372   0.926249  0.987263   0.0804315   
4  RandomForestClassifier  0.916017   0.971687  0.986107   0.0136562   
5           MLPClassifier  0.957848    0.97525  0.987296  0.00686104   
6      AdaBoostClassifier   0.87083   0.968579  0.991912   0.0178122   
8        VotingClassifier  0.886461   0.934596  0.970164   0.0197244   
1      LogisticRegression         0   0.694294  0.919438    0.156071   
2           SGDClassifier -0.142955   0.460451  0.820226    0.225787   

        acc       auc           conf_matrix     f1_c0      f1_c1       kappa  \
0  0.594086  0.795393  [[218, 151], [0, 3]]   0.74276  0.0382166   0.0227557   
7  0.978495  0.658537    [[363, 6], [2, 1]]  0.989101        0.2    0.190865   
9  0.943548  0.640921   [[350, 19], [2, 1]]  0.970874  0.0869565   0.0739687   
3  0.986559   0.49729    [[367, 2], [3, 0]]  0.993234          0 -0.00649351   
4  0.986559   0.49729    [[367, 2], [3, 0]]  0.993234          0 -0.00649351   
5  0.978495  0.493225    [[364, 5], [3, 0]]   0.98913          0  -0.0101833   
6  0.975806   0.49187    [[363, 6], [3, 0]]  0.987755          0  -0.0108696   
8   0.97043   0.48916    [[361, 8], [3, 0]]  0.984993          0  -0.0118694   
1  0.922043   0.46477   [[343, 26], [3, 0]]  0.959441          0  -0.0146727   
2  0.862903  0.434959   [[321, 48], [3, 0]]  0.926407          0  -0.0154143   

  model_score   prec_c0    prec_c1    rec_c0    rec_c1  
0    0.107279         1  0.0194805  0.590786         1  
7    0.208707  0.994521   0.142857   0.98374  0.333333  
9    0.111762  0.994318       0.05  0.948509  0.333333  
3 -0.00662921  0.991892          0   0.99458         0  
4 -0.00662921  0.991892          0   0.99458         0  
5  -0.0105245  0.991826          0   0.98645         0  
6  -0.0115447  0.991803          0   0.98374         0  
8  -0.0133672  0.991758          0   0.97832         0  
1   -0.024717  0.991329          0  0.929539         0  
2  -0.0347053  0.990741          0  0.869919         0  
Elapsed time 161.18 mins 

************************************************************

pre/post: 25/0  win/stride: 500/25  label:start 
filename: stm_sb_modified.csv 
datetime: 2017-05-05 17:17:46.131000 
pca_target: 0 	 poly degree: 2 	 kselect: 0 
Imbalance: ClusterCentroids(estimator=None, n_jobs=1, random_state=None, ratio='auto') 
Extended target (count):  31485 325
('Total : Processed (count): ', (1240L, 276L), 13)
Final feature (count):  (1240L, 276L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.567 	0.102 	0.020 	0.782 	0.751 	0.588
[[208 161]
 [  0   3]]
             precision    recall  f1-score   support

          0       1.00      0.56      0.72       369
          1       0.02      1.00      0.04         3

avg / total       0.99      0.57      0.72       372


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.001, class_weight={1: 50}, dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.516 	0.092 	0.017 	0.756 	0.716 	0.537
[[189 180]
 [  0   3]]
             precision    recall  f1-score   support

          0       1.00      0.51      0.68       369
          1       0.02      1.00      0.03         3

avg / total       0.99      0.52      0.67       372


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.0001, average=False, class_weight={1: 500}, epsilon=0.1,
       eta0=0.001, fit_intercept=True, l1_ratio=0.15,
       learning_rate='invscaling', loss='squared_hinge', n_iter=5,
       n_jobs=4, penalty='l2', power_t=0.5, random_state=None,
       shuffle=True, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.500 	0.089 	0.016 	0.748 	0.704 	0.521
[[183 186]
 [  0   3]]
             precision    recall  f1-score   support

          0       1.00      0.50      0.66       369
          1       0.02      1.00      0.03         3

avg / total       0.99      0.50      0.66       372


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=8, max_features=0.75, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.352 	0.065 	0.008 	0.673 	0.589 	0.370
[[128 241]
 [  0   3]]
             precision    recall  f1-score   support

          0       1.00      0.35      0.52       369
          1       0.01      1.00      0.02         3

avg / total       0.99      0.35      0.51       372


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features=0.75, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=30, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.379 	0.069 	0.010 	0.687 	0.612 	0.397
[[138 231]
 [  0   3]]
             precision    recall  f1-score   support

          0       1.00      0.37      0.54       369
          1       0.01      1.00      0.03         3

avg / total       0.99      0.38      0.54       372


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.1, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.597 	0.048 	0.010 	0.631 	0.630 	0.400
[[220 149]
 [  1   2]]
             precision    recall  f1-score   support

          0       1.00      0.60      0.75       369
          1       0.01      0.67      0.03         3

avg / total       0.99      0.60      0.74       372


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=2.0, n_estimators=80, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.395 	0.072 	0.010 	0.695 	0.625 	0.414
[[144 225]
 [  0   3]]
             precision    recall  f1-score   support

          0       1.00      0.39      0.56       369
          1       0.01      1.00      0.03         3

avg / total       0.99      0.40      0.56       372


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.1, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='linear',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.516 	0.092 	0.017 	0.756 	0.716 	0.537
[[189 180]
 [  0   3]]
             precision    recall  f1-score   support

          0       1.00      0.51      0.68       369
          1       0.02      1.00      0.03         3

avg / total       0.99      0.52      0.67       372


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 500}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Ran...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.425 	0.076 	0.012 	0.710 	0.648 	0.444
[[155 214]
 [  0   3]]
             precision    recall  f1-score   support

          0       1.00      0.42      0.59       369
          1       0.01      1.00      0.03         3

avg / total       0.99      0.42      0.59       372


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=4, p=1,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.594 	0.047 	0.010 	0.630 	0.629 	0.399
[[219 150]
 [  1   2]]
             precision    recall  f1-score   support

          0       1.00      0.59      0.74       369
          1       0.01      0.67      0.03         3

avg / total       0.99      0.59      0.74       372


                estimator min_score  mean_score max_score   sd_score  \
0              GaussianNB   0.63094     0.63094   0.63094          0   
1      LogisticRegression  -0.63094  -0.0945525   0.57735   0.232158   
7                     SVC      -0.4   0.0962537   0.51547   0.223804   
2           SGDClassifier  -0.66188   0.0363982   0.66188   0.220463   
8        VotingClassifier  -0.46188  -0.0436214       0.4   0.262942   
6      AdaBoostClassifier       0.4    0.702778   0.91547  0.0760172   
4  RandomForestClassifier   0.23094    0.668741   0.83094   0.148038   
3    ExtraTreesClassifier       0.2    0.796642         1   0.273645   
5           MLPClassifier  -0.34641  0.00356836   0.31547   0.201131   
9    KNeighborsClassifier  -0.46188   -0.192012   0.23094   0.200783   

        acc       auc           conf_matrix     f1_c0      f1_c1       kappa  \
0  0.567204  0.781843  [[208, 161], [0, 3]]  0.720971  0.0359281   0.0204122   
1  0.516129  0.756098  [[189, 180], [0, 3]]  0.677419  0.0322581   0.0166534   
7  0.516129  0.756098  [[189, 180], [0, 3]]  0.677419  0.0322581   0.0166534   
2       0.5  0.747967  [[183, 186], [0, 3]]  0.663043    0.03125    0.015621   
8  0.424731  0.710027  [[155, 214], [0, 3]]  0.591603  0.0272727   0.0115473   
6  0.395161  0.695122  [[144, 225], [0, 3]]  0.561404   0.025974   0.0102171   
4  0.379032  0.686992  [[138, 231], [0, 3]]  0.544379  0.0253165  0.00954357   
3  0.352151  0.673442  [[128, 241], [0, 3]]  0.515091  0.0242915   0.0084937   
5  0.596774  0.631436  [[220, 149], [1, 2]]  0.745763   0.025974   0.0103224   
9  0.594086  0.630081  [[219, 150], [1, 2]]  0.743633  0.0258065   0.0101501   

  model_score   prec_c0    prec_c1    rec_c0    rec_c1  
0    0.101545         1  0.0182927  0.563686         1  
1   0.0916332         1  0.0163934  0.512195         1  
7   0.0916332         1  0.0163934  0.512195         1  
2   0.0887242         1   0.015873  0.495935         1  
8    0.076205         1  0.0138249  0.420054         1  
6   0.0716574         1  0.0131579  0.390244         1  
4   0.0692435         1  0.0128205  0.373984         1  
3   0.0653067         1  0.0122951  0.346883         1  
5   0.0478778  0.995475   0.013245  0.596206  0.666667  
9   0.0473353  0.995455  0.0131579  0.593496  0.666667  
Elapsed time 22.39 mins 

************************************************************

pre/post: 25/0  win/stride: 500/25  label:start 
filename: stm_sb_modified.csv 
datetime: 2017-05-05 17:40:09.665000 
pca_target: 60 	 poly degree: 2 	 kselect: 60 
Imbalance: None 
Extended target (count):  31485 325
('Total : Processed (count): ', (1240L, 276L), 13)
Final feature (count):  (1240L, 276L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.812 	-0.042 	-0.016 	0.409 	0.000 	0.000
[[302  67]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.82      0.90       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.81      0.89       372


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=10, class_weight={1: 500}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.933 	-0.023 	-0.014 	0.470 	0.000 	0.000
[[347  22]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.94      0.97       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.93      0.96       372


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=1, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='constant', loss='modified_huber', n_iter=5, n_jobs=4,
       penalty='none', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.978 	-0.011 	-0.010 	0.493 	0.000 	0.000
[[364   5]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.98      0.98       372


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 500},
           criterion='entropy', max_depth=8, max_features=0.33,
           max_leaf_nodes=None, min_impurity_split=1e-07,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=4,
           oob_score=False, random_state=None, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.970 	0.171 	0.143 	0.654 	0.570 	0.304
[[360   9]
 [  2   1]]
             precision    recall  f1-score   support

          0       0.99      0.98      0.98       369
          1       0.10      0.33      0.15         3

avg / total       0.99      0.97      0.98       372


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=30, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.992 	0.000 	0.000 	0.500 	0.000 	0.000
[[369   0]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      1.00       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.99      0.99       372


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.5, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	-0.005 	-0.004 	0.499 	0.000 	0.000
[[368   1]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.99      0.99       372


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 50}, criterion='entropy',
            max_depth=16, max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=0.5, n_estimators=50, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.973 	-0.012 	-0.011 	0.491 	0.000 	0.000
[[362   7]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.98      0.99       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.97      0.98       372


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.1, cache_size=200, class_weight='balanced', coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	-0.005 	-0.004 	0.499 	0.000 	0.000
[[368   1]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.99      0.99       372


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 500}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Ran...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.984 	-0.008 	-0.008 	0.496 	0.000 	0.000
[[366   3]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.98      0.98       372


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=1,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.978 	-0.011 	-0.010 	0.493 	0.000 	0.000
[[364   5]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.98      0.98       372


                estimator   min_score   mean_score  max_score     sd_score  \
3    ExtraTreesClassifier  -0.0186283   0.00386753   0.151806    0.0231029   
4  RandomForestClassifier -0.00328699 -5.93483e-05          0  0.000330185   
5           MLPClassifier  -0.0156259    0.0249553  0.0935584     0.042895   
7                     SVC  -0.0216831    0.0339285   0.238182    0.0574131   
8        VotingClassifier -0.00657389     0.031545   0.278572    0.0688282   
2           SGDClassifier   -0.144466   0.00390468   0.129269    0.0331644   
9    KNeighborsClassifier -0.00328707    0.0213966  0.0923385    0.0382772   
6      AdaBoostClassifier  -0.0182745    0.0480755   0.238182    0.0672772   
1      LogisticRegression   -0.056257    0.0188287    0.12011     0.038363   
0              GaussianNB   0.0027498    0.0027498  0.0027498            0   

        acc       auc          conf_matrix     f1_c0     f1_c1       kappa  \
3   0.97043  0.654472   [[360, 9], [2, 1]]  0.984952  0.153846    0.143216   
4  0.991935       0.5   [[369, 0], [3, 0]]  0.995951         0           0   
5  0.989247  0.498645   [[368, 1], [3, 0]]  0.994595         0 -0.00404858   
7  0.989247  0.498645   [[368, 1], [3, 0]]  0.994595         0 -0.00404858   
8  0.983871  0.495935   [[366, 3], [3, 0]]   0.99187         0 -0.00813008   
2  0.978495  0.493225   [[364, 5], [3, 0]]   0.98913         0  -0.0101833   
9  0.978495  0.493225   [[364, 5], [3, 0]]   0.98913         0  -0.0101833   
6  0.973118  0.490515   [[362, 7], [3, 0]]  0.986376         0  -0.0114192   
1  0.932796   0.47019  [[347, 22], [3, 0]]  0.965229         0  -0.0143979   
0  0.811828  0.409214  [[302, 67], [3, 0]]  0.896142         0  -0.0156799   

  model_score   prec_c0 prec_c1    rec_c0    rec_c1  
3    0.170843  0.994475     0.1   0.97561  0.333333  
4           0  0.991935       0         1         0  
5 -0.00468124  0.991914       0   0.99729         0  
7 -0.00468124  0.991914       0   0.99729         0  
8 -0.00813008   0.99187       0   0.99187         0  
2  -0.0105245  0.991826       0   0.98645         0  
9  -0.0105245  0.991826       0   0.98645         0  
6  -0.0124868  0.991781       0   0.98103         0  
1  -0.0226061  0.991429       0  0.940379         0  
0  -0.0422605  0.990164       0  0.818428         0  
Elapsed time 31.40 mins 

************************************************************

pre/post: 25/0  win/stride: 500/25  label:start 
filename: stm_sb_modified.csv 
datetime: 2017-05-05 18:11:33.712000 
pca_target: 60 	 poly degree: 2 	 kselect: 60 
Imbalance: SMOTE(k=None, k_neighbors=5, kind='regular', m=None, m_neighbors=10, n_jobs=1,
   out_step=0.5, random_state=None, ratio='auto', svm_estimator=None) 
Extended target (count):  31485 325
('Total : Processed (count): ', (1240L, 276L), 13)
Final feature (count):  (1240L, 276L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.976 	-0.012 	-0.011 	0.492 	0.000 	0.000
[[363   6]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.98      0.99       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.98      0.98       372


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=10, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=5, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.944 	-0.020 	-0.014 	0.476 	0.000 	0.000
[[351  18]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.95      0.97       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.94      0.96       372


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.001, average=False, class_weight='balanced',
       epsilon=0.1, eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='invscaling', loss='perceptron', n_iter=5, n_jobs=4,
       penalty='l1', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.960 	-0.016 	-0.013 	0.484 	0.000 	0.000
[[357  12]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.97      0.98       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.96      0.97       372


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=8, max_features=0.75, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=30, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	-0.005 	-0.004 	0.499 	0.000 	0.000
[[368   1]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.99      0.99       372


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.992 	0.000 	0.000 	0.500 	0.000 	0.000
[[369   0]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      1.00       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.99      0.99       372


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	-0.005 	-0.004 	0.499 	0.000 	0.000
[[368   1]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.99      0.99       372


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=0.5, n_estimators=50, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.992 	0.000 	0.000 	0.500 	0.000 	0.000
[[369   0]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      1.00       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.99      0.99       372


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=1, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	-0.005 	-0.004 	0.499 	0.000 	0.000
[[368   1]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.99      0.99       372


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=10.0, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', ...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.981 	-0.009 	-0.009 	0.495 	0.000 	0.000
[[365   4]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.98      0.98       372


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=3,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.978 	-0.011 	-0.010 	0.493 	0.000 	0.000
[[364   5]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.98      0.98       372


                estimator  min_score mean_score max_score    sd_score  \
4  RandomForestClassifier   0.995358    0.99893         1  0.00129581   
6      AdaBoostClassifier   0.871799   0.991908         1  0.00856068   
3    ExtraTreesClassifier    0.87218   0.994605         1   0.0189996   
5           MLPClassifier   0.958965   0.976415  0.994203   0.0109872   
7                     SVC          0    0.84412  0.998838    0.282696   
8        VotingClassifier   0.965669   0.981359  0.995358  0.00631082   
9    KNeighborsClassifier   0.909893   0.957636  0.983836     0.02018   
0              GaussianNB   0.990743   0.990743  0.990743           0   
2           SGDClassifier -0.0508484   0.607846  0.961184    0.293053   
1      LogisticRegression  0.0608254   0.815214  0.953352    0.167112   

        acc       auc          conf_matrix     f1_c0 f1_c1       kappa  \
4  0.991935       0.5   [[369, 0], [3, 0]]  0.995951     0           0   
6  0.991935       0.5   [[369, 0], [3, 0]]  0.995951     0           0   
3  0.989247  0.498645   [[368, 1], [3, 0]]  0.994595     0 -0.00404858   
5  0.989247  0.498645   [[368, 1], [3, 0]]  0.994595     0 -0.00404858   
7  0.989247  0.498645   [[368, 1], [3, 0]]  0.994595     0 -0.00404858   
8  0.981183   0.49458   [[365, 4], [3, 0]]  0.990502     0 -0.00930233   
9  0.978495  0.493225   [[364, 5], [3, 0]]   0.98913     0  -0.0101833   
0  0.975806   0.49187   [[363, 6], [3, 0]]  0.987755     0  -0.0108696   
2  0.959677   0.48374  [[357, 12], [3, 0]]  0.979424     0  -0.0130719   
1  0.943548   0.47561  [[351, 18], [3, 0]]  0.970954     0  -0.0140187   

  model_score   prec_c0 prec_c1   rec_c0 rec_c1  
4           0  0.991935       0        1      0  
6           0  0.991935       0        1      0  
3 -0.00468124  0.991914       0  0.99729      0  
5 -0.00468124  0.991914       0  0.99729      0  
7 -0.00468124  0.991914       0  0.99729      0  
8 -0.00940056  0.991848       0  0.98916      0  
9  -0.0105245  0.991826       0  0.98645      0  
0  -0.0115447  0.991803       0  0.98374      0  
2  -0.0164622  0.991667       0  0.96748      0  
1  -0.0203321  0.991525       0  0.95122      0  
Elapsed time 52.76 mins 

************************************************************

pre/post: 25/0  win/stride: 500/25  label:start 
filename: stm_sb_modified.csv 
datetime: 2017-05-05 19:04:19.472000 
pca_target: 60 	 poly degree: 2 	 kselect: 60 
Imbalance: ClusterCentroids(estimator=None, n_jobs=1, random_state=None, ratio='auto') 
Extended target (count):  31485 325
('Total : Processed (count): ', (1240L, 276L), 13)
Final feature (count):  (1240L, 276L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.992 	0.000 	0.000 	0.500 	0.000 	0.000
[[369   0]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      1.00       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.99      0.99       372


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.001, class_weight={1: 500}, dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.511 	-0.028 	-0.005 	0.423 	0.413 	0.168
[[189 180]
 [  2   1]]
             precision    recall  f1-score   support

          0       0.99      0.51      0.68       369
          1       0.01      0.33      0.01         3

avg / total       0.98      0.51      0.67       372


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.001, average=False, class_weight={1: 50}, epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='invscaling', loss='squared_hinge', n_iter=5,
       n_jobs=4, penalty='none', power_t=0.5, random_state=None,
       shuffle=True, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.465 	-0.036 	-0.006 	0.400 	0.394 	0.153
[[172 197]
 [  2   1]]
             precision    recall  f1-score   support

          0       0.99      0.47      0.63       369
          1       0.01      0.33      0.01         3

avg / total       0.98      0.47      0.63       372


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=8, max_features=0.75, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.387 	0.070 	0.010 	0.691 	0.618 	0.406
[[141 228]
 [  0   3]]
             precision    recall  f1-score   support

          0       1.00      0.38      0.55       369
          1       0.01      1.00      0.03         3

avg / total       0.99      0.39      0.55       372


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 15}, criterion='gini',
            max_depth=16, max_features=0.75, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.358 	0.066 	0.009 	0.676 	0.594 	0.375
[[130 239]
 [  0   3]]
             precision    recall  f1-score   support

          0       1.00      0.35      0.52       369
          1       0.01      1.00      0.02         3

avg / total       0.99      0.36      0.52       372


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.01, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.497 	-0.089 	-0.016 	0.251 	0.000 	0.000
[[185 184]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.98      0.50      0.66       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.50      0.66       372


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=1.0, n_estimators=50, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.395 	0.072 	0.010 	0.695 	0.625 	0.414
[[144 225]
 [  0   3]]
             precision    recall  f1-score   support

          0       1.00      0.39      0.56       369
          1       0.01      1.00      0.03         3

avg / total       0.99      0.40      0.56       372


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.1, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='linear',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.470 	-0.035 	-0.006 	0.402 	0.396 	0.155
[[174 195]
 [  2   1]]
             precision    recall  f1-score   support

          0       0.99      0.47      0.64       369
          1       0.01      0.33      0.01         3

avg / total       0.98      0.47      0.63       372


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.454 	-0.038 	-0.006 	0.394 	0.390 	0.150
[[168 201]
 [  2   1]]
             precision    recall  f1-score   support

          0       0.99      0.46      0.62       369
          1       0.00      0.33      0.01         3

avg / total       0.98      0.45      0.62       372


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=4,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.473 	-0.034 	-0.006 	0.404 	0.398 	0.156
[[175 194]
 [  2   1]]
             precision    recall  f1-score   support

          0       0.99      0.47      0.64       369
          1       0.01      0.33      0.01         3

avg / total       0.98      0.47      0.64       372


                estimator min_score mean_score max_score   sd_score       acc  \
6      AdaBoostClassifier   0.23094   0.556702   0.83094   0.126905  0.395161   
3    ExtraTreesClassifier       0.4   0.715346   0.83094  0.0951072  0.387097   
4  RandomForestClassifier       0.4   0.787349   0.91547  0.0827174  0.357527   
0              GaussianNB   0.91547    0.91547   0.91547          0  0.991935   
1      LogisticRegression  -0.11547   0.251042   0.54641   0.175263  0.510753   
9    KNeighborsClassifier  -0.46188 -0.0272792   0.43094   0.248127  0.473118   
7                     SVC  -0.34641   0.105207   0.31547   0.194153   0.47043   
2           SGDClassifier  -0.54641   0.220927   0.74641   0.204255  0.465054   
8        VotingClassifier   0.31547     0.5483   0.74641  0.0927222  0.454301   
5           MLPClassifier      -0.2   0.212247       0.4   0.131083  0.497312   

        auc           conf_matrix     f1_c0       f1_c1       kappa  \
6  0.695122  [[144, 225], [0, 3]]  0.561404    0.025974   0.0102171   
3  0.691057  [[141, 228], [0, 3]]  0.552941    0.025641  0.00987602   
4  0.676152  [[130, 239], [0, 3]]  0.521042   0.0244898  0.00869682   
0       0.5    [[369, 0], [3, 0]]  0.995951           0           0   
1  0.422764  [[189, 180], [2, 1]]     0.675   0.0108696 -0.00507705   
9  0.403794  [[175, 194], [2, 1]]  0.641026    0.010101   -0.005877   
7  0.402439  [[174, 195], [2, 1]]  0.638532   0.0100503 -0.00592983   
2  0.399729  [[172, 197], [2, 1]]  0.633517  0.00995025 -0.00603392   
8  0.394309  [[168, 201], [2, 1]]  0.623377   0.0097561 -0.00623601   
5  0.250678  [[185, 184], [3, 0]]  0.664273           0  -0.0161262   

  model_score   prec_c0     prec_c1    rec_c0    rec_c1  
6   0.0716574         1   0.0131579  0.390244         1  
3   0.0704451         1    0.012987  0.382114         1  
4   0.0660863         1   0.0123967  0.352304         1  
0           0  0.991935           0         1         0  
1  -0.0276418  0.989529  0.00552486  0.512195  0.333333  
9  -0.0344589  0.988701  0.00512821  0.474255  0.333333  
7  -0.0349539  0.988636  0.00510204  0.471545  0.333333  
2  -0.0359478  0.988506  0.00505051  0.466125  0.333333  
8  -0.0379526  0.988235   0.0049505  0.455285  0.333333  
5  -0.0892026  0.984043           0  0.501355         0  
Elapsed time 14.88 mins 

************************************************************

pre/post: 25/0  win/stride: 500/25  label:start 
filename: stm_sb_modified.csv 
datetime: 2017-05-05 19:19:12.539000 
pca_target: 60 	 poly degree: 2 	 kselect: 40 
Imbalance: None 
Extended target (count):  31485 325
('Total : Processed (count): ', (1240L, 276L), 13)
Final feature (count):  (1240L, 276L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.852 	-0.036 	-0.015 	0.430 	0.000 	0.000
[[317  52]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.86      0.92       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.85      0.91       372


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=10, class_weight={1: 500}, dual=False,
          fit_intercept=True, intercept_scaling=5, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='sag', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.726 	0.013 	0.004 	0.531 	0.493 	0.233
[[269 100]
 [  2   1]]
             precision    recall  f1-score   support

          0       0.99      0.73      0.84       369
          1       0.01      0.33      0.02         3

avg / total       0.98      0.73      0.83       372


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.0001, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='invscaling', loss='squared_hinge', n_iter=5,
       n_jobs=4, penalty='elasticnet', power_t=0.5, random_state=None,
       shuffle=True, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.992 	0.000 	0.000 	0.500 	0.000 	0.000
[[369   0]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      1.00       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.99      0.99       372


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 500},
           criterion='entropy', max_depth=8, max_features='auto',
           max_leaf_nodes=None, min_impurity_split=1e-07,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=4,
           oob_score=False, random_state=None, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.981 	-0.009 	-0.009 	0.495 	0.000 	0.000
[[365   4]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.98      0.98       372


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=30, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.992 	0.000 	0.000 	0.500 	0.000 	0.000
[[369   0]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      1.00       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.99      0.99       372


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.1, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(500,), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	-0.007 	-0.006 	0.497 	0.000 	0.000
[[367   2]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.99      0.99       372


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight='balanced', criterion='gini',
            max_depth=16, max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=0.5, n_estimators=15, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	-0.005 	-0.004 	0.499 	0.000 	0.000
[[368   1]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.99      0.99       372


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=10, cache_size=200, class_weight='balanced', coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.981 	-0.009 	-0.009 	0.495 	0.000 	0.000
[[365   4]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.98      0.98       372


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=1.0, class_weight={1: 500}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Ran...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	-0.007 	-0.006 	0.497 	0.000 	0.000
[[367   2]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.99      0.99       372


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=4,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.981 	-0.009 	-0.009 	0.495 	0.000 	0.000
[[365   4]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.98      0.98       372


                estimator   min_score   mean_score  max_score     sd_score  \
1      LogisticRegression  -0.0553689    0.0179076  0.0911837    0.0274634   
2           SGDClassifier   -0.141337   0.00433701   0.139006    0.0336802   
4  RandomForestClassifier -0.00164354 -5.47834e-05          0  0.000295017   
6      AdaBoostClassifier  -0.0186635     0.037445     0.2363    0.0607518   
5           MLPClassifier  -0.0155442   -0.0024643  0.0919149    0.0257598   
8        VotingClassifier -0.00821743   0.00588486   0.137235     0.031035   
3    ExtraTreesClassifier  -0.0211246  0.000617625   0.137362    0.0132707   
7                     SVC   -0.020828    0.0183858   0.215417    0.0454337   
9    KNeighborsClassifier -0.00164354    0.0334893   0.134904    0.0583233   
0              GaussianNB  -0.0101763   -0.0101763 -0.0101763            0   

        acc       auc           conf_matrix     f1_c0      f1_c1       kappa  \
1  0.725806  0.531165  [[269, 100], [2, 1]]  0.840625  0.0192308  0.00362376   
2  0.991935       0.5    [[369, 0], [3, 0]]  0.995951          0           0   
4  0.991935       0.5    [[369, 0], [3, 0]]  0.995951          0           0   
6  0.989247  0.498645    [[368, 1], [3, 0]]  0.994595          0 -0.00404858   
5  0.986559   0.49729    [[367, 2], [3, 0]]  0.993234          0 -0.00649351   
8  0.986559   0.49729    [[367, 2], [3, 0]]  0.993234          0 -0.00649351   
3  0.981183   0.49458    [[365, 4], [3, 0]]  0.990502          0 -0.00930233   
7  0.981183   0.49458    [[365, 4], [3, 0]]  0.990502          0 -0.00930233   
9  0.981183   0.49458    [[365, 4], [3, 0]]  0.990502          0 -0.00930233   
0  0.852151  0.429539   [[317, 52], [3, 0]]  0.920174          0  -0.0154854   

  model_score   prec_c0     prec_c1    rec_c0    rec_c1  
1   0.0125352   0.99262  0.00990099  0.728997  0.333333  
2           0  0.991935           0         1         0  
4           0  0.991935           0         1         0  
6 -0.00468124  0.991914           0   0.99729         0  
5 -0.00662921  0.991892           0   0.99458         0  
8 -0.00662921  0.991892           0   0.99458         0  
3 -0.00940056  0.991848           0   0.98916         0  
7 -0.00940056  0.991848           0   0.98916         0  
9 -0.00940056  0.991848           0   0.98916         0  
0  -0.0363475  0.990625           0  0.859079         0  
Elapsed time 29.56 mins 

************************************************************

pre/post: 25/0  win/stride: 500/25  label:start 
filename: stm_sb_modified.csv 
datetime: 2017-05-05 19:48:46.342000 
pca_target: 60 	 poly degree: 2 	 kselect: 40 
Imbalance: SMOTE(k=None, k_neighbors=5, kind='regular', m=None, m_neighbors=10, n_jobs=1,
   out_step=0.5, random_state=None, ratio='auto', svm_estimator=None) 
Extended target (count):  31485 325
('Total : Processed (count): ', (1240L, 276L), 13)
Final feature (count):  (1240L, 276L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.933 	-0.023 	-0.014 	0.470 	0.000 	0.000
[[347  22]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.94      0.97       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.93      0.96       372


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=10, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.941 	-0.021 	-0.014 	0.474 	0.000 	0.000
[[350  19]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.95      0.97       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.94      0.96       372


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.1, average=False, class_weight='balanced', epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='invscaling', loss='perceptron', n_iter=5, n_jobs=4,
       penalty='l2', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.946 	-0.020 	-0.014 	0.477 	0.000 	0.000
[[352  17]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.95      0.97       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.95      0.96       372


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=16, max_features='auto', max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.992 	0.000 	0.000 	0.500 	0.000 	0.000
[[369   0]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      1.00       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.99      0.99       372


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=30, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.992 	0.000 	0.000 	0.500 	0.000 	0.000
[[369   0]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      1.00       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.99      0.99       372


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.01, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	-0.007 	-0.006 	0.497 	0.000 	0.000
[[367   2]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.99      0.99       372


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=0.5, n_estimators=80, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.992 	0.000 	0.000 	0.500 	0.000 	0.000
[[369   0]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      1.00       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.99      0.99       372


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.1, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.992 	0.000 	0.000 	0.500 	0.000 	0.000
[[369   0]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      1.00       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.99      0.99       372


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=1.0, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', R...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.984 	-0.008 	-0.008 	0.496 	0.000 	0.000
[[366   3]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.98      0.98       372


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=4,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.981 	-0.009 	-0.009 	0.495 	0.000 	0.000
[[365   4]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.98      0.98       372


                estimator  min_score mean_score max_score     sd_score  \
3    ExtraTreesClassifier   0.891166   0.996189         1    0.0136978   
4  RandomForestClassifier   0.995345   0.999184         1  0.000957718   
6      AdaBoostClassifier    0.91881   0.990117         1   0.00849526   
7                     SVC          0   0.846402  0.998838     0.279773   
5           MLPClassifier   0.953381   0.976974  0.995371    0.0116759   
8        VotingClassifier   0.967898   0.984097  0.993054   0.00582445   
9    KNeighborsClassifier   0.917283   0.960637  0.987283    0.0206997   
2           SGDClassifier -0.0646419   0.620378  0.968908     0.295191   
1      LogisticRegression   0.123706    0.82182  0.954476     0.165686   
0              GaussianNB   0.946676   0.946676  0.946676            0   

        acc       auc          conf_matrix     f1_c0 f1_c1       kappa  \
3  0.991935       0.5   [[369, 0], [3, 0]]  0.995951     0           0   
4  0.991935       0.5   [[369, 0], [3, 0]]  0.995951     0           0   
6  0.991935       0.5   [[369, 0], [3, 0]]  0.995951     0           0   
7  0.991935       0.5   [[369, 0], [3, 0]]  0.995951     0           0   
5  0.986559   0.49729   [[367, 2], [3, 0]]  0.993234     0 -0.00649351   
8  0.983871  0.495935   [[366, 3], [3, 0]]   0.99187     0 -0.00813008   
9  0.981183   0.49458   [[365, 4], [3, 0]]  0.990502     0 -0.00930233   
2  0.946237  0.476965  [[352, 17], [3, 0]]  0.972376     0  -0.0139002   
1   0.94086  0.474255  [[350, 19], [3, 0]]  0.969529     0  -0.0141264   
0  0.932796   0.47019  [[347, 22], [3, 0]]  0.965229     0  -0.0143979   

  model_score   prec_c0 prec_c1    rec_c0 rec_c1  
3           0  0.991935       0         1      0  
4           0  0.991935       0         1      0  
6           0  0.991935       0         1      0  
7           0  0.991935       0         1      0  
5 -0.00662921  0.991892       0   0.99458      0  
8 -0.00813008   0.99187       0   0.99187      0  
9 -0.00940056  0.991848       0   0.98916      0  
2  -0.0197314  0.991549       0   0.95393      0  
1  -0.0209188  0.991501       0  0.948509      0  
0  -0.0226061  0.991429       0  0.940379      0  
Elapsed time 46.37 mins 

************************************************************

pre/post: 25/0  win/stride: 500/25  label:start 
filename: stm_sb_modified.csv 
datetime: 2017-05-05 20:35:08.823000 
pca_target: 60 	 poly degree: 2 	 kselect: 40 
Imbalance: ClusterCentroids(estimator=None, n_jobs=1, random_state=None, ratio='auto') 
Extended target (count):  31485 325
('Total : Processed (count): ', (1240L, 276L), 13)
Final feature (count):  (1240L, 276L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.992 	0.000 	0.000 	0.500 	0.000 	0.000
[[369   0]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      1.00       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.99      0.99       372


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=10, class_weight={1: 500}, dual=False,
          fit_intercept=True, intercept_scaling=0.01, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='sag', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.457 	0.081 	0.013 	0.726 	0.673 	0.477
[[167 202]
 [  0   3]]
             precision    recall  f1-score   support

          0       1.00      0.45      0.62       369
          1       0.01      1.00      0.03         3

avg / total       0.99      0.46      0.62       372


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.5, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='constant', loss='perceptron', n_iter=5, n_jobs=4,
       penalty='l2', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.530 	-0.024 	-0.005 	0.432 	0.421 	0.174
[[196 173]
 [  2   1]]
             precision    recall  f1-score   support

          0       0.99      0.53      0.69       369
          1       0.01      0.33      0.01         3

avg / total       0.98      0.53      0.69       372


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=32, max_features=0.75, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=50, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.392 	0.071 	0.010 	0.694 	0.623 	0.411
[[143 226]
 [  0   3]]
             precision    recall  f1-score   support

          0       1.00      0.39      0.56       369
          1       0.01      1.00      0.03         3

avg / total       0.99      0.39      0.55       372


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=None, max_features=0.75, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.360 	0.066 	0.009 	0.678 	0.596 	0.378
[[131 238]
 [  0   3]]
             precision    recall  f1-score   support

          0       1.00      0.36      0.52       369
          1       0.01      1.00      0.02         3

avg / total       0.99      0.36      0.52       372


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.548 	0.038 	0.008 	0.607 	0.604 	0.369
[[202 167]
 [  1   2]]
             precision    recall  f1-score   support

          0       1.00      0.55      0.71       369
          1       0.01      0.67      0.02         3

avg / total       0.99      0.55      0.70       372


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 50}, criterion='entropy', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=2.0, n_estimators=50, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.508 	0.031 	0.006 	0.587 	0.581 	0.343
[[187 182]
 [  1   2]]
             precision    recall  f1-score   support

          0       0.99      0.51      0.67       369
          1       0.01      0.67      0.02         3

avg / total       0.99      0.51      0.67       372


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.01, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='linear',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.468 	-0.035 	-0.006 	0.401 	0.395 	0.154
[[173 196]
 [  2   1]]
             precision    recall  f1-score   support

          0       0.99      0.47      0.64       369
          1       0.01      0.33      0.01         3

avg / total       0.98      0.47      0.63       372


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...wski',
           metric_params=None, n_jobs=4, n_neighbors=4, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.505 	0.090 	0.016 	0.751 	0.708 	0.526
[[185 184]
 [  0   3]]
             precision    recall  f1-score   support

          0       1.00      0.50      0.67       369
          1       0.02      1.00      0.03         3

avg / total       0.99      0.51      0.66       372


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=4, p=1,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.495 	0.029 	0.005 	0.580 	0.573 	0.335
[[182 187]
 [  1   2]]
             precision    recall  f1-score   support

          0       0.99      0.49      0.66       369
          1       0.01      0.67      0.02         3

avg / total       0.99      0.49      0.65       372


                estimator  min_score mean_score max_score   sd_score  \
8        VotingClassifier    0.14641   0.464668   0.83094   0.144104   
1      LogisticRegression -0.0845299    0.27501   0.66188   0.183423   
3    ExtraTreesClassifier    0.34641   0.639245   0.83094  0.0922917   
4  RandomForestClassifier    0.43094   0.784956   0.91547  0.0720184   
5           MLPClassifier   -0.11547   0.108114   0.51547   0.106298   
6      AdaBoostClassifier    0.23094   0.619216   0.91547    0.12318   
9    KNeighborsClassifier   -0.34641  0.0745281   0.54641    0.21781   
0              GaussianNB    0.91547    0.91547   0.91547          0   
2           SGDClassifier   -0.43094   0.242513   0.74641   0.193021   
7                     SVC       -0.4  0.0164369       0.2   0.105913   

        acc       auc           conf_matrix     f1_c0      f1_c1       kappa  \
8  0.505376  0.750678  [[185, 184], [0, 3]]   0.66787  0.0315789   0.0159579   
1  0.456989  0.726287  [[167, 202], [0, 3]]  0.623134  0.0288462   0.0131589   
3  0.392473  0.693767  [[143, 226], [0, 3]]  0.558594  0.0258621   0.0101024   
4  0.360215  0.677507  [[131, 238], [0, 3]]     0.524  0.0245902  0.00879962   
5  0.548387  0.607046  [[202, 167], [1, 2]]  0.706294  0.0232558  0.00752739   
6  0.508065  0.586721  [[187, 182], [1, 2]]  0.671454  0.0213904  0.00560911   
9  0.494624  0.579946  [[182, 187], [1, 2]]   0.65942  0.0208333  0.00503628   
0  0.991935       0.5    [[369, 0], [3, 0]]  0.995951          0           0   
2   0.52957  0.432249  [[196, 173], [2, 1]]  0.691358  0.0112994 -0.00462963   
7  0.467742  0.401084  [[173, 196], [2, 1]]  0.636029       0.01 -0.00598214   

  model_score   prec_c0     prec_c1    rec_c0    rec_c1  
8   0.0896835         1   0.0160428  0.501355         1  
1   0.0813821         1   0.0146341  0.452575         1  
3   0.0712521         1   0.0131004  0.387534         1  
4   0.0664775         1   0.0124481  0.355014         1  
5   0.0384577  0.995074   0.0118343  0.547425  0.666667  
6    0.031027  0.994681   0.0108696  0.506775  0.666667  
9   0.0286051  0.994536    0.010582  0.493225  0.666667  
0           0  0.991935           0         1         0  
2   -0.024289  0.989899  0.00574713  0.531165  0.333333  
7  -0.0354502  0.988571  0.00507614  0.468835  0.333333  
Elapsed time 14.48 mins 

************************************************************

pre/post: 25/0  win/stride: 500/25  label:start 
filename: stm_sb_modified.csv 
datetime: 2017-05-05 20:49:37.890000 
pca_target: 60 	 poly degree: 2 	 kselect: 0 
Imbalance: None 
Extended target (count):  31485 325
('Total : Processed (count): ', (1240L, 276L), 13)
Final feature (count):  (1240L, 276L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.954 	-0.018 	-0.013 	0.481 	0.000 	0.000
[[355  14]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.96      0.98       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.95      0.97       372


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=10, class_weight={1: 50}, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=4,
          penalty='l2', random_state=None, solver='sag', tol=0.0001,
          verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.917 	-0.026 	-0.015 	0.462 	0.000 	0.000
[[341  28]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.92      0.96       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.92      0.95       372


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.5, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='constant', loss='squared_hinge', n_iter=5, n_jobs=4,
       penalty='l2', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.992 	0.000 	0.000 	0.500 	0.000 	0.000
[[369   0]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      1.00       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.99      0.99       372


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 500}, criterion='gini',
           max_depth=16, max_features=0.75, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.978 	-0.011 	-0.010 	0.493 	0.000 	0.000
[[364   5]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.98      0.98       372


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.992 	0.000 	0.000 	0.500 	0.000 	0.000
[[369   0]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      1.00       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.99      0.99       372


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.1, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.984 	-0.008 	-0.008 	0.496 	0.000 	0.000
[[366   3]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.98      0.98       372


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight='balanced', criterion='gini',
            max_depth=16, max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=0.5, n_estimators=15, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.981 	-0.009 	-0.009 	0.495 	0.000 	0.000
[[365   4]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.98      0.98       372


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.5, cache_size=200, class_weight='balanced', coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.984 	-0.008 	-0.008 	0.496 	0.000 	0.000
[[366   3]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.98      0.98       372


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=10.0, class_weight={1: 500}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Ra...wski',
           metric_params=None, n_jobs=4, n_neighbors=4, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	-0.005 	-0.004 	0.499 	0.000 	0.000
[[368   1]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.99      0.99       372


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=1,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.973 	-0.012 	-0.011 	0.491 	0.000 	0.000
[[362   7]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.98      0.99       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.97      0.98       372


                estimator   min_score   mean_score  max_score     sd_score  \
2           SGDClassifier  -0.0970038   0.00111424     0.1608     0.026553   
4  RandomForestClassifier -0.00328707 -1.36959e-05          0  0.000193206   
8        VotingClassifier -0.00729067    0.0294891   0.280216    0.0658035   
5           MLPClassifier  -0.0142388    0.0496509   0.173995    0.0478455   
7                     SVC  -0.0224116    0.0460228   0.280216    0.0652301   
6      AdaBoostClassifier  -0.0171668    0.0409601   0.275021    0.0611781   
3    ExtraTreesClassifier -0.00630557   0.00793702   0.280216    0.0357168   
9    KNeighborsClassifier -0.00164345    0.0584214   0.277352     0.104342   
0              GaussianNB  -0.0199495   -0.0199495 -0.0199495            0   
1      LogisticRegression  -0.0494442    0.0240858  0.0789214    0.0348767   

        acc       auc          conf_matrix     f1_c0 f1_c1       kappa  \
2  0.991935       0.5   [[369, 0], [3, 0]]  0.995951     0           0   
4  0.991935       0.5   [[369, 0], [3, 0]]  0.995951     0           0   
8  0.989247  0.498645   [[368, 1], [3, 0]]  0.994595     0 -0.00404858   
5  0.983871  0.495935   [[366, 3], [3, 0]]   0.99187     0 -0.00813008   
7  0.983871  0.495935   [[366, 3], [3, 0]]   0.99187     0 -0.00813008   
6  0.981183   0.49458   [[365, 4], [3, 0]]  0.990502     0 -0.00930233   
3  0.978495  0.493225   [[364, 5], [3, 0]]   0.98913     0  -0.0101833   
9  0.973118  0.490515   [[362, 7], [3, 0]]  0.986376     0  -0.0114192   
0  0.954301   0.48103  [[355, 14], [3, 0]]  0.976616     0  -0.0134615   
1  0.916667   0.46206  [[341, 28], [3, 0]]  0.956522     0  -0.0147835   

  model_score   prec_c0 prec_c1    rec_c0 rec_c1  
2           0  0.991935       0         1      0  
4           0  0.991935       0         1      0  
8 -0.00468124  0.991914       0   0.99729      0  
5 -0.00813008   0.99187       0   0.99187      0  
7 -0.00813008   0.99187       0   0.99187      0  
6 -0.00940056  0.991848       0   0.98916      0  
3  -0.0105245  0.991826       0   0.98645      0  
9  -0.0124868  0.991781       0   0.98103      0  
0  -0.0178308   0.99162       0   0.96206      0  
1  -0.0257245  0.991279       0  0.924119      0  
Elapsed time 23.45 mins 

************************************************************

pre/post: 25/0  win/stride: 500/25  label:start 
filename: stm_sb_modified.csv 
datetime: 2017-05-05 21:13:05.128000 
pca_target: 60 	 poly degree: 2 	 kselect: 0 
Imbalance: SMOTE(k=None, k_neighbors=5, kind='regular', m=None, m_neighbors=10, n_jobs=1,
   out_step=0.5, random_state=None, ratio='auto', svm_estimator=None) 
Extended target (count):  31485 325
('Total : Processed (count): ', (1240L, 276L), 13)
Final feature (count):  (1240L, 276L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.968 	-0.014 	-0.012 	0.488 	0.000 	0.000
[[360   9]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.98      0.98       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.97      0.98       372


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=10, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.954 	-0.018 	-0.013 	0.481 	0.000 	0.000
[[355  14]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.96      0.98       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.95      0.97       372


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.0001, average=False, class_weight='balanced',
       epsilon=0.1, eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='modified_huber', n_iter=5, n_jobs=4,
       penalty='none', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.965 	-0.015 	-0.013 	0.486 	0.000 	0.000
[[359  10]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.97      0.98       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.97      0.97       372


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=16, max_features='auto', max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=30, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	-0.005 	-0.004 	0.499 	0.000 	0.000
[[368   1]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.99      0.99       372


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=30, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.992 	0.000 	0.000 	0.500 	0.000 	0.000
[[369   0]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      1.00       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.99      0.99       372


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.01, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.981 	-0.009 	-0.009 	0.495 	0.000 	0.000
[[365   4]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.98      0.98       372


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=0.5, n_estimators=15, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.992 	0.000 	0.000 	0.500 	0.000 	0.000
[[369   0]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      1.00       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.99      0.99       372


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.1, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	-0.005 	-0.004 	0.499 	0.000 	0.000
[[368   1]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.99      0.99       372


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=10.0, class_weight={1: 500}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Ra...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.978 	-0.011 	-0.010 	0.493 	0.000 	0.000
[[364   5]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.98      0.98       372


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=1,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.981 	-0.009 	-0.009 	0.495 	0.000 	0.000
[[365   4]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.98      0.98       372


                estimator min_score mean_score max_score    sd_score  \
4  RandomForestClassifier  0.991872   0.998572         1  0.00178828   
6      AdaBoostClassifier  0.936513     0.9897         1  0.00943762   
3    ExtraTreesClassifier  0.771682   0.987813         1   0.0367926   
7                     SVC         0   0.848812         1     0.27707   
5           MLPClassifier  0.956723   0.978542  0.995365   0.0117923   
9    KNeighborsClassifier  0.948888   0.968105  0.986121   0.0130867   
8        VotingClassifier  0.967923   0.985816  0.993054  0.00522248   
0              GaussianNB  0.972449   0.972449  0.972449           0   
2           SGDClassifier -0.125658   0.627604  0.974695    0.314102   
1      LogisticRegression         0   0.791985  0.951163    0.258447   

        acc       auc          conf_matrix     f1_c0 f1_c1       kappa  \
4  0.991935       0.5   [[369, 0], [3, 0]]  0.995951     0           0   
6  0.991935       0.5   [[369, 0], [3, 0]]  0.995951     0           0   
3  0.989247  0.498645   [[368, 1], [3, 0]]  0.994595     0 -0.00404858   
7  0.989247  0.498645   [[368, 1], [3, 0]]  0.994595     0 -0.00404858   
5  0.981183   0.49458   [[365, 4], [3, 0]]  0.990502     0 -0.00930233   
9  0.981183   0.49458   [[365, 4], [3, 0]]  0.990502     0 -0.00930233   
8  0.978495  0.493225   [[364, 5], [3, 0]]   0.98913     0  -0.0101833   
0  0.967742  0.487805   [[360, 9], [3, 0]]  0.983607     0  -0.0122449   
2  0.965054   0.48645  [[359, 10], [3, 0]]  0.982216     0  -0.0125628   
1  0.954301   0.48103  [[355, 14], [3, 0]]  0.976616     0  -0.0134615   

  model_score   prec_c0 prec_c1   rec_c0 rec_c1  
4           0  0.991935       0        1      0  
6           0  0.991935       0        1      0  
3 -0.00468124  0.991914       0  0.99729      0  
7 -0.00468124  0.991914       0  0.99729      0  
5 -0.00940056  0.991848       0  0.98916      0  
9 -0.00940056  0.991848       0  0.98916      0  
8  -0.0105245  0.991826       0  0.98645      0  
0  -0.0141976  0.991736       0  0.97561      0  
2  -0.0149863  0.991713       0   0.9729      0  
1  -0.0178308   0.99162       0  0.96206      0  
Elapsed time 33.97 mins 

************************************************************

pre/post: 25/0  win/stride: 500/25  label:start 
filename: stm_sb_modified.csv 
datetime: 2017-05-05 21:47:03.497000 
pca_target: 60 	 poly degree: 2 	 kselect: 0 
Imbalance: ClusterCentroids(estimator=None, n_jobs=1, random_state=None, ratio='auto') 
Extended target (count):  31485 325
('Total : Processed (count): ', (1240L, 276L), 13)
Final feature (count):  (1240L, 276L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.008 	0.000 	0.000 	0.500 	0.000 	0.000
[[  0 369]
 [  0   3]]
             precision    recall  f1-score   support

          0       0.00      0.00      0.00       369
          1       0.01      1.00      0.02         3

avg / total       0.00      0.01      0.00       372


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.001, class_weight={1: 3}, dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.457 	-0.037 	-0.006 	0.396 	0.391 	0.151
[[169 200]
 [  2   1]]
             precision    recall  f1-score   support

          0       0.99      0.46      0.63       369
          1       0.00      0.33      0.01         3

avg / total       0.98      0.46      0.62       372


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.5, average=False, class_weight='balanced', epsilon=0.1,
       eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='modified_huber', n_iter=5, n_jobs=4,
       penalty='l1', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.548 	0.038 	0.008 	0.607 	0.604 	0.369
[[202 167]
 [  1   2]]
             precision    recall  f1-score   support

          0       1.00      0.55      0.71       369
          1       0.01      0.67      0.02         3

avg / total       0.99      0.55      0.70       372


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3},
           criterion='entropy', max_depth=16, max_features=0.33,
           max_leaf_nodes=None, min_impurity_split=1e-07,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=4,
           oob_score=False, random_state=None, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.718 	0.011 	0.003 	0.527 	0.490 	0.231
[[266 103]
 [  2   1]]
             precision    recall  f1-score   support

          0       0.99      0.72      0.84       369
          1       0.01      0.33      0.02         3

avg / total       0.98      0.72      0.83       372


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=32, max_features=0.75, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.793 	0.029 	0.010 	0.565 	0.515 	0.253
[[294  75]
 [  2   1]]
             precision    recall  f1-score   support

          0       0.99      0.80      0.88       369
          1       0.01      0.33      0.03         3

avg / total       0.99      0.79      0.88       372


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.556 	0.040 	0.008 	0.611 	0.609 	0.374
[[205 164]
 [  1   2]]
             precision    recall  f1-score   support

          0       1.00      0.56      0.71       369
          1       0.01      0.67      0.02         3

avg / total       0.99      0.56      0.71       372


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=0.5, n_estimators=15, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.661 	0.124 	0.030 	0.829 	0.812 	0.681
[[243 126]
 [  0   3]]
             precision    recall  f1-score   support

          0       1.00      0.66      0.79       369
          1       0.02      1.00      0.05         3

avg / total       0.99      0.66      0.79       372


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='linear',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.516 	0.032 	0.006 	0.591 	0.586 	0.348
[[190 179]
 [  1   2]]
             precision    recall  f1-score   support

          0       0.99      0.51      0.68       369
          1       0.01      0.67      0.02         3

avg / total       0.99      0.52      0.67       372


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=1.0, class_weight={1: 500}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Ran...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.524 	0.034 	0.006 	0.595 	0.590 	0.354
[[193 176]
 [  1   2]]
             precision    recall  f1-score   support

          0       0.99      0.52      0.69       369
          1       0.01      0.67      0.02         3

avg / total       0.99      0.52      0.68       372


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=4, p=3,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.489 	-0.032 	-0.006 	0.412 	0.404 	0.161
[[181 188]
 [  2   1]]
             precision    recall  f1-score   support

          0       0.99      0.49      0.66       369
          1       0.01      0.33      0.01         3

avg / total       0.98      0.49      0.65       372


                estimator min_score   mean_score max_score   sd_score  \
6      AdaBoostClassifier  -0.54641     0.229072   0.83094   0.352703   
5           MLPClassifier         0     0.206745   0.43094  0.0763395   
2           SGDClassifier  -0.54641    -0.170195   0.66188   0.166646   
8        VotingClassifier  -0.34641    0.0848069   0.43094   0.167995   
7                     SVC  -0.51547   -0.0162564   0.14641   0.197025   
4  RandomForestClassifier      -0.8   -0.0786709   0.54641   0.290358   
3    ExtraTreesClassifier      -0.6 -0.000567897   0.54641   0.230426   
0              GaussianNB  -0.23094     -0.23094  -0.23094          0   
9    KNeighborsClassifier  -0.43094    0.0468234       0.6   0.245676   
1      LogisticRegression  -0.51547    -0.117062         0   0.138708   

          acc       auc           conf_matrix     f1_c0       f1_c1  \
6     0.66129  0.829268  [[243, 126], [0, 3]]  0.794118   0.0454545   
5    0.556452  0.611111  [[205, 164], [1, 2]]  0.713043   0.0236686   
2    0.548387  0.607046  [[202, 167], [1, 2]]  0.706294   0.0232558   
8    0.524194  0.594851  [[193, 176], [1, 2]]  0.685613   0.0220994   
7    0.516129  0.590786  [[190, 179], [1, 2]]  0.678571   0.0217391   
4    0.793011  0.565041   [[294, 75], [2, 1]]  0.884211   0.0253165   
3    0.717742    0.5271  [[266, 103], [2, 1]]  0.835165   0.0186916   
0  0.00806452       0.5    [[0, 369], [0, 3]]         0       0.016   
9    0.489247  0.411924  [[181, 188], [2, 1]]  0.655797   0.0104167   
1    0.456989  0.395664  [[169, 200], [2, 1]]  0.625926  0.00980392   

        kappa model_score   prec_c0     prec_c1    rec_c0    rec_c1  
6   0.0301676    0.123753         1   0.0232558  0.658537         1  
5   0.0079519   0.0399828  0.995146   0.0120482  0.555556  0.666667  
2  0.00752739   0.0384577  0.995074   0.0118343  0.547425  0.666667  
8  0.00633828   0.0339652  0.994845    0.011236  0.523035  0.666667  
7  0.00596776   0.0324912  0.994764   0.0110497  0.514905  0.666667  
4  0.00995438    0.028856  0.993243   0.0131579  0.796748  0.333333  
3  0.00306279   0.0108017  0.992537  0.00961538  0.720867  0.333333  
0           0           0         0  0.00806452         0         1  
9 -0.00554844  -0.0315141  0.989071  0.00529101  0.490515  0.333333  
1 -0.00618623  -0.0374492  0.988304  0.00497512  0.457995  0.333333  
Elapsed time 13.92 mins 

************************************************************





Standard, lagged(3,4)x1, filter(tukey), NT+, UNtruncated






    pca = [0, 60]
    poly = [2]
    ksel = [60, 0]
    imb = [None, SMOTE(), ClusterCentroids() ]
	
	

pre/post: 25/0  win/stride: 500/25  label:start 
filename: stm_sb_modified.csv 
datetime: 2017-05-05 23:15:14.624000 
pca_target: 0 	 poly degree: 2 	 kselect: 60 
Imbalance: None 
Extended target (count):  31485 325
('Total : Processed (count): ', (1240L, 276L), 13)
Final feature (count):  (1240L, 276L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.629 	0.115 	0.026 	0.813 	0.791 	0.649
[[231 138]
 [  0   3]]
             precision    recall  f1-score   support

          0       1.00      0.63      0.77       369
          1       0.02      1.00      0.04         3

avg / total       0.99      0.63      0.76       372


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=5, class_weight={1: 15}, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=4,
          penalty='l2', random_state=None, solver='sag', tol=0.0001,
          verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.952 	0.124 	0.087 	0.645 	0.565 	0.299
[[353  16]
 [  2   1]]
             precision    recall  f1-score   support

          0       0.99      0.96      0.98       369
          1       0.06      0.33      0.10         3

avg / total       0.99      0.95      0.97       372


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.001, average=False, class_weight={1: 15}, epsilon=0.1,
       eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='invscaling', loss='perceptron', n_iter=5, n_jobs=4,
       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.933 	-0.023 	-0.014 	0.470 	0.000 	0.000
[[347  22]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.94      0.97       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.93      0.96       372


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 15},
           criterion='entropy', max_depth=32, max_features='auto',
           max_leaf_nodes=None, min_impurity_split=1e-07,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=4,
           oob_score=False, random_state=None, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.992 	0.000 	0.000 	0.500 	0.000 	0.000
[[369   0]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      1.00       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.99      0.99       372


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 500},
            criterion='gini', max_depth=8, max_features=0.33,
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.968 	0.162 	0.132 	0.653 	0.569 	0.304
[[359  10]
 [  2   1]]
             precision    recall  f1-score   support

          0       0.99      0.97      0.98       369
          1       0.09      0.33      0.14         3

avg / total       0.99      0.97      0.98       372


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.1, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.965 	-0.015 	-0.013 	0.486 	0.000 	0.000
[[359  10]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.97      0.98       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.97      0.97       372


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 500}, criterion='gini', max_depth=8,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=2.0, n_estimators=50, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.981 	-0.009 	-0.009 	0.495 	0.000 	0.000
[[365   4]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.98      0.98       372


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=1, cache_size=200, class_weight={1: 50}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.946 	-0.020 	-0.014 	0.477 	0.000 	0.000
[[352  17]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.95      0.97       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.95      0.96       372


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=10.0, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Ran...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.992 	0.000 	0.000 	0.500 	0.000 	0.000
[[369   0]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      1.00       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.99      0.99       372


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=3,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.981 	-0.009 	-0.009 	0.495 	0.000 	0.000
[[365   4]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.98      0.98       372


                estimator   min_score   mean_score   max_score   sd_score  \
0              GaussianNB -0.00797355  -0.00797355 -0.00797355          0   
4  RandomForestClassifier  -0.0183389  0.000890826    0.133112  0.0125975   
1      LogisticRegression  -0.0886074    0.0392227    0.136681  0.0456093   
3    ExtraTreesClassifier  -0.0267081   0.00113741    0.138879  0.0200003   
8        VotingClassifier  -0.0134698    0.0155224    0.138879  0.0348862   
6      AdaBoostClassifier  -0.0194779   0.00789286    0.233645  0.0372928   
9    KNeighborsClassifier -0.00493052    0.0166216   0.0723275  0.0298726   
5           MLPClassifier  -0.0130627    0.0421708     0.14258  0.0400828   
7                     SVC  -0.0386302    0.0405637    0.108275  0.0367866   
2           SGDClassifier  -0.0887329    0.0226912    0.156238   0.039062   

        acc       auc           conf_matrix     f1_c0      f1_c1       kappa  \
0  0.629032  0.813008  [[231, 138], [0, 3]]      0.77  0.0416667   0.0262888   
4  0.967742  0.653117   [[359, 10], [2, 1]]  0.983562   0.142857    0.131855   
1  0.951613  0.644986   [[353, 16], [2, 1]]  0.975138        0.1   0.0874898   
3  0.991935       0.5    [[369, 0], [3, 0]]  0.995951          0           0   
8  0.991935       0.5    [[369, 0], [3, 0]]  0.995951          0           0   
6  0.981183   0.49458    [[365, 4], [3, 0]]  0.990502          0 -0.00930233   
9  0.981183   0.49458    [[365, 4], [3, 0]]  0.990502          0 -0.00930233   
5  0.965054   0.48645   [[359, 10], [3, 0]]  0.982216          0  -0.0125628   
7  0.946237  0.476965   [[352, 17], [3, 0]]  0.972376          0  -0.0139002   
2  0.932796   0.47019   [[347, 22], [3, 0]]  0.965229          0  -0.0143979   

  model_score   prec_c0    prec_c1    rec_c0    rec_c1  
0     0.11541         1  0.0212766  0.626016         1  
4    0.161687   0.99446  0.0909091    0.9729  0.333333  
1    0.124192  0.994366  0.0588235   0.95664  0.333333  
3           0  0.991935          0         1         0  
8           0  0.991935          0         1         0  
6 -0.00940056  0.991848          0   0.98916         0  
9 -0.00940056  0.991848          0   0.98916         0  
5  -0.0149863  0.991713          0    0.9729         0  
7  -0.0197314  0.991549          0   0.95393         0  
2  -0.0226061  0.991429          0  0.940379         0  
Elapsed time 29.49 mins 

************************************************************

pre/post: 25/0  win/stride: 500/25  label:start 
filename: stm_sb_modified.csv 
datetime: 2017-05-05 23:44:43.918000 
pca_target: 0 	 poly degree: 2 	 kselect: 60 
Imbalance: SMOTE(k=None, k_neighbors=5, kind='regular', m=None, m_neighbors=10, n_jobs=1,
   out_step=0.5, random_state=None, ratio='auto', svm_estimator=None) 
Extended target (count):  31485 325
('Total : Processed (count): ', (1240L, 276L), 13)
Final feature (count):  (1240L, 276L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.602 	0.109 	0.024 	0.799 	0.774 	0.623
[[221 148]
 [  0   3]]
             precision    recall  f1-score   support

          0       1.00      0.60      0.75       369
          1       0.02      1.00      0.04         3

avg / total       0.99      0.60      0.74       372


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=10, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.879 	0.060 	0.028 	0.608 	0.543 	0.278
[[326  43]
 [  2   1]]
             precision    recall  f1-score   support

          0       0.99      0.88      0.94       369
          1       0.02      0.33      0.04         3

avg / total       0.99      0.88      0.93       372


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.1, average=False, class_weight='balanced', epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='modified_huber', n_iter=5, n_jobs=4,
       penalty='none', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.855 	0.132 	0.055 	0.762 	0.756 	0.560
[[316  53]
 [  1   2]]
             precision    recall  f1-score   support

          0       1.00      0.86      0.92       369
          1       0.04      0.67      0.07         3

avg / total       0.99      0.85      0.91       372


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 15}, criterion='gini',
           max_depth=None, max_features=0.75, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=30, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.976 	-0.012 	-0.011 	0.492 	0.000 	0.000
[[363   6]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.98      0.99       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.98      0.98       372


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=32, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=30, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.965 	-0.015 	-0.013 	0.486 	0.000 	0.000
[[359  10]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.97      0.98       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.97      0.97       372


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.01, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.957 	-0.017 	-0.013 	0.482 	0.000 	0.000
[[356  13]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.96      0.98       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.96      0.97       372


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 50}, criterion='gini', max_depth=32,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=1.0, n_estimators=80, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.970 	-0.013 	-0.012 	0.489 	0.000 	0.000
[[361   8]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.98      0.98       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.97      0.98       372


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=10, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	-0.007 	-0.006 	0.497 	0.000 	0.000
[[367   2]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.99      0.99       372


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=10.0, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', ...owski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='uniform'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.952 	-0.018 	-0.014 	0.480 	0.000 	0.000
[[354  15]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.96      0.98       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.95      0.97       372


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=2,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.965 	-0.015 	-0.013 	0.486 	0.000 	0.000
[[359  10]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.97      0.98       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.97      0.97       372


                estimator min_score mean_score max_score   sd_score       acc  \
0              GaussianNB  0.635553   0.635553  0.635553          0  0.602151   
2           SGDClassifier -0.105688   0.518907  0.834723   0.221381  0.854839   
1      LogisticRegression  0.165826   0.687886  0.858888   0.141698  0.879032   
7                     SVC         0   0.805837    0.9827   0.229305  0.986559   
3    ExtraTreesClassifier  0.652181   0.889175  0.981589   0.100699  0.975806   
6      AdaBoostClassifier  0.761506   0.932126  0.974655  0.0287659   0.97043   
4  RandomForestClassifier  0.760831   0.907314  0.972259  0.0673343  0.965054   
9    KNeighborsClassifier  0.880451   0.924909  0.957722  0.0231611  0.965054   
5           MLPClassifier  0.955214    0.97284  0.982815  0.0054989  0.956989   
8        VotingClassifier  0.881486   0.929098  0.955578  0.0151244  0.951613   

        auc           conf_matrix     f1_c0      f1_c1       kappa  \
0  0.799458  [[221, 148], [0, 3]]  0.749153   0.038961   0.0235181   
2  0.761518   [[316, 53], [1, 2]]  0.921283  0.0689655   0.0545044   
1  0.608401   [[326, 43], [2, 1]]  0.935438  0.0425532   0.0278746   
7   0.49729    [[367, 2], [3, 0]]  0.993234          0 -0.00649351   
3   0.49187    [[363, 6], [3, 0]]  0.987755          0  -0.0108696   
6   0.48916    [[361, 8], [3, 0]]  0.984993          0  -0.0118694   
4   0.48645   [[359, 10], [3, 0]]  0.982216          0  -0.0125628   
9   0.48645   [[359, 10], [3, 0]]  0.982216          0  -0.0125628   
5  0.482385   [[356, 13], [3, 0]]  0.978022          0  -0.0132789   
8  0.479675   [[354, 15], [3, 0]]  0.975207          0   -0.013624   

  model_score   prec_c0    prec_c1    rec_c0    rec_c1  
0    0.109083         1  0.0198675  0.598916         1  
2    0.131793  0.996845  0.0363636  0.856369  0.666667  
1   0.0600446  0.993902  0.0227273  0.883469  0.333333  
7 -0.00662921  0.991892          0   0.99458         0  
3  -0.0115447  0.991803          0   0.98374         0  
6  -0.0133672  0.991758          0   0.97832         0  
4  -0.0149863  0.991713          0    0.9729         0  
9  -0.0149863  0.991713          0    0.9729         0  
5  -0.0171582  0.991643          0   0.96477         0  
8  -0.0184824  0.991597          0   0.95935         0  
Elapsed time 65.50 mins 

************************************************************

pre/post: 25/0  win/stride: 500/25  label:start 
filename: stm_sb_modified.csv 
datetime: 2017-05-06 00:50:13.767000 
pca_target: 0 	 poly degree: 2 	 kselect: 60 
Imbalance: ClusterCentroids(estimator=None, n_jobs=1, random_state=None, ratio='auto') 
Extended target (count):  31485 325
('Total : Processed (count): ', (1240L, 276L), 13)
Final feature (count):  (1240L, 276L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.610 	0.111 	0.024 	0.804 	0.779 	0.631
[[224 145]
 [  0   3]]
             precision    recall  f1-score   support

          0       1.00      0.61      0.76       369
          1       0.02      1.00      0.04         3

avg / total       0.99      0.61      0.75       372


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.001, class_weight={1: 3}, dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.401 	0.072 	0.010 	0.698 	0.629 	0.420
[[146 223]
 [  0   3]]
             precision    recall  f1-score   support

          0       1.00      0.40      0.57       369
          1       0.01      1.00      0.03         3

avg / total       0.99      0.40      0.56       372


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.0001, average=False, class_weight='balanced',
       epsilon=0.1, eta0=0.001, fit_intercept=True, l1_ratio=0.15,
       learning_rate='invscaling', loss='modified_huber', n_iter=5,
       n_jobs=4, penalty='l2', power_t=0.5, random_state=None,
       shuffle=True, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.376 	0.069 	0.009 	0.686 	0.609 	0.395
[[137 232]
 [  0   3]]
             precision    recall  f1-score   support

          0       1.00      0.37      0.54       369
          1       0.01      1.00      0.03         3

avg / total       0.99      0.38      0.54       372


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=8, max_features=0.75, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.632 	0.116 	0.027 	0.814 	0.793 	0.652
[[232 137]
 [  0   3]]
             precision    recall  f1-score   support

          0       1.00      0.63      0.77       369
          1       0.02      1.00      0.04         3

avg / total       0.99      0.63      0.77       372


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 15}, criterion='gini',
            max_depth=None, max_features=0.75, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.626 	0.115 	0.026 	0.812 	0.789 	0.647
[[230 139]
 [  0   3]]
             precision    recall  f1-score   support

          0       1.00      0.62      0.77       369
          1       0.02      1.00      0.04         3

avg / total       0.99      0.63      0.76       372


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.01, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.702 	0.136 	0.036 	0.850 	0.836 	0.720
[[258 111]
 [  0   3]]
             precision    recall  f1-score   support

          0       1.00      0.70      0.82       369
          1       0.03      1.00      0.05         3

avg / total       0.99      0.70      0.82       372


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=2.0, n_estimators=80, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.659 	0.123 	0.030 	0.828 	0.810 	0.678
[[242 127]
 [  0   3]]
             precision    recall  f1-score   support

          0       1.00      0.66      0.79       369
          1       0.02      1.00      0.05         3

avg / total       0.99      0.66      0.79       372


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=1, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='linear',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.707 	0.137 	0.037 	0.852 	0.839 	0.725
[[260 109]
 [  0   3]]
             precision    recall  f1-score   support

          0       1.00      0.70      0.83       369
          1       0.03      1.00      0.05         3

avg / total       0.99      0.71      0.82       372


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', R...owski',
           metric_params=None, n_jobs=4, n_neighbors=4, p=2,
           weights='uniform'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.594 	0.107 	0.023 	0.795 	0.769 	0.615
[[218 151]
 [  0   3]]
             precision    recall  f1-score   support

          0       1.00      0.59      0.74       369
          1       0.02      1.00      0.04         3

avg / total       0.99      0.59      0.74       372


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=4, p=1,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.691 	0.132 	0.034 	0.844 	0.830 	0.710
[[254 115]
 [  0   3]]
             precision    recall  f1-score   support

          0       1.00      0.69      0.82       369
          1       0.03      1.00      0.05         3

avg / total       0.99      0.69      0.81       372


                estimator min_score mean_score max_score   sd_score       acc  \
7                     SVC  -0.11547   0.239469   0.57735   0.247612  0.706989   
5           MLPClassifier   0.11547   0.288675   0.34641  0.0912871  0.701613   
9    KNeighborsClassifier  -0.23094 -0.0805021   0.31547   0.110229   0.69086   
6      AdaBoostClassifier         0   0.617261   0.91547   0.157563  0.658602   
3    ExtraTreesClassifier   0.26188   0.554031   0.74641  0.0874692   0.63172   
4  RandomForestClassifier         0   0.477136   0.74641   0.165408  0.626344   
0              GaussianNB   0.74641    0.74641   0.74641          0  0.610215   
8        VotingClassifier         0   0.141301   0.43094  0.0811668  0.594086   
1      LogisticRegression  -0.23094  0.0977449   0.34641   0.131866  0.400538   
2           SGDClassifier  -0.54641   0.151648   0.54641   0.159731  0.376344   

        auc           conf_matrix     f1_c0      f1_c1       kappa  \
7  0.852304  [[260, 109], [0, 3]]  0.826709  0.0521739   0.0370476   
5  0.849593  [[258, 111], [0, 3]]  0.822967  0.0512821   0.0361345   
9  0.844173  [[254, 115], [0, 3]]  0.815409  0.0495868   0.0343987   
6  0.827913  [[242, 127], [0, 3]]  0.792144  0.0451128   0.0298176   
3  0.814363  [[232, 137], [0, 3]]  0.772047   0.041958   0.0265872   
4  0.811653  [[230, 139], [0, 3]]  0.767947  0.0413793   0.0259946   
0  0.803523  [[224, 145], [0, 3]]  0.755481  0.0397351   0.0243108   
8  0.795393  [[218, 151], [0, 3]]   0.74276  0.0382166   0.0227557   
1  0.697832  [[146, 223], [0, 3]]   0.56699  0.0262009   0.0104495   
2  0.685637  [[137, 232], [0, 3]]  0.541502  0.0252101  0.00943461   

  model_score prec_c0    prec_c1    rec_c0 rec_c1  
7    0.137381       1  0.0267857  0.704607      1  
5    0.135645       1  0.0263158  0.699187      1  
9    0.132289       1  0.0254237  0.688347      1  
6    0.123022       1  0.0230769  0.655827      1  
3    0.116072       1  0.0214286  0.628726      1  
4    0.114754       1  0.0211268  0.623306      1  
0    0.110928       1  0.0202703  0.607046      1  
8    0.107279       1  0.0194805  0.590786      1  
1   0.0724719       1  0.0132743  0.395664      1  
2   0.0688452       1   0.012766  0.371274      1  
Elapsed time 15.67 mins 

************************************************************

pre/post: 25/0  win/stride: 500/25  label:start 
filename: stm_sb_modified.csv 
datetime: 2017-05-06 01:05:54.003000 
pca_target: 0 	 poly degree: 2 	 kselect: 0 
Imbalance: None 
Extended target (count):  31485 325
('Total : Processed (count): ', (1240L, 276L), 13)
Final feature (count):  (1240L, 276L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.626 	0.115 	0.026 	0.812 	0.789 	0.647
[[230 139]
 [  0   3]]
             precision    recall  f1-score   support

          0       1.00      0.62      0.77       369
          1       0.02      1.00      0.04         3

avg / total       0.99      0.63      0.76       372


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=1, class_weight={1: 500}, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=4,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.903 	0.074 	0.038 	0.621 	0.550 	0.285
[[335  34]
 [  2   1]]
             precision    recall  f1-score   support

          0       0.99      0.91      0.95       369
          1       0.03      0.33      0.05         3

avg / total       0.99      0.90      0.94       372


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.1, average=False, class_weight={1: 50}, epsilon=0.1,
       eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='constant', loss='modified_huber', n_iter=5, n_jobs=4,
       penalty='none', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.742 	-0.052 	-0.016 	0.374 	0.000 	0.000
[[276  93]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.75      0.85       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.74      0.84       372


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 500}, criterion='gini',
           max_depth=8, max_features=0.33, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.812 	0.109 	0.039 	0.740 	0.736 	0.534
[[300  69]
 [  1   2]]
             precision    recall  f1-score   support

          0       1.00      0.81      0.90       369
          1       0.03      0.67      0.05         3

avg / total       0.99      0.81      0.89       372


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 500},
            criterion='gini', max_depth=8, max_features='auto',
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=15, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.965 	-0.015 	-0.013 	0.486 	0.000 	0.000
[[359  10]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.97      0.98       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.97      0.97       372


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.981 	-0.009 	-0.009 	0.495 	0.000 	0.000
[[365   4]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.98      0.98       372


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=32,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=0.5, n_estimators=80, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.981 	-0.009 	-0.009 	0.495 	0.000 	0.000
[[365   4]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.98      0.98       372


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.1, cache_size=200, class_weight={1: 50}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.978 	-0.011 	-0.010 	0.493 	0.000 	0.000
[[364   5]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.98      0.98       372


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 500}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Ran...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.981 	-0.009 	-0.009 	0.495 	0.000 	0.000
[[365   4]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.98      0.98       372


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=4,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	-0.007 	-0.006 	0.497 	0.000 	0.000
[[367   2]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.99      0.99       372


                estimator   min_score  mean_score  max_score    sd_score  \
0              GaussianNB   0.0308403   0.0308403  0.0308403           0   
3    ExtraTreesClassifier  -0.0298701 -0.00167309  0.0902334  0.00930072   
1      LogisticRegression  -0.0478784   0.0393069    0.16022   0.0438167   
9    KNeighborsClassifier  -0.0101539   0.0325187    0.19469   0.0703899   
5           MLPClassifier  -0.0129376   0.0374229   0.114299   0.0333275   
6      AdaBoostClassifier  -0.0205414  0.00932257   0.235164   0.0399482   
8        VotingClassifier -0.00851044    0.012751   0.207401   0.0356316   
7                     SVC  -0.0119524   0.0389721   0.145247   0.0450792   
4  RandomForestClassifier -0.00848139   0.0010285   0.146639   0.0131511   
2           SGDClassifier  -0.0826695   0.0152696   0.138838   0.0324253   

        acc       auc           conf_matrix     f1_c0      f1_c1       kappa  \
0  0.626344  0.811653  [[230, 139], [0, 3]]  0.767947  0.0413793   0.0259946   
3  0.811828  0.739837   [[300, 69], [1, 2]]  0.895522  0.0540541   0.0391853   
1  0.903226  0.620596   [[335, 34], [2, 1]]  0.949008  0.0526316   0.0383455   
9  0.986559   0.49729    [[367, 2], [3, 0]]  0.993234          0 -0.00649351   
5  0.981183   0.49458    [[365, 4], [3, 0]]  0.990502          0 -0.00930233   
6  0.981183   0.49458    [[365, 4], [3, 0]]  0.990502          0 -0.00930233   
8  0.981183   0.49458    [[365, 4], [3, 0]]  0.990502          0 -0.00930233   
7  0.978495  0.493225    [[364, 5], [3, 0]]   0.98913          0  -0.0101833   
4  0.965054   0.48645   [[359, 10], [3, 0]]  0.982216          0  -0.0125628   
2  0.741935  0.373984   [[276, 93], [3, 0]]  0.851852          0   -0.015873   

  model_score   prec_c0    prec_c1    rec_c0    rec_c1  
0    0.114754         1  0.0211268  0.623306         1  
3    0.109171  0.996678   0.028169  0.813008  0.666667  
1   0.0738905  0.994065  0.0285714  0.907859  0.333333  
9 -0.00662921  0.991892          0   0.99458         0  
5 -0.00940056  0.991848          0   0.98916         0  
6 -0.00940056  0.991848          0   0.98916         0  
8 -0.00940056  0.991848          0   0.98916         0  
7  -0.0105245  0.991826          0   0.98645         0  
4  -0.0149863  0.991713          0    0.9729         0  
2  -0.0520579  0.989247          0  0.747967         0  
Elapsed time 53.94 mins 

************************************************************

pre/post: 25/0  win/stride: 500/25  label:start 
filename: stm_sb_modified.csv 
datetime: 2017-05-06 01:59:50.581000 
pca_target: 0 	 poly degree: 2 	 kselect: 0 
Imbalance: SMOTE(k=None, k_neighbors=5, kind='regular', m=None, m_neighbors=10, n_jobs=1,
   out_step=0.5, random_state=None, ratio='auto', svm_estimator=None) 
Extended target (count):  31485 325
('Total : Processed (count): ', (1240L, 276L), 13)
Final feature (count):  (1240L, 276L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.645 	0.119 	0.028 	0.821 	0.801 	0.665
[[237 132]
 [  0   3]]
             precision    recall  f1-score   support

          0       1.00      0.64      0.78       369
          1       0.02      1.00      0.04         3

avg / total       0.99      0.65      0.78       372


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=10, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.949 	0.120 	0.083 	0.644 	0.564 	0.298
[[352  17]
 [  2   1]]
             precision    recall  f1-score   support

          0       0.99      0.95      0.97       369
          1       0.06      0.33      0.10         3

avg / total       0.99      0.95      0.97       372


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.001, average=False, class_weight='balanced',
       epsilon=0.1, eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='perceptron', n_iter=5, n_jobs=4,
       penalty='l1', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.925 	0.091 	0.053 	0.631 	0.557 	0.291
[[343  26]
 [  2   1]]
             precision    recall  f1-score   support

          0       0.99      0.93      0.96       369
          1       0.04      0.33      0.07         3

avg / total       0.99      0.92      0.95       372


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 15},
           criterion='entropy', max_depth=32, max_features=0.75,
           max_leaf_nodes=None, min_impurity_split=1e-07,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=4,
           oob_score=False, random_state=None, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.981 	-0.009 	-0.009 	0.495 	0.000 	0.000
[[365   4]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.98      0.98       372


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight='balanced',
            criterion='entropy', max_depth=32, max_features='auto',
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.978 	-0.011 	-0.010 	0.493 	0.000 	0.000
[[364   5]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.98      0.98       372


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(500,), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.976 	-0.012 	-0.011 	0.492 	0.000 	0.000
[[363   6]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.98      0.99       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.98      0.98       372


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='entropy', max_depth=8,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=1.0, n_estimators=50, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.976 	-0.012 	-0.011 	0.492 	0.000 	0.000
[[363   6]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.98      0.99       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.98      0.98       372


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=1, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.984 	-0.008 	-0.008 	0.496 	0.000 	0.000
[[366   3]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.98      0.98       372


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=10.0, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', ...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.970 	-0.013 	-0.012 	0.489 	0.000 	0.000
[[361   8]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.98      0.98       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.97      0.98       372


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.965 	-0.015 	-0.013 	0.486 	0.000 	0.000
[[359  10]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.97      0.98       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.97      0.97       372


                estimator  min_score mean_score max_score    sd_score  \
0              GaussianNB   0.584346   0.584346  0.584346           0   
1      LogisticRegression    0.31011   0.763611  0.960085    0.162494   
2           SGDClassifier -0.0952744   0.538725  0.943045    0.262721   
7                     SVC          0   0.797768  0.983836    0.289493   
3    ExtraTreesClassifier   0.696178   0.928328  0.993054   0.0738832   
4  RandomForestClassifier   0.853068    0.94462  0.983803   0.0394614   
5           MLPClassifier   0.969104    0.97816  0.986179  0.00399895   
6      AdaBoostClassifier   0.911837    0.96399  0.991912   0.0173447   
8        VotingClassifier   0.908843   0.950799  0.976988   0.0157134   
9    KNeighborsClassifier   0.895379   0.932305  0.965461   0.0238483   

        acc       auc           conf_matrix     f1_c0      f1_c1       kappa  \
0  0.645161  0.821138  [[237, 132], [0, 3]]  0.782178  0.0434783   0.0281439   
1  0.948925  0.643631   [[352, 17], [2, 1]]  0.973721  0.0952381   0.0825545   
2  0.924731  0.631436   [[343, 26], [2, 1]]  0.960784  0.0666667   0.0529187   
7  0.983871  0.495935    [[366, 3], [3, 0]]   0.99187          0 -0.00813008   
3  0.981183   0.49458    [[365, 4], [3, 0]]  0.990502          0 -0.00930233   
4  0.978495  0.493225    [[364, 5], [3, 0]]   0.98913          0  -0.0101833   
5  0.975806   0.49187    [[363, 6], [3, 0]]  0.987755          0  -0.0108696   
6  0.975806   0.49187    [[363, 6], [3, 0]]  0.987755          0  -0.0108696   
8   0.97043   0.48916    [[361, 8], [3, 0]]  0.984993          0  -0.0118694   
9  0.965054   0.48645   [[359, 10], [3, 0]]  0.982216          0  -0.0125628   

  model_score   prec_c0    prec_c1    rec_c0    rec_c1  
0    0.119469         1  0.0222222  0.642276         1  
1    0.119733   0.99435  0.0555556   0.95393  0.333333  
2   0.0906208  0.994203   0.037037  0.929539  0.333333  
7 -0.00813008   0.99187          0   0.99187         0  
3 -0.00940056  0.991848          0   0.98916         0  
4  -0.0105245  0.991826          0   0.98645         0  
5  -0.0115447  0.991803          0   0.98374         0  
6  -0.0115447  0.991803          0   0.98374         0  
8  -0.0133672  0.991758          0   0.97832         0  
9  -0.0149863  0.991713          0    0.9729         0  
Elapsed time 151.43 mins 

************************************************************

pre/post: 25/0  win/stride: 500/25  label:start 
filename: stm_sb_modified.csv 
datetime: 2017-05-06 04:31:16.561000 
pca_target: 0 	 poly degree: 2 	 kselect: 0 
Imbalance: ClusterCentroids(estimator=None, n_jobs=1, random_state=None, ratio='auto') 
Extended target (count):  31485 325
('Total : Processed (count): ', (1240L, 276L), 13)
Final feature (count):  (1240L, 276L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.624 	0.114 	0.026 	0.810 	0.788 	0.644
[[229 140]
 [  0   3]]
             precision    recall  f1-score   support

          0       1.00      0.62      0.77       369
          1       0.02      1.00      0.04         3

avg / total       0.99      0.62      0.76       372


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=1, class_weight={1: 3}, dual=False, fit_intercept=True,
          intercept_scaling=0.1, max_iter=100, multi_class='ovr', n_jobs=4,
          penalty='l2', random_state=None, solver='lbfgs', tol=0.0001,
          verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.691 	0.132 	0.034 	0.844 	0.830 	0.710
[[254 115]
 [  0   3]]
             precision    recall  f1-score   support

          0       1.00      0.69      0.82       369
          1       0.03      1.00      0.05         3

avg / total       0.99      0.69      0.81       372


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=1, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='constant', loss='modified_huber', n_iter=5, n_jobs=4,
       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.078 	0.025 	0.001 	0.535 	0.265 	0.077
[[ 26 343]
 [  0   3]]
             precision    recall  f1-score   support

          0       1.00      0.07      0.13       369
          1       0.01      1.00      0.02         3

avg / total       0.99      0.08      0.13       372


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=16, max_features=0.75, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=50, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.637 	0.117 	0.027 	0.817 	0.796 	0.657
[[234 135]
 [  0   3]]
             precision    recall  f1-score   support

          0       1.00      0.63      0.78       369
          1       0.02      1.00      0.04         3

avg / total       0.99      0.64      0.77       372


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3},
            criterion='entropy', max_depth=32, max_features=0.33,
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.645 	0.119 	0.028 	0.821 	0.801 	0.665
[[237 132]
 [  0   3]]
             precision    recall  f1-score   support

          0       1.00      0.64      0.78       369
          1       0.02      1.00      0.04         3

avg / total       0.99      0.65      0.78       372


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.720 	0.077 	0.022 	0.694 	0.693 	0.478
[[266 103]
 [  1   2]]
             precision    recall  f1-score   support

          0       1.00      0.72      0.84       369
          1       0.02      0.67      0.04         3

avg / total       0.99      0.72      0.83       372


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=16,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=0.5, n_estimators=15, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.624 	0.114 	0.026 	0.810 	0.788 	0.644
[[229 140]
 [  0   3]]
             precision    recall  f1-score   support

          0       1.00      0.62      0.77       369
          1       0.02      1.00      0.04         3

avg / total       0.99      0.62      0.76       372


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=1, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='linear',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.761 	0.089 	0.028 	0.714 	0.713 	0.503
[[281  88]
 [  1   2]]
             precision    recall  f1-score   support

          0       1.00      0.76      0.86       369
          1       0.02      0.67      0.04         3

avg / total       0.99      0.76      0.86       372


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=1.0, class_weight={1: 500}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Ran...owski',
           metric_params=None, n_jobs=4, n_neighbors=4, p=2,
           weights='uniform'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.626 	0.115 	0.026 	0.812 	0.789 	0.647
[[230 139]
 [  0   3]]
             precision    recall  f1-score   support

          0       1.00      0.62      0.77       369
          1       0.02      1.00      0.04         3

avg / total       0.99      0.63      0.76       372


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=5, p=2,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.296 	0.057 	0.007 	0.645 	0.538 	0.311
[[107 262]
 [  0   3]]
             precision    recall  f1-score   support

          0       1.00      0.29      0.45       369
          1       0.01      1.00      0.02         3

avg / total       0.99      0.30      0.45       372


                estimator min_score mean_score max_score  sd_score       acc  \
1      LogisticRegression  -0.43094 -0.0155822   0.34641   0.20993   0.69086   
4  RandomForestClassifier  -0.28453   0.210872       0.6  0.154613  0.645161   
3    ExtraTreesClassifier      -0.2   0.229129   0.43094  0.149387  0.637097   
8        VotingClassifier  -0.43094 -0.0927255       0.2  0.151312  0.626344   
0              GaussianNB   0.46188    0.46188   0.46188         0  0.623656   
6      AdaBoostClassifier  -0.43094   0.529547   0.83094    0.1869  0.623656   
7                     SVC  -0.34641  0.0457735   0.31547  0.208422  0.760753   
5           MLPClassifier  -0.66188  -0.270846  -0.11547  0.154189   0.72043   
9    KNeighborsClassifier  -0.54641  -0.268819   0.11547  0.158196  0.295699   
2           SGDClassifier  -0.71547 -0.0487604   0.63094  0.199011  0.077957   

        auc           conf_matrix     f1_c0      f1_c1       kappa  \
1  0.844173  [[254, 115], [0, 3]]  0.815409  0.0495868   0.0343987   
4  0.821138  [[237, 132], [0, 3]]  0.782178  0.0434783   0.0281439   
3  0.817073  [[234, 135], [0, 3]]  0.776119  0.0425532   0.0271967   
8  0.811653  [[230, 139], [0, 3]]  0.767947  0.0413793   0.0259946   
0  0.810298  [[229, 140], [0, 3]]  0.765886  0.0410959   0.0257043   
6  0.810298  [[229, 140], [0, 3]]  0.765886  0.0410959   0.0257043   
7  0.714092   [[281, 88], [1, 2]]  0.863287  0.0430108   0.0278365   
5  0.693767  [[266, 103], [1, 2]]  0.836478   0.037037   0.0216963   
9  0.644986  [[107, 262], [0, 3]]   0.44958  0.0223881  0.00654394   
2   0.53523   [[26, 343], [0, 3]]  0.131646   0.017192  0.00122112   

  model_score   prec_c0     prec_c1     rec_c0    rec_c1  
1    0.132289         1   0.0254237   0.688347         1  
4    0.119469         1   0.0222222   0.642276         1  
3    0.117413         1   0.0217391   0.634146         1  
8    0.114754         1   0.0211268   0.623306         1  
0    0.114103         1    0.020979   0.620596         1  
6    0.114103         1    0.020979   0.620596         1  
7    0.089425  0.996454   0.0222222   0.761518  0.666667  
5   0.0770075  0.996255   0.0190476   0.720867  0.666667  
9    0.057295         1   0.0113208   0.289973         1  
2    0.024717         1  0.00867052  0.0704607         1  
Elapsed time 21.50 mins 

************************************************************

pre/post: 25/0  win/stride: 500/25  label:start 
filename: stm_sb_modified.csv 
datetime: 2017-05-06 04:52:46.440000 
pca_target: 60 	 poly degree: 2 	 kselect: 60 
Imbalance: None 
Extended target (count):  31485 325
('Total : Processed (count): ', (1240L, 276L), 13)
Final feature (count):  (1240L, 276L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.720 	0.077 	0.022 	0.694 	0.693 	0.478
[[266 103]
 [  1   2]]
             precision    recall  f1-score   support

          0       1.00      0.72      0.84       369
          1       0.02      0.67      0.04         3

avg / total       0.99      0.72      0.83       372


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.1, class_weight={1: 500}, dual=False,
          fit_intercept=True, intercept_scaling=5, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.890 	0.066 	0.032 	0.614 	0.546 	0.281
[[330  39]
 [  2   1]]
             precision    recall  f1-score   support

          0       0.99      0.89      0.94       369
          1       0.03      0.33      0.05         3

avg / total       0.99      0.89      0.93       372


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=1, average=False, class_weight='balanced', epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='constant', loss='perceptron', n_iter=5, n_jobs=4,
       penalty='l2', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.390 	0.071 	0.010 	0.692 	0.620 	0.408
[[142 227]
 [  0   3]]
             precision    recall  f1-score   support

          0       1.00      0.38      0.56       369
          1       0.01      1.00      0.03         3

avg / total       0.99      0.39      0.55       372


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 500},
           criterion='entropy', max_depth=8, max_features=0.33,
           max_leaf_nodes=None, min_impurity_split=1e-07,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=15, n_jobs=4,
           oob_score=False, random_state=None, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.911 	0.080 	0.043 	0.625 	0.553 	0.288
[[338  31]
 [  2   1]]
             precision    recall  f1-score   support

          0       0.99      0.92      0.95       369
          1       0.03      0.33      0.06         3

avg / total       0.99      0.91      0.95       372


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.992 	0.000 	0.000 	0.500 	0.000 	0.000
[[369   0]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      1.00       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.99      0.99       372


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.1, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(500,), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.981 	-0.009 	-0.009 	0.495 	0.000 	0.000
[[365   4]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.98      0.98       372


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 50}, criterion='entropy',
            max_depth=16, max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=1.0, n_estimators=15, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.981 	-0.009 	-0.009 	0.495 	0.000 	0.000
[[365   4]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.98      0.98       372


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=10, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='linear',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.973 	0.181 	0.156 	0.656 	0.571 	0.305
[[361   8]
 [  2   1]]
             precision    recall  f1-score   support

          0       0.99      0.98      0.99       369
          1       0.11      0.33      0.17         3

avg / total       0.99      0.97      0.98       372


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 500}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Ran...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.981 	-0.009 	-0.009 	0.495 	0.000 	0.000
[[365   4]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.98      0.98       372


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=2,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.984 	-0.008 	-0.008 	0.496 	0.000 	0.000
[[366   3]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.98      0.98       372


                estimator   min_score   mean_score  max_score     sd_score  \
0              GaussianNB  -0.0355967   -0.0355967 -0.0355967            0   
2           SGDClassifier   -0.127225     0.031902   0.164717    0.0411439   
7                     SVC -0.00985636    0.0336424   0.114572    0.0424198   
3    ExtraTreesClassifier    -0.01264   0.00647042   0.165787    0.0308119   
1      LogisticRegression   -0.035102     0.047273   0.163408     0.042856   
4  RandomForestClassifier -0.00328707 -0.000197475          0  0.000573525   
9    KNeighborsClassifier -0.00397463    0.0402782   0.193579     0.074144   
5           MLPClassifier   0.0303046    0.0613457   0.148234    0.0276141   
6      AdaBoostClassifier  -0.0174742    0.0146476   0.231489    0.0450906   
8        VotingClassifier -0.00848139    0.0208651   0.175446    0.0410841   

        acc       auc           conf_matrix     f1_c0      f1_c1       kappa  \
0   0.72043  0.693767  [[266, 103], [1, 2]]  0.836478   0.037037   0.0216963   
2  0.389785  0.692412  [[142, 227], [0, 3]]  0.555773  0.0257511  0.00998875   
7  0.973118  0.655827    [[361, 8], [2, 1]]  0.986339   0.166667    0.156463   
3   0.91129  0.624661   [[338, 31], [2, 1]]  0.953456  0.0571429   0.0430309   
1  0.889785  0.613821   [[330, 39], [2, 1]]  0.941512  0.0465116   0.0319878   
4  0.991935       0.5    [[369, 0], [3, 0]]  0.995951          0           0   
9  0.983871  0.495935    [[366, 3], [3, 0]]   0.99187          0 -0.00813008   
5  0.981183   0.49458    [[365, 4], [3, 0]]  0.990502          0 -0.00930233   
6  0.981183   0.49458    [[365, 4], [3, 0]]  0.990502          0 -0.00930233   
8  0.981183   0.49458    [[365, 4], [3, 0]]  0.990502          0 -0.00930233   

  model_score   prec_c0    prec_c1    rec_c0    rec_c1  
0   0.0770075  0.996255  0.0190476  0.720867  0.666667  
2    0.070848         1  0.0130435  0.384824         1  
7    0.181414   0.99449   0.111111   0.97832  0.333333  
3   0.0795281  0.994118    0.03125  0.915989  0.333333  
1   0.0657246  0.993976      0.025  0.894309  0.333333  
4           0  0.991935          0         1         0  
9 -0.00813008   0.99187          0   0.99187         0  
5 -0.00940056  0.991848          0   0.98916         0  
6 -0.00940056  0.991848          0   0.98916         0  
8 -0.00940056  0.991848          0   0.98916         0  
Elapsed time 31.55 mins 

************************************************************

pre/post: 25/0  win/stride: 500/25  label:start 
filename: stm_sb_modified.csv 
datetime: 2017-05-06 05:24:19.145000 
pca_target: 60 	 poly degree: 2 	 kselect: 60 
Imbalance: SMOTE(k=None, k_neighbors=5, kind='regular', m=None, m_neighbors=10, n_jobs=1,
   out_step=0.5, random_state=None, ratio='auto', svm_estimator=None) 
Extended target (count):  31485 325
('Total : Processed (count): ', (1240L, 276L), 13)
Final feature (count):  (1240L, 276L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.927 	0.202 	0.116 	0.798 	0.787 	0.603
[[343  26]
 [  1   2]]
             precision    recall  f1-score   support

          0       1.00      0.93      0.96       369
          1       0.07      0.67      0.13         3

avg / total       0.99      0.93      0.96       372


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=10, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.976 	0.194 	0.172 	0.657 	0.572 	0.306
[[362   7]
 [  2   1]]
             precision    recall  f1-score   support

          0       0.99      0.98      0.99       369
          1       0.12      0.33      0.18         3

avg / total       0.99      0.98      0.98       372


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.0001, average=False, class_weight='balanced',
       epsilon=0.1, eta0=0.001, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='modified_huber', n_iter=5, n_jobs=4,
       penalty='none', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.976 	0.194 	0.172 	0.657 	0.572 	0.306
[[362   7]
 [  2   1]]
             precision    recall  f1-score   support

          0       0.99      0.98      0.99       369
          1       0.12      0.33      0.18         3

avg / total       0.99      0.98      0.98       372


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=16, max_features=0.75, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	-0.005 	-0.004 	0.499 	0.000 	0.000
[[368   1]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.99      0.99       372


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=None, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	-0.005 	-0.004 	0.499 	0.000 	0.000
[[368   1]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.99      0.99       372


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.984 	-0.008 	-0.008 	0.496 	0.000 	0.000
[[366   3]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.98      0.98       372


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 50}, criterion='entropy', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=1.0, n_estimators=15, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.992 	0.000 	0.000 	0.500 	0.000 	0.000
[[369   0]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      1.00       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.99      0.99       372


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.5, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	-0.005 	-0.004 	0.499 	0.000 	0.000
[[368   1]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.99      0.99       372


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=10.0, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', ...owski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='uniform'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.981 	-0.009 	-0.009 	0.495 	0.000 	0.000
[[365   4]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.98      0.98       372


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=2,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.981 	-0.009 	-0.009 	0.495 	0.000 	0.000
[[365   4]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.98      0.98       372


                estimator  min_score mean_score max_score    sd_score  \
0              GaussianNB   0.909767   0.909767  0.909767           0   
1      LogisticRegression   0.349353   0.839838   0.96904    0.157341   
2           SGDClassifier -0.0286807   0.666314  0.981518    0.287306   
6      AdaBoostClassifier   0.937605   0.989569         1  0.00893632   
3    ExtraTreesClassifier   0.814478   0.985232         1   0.0330302   
4  RandomForestClassifier   0.990723   0.995927         1  0.00181159   
7                     SVC          0   0.850469  0.995358    0.277274   
5           MLPClassifier   0.971319    0.98051  0.993067  0.00597784   
8        VotingClassifier   0.964593   0.979778  0.989594  0.00622733   
9    KNeighborsClassifier   0.925976   0.966409  0.988445   0.0168997   

        acc       auc          conf_matrix     f1_c0     f1_c1       kappa  \
0  0.927419  0.798103  [[343, 26], [1, 2]]  0.962132  0.129032    0.116156   
1  0.975806  0.657182   [[362, 7], [2, 1]]  0.987722  0.181818    0.172107   
2  0.975806  0.657182   [[362, 7], [2, 1]]  0.987722  0.181818    0.172107   
6  0.991935       0.5   [[369, 0], [3, 0]]  0.995951         0           0   
3  0.989247  0.498645   [[368, 1], [3, 0]]  0.994595         0 -0.00404858   
4  0.989247  0.498645   [[368, 1], [3, 0]]  0.994595         0 -0.00404858   
7  0.989247  0.498645   [[368, 1], [3, 0]]  0.994595         0 -0.00404858   
5  0.983871  0.495935   [[366, 3], [3, 0]]   0.99187         0 -0.00813008   
8  0.981183   0.49458   [[365, 4], [3, 0]]  0.990502         0 -0.00930233   
9  0.981183   0.49458   [[365, 4], [3, 0]]  0.990502         0 -0.00930233   

  model_score   prec_c0    prec_c1    rec_c0    rec_c1  
0    0.202121  0.997093  0.0714286  0.929539  0.666667  
1    0.193825  0.994505      0.125   0.98103  0.333333  
2    0.193825  0.994505      0.125   0.98103  0.333333  
6           0  0.991935          0         1         0  
3 -0.00468124  0.991914          0   0.99729         0  
4 -0.00468124  0.991914          0   0.99729         0  
7 -0.00468124  0.991914          0   0.99729         0  
5 -0.00813008   0.99187          0   0.99187         0  
8 -0.00940056  0.991848          0   0.98916         0  
9 -0.00940056  0.991848          0   0.98916         0  
Elapsed time 53.02 mins 

************************************************************

pre/post: 25/0  win/stride: 500/25  label:start 
filename: stm_sb_modified.csv 
datetime: 2017-05-06 06:17:20.520000 
pca_target: 60 	 poly degree: 2 	 kselect: 60 
Imbalance: ClusterCentroids(estimator=None, n_jobs=1, random_state=None, ratio='auto') 
Extended target (count):  31485 325
('Total : Processed (count): ', (1240L, 276L), 13)
Final feature (count):  (1240L, 276L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.992 	0.000 	0.000 	0.500 	0.000 	0.000
[[369   0]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      1.00       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.99      0.99       372


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=5, class_weight={1: 500}, dual=False, fit_intercept=True,
          intercept_scaling=0.1, max_iter=100, multi_class='ovr', n_jobs=4,
          penalty='l2', random_state=None, solver='sag', tol=0.0001,
          verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.508 	-0.087 	-0.016 	0.256 	0.000 	0.000
[[189 180]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.98      0.51      0.67       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.51      0.67       372


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.0001, average=False, class_weight={1: 500}, epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='constant', loss='perceptron', n_iter=5, n_jobs=4,
       penalty='none', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.489 	-0.032 	-0.006 	0.412 	0.404 	0.161
[[181 188]
 [  2   1]]
             precision    recall  f1-score   support

          0       0.99      0.49      0.66       369
          1       0.01      0.33      0.01         3

avg / total       0.98      0.49      0.65       372


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 15},
           criterion='entropy', max_depth=8, max_features=0.75,
           max_leaf_nodes=None, min_impurity_split=1e-07,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=15, n_jobs=4,
           oob_score=False, random_state=None, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.629 	0.115 	0.026 	0.813 	0.791 	0.649
[[231 138]
 [  0   3]]
             precision    recall  f1-score   support

          0       1.00      0.63      0.77       369
          1       0.02      1.00      0.04         3

avg / total       0.99      0.63      0.76       372


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 50}, criterion='gini',
            max_depth=None, max_features=0.75, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.661 	0.124 	0.030 	0.829 	0.812 	0.681
[[243 126]
 [  0   3]]
             precision    recall  f1-score   support

          0       1.00      0.66      0.79       369
          1       0.02      1.00      0.05         3

avg / total       0.99      0.66      0.79       372


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.01, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.462 	0.082 	0.013 	0.729 	0.677 	0.483
[[169 200]
 [  0   3]]
             precision    recall  f1-score   support

          0       1.00      0.46      0.63       369
          1       0.01      1.00      0.03         3

avg / total       0.99      0.46      0.62       372


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=16,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=1.0, n_estimators=50, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.624 	0.114 	0.026 	0.810 	0.788 	0.644
[[229 140]
 [  0   3]]
             precision    recall  f1-score   support

          0       1.00      0.62      0.77       369
          1       0.02      1.00      0.04         3

avg / total       0.99      0.62      0.76       372


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.992 	0.000 	0.000 	0.500 	0.000 	0.000
[[369   0]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      1.00       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.99      0.99       372


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', R...owski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='uniform'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.484 	-0.032 	-0.006 	0.409 	0.402 	0.159
[[179 190]
 [  2   1]]
             precision    recall  f1-score   support

          0       0.99      0.49      0.65       369
          1       0.01      0.33      0.01         3

avg / total       0.98      0.48      0.65       372


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=4, p=2,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.489 	-0.032 	-0.006 	0.412 	0.404 	0.161
[[181 188]
 [  2   1]]
             precision    recall  f1-score   support

          0       0.99      0.49      0.66       369
          1       0.01      0.33      0.01         3

avg / total       0.98      0.49      0.65       372


                estimator min_score mean_score max_score  sd_score       acc  \
4  RandomForestClassifier  -0.43094   0.202086   0.83094  0.176984   0.66129   
3    ExtraTreesClassifier   0.11547   0.534602   0.74641  0.115622  0.629032   
6      AdaBoostClassifier  -0.54641   0.258882   0.83094  0.267479  0.623656   
5           MLPClassifier  -0.31547  0.0421848   0.34641  0.124786  0.462366   
0              GaussianNB   0.74641    0.74641   0.74641         0  0.991935   
7                     SVC  -0.34641  0.0443024   0.28453  0.170866  0.991935   
2           SGDClassifier  -0.63094  0.0735523   0.66188  0.184055  0.489247   
9    KNeighborsClassifier  -0.34641  0.0613835   0.51547  0.207908  0.489247   
8        VotingClassifier         0   0.177157   0.63094  0.118912  0.483871   
1      LogisticRegression  -0.11547  0.0655975   0.34641  0.107613  0.508065   

        auc           conf_matrix     f1_c0      f1_c1       kappa  \
4  0.829268  [[243, 126], [0, 3]]  0.794118  0.0454545   0.0301676   
3  0.813008  [[231, 138], [0, 3]]      0.77  0.0416667   0.0262888   
6  0.810298  [[229, 140], [0, 3]]  0.765886  0.0410959   0.0257043   
5  0.728997  [[169, 200], [0, 3]]  0.628253  0.0291262   0.0134458   
0       0.5    [[369, 0], [3, 0]]  0.995951          0           0   
7       0.5    [[369, 0], [3, 0]]  0.995951          0           0   
2  0.411924  [[181, 188], [2, 1]]  0.655797  0.0104167 -0.00554844   
9  0.411924  [[181, 188], [2, 1]]  0.655797  0.0104167 -0.00554844   
8  0.409214  [[179, 190], [2, 1]]  0.650909  0.0103093 -0.00566022   
1  0.256098  [[189, 180], [3, 0]]  0.673797          0  -0.0161204   

  model_score   prec_c0     prec_c1    rec_c0    rec_c1  
4    0.123753         1   0.0232558  0.658537         1  
3     0.11541         1   0.0212766  0.626016         1  
6    0.114103         1    0.020979  0.620596         1  
5   0.0822702         1   0.0147783  0.457995         1  
0           0  0.991935           0         1         0  
7           0  0.991935           0         1         0  
2  -0.0315141  0.989071  0.00529101  0.490515  0.333333  
9  -0.0315141  0.989071  0.00529101  0.490515  0.333333  
8  -0.0324912   0.98895   0.0052356  0.485095  0.333333  
1  -0.0873038  0.984375           0  0.512195         0  
Elapsed time 14.96 mins 

************************************************************

pre/post: 25/0  win/stride: 500/25  label:start 
filename: stm_sb_modified.csv 
datetime: 2017-05-06 06:32:18.240000 
pca_target: 60 	 poly degree: 2 	 kselect: 0 
Imbalance: None 
Extended target (count):  31485 325
('Total : Processed (count): ', (1240L, 276L), 13)
Final feature (count):  (1240L, 276L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.981 	-0.009 	-0.009 	0.495 	0.000 	0.000
[[365   4]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.98      0.98       372


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=1, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.780 	0.096 	0.031 	0.724 	0.721 	0.514
[[288  81]
 [  1   2]]
             precision    recall  f1-score   support

          0       1.00      0.78      0.88       369
          1       0.02      0.67      0.05         3

avg / total       0.99      0.78      0.87       372


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.0001, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='constant', loss='squared_hinge', n_iter=5, n_jobs=4,
       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.927 	0.093 	0.055 	0.633 	0.557 	0.292
[[344  25]
 [  2   1]]
             precision    recall  f1-score   support

          0       0.99      0.93      0.96       369
          1       0.04      0.33      0.07         3

avg / total       0.99      0.93      0.96       372


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 500}, criterion='gini',
           max_depth=16, max_features=0.33, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=30, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.984 	-0.008 	-0.008 	0.496 	0.000 	0.000
[[366   3]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.98      0.98       372


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.992 	0.000 	0.000 	0.500 	0.000 	0.000
[[369   0]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      1.00       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.99      0.99       372


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.01, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.973 	0.181 	0.156 	0.656 	0.571 	0.305
[[361   8]
 [  2   1]]
             precision    recall  f1-score   support

          0       0.99      0.98      0.99       369
          1       0.11      0.33      0.17         3

avg / total       0.99      0.97      0.98       372


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 50}, criterion='gini', max_depth=16,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=0.5, n_estimators=80, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.992 	0.000 	0.000 	0.500 	0.000 	0.000
[[369   0]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      1.00       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.99      0.99       372


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=1, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='linear',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.970 	-0.013 	-0.012 	0.489 	0.000 	0.000
[[361   8]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.98      0.98       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.97      0.98       372


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 500}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Ran...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.984 	-0.008 	-0.008 	0.496 	0.000 	0.000
[[366   3]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.98      0.98       372


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=2,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.984 	-0.008 	-0.008 	0.496 	0.000 	0.000
[[366   3]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.98      0.98       372


                estimator   min_score   mean_score  max_score     sd_score  \
1      LogisticRegression  -0.0220879    0.0420064    0.13473     0.040564   
5           MLPClassifier  -0.0113736    0.0639968   0.136959     0.033038   
2           SGDClassifier  -0.0990649    0.0391851   0.216676    0.0435176   
4  RandomForestClassifier -0.00328699 -8.40734e-05          0  0.000416683   
6      AdaBoostClassifier  -0.0161713   0.00702415   0.215305    0.0361116   
3    ExtraTreesClassifier  -0.0113445   0.00267687   0.137362    0.0219702   
8        VotingClassifier -0.00904264    0.0184463   0.175341    0.0367901   
9    KNeighborsClassifier  -0.0079491    0.0279547   0.195223    0.0639925   
0              GaussianNB  -0.0162961   -0.0162961 -0.0162961            0   
7                     SVC -0.00916887     0.031676    0.11663    0.0415668   

        acc       auc          conf_matrix     f1_c0      f1_c1       kappa  \
1   0.77957  0.723577  [[288, 81], [1, 2]]   0.87538  0.0465116   0.0314346   
5  0.973118  0.655827   [[361, 8], [2, 1]]  0.986339   0.166667    0.156463   
2  0.927419  0.632791  [[344, 25], [2, 1]]  0.962238  0.0689655   0.0553047   
4  0.991935       0.5   [[369, 0], [3, 0]]  0.995951          0           0   
6  0.991935       0.5   [[369, 0], [3, 0]]  0.995951          0           0   
3  0.983871  0.495935   [[366, 3], [3, 0]]   0.99187          0 -0.00813008   
8  0.983871  0.495935   [[366, 3], [3, 0]]   0.99187          0 -0.00813008   
9  0.983871  0.495935   [[366, 3], [3, 0]]   0.99187          0 -0.00813008   
0  0.981183   0.49458   [[365, 4], [3, 0]]  0.990502          0 -0.00930233   
7   0.97043   0.48916   [[361, 8], [3, 0]]  0.984993          0  -0.0118694   

  model_score   prec_c0    prec_c1    rec_c0    rec_c1  
1   0.0960602   0.99654  0.0240964  0.780488  0.666667  
5    0.181414   0.99449   0.111111   0.97832  0.333333  
2   0.0931641   0.99422  0.0384615  0.932249  0.333333  
4           0  0.991935          0         1         0  
6           0  0.991935          0         1         0  
3 -0.00813008   0.99187          0   0.99187         0  
8 -0.00813008   0.99187          0   0.99187         0  
9 -0.00813008   0.99187          0   0.99187         0  
0 -0.00940056  0.991848          0   0.98916         0  
7  -0.0133672  0.991758          0   0.97832         0  
Elapsed time 24.05 mins 

************************************************************

pre/post: 25/0  win/stride: 500/25  label:start 
filename: stm_sb_modified.csv 
datetime: 2017-05-06 06:56:21.478000 
pca_target: 60 	 poly degree: 2 	 kselect: 0 
Imbalance: SMOTE(k=None, k_neighbors=5, kind='regular', m=None, m_neighbors=10, n_jobs=1,
   out_step=0.5, random_state=None, ratio='auto', svm_estimator=None) 
Extended target (count):  31485 325
('Total : Processed (count): ', (1240L, 276L), 13)
Final feature (count):  (1240L, 276L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.978 	-0.011 	-0.010 	0.493 	0.000 	0.000
[[364   5]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.98      0.98       372


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=10, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.968 	0.162 	0.132 	0.653 	0.569 	0.304
[[359  10]
 [  2   1]]
             precision    recall  f1-score   support

          0       0.99      0.97      0.98       369
          1       0.09      0.33      0.14         3

avg / total       0.99      0.97      0.98       372


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.001, average=False, class_weight='balanced',
       epsilon=0.1, eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='modified_huber', n_iter=5, n_jobs=4,
       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.978 	-0.011 	-0.010 	0.493 	0.000 	0.000
[[364   5]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.98      0.98       372


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=32, max_features=0.33, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=30, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.992 	0.000 	0.000 	0.500 	0.000 	0.000
[[369   0]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      1.00       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.99      0.99       372


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=50, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.992 	0.000 	0.000 	0.500 	0.000 	0.000
[[369   0]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      1.00       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.99      0.99       372


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.1, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.984 	-0.008 	-0.008 	0.496 	0.000 	0.000
[[366   3]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.98      0.98       372


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight='balanced', criterion='gini', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=1.0, n_estimators=15, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	-0.007 	-0.006 	0.497 	0.000 	0.000
[[367   2]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.99      0.99       372


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.5, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	-0.005 	-0.004 	0.499 	0.000 	0.000
[[368   1]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.99      0.99       372


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=1.0, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', R...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.984 	-0.008 	-0.008 	0.496 	0.000 	0.000
[[366   3]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.98      0.98       372


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=4,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.984 	-0.008 	-0.008 	0.496 	0.000 	0.000
[[366   3]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.98      0.98       372


                estimator  min_score mean_score max_score    sd_score  \
1      LogisticRegression          0   0.808606  0.969065     0.26094   
3    ExtraTreesClassifier   0.705485   0.986739         1   0.0337086   
4  RandomForestClassifier   0.994189   0.997793         1  0.00145111   
7                     SVC          0   0.853087  0.996514    0.272251   
6      AdaBoostClassifier   0.916579   0.985265         1  0.00974877   
5           MLPClassifier   0.965656   0.980001  0.994203  0.00785668   
8        VotingClassifier   0.965687   0.982561  0.990736   0.0055522   
9    KNeighborsClassifier   0.945655   0.969196  0.988432   0.0141602   
0              GaussianNB   0.970886   0.970886  0.970886           0   
2           SGDClassifier -0.0958934   0.656135  0.990703    0.318916   

        acc       auc          conf_matrix     f1_c0     f1_c1       kappa  \
1  0.967742  0.653117  [[359, 10], [2, 1]]  0.983562  0.142857    0.131855   
3  0.991935       0.5   [[369, 0], [3, 0]]  0.995951         0           0   
4  0.991935       0.5   [[369, 0], [3, 0]]  0.995951         0           0   
7  0.989247  0.498645   [[368, 1], [3, 0]]  0.994595         0 -0.00404858   
6  0.986559   0.49729   [[367, 2], [3, 0]]  0.993234         0 -0.00649351   
5  0.983871  0.495935   [[366, 3], [3, 0]]   0.99187         0 -0.00813008   
8  0.983871  0.495935   [[366, 3], [3, 0]]   0.99187         0 -0.00813008   
9  0.983871  0.495935   [[366, 3], [3, 0]]   0.99187         0 -0.00813008   
0  0.978495  0.493225   [[364, 5], [3, 0]]   0.98913         0  -0.0101833   
2  0.978495  0.493225   [[364, 5], [3, 0]]   0.98913         0  -0.0101833   

  model_score   prec_c0    prec_c1   rec_c0    rec_c1  
1    0.161687   0.99446  0.0909091   0.9729  0.333333  
3           0  0.991935          0        1         0  
4           0  0.991935          0        1         0  
7 -0.00468124  0.991914          0  0.99729         0  
6 -0.00662921  0.991892          0  0.99458         0  
5 -0.00813008   0.99187          0  0.99187         0  
8 -0.00813008   0.99187          0  0.99187         0  
9 -0.00813008   0.99187          0  0.99187         0  
0  -0.0105245  0.991826          0  0.98645         0  
2  -0.0105245  0.991826          0  0.98645         0  
Elapsed time 35.04 mins 

************************************************************

pre/post: 25/0  win/stride: 500/25  label:start 
filename: stm_sb_modified.csv 
datetime: 2017-05-06 07:31:23.733000 
pca_target: 60 	 poly degree: 2 	 kselect: 0 
Imbalance: ClusterCentroids(estimator=None, n_jobs=1, random_state=None, ratio='auto') 
Extended target (count):  31485 325
('Total : Processed (count): ', (1240L, 276L), 13)
Final feature (count):  (1240L, 276L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.992 	0.000 	0.000 	0.500 	0.000 	0.000
[[369   0]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      1.00       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.99      0.99       372


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=10, class_weight={1: 3}, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=4,
          penalty='l2', random_state=None, solver='sag', tol=0.0001,
          verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.505 	-0.029 	-0.005 	0.420 	0.411 	0.166
[[187 182]
 [  2   1]]
             precision    recall  f1-score   support

          0       0.99      0.51      0.67       369
          1       0.01      0.33      0.01         3

avg / total       0.98      0.51      0.66       372


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.5, average=False, class_weight='balanced', epsilon=0.1,
       eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='invscaling', loss='perceptron', n_iter=5, n_jobs=4,
       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.659 	0.061 	0.015 	0.663 	0.663 	0.439
[[243 126]
 [  1   2]]
             precision    recall  f1-score   support

          0       1.00      0.66      0.79       369
          1       0.02      0.67      0.03         3

avg / total       0.99      0.66      0.79       372


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight='balanced',
           criterion='entropy', max_depth=8, max_features=0.33,
           max_leaf_nodes=None, min_impurity_split=1e-07,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=15, n_jobs=4,
           oob_score=False, random_state=None, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.586 	0.106 	0.022 	0.791 	0.763 	0.607
[[215 154]
 [  0   3]]
             precision    recall  f1-score   support

          0       1.00      0.58      0.74       369
          1       0.02      1.00      0.04         3

avg / total       0.99      0.59      0.73       372


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight='balanced',
            criterion='entropy', max_depth=None, max_features=0.33,
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=15, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.610 	0.111 	0.024 	0.804 	0.779 	0.631
[[224 145]
 [  0   3]]
             precision    recall  f1-score   support

          0       1.00      0.61      0.76       369
          1       0.02      1.00      0.04         3

avg / total       0.99      0.61      0.75       372


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.484 	0.086 	0.015 	0.740 	0.693 	0.505
[[177 192]
 [  0   3]]
             precision    recall  f1-score   support

          0       1.00      0.48      0.65       369
          1       0.02      1.00      0.03         3

avg / total       0.99      0.48      0.64       372


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 500}, criterion='entropy',
            max_depth=8, max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=1.0, n_estimators=15, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.887 	0.155 	0.073 	0.778 	0.770 	0.579
[[328  41]
 [  1   2]]
             precision    recall  f1-score   support

          0       1.00      0.89      0.94       369
          1       0.05      0.67      0.09         3

avg / total       0.99      0.89      0.93       372


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.01, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='linear',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.551 	0.039 	0.008 	0.608 	0.606 	0.371
[[203 166]
 [  1   2]]
             precision    recall  f1-score   support

          0       1.00      0.55      0.71       369
          1       0.01      0.67      0.02         3

avg / total       0.99      0.55      0.70       372


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=1.0, class_weight={1: 500}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Ran...owski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='uniform'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.535 	-0.023 	-0.004 	0.435 	0.423 	0.175
[[198 171]
 [  2   1]]
             precision    recall  f1-score   support

          0       0.99      0.54      0.70       369
          1       0.01      0.33      0.01         3

avg / total       0.98      0.53      0.69       372


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=4,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.992 	0.000 	0.000 	0.500 	0.000 	0.000
[[369   0]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      1.00       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.99      0.99       372


                estimator min_score mean_score max_score  sd_score       acc  \
4  RandomForestClassifier  -0.57735 -0.0853808   0.43094  0.169862  0.610215   
3    ExtraTreesClassifier  -0.54641  -0.027193   0.54641  0.205594  0.586022   
6      AdaBoostClassifier  -0.74641  -0.265374   0.54641  0.219384  0.887097   
5           MLPClassifier   0.11547   0.388456   0.63094  0.089538  0.483871   
2           SGDClassifier  -0.63094   -0.18873   0.63094  0.228572  0.658602   
7                     SVC  -0.43094  -0.244286         0  0.190896  0.551075   
0              GaussianNB   0.11547    0.11547   0.11547         0  0.991935   
9    KNeighborsClassifier  -0.31547   0.281366   0.57735  0.202608  0.991935   
8        VotingClassifier  -0.51547 -0.0400985   0.34641  0.180791  0.534946   
1      LogisticRegression  -0.43094  0.0254843   0.23094  0.110056  0.505376   

        auc           conf_matrix     f1_c0      f1_c1       kappa  \
4  0.803523  [[224, 145], [0, 3]]  0.755481  0.0397351   0.0243108   
3  0.791328  [[215, 154], [0, 3]]  0.736301     0.0375   0.0220219   
6  0.777778   [[328, 41], [1, 2]]  0.939828  0.0869565   0.0729797   
5  0.739837  [[177, 192], [0, 3]]  0.648352   0.030303   0.0146511   
2  0.662602  [[243, 126], [1, 2]]  0.792822  0.0305344   0.0150113   
7  0.608401  [[203, 166], [1, 2]]  0.708551  0.0233918  0.00766724   
0       0.5    [[369, 0], [3, 0]]  0.995951          0           0   
9       0.5    [[369, 0], [3, 0]]  0.995951          0           0   
8  0.434959  [[198, 171], [2, 1]]  0.695958  0.0114286 -0.00449522   
1  0.420054  [[187, 182], [2, 1]]  0.670251  0.0107527  -0.0051987   

  model_score   prec_c0     prec_c1    rec_c0    rec_c1  
4    0.110928         1   0.0202703  0.607046         1  
3    0.105516         1   0.0191083  0.582656         1  
6    0.155406   0.99696   0.0465116  0.888889  0.666667  
5   0.0859047         1   0.0153846  0.479675         1  
2    0.061225  0.995902    0.015625  0.658537  0.666667  
7   0.0389644  0.995098   0.0119048  0.550136  0.666667  
0           0  0.991935           0         1         0  
9           0  0.991935           0         1         0  
8  -0.0233351      0.99  0.00581395  0.536585  0.333333  
1  -0.0286051  0.989418  0.00546448  0.506775  0.333333  
Elapsed time 13.88 mins 

************************************************************






Standard, lagged(3,4)x1, filter(hp), NT+, UNtruncated






    pca = [0]
    poly = [2]
    ksel = [60]
    imb = [None, SMOTE(), ClusterCentroids() ]
    
	
	

	
	

pre/post: 25/0  win/stride: 500/25  label:start 
filename: stm_sb_modified.csv 
datetime: 2017-05-06 08:35:02.474000 
pca_target: 0 	 poly degree: 2 	 kselect: 60 
Imbalance: None 
Extended target (count):  31485 325
('Total : Processed (count): ', (1240L, 276L), 13)
Final feature (count):  (1240L, 276L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.532 	0.095 	0.018 	0.764 	0.727 	0.553
[[195 174]
 [  0   3]]
             precision    recall  f1-score   support

          0       1.00      0.53      0.69       369
          1       0.02      1.00      0.03         3

avg / total       0.99      0.53      0.69       372


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.01, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.546 	0.097 	0.019 	0.771 	0.736 	0.567
[[200 169]
 [  0   3]]
             precision    recall  f1-score   support

          0       1.00      0.54      0.70       369
          1       0.02      1.00      0.03         3

avg / total       0.99      0.55      0.70       372


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.0001, average=False, class_weight={1: 15}, epsilon=0.1,
       eta0=0.001, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='squared_hinge', n_iter=5, n_jobs=4,
       penalty='none', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.685 	0.068 	0.018 	0.676 	0.676 	0.456
[[253 116]
 [  1   2]]
             precision    recall  f1-score   support

          0       1.00      0.69      0.81       369
          1       0.02      0.67      0.03         3

avg / total       0.99      0.69      0.81       372


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 50},
           criterion='entropy', max_depth=8, max_features=0.75,
           max_leaf_nodes=None, min_impurity_split=1e-07,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=15, n_jobs=4,
           oob_score=False, random_state=None, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.978 	-0.011 	-0.010 	0.493 	0.000 	0.000
[[364   5]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.98      0.98       372


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 50}, criterion='gini',
            max_depth=16, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	-0.005 	-0.004 	0.499 	0.000 	0.000
[[368   1]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.99      0.99       372


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.1, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.968 	-0.014 	-0.012 	0.488 	0.000 	0.000
[[360   9]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.98      0.98       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.97      0.98       372


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='entropy', max_depth=32,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=2.0, n_estimators=80, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.978 	-0.011 	-0.010 	0.493 	0.000 	0.000
[[364   5]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.98      0.98       372


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.5, cache_size=200, class_weight={1: 50}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.970 	-0.013 	-0.012 	0.489 	0.000 	0.000
[[361   8]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.98      0.98       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.97      0.98       372


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 500}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Ran...owski',
           metric_params=None, n_jobs=4, n_neighbors=4, p=2,
           weights='uniform'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	-0.005 	-0.004 	0.499 	0.000 	0.000
[[368   1]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.99      0.99       372


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=1,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.992 	0.000 	0.000 	0.500 	0.000 	0.000
[[369   0]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      1.00       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.99      0.99       372


                estimator  min_score   mean_score  max_score    sd_score  \
1      LogisticRegression -0.0437532    0.0199073   0.117751    0.035373   
0              GaussianNB   0.112386     0.112386   0.112386           0   
2           SGDClassifier -0.0828046    0.0304083    0.17296   0.0401317   
9    KNeighborsClassifier -0.0124847  -0.00400996          0  0.00474625   
4  RandomForestClassifier -0.0105471  -0.00134553   0.138879  0.00749725   
8        VotingClassifier -0.0120321 -0.000322037   0.138879   0.0243916   
3    ExtraTreesClassifier -0.0234586  -0.00144128   0.130901   0.0151386   
6      AdaBoostClassifier -0.0171431    0.0411043   0.234866   0.0692555   
7                     SVC -0.0509991    0.0153277   0.130204   0.0379441   
5           MLPClassifier  -0.015712  -0.00886142  0.0691592   0.0119155   

        acc       auc           conf_matrix     f1_c0      f1_c1       kappa  \
1  0.545699  0.771003  [[200, 169], [0, 3]]  0.702988  0.0342857   0.0187301   
0  0.532258  0.764228  [[195, 174], [0, 3]]  0.691489  0.0333333   0.0177547   
2  0.685484  0.676152  [[253, 116], [1, 2]]  0.812199  0.0330579   0.0176056   
9  0.991935       0.5    [[369, 0], [3, 0]]  0.995951          0           0   
4  0.989247  0.498645    [[368, 1], [3, 0]]  0.994595          0 -0.00404858   
8  0.989247  0.498645    [[368, 1], [3, 0]]  0.994595          0 -0.00404858   
3  0.978495  0.493225    [[364, 5], [3, 0]]   0.98913          0  -0.0101833   
6  0.978495  0.493225    [[364, 5], [3, 0]]   0.98913          0  -0.0101833   
7   0.97043   0.48916    [[361, 8], [3, 0]]  0.984993          0  -0.0118694   
5  0.967742  0.487805    [[360, 9], [3, 0]]  0.983607          0  -0.0122449   

  model_score   prec_c0    prec_c1    rec_c0    rec_c1  
1   0.0972295         1  0.0174419  0.542005         1  
0   0.0946407         1  0.0169492  0.528455         1  
2   0.0677069  0.996063  0.0169492  0.685637  0.666667  
9           0  0.991935          0         1         0  
4 -0.00468124  0.991914          0   0.99729         0  
8 -0.00468124  0.991914          0   0.99729         0  
3  -0.0105245  0.991826          0   0.98645         0  
6  -0.0105245  0.991826          0   0.98645         0  
7  -0.0133672  0.991758          0   0.97832         0  
5  -0.0141976  0.991736          0   0.97561         0  
Elapsed time 31.44 mins 

************************************************************

pre/post: 25/0  win/stride: 500/25  label:start 
filename: stm_sb_modified.csv 
datetime: 2017-05-06 09:06:29.162000 
pca_target: 0 	 poly degree: 2 	 kselect: 60 
Imbalance: SMOTE(k=None, k_neighbors=5, kind='regular', m=None, m_neighbors=10, n_jobs=1,
   out_step=0.5, random_state=None, ratio='auto', svm_estimator=None) 
Extended target (count):  31485 325
('Total : Processed (count): ', (1240L, 276L), 13)
Final feature (count):  (1240L, 276L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.567 	0.102 	0.020 	0.782 	0.751 	0.588
[[208 161]
 [  0   3]]
             precision    recall  f1-score   support

          0       1.00      0.56      0.72       369
          1       0.02      1.00      0.04         3

avg / total       0.99      0.57      0.72       372


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=10, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.833 	0.041 	0.016 	0.585 	0.528 	0.265
[[309  60]
 [  2   1]]
             precision    recall  f1-score   support

          0       0.99      0.84      0.91       369
          1       0.02      0.33      0.03         3

avg / total       0.99      0.83      0.90       372


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.001, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.001, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='perceptron', n_iter=5, n_jobs=4,
       penalty='none', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.632 	0.116 	0.027 	0.814 	0.793 	0.652
[[232 137]
 [  0   3]]
             precision    recall  f1-score   support

          0       1.00      0.63      0.77       369
          1       0.02      1.00      0.04         3

avg / total       0.99      0.63      0.77       372


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 15}, criterion='gini',
           max_depth=None, max_features=0.33, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=50, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.978 	-0.011 	-0.010 	0.493 	0.000 	0.000
[[364   5]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.98      0.98       372


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight='balanced',
            criterion='entropy', max_depth=None, max_features='auto',
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.965 	-0.015 	-0.013 	0.486 	0.000 	0.000
[[359  10]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.97      0.98       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.97      0.97       372


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.1, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.957 	0.134 	0.099 	0.648 	0.566 	0.301
[[355  14]
 [  2   1]]
             precision    recall  f1-score   support

          0       0.99      0.96      0.98       369
          1       0.07      0.33      0.11         3

avg / total       0.99      0.96      0.97       372


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=16,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=1.0, n_estimators=80, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.976 	0.194 	0.172 	0.657 	0.572 	0.306
[[362   7]
 [  2   1]]
             precision    recall  f1-score   support

          0       0.99      0.98      0.99       369
          1       0.12      0.33      0.18         3

avg / total       0.99      0.98      0.98       372


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=10, cache_size=200, class_weight='balanced', coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.952 	0.124 	0.087 	0.645 	0.565 	0.299
[[353  16]
 [  2   1]]
             precision    recall  f1-score   support

          0       0.99      0.96      0.98       369
          1       0.06      0.33      0.10         3

avg / total       0.99      0.95      0.97       372


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=10.0, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', ...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.946 	0.238 	0.155 	0.808 	0.795 	0.615
[[350  19]
 [  1   2]]
             precision    recall  f1-score   support

          0       1.00      0.95      0.97       369
          1       0.10      0.67      0.17         3

avg / total       0.99      0.95      0.97       372


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=1,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.919 	0.086 	0.049 	0.629 	0.555 	0.290
[[341  28]
 [  2   1]]
             precision    recall  f1-score   support

          0       0.99      0.92      0.96       369
          1       0.03      0.33      0.06         3

avg / total       0.99      0.92      0.95       372


                estimator  min_score mean_score max_score   sd_score  \
2           SGDClassifier -0.0377371   0.468315   0.69857   0.203472   
8        VotingClassifier   0.833819   0.887729  0.931235  0.0249615   
0              GaussianNB   0.623203   0.623203  0.623203          0   
6      AdaBoostClassifier   0.771209   0.928887  0.974629  0.0287886   
5           MLPClassifier   0.880965   0.940665  0.966764  0.0191092   
7                     SVC          0   0.714943  0.958373   0.202897   
9    KNeighborsClassifier   0.836379   0.884509  0.935296  0.0297156   
1      LogisticRegression   0.122382   0.619636  0.824338    0.11548   
3    ExtraTreesClassifier   0.652146   0.887015  0.974669   0.101758   
4  RandomForestClassifier   0.790557   0.908069  0.954085  0.0507324   

        acc       auc           conf_matrix     f1_c0      f1_c1      kappa  \
2   0.63172  0.814363  [[232, 137], [0, 3]]  0.772047   0.041958  0.0265872   
8  0.946237  0.807588   [[350, 19], [1, 2]]  0.972222   0.166667   0.154738   
0  0.567204  0.781843  [[208, 161], [0, 3]]  0.720971  0.0359281  0.0204122   
6  0.975806  0.657182    [[362, 7], [2, 1]]  0.987722   0.181818   0.172107   
5  0.956989  0.647696   [[355, 14], [2, 1]]  0.977961   0.111111  0.0990009   
7  0.951613  0.644986   [[353, 16], [2, 1]]  0.975138        0.1  0.0874898   
9  0.919355  0.628726   [[341, 28], [2, 1]]  0.957865     0.0625  0.0485934   
1  0.833333  0.585366   [[309, 60], [2, 1]]  0.908824    0.03125  0.0161249   
3  0.978495  0.493225    [[364, 5], [3, 0]]   0.98913          0 -0.0101833   
4  0.965054   0.48645   [[359, 10], [3, 0]]  0.982216          0 -0.0125628   

  model_score   prec_c0    prec_c1    rec_c0    rec_c1  
2    0.116072         1  0.0214286  0.628726         1  
8    0.238402  0.997151  0.0952381  0.948509  0.666667  
0    0.101545         1  0.0182927  0.563686         1  
6    0.193825  0.994505      0.125   0.98103  0.333333  
5    0.134306  0.994398  0.0666667   0.96206  0.333333  
7    0.124192  0.994366  0.0588235   0.95664  0.333333  
9   0.0858865  0.994169  0.0344828  0.924119  0.333333  
1   0.0412423  0.993569  0.0163934  0.837398  0.333333  
3  -0.0105245  0.991826          0   0.98645         0  
4  -0.0149863  0.991713          0    0.9729         0  
Elapsed time 68.66 mins 

************************************************************

pre/post: 25/0  win/stride: 500/25  label:start 
filename: stm_sb_modified.csv 
datetime: 2017-05-06 10:15:08.851000 
pca_target: 0 	 poly degree: 2 	 kselect: 60 
Imbalance: ClusterCentroids(estimator=None, n_jobs=1, random_state=None, ratio='auto') 
Extended target (count):  31485 325
('Total : Processed (count): ', (1240L, 276L), 13)
Final feature (count):  (1240L, 276L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.567 	0.102 	0.020 	0.782 	0.751 	0.588
[[208 161]
 [  0   3]]
             precision    recall  f1-score   support

          0       1.00      0.56      0.72       369
          1       0.02      1.00      0.04         3

avg / total       0.99      0.57      0.72       372


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.001, class_weight={1: 3}, dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.522 	0.093 	0.017 	0.759 	0.719 	0.543
[[191 178]
 [  0   3]]
             precision    recall  f1-score   support

          0       1.00      0.52      0.68       369
          1       0.02      1.00      0.03         3

avg / total       0.99      0.52      0.68       372


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.0001, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='perceptron', n_iter=5, n_jobs=4,
       penalty='l1', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.543 	0.097 	0.019 	0.770 	0.734 	0.564
[[199 170]
 [  0   3]]
             precision    recall  f1-score   support

          0       1.00      0.54      0.70       369
          1       0.02      1.00      0.03         3

avg / total       0.99      0.54      0.70       372


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=8, max_features='auto', max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.535 	0.095 	0.018 	0.766 	0.729 	0.556
[[196 173]
 [  0   3]]
             precision    recall  f1-score   support

          0       1.00      0.53      0.69       369
          1       0.02      1.00      0.03         3

avg / total       0.99      0.53      0.69       372


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features=0.33, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.358 	0.066 	0.009 	0.676 	0.594 	0.375
[[130 239]
 [  0   3]]
             precision    recall  f1-score   support

          0       1.00      0.35      0.52       369
          1       0.01      1.00      0.02         3

avg / total       0.99      0.36      0.52       372


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.530 	0.035 	0.007 	0.598 	0.594 	0.357
[[195 174]
 [  1   2]]
             precision    recall  f1-score   support

          0       0.99      0.53      0.69       369
          1       0.01      0.67      0.02         3

avg / total       0.99      0.53      0.68       372


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=16,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=0.5, n_estimators=80, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.699 	0.071 	0.019 	0.683 	0.683 	0.465
[[258 111]
 [  1   2]]
             precision    recall  f1-score   support

          0       1.00      0.70      0.82       369
          1       0.02      0.67      0.03         3

avg / total       0.99      0.70      0.82       372


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.1, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='linear',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.368 	0.068 	0.009 	0.682 	0.603 	0.386
[[134 235]
 [  0   3]]
             precision    recall  f1-score   support

          0       1.00      0.36      0.53       369
          1       0.01      1.00      0.02         3

avg / total       0.99      0.37      0.53       372


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...wski',
           metric_params=None, n_jobs=4, n_neighbors=4, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.497 	0.088 	0.015 	0.747 	0.702 	0.518
[[182 187]
 [  0   3]]
             precision    recall  f1-score   support

          0       1.00      0.49      0.66       369
          1       0.02      1.00      0.03         3

avg / total       0.99      0.50      0.66       372


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=5, p=2,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.430 	0.077 	0.012 	0.713 	0.652 	0.450
[[157 212]
 [  0   3]]
             precision    recall  f1-score   support

          0       1.00      0.43      0.60       369
          1       0.01      1.00      0.03         3

avg / total       0.99      0.43      0.59       372


                estimator  min_score mean_score max_score   sd_score  \
0              GaussianNB    0.91547    0.91547   0.91547          0   
2           SGDClassifier   -0.54641   0.348768   0.74641   0.169291   
3    ExtraTreesClassifier    0.51547   0.739611   0.74641   0.027867   
1      LogisticRegression   -0.11547   0.269579   0.54641   0.197997   
8        VotingClassifier  0.0845299   0.346476   0.66188   0.156036   
9    KNeighborsClassifier   -0.11547   0.133599   0.46188   0.127784   
6      AdaBoostClassifier    0.23094   0.585721   0.83094   0.109005   
7                     SVC   -0.23094   0.197777   0.54641   0.188309   
4  RandomForestClassifier    0.51547   0.741364   0.83094  0.0293631   
5           MLPClassifier   -0.11547   0.150817   0.43094   0.133453   

        acc       auc           conf_matrix     f1_c0      f1_c1       kappa  \
0  0.567204  0.781843  [[208, 161], [0, 3]]  0.720971  0.0359281   0.0204122   
2  0.543011  0.769648  [[199, 170], [0, 3]]  0.700704  0.0340909   0.0185306   
3  0.534946  0.765583  [[196, 173], [0, 3]]  0.693805  0.0335196   0.0179454   
1  0.521505  0.758808  [[191, 178], [0, 3]]  0.682143  0.0326087   0.0170126   
8  0.497312  0.746612  [[182, 187], [0, 3]]  0.660617  0.0310881   0.0154552   
9  0.430108  0.712737  [[157, 212], [0, 3]]  0.596958  0.0275229   0.0118036   
6  0.698925  0.682927  [[258, 111], [1, 2]]  0.821656  0.0344828   0.0190705   
7   0.36828  0.681572  [[134, 235], [0, 3]]  0.532803  0.0248963  0.00911317   
4  0.357527  0.676152  [[130, 239], [0, 3]]  0.521042  0.0244898  0.00869682   
5   0.52957  0.597561  [[195, 174], [1, 2]]  0.690265  0.0223464   0.0065922   

  model_score   prec_c0    prec_c1    rec_c0    rec_c1  
0    0.101545         1  0.0182927  0.563686         1  
2   0.0967054         1   0.017341  0.539295         1  
3   0.0951523         1  0.0170455  0.531165         1  
1   0.0926243         1  0.0165746  0.517615         1  
8   0.0882483         1  0.0157895  0.493225         1  
9    0.077051         1  0.0139535  0.425474         1  
6   0.0711528  0.996139  0.0176991  0.699187  0.666667  
7   0.0676568         1   0.012605  0.363144         1  
4   0.0660863         1  0.0123967  0.352304         1  
5   0.0349539  0.994898  0.0113636  0.528455  0.666667  
Elapsed time 16.09 mins 

************************************************************





Standard, lagged(all)x1, filter(tukey), NT+, UNtruncated







    pca = [0]
    poly = [0]
    ksel = [0, 20]
    imb = [None, SMOTE(), ClusterCentroids() ]
	
	
	

pre/post: 25/0  win/stride: 500/25  label:start 
filename: stm_sb_modified.csv 
datetime: 2017-05-06 12:29:26.796000 
pca_target: 0 	 poly degree: 0 	 kselect: 0 
Imbalance: None 
Extended target (count):  31485 325
('Total : Processed (count): ', (1240L, 38L), 13)
Final feature (count):  (1240L, 38L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.578 	0.104 	0.021 	0.787 	0.758 	0.599
[[212 157]
 [  0   3]]
             precision    recall  f1-score   support

          0       1.00      0.57      0.73       369
          1       0.02      1.00      0.04         3

avg / total       0.99      0.58      0.72       372


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.1, class_weight={1: 50}, dual=False,
          fit_intercept=True, intercept_scaling=10, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='sag', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.852 	0.048 	0.020 	0.595 	0.534 	0.271
[[316  53]
 [  2   1]]
             precision    recall  f1-score   support

          0       0.99      0.86      0.92       369
          1       0.02      0.33      0.04         3

avg / total       0.99      0.85      0.91       372


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.0001, average=False, class_weight={1: 15}, epsilon=0.1,
       eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='perceptron', n_iter=5, n_jobs=4,
       penalty='l2', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.812 	-0.042 	-0.016 	0.409 	0.000 	0.000
[[302  67]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.82      0.90       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.81      0.89       372


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 500}, criterion='gini',
           max_depth=8, max_features=0.33, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=50, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.766 	0.091 	0.029 	0.717 	0.715 	0.506
[[283  86]
 [  1   2]]
             precision    recall  f1-score   support

          0       1.00      0.77      0.87       369
          1       0.02      0.67      0.04         3

avg / total       0.99      0.77      0.86       372


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 500},
            criterion='gini', max_depth=8, max_features=0.33,
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.903 	-0.028 	-0.015 	0.455 	0.000 	0.000
[[336  33]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.91      0.95       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.90      0.94       372


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.01, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.970 	-0.013 	-0.012 	0.489 	0.000 	0.000
[[361   8]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.98      0.98       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.97      0.98       372


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight='balanced', criterion='entropy',
            max_depth=32, max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=0.5, n_estimators=80, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.973 	-0.012 	-0.011 	0.491 	0.000 	0.000
[[362   7]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.98      0.99       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.97      0.98       372


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.941 	-0.021 	-0.014 	0.474 	0.000 	0.000
[[350  19]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.95      0.97       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.94      0.96       372


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=1.0, class_weight={1: 500}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Ran...owski',
           metric_params=None, n_jobs=4, n_neighbors=4, p=2,
           weights='uniform'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	-0.005 	-0.004 	0.499 	0.000 	0.000
[[368   1]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.99      0.99       372


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=4,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	-0.007 	-0.006 	0.497 	0.000 	0.000
[[367   2]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.99      0.99       372


                estimator   min_score   mean_score  max_score    sd_score  \
0              GaussianNB   0.0219252    0.0219252  0.0219252           0   
3    ExtraTreesClassifier  -0.0354699  -0.00404219   0.030221  0.00567548   
1      LogisticRegression  -0.0489403    0.0142961    0.14781   0.0328736   
8        VotingClassifier -0.00986884 -0.000994101    0.13805   0.0132185   
9    KNeighborsClassifier  -0.0109234    0.0104216  0.0644204   0.0245147   
6      AdaBoostClassifier  -0.0204088   0.00815188   0.172395   0.0365432   
5           MLPClassifier   -0.014857    0.0175697   0.136335    0.035341   
7                     SVC  -0.0455871    0.0266578   0.131812   0.0358116   
4  RandomForestClassifier  -0.0204578 -8.25952e-05  0.0832452  0.00659988   
2           SGDClassifier  -0.0673193    0.0123564   0.148885   0.0303738   

        acc       auc           conf_matrix     f1_c0      f1_c1       kappa  \
0  0.577957  0.787263  [[212, 157], [0, 3]]  0.729776  0.0368098   0.0213151   
3  0.766129  0.716802   [[283, 86], [1, 2]]  0.866769   0.043956   0.0288081   
1  0.852151  0.594851   [[316, 53], [2, 1]]  0.919942  0.0350877   0.0201149   
8  0.989247  0.498645    [[368, 1], [3, 0]]  0.994595          0 -0.00404858   
9  0.986559   0.49729    [[367, 2], [3, 0]]  0.993234          0 -0.00649351   
6  0.973118  0.490515    [[362, 7], [3, 0]]  0.986376          0  -0.0114192   
5   0.97043   0.48916    [[361, 8], [3, 0]]  0.984993          0  -0.0118694   
7   0.94086  0.474255   [[350, 19], [3, 0]]  0.969529          0  -0.0141264   
4  0.903226  0.455285   [[336, 33], [3, 0]]  0.949153          0  -0.0150068   
2  0.811828  0.409214   [[302, 67], [3, 0]]  0.896142          0  -0.0156799   

  model_score   prec_c0    prec_c1    rec_c0    rec_c1  
0     0.10379         1    0.01875  0.574526         1  
3   0.0912572  0.996479  0.0227273  0.766938  0.666667  
1   0.0481654  0.993711  0.0185185  0.856369  0.333333  
8 -0.00468124  0.991914          0   0.99729         0  
9 -0.00662921  0.991892          0   0.99458         0  
6  -0.0124868  0.991781          0   0.98103         0  
5  -0.0133672  0.991758          0   0.97832         0  
7  -0.0209188  0.991501          0  0.948509         0  
4  -0.0281323   0.99115          0  0.910569         0  
2  -0.0422605  0.990164          0  0.818428         0  
Elapsed time 26.39 mins 

************************************************************

pre/post: 25/0  win/stride: 500/25  label:start 
filename: stm_sb_modified.csv 
datetime: 2017-05-06 12:55:50.013000 
pca_target: 0 	 poly degree: 0 	 kselect: 0 
Imbalance: SMOTE(k=None, k_neighbors=5, kind='regular', m=None, m_neighbors=10, n_jobs=1,
   out_step=0.5, random_state=None, ratio='auto', svm_estimator=None) 
Extended target (count):  31485 325
('Total : Processed (count): ', (1240L, 38L), 13)
Final feature (count):  (1240L, 38L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.589 	0.106 	0.022 	0.793 	0.765 	0.610
[[216 153]
 [  0   3]]
             precision    recall  f1-score   support

          0       1.00      0.59      0.74       369
          1       0.02      1.00      0.04         3

avg / total       0.99      0.59      0.73       372


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=10, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.866 	0.054 	0.024 	0.602 	0.538 	0.274
[[321  48]
 [  2   1]]
             precision    recall  f1-score   support

          0       0.99      0.87      0.93       369
          1       0.02      0.33      0.04         3

avg / total       0.99      0.87      0.92       372


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.001, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='perceptron', n_iter=5, n_jobs=4,
       penalty='l1', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.820 	0.113 	0.042 	0.744 	0.740 	0.539
[[303  66]
 [  1   2]]
             precision    recall  f1-score   support

          0       1.00      0.82      0.90       369
          1       0.03      0.67      0.06         3

avg / total       0.99      0.82      0.89       372


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 500},
           criterion='entropy', max_depth=32, max_features=0.75,
           max_leaf_nodes=None, min_impurity_split=1e-07,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=4,
           oob_score=False, random_state=None, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.973 	-0.012 	-0.011 	0.491 	0.000 	0.000
[[362   7]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.98      0.99       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.97      0.98       372


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight='balanced',
            criterion='entropy', max_depth=None, max_features=0.33,
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.970 	-0.013 	-0.012 	0.489 	0.000 	0.000
[[361   8]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.98      0.98       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.97      0.98       372


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.1, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.970 	-0.013 	-0.012 	0.489 	0.000 	0.000
[[361   8]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.98      0.98       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.97      0.98       372


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='entropy', max_depth=8,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=1.0, n_estimators=50, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.978 	-0.011 	-0.010 	0.493 	0.000 	0.000
[[364   5]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.98      0.98       372


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=10, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	-0.005 	-0.004 	0.499 	0.000 	0.000
[[368   1]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.99      0.99       372


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=10.0, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', ...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.960 	-0.016 	-0.013 	0.484 	0.000 	0.000
[[357  12]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.97      0.98       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.96      0.97       372


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=3,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.965 	-0.015 	-0.013 	0.486 	0.000 	0.000
[[359  10]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.97      0.98       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.97      0.97       372


                estimator  min_score mean_score max_score    sd_score  \
0              GaussianNB   0.614342   0.614342  0.614342           0   
2           SGDClassifier -0.0547692   0.497949   0.88955    0.236078   
1      LogisticRegression  0.0288095   0.646332   0.88139    0.188639   
7                     SVC          0   0.768988  0.983849    0.224798   
6      AdaBoostClassifier   0.794477    0.93951  0.982647   0.0308751   
3    ExtraTreesClassifier   0.614257   0.886277  0.981596    0.112415   
4  RandomForestClassifier   0.728683   0.908284  0.977018   0.0702262   
5           MLPClassifier   0.958906   0.967595  0.975979  0.00443893   
9    KNeighborsClassifier    0.85611   0.912208  0.954258   0.0302768   
8        VotingClassifier   0.866749   0.920668  0.952429   0.0192581   

        acc       auc           conf_matrix     f1_c0      f1_c1       kappa  \
0   0.58871  0.792683  [[216, 153], [0, 3]]  0.738462  0.0377358   0.0222635   
2  0.819892  0.743902   [[303, 66], [1, 2]]  0.900446   0.056338   0.0415321   
1  0.865591  0.601626   [[321, 48], [2, 1]]  0.927746  0.0384615    0.023622   
7  0.989247  0.498645    [[368, 1], [3, 0]]  0.994595          0 -0.00404858   
6  0.978495  0.493225    [[364, 5], [3, 0]]   0.98913          0  -0.0101833   
3  0.973118  0.490515    [[362, 7], [3, 0]]  0.986376          0  -0.0114192   
4   0.97043   0.48916    [[361, 8], [3, 0]]  0.984993          0  -0.0118694   
5   0.97043   0.48916    [[361, 8], [3, 0]]  0.984993          0  -0.0118694   
9  0.965054   0.48645   [[359, 10], [3, 0]]  0.982216          0  -0.0125628   
8  0.959677   0.48374   [[357, 12], [3, 0]]  0.979424          0  -0.0130719   

  model_score   prec_c0    prec_c1    rec_c0    rec_c1  
0    0.106099         1  0.0192308  0.585366         1  
2    0.112883  0.996711  0.0294118  0.821138  0.666667  
1   0.0537538  0.993808  0.0204082  0.869919  0.333333  
7 -0.00468124  0.991914          0   0.99729         0  
6  -0.0105245  0.991826          0   0.98645         0  
3  -0.0124868  0.991781          0   0.98103         0  
4  -0.0133672  0.991758          0   0.97832         0  
5  -0.0133672  0.991758          0   0.97832         0  
9  -0.0149863  0.991713          0    0.9729         0  
8  -0.0164622  0.991667          0   0.96748         0  
Elapsed time 51.66 mins 

************************************************************

pre/post: 25/0  win/stride: 500/25  label:start 
filename: stm_sb_modified.csv 
datetime: 2017-05-06 13:47:29.454000 
pca_target: 0 	 poly degree: 0 	 kselect: 0 
Imbalance: ClusterCentroids(estimator=None, n_jobs=1, random_state=None, ratio='auto') 
Extended target (count):  31485 325
('Total : Processed (count): ', (1240L, 38L), 13)
Final feature (count):  (1240L, 38L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.578 	0.104 	0.021 	0.787 	0.758 	0.599
[[212 157]
 [  0   3]]
             precision    recall  f1-score   support

          0       1.00      0.57      0.73       369
          1       0.02      1.00      0.04         3

avg / total       0.99      0.58      0.72       372


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.001, class_weight={1: 50}, dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.422 	0.076 	0.011 	0.709 	0.646 	0.442
[[154 215]
 [  0   3]]
             precision    recall  f1-score   support

          0       1.00      0.42      0.59       369
          1       0.01      1.00      0.03         3

avg / total       0.99      0.42      0.58       372


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.1, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='constant', loss='perceptron', n_iter=5, n_jobs=4,
       penalty='l2', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.317 	0.060 	0.007 	0.656 	0.558 	0.333
[[115 254]
 [  0   3]]
             precision    recall  f1-score   support

          0       1.00      0.31      0.48       369
          1       0.01      1.00      0.02         3

avg / total       0.99      0.32      0.47       372


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 50}, criterion='gini',
           max_depth=8, max_features=0.33, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=30, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.621 	0.113 	0.025 	0.809 	0.786 	0.641
[[228 141]
 [  0   3]]
             precision    recall  f1-score   support

          0       1.00      0.62      0.76       369
          1       0.02      1.00      0.04         3

avg / total       0.99      0.62      0.76       372


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 50}, criterion='gini',
            max_depth=None, max_features=0.75, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=50, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.605 	0.110 	0.024 	0.801 	0.776 	0.626
[[222 147]
 [  0   3]]
             precision    recall  f1-score   support

          0       1.00      0.60      0.75       369
          1       0.02      1.00      0.04         3

avg / total       0.99      0.60      0.75       372


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(500,), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.750 	0.086 	0.026 	0.709 	0.707 	0.496
[[277  92]
 [  1   2]]
             precision    recall  f1-score   support

          0       1.00      0.75      0.86       369
          1       0.02      0.67      0.04         3

avg / total       0.99      0.75      0.85       372


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='entropy', max_depth=16,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=2.0, n_estimators=50, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.581 	0.104 	0.022 	0.789 	0.760 	0.602
[[213 156]
 [  0   3]]
             precision    recall  f1-score   support

          0       1.00      0.58      0.73       369
          1       0.02      1.00      0.04         3

avg / total       0.99      0.58      0.73       372


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=1, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='linear',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.634 	0.117 	0.027 	0.816 	0.795 	0.655
[[233 136]
 [  0   3]]
             precision    recall  f1-score   support

          0       1.00      0.63      0.77       369
          1       0.02      1.00      0.04         3

avg / total       0.99      0.63      0.77       372


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=10.0, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Ran...owski',
           metric_params=None, n_jobs=4, n_neighbors=4, p=2,
           weights='uniform'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.621 	0.113 	0.025 	0.809 	0.786 	0.641
[[228 141]
 [  0   3]]
             precision    recall  f1-score   support

          0       1.00      0.62      0.76       369
          1       0.02      1.00      0.04         3

avg / total       0.99      0.62      0.76       372


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=5, p=1,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.513 	0.091 	0.016 	0.755 	0.714 	0.534
[[188 181]
 [  0   3]]
             precision    recall  f1-score   support

          0       1.00      0.51      0.68       369
          1       0.02      1.00      0.03         3

avg / total       0.99      0.51      0.67       372


                estimator min_score mean_score max_score  sd_score       acc  \
7                     SVC  -0.51547 -0.0170753   0.43094  0.240045  0.634409   
3    ExtraTreesClassifier  -0.34641   0.329588   0.66188  0.193477  0.620968   
8        VotingClassifier  -0.57735  -0.195857   0.11547  0.127992  0.620968   
4  RandomForestClassifier  -0.23094   0.270774   0.66188  0.209946  0.604839   
6      AdaBoostClassifier  -0.31547   0.517971   0.83094  0.185787  0.580645   
0              GaussianNB       0.4        0.4       0.4         0  0.577957   
9    KNeighborsClassifier  -0.43094  -0.250657         0  0.114427  0.513441   
1      LogisticRegression  -0.54641 -0.0305732   0.23094  0.139733  0.422043   
5           MLPClassifier         0   0.224655       0.4  0.101128      0.75   
2           SGDClassifier  -0.63094  0.0012766   0.57735  0.203081  0.317204   

        auc           conf_matrix     f1_c0      f1_c1       kappa  \
7  0.815718  [[233, 136], [0, 3]]  0.774086  0.0422535   0.0268898   
3  0.808943  [[228, 141], [0, 3]]  0.763819  0.0408163   0.0254181   
8  0.808943  [[228, 141], [0, 3]]  0.763819  0.0408163   0.0254181   
4  0.800813  [[222, 147], [0, 3]]  0.751269  0.0392157   0.0237789   
6  0.788618  [[213, 156], [0, 3]]  0.731959   0.037037   0.0215478   
0  0.787263  [[212, 157], [0, 3]]  0.729776  0.0368098   0.0213151   
9  0.754743  [[188, 181], [0, 3]]  0.675045  0.0320856   0.0164768   
1  0.708672  [[154, 215], [0, 3]]   0.58891  0.0271493   0.0114209   
5  0.708672   [[277, 92], [1, 2]]   0.85626  0.0412371   0.0260135   
2  0.655827  [[115, 254], [0, 3]]  0.475207  0.0230769  0.00724957   

  model_score   prec_c0    prec_c1    rec_c0    rec_c1  
7     0.11674         1  0.0215827  0.631436         1  
3    0.113458         1  0.0208333  0.617886         1  
8    0.113458         1  0.0208333  0.617886         1  
4    0.109693         1       0.02  0.601626         1  
6    0.104361         1  0.0188679  0.577236         1  
0     0.10379         1    0.01875  0.574526         1  
9   0.0911418         1  0.0163043  0.509485         1  
1   0.0757844         1  0.0137615  0.417344         1  
5   0.0858978  0.996403  0.0212766  0.750678  0.666667  
2   0.0603156         1  0.0116732  0.311653         1  
Elapsed time 15.34 mins 

************************************************************

pre/post: 25/0  win/stride: 500/25  label:start 
filename: stm_sb_modified.csv 
datetime: 2017-05-06 14:02:50.014000 
pca_target: 0 	 poly degree: 0 	 kselect: 20 
Imbalance: None 
Extended target (count):  31485 325
('Total : Processed (count): ', (1240L, 38L), 13)
Final feature (count):  (1240L, 38L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.583 	0.105 	0.022 	0.790 	0.762 	0.604
[[214 155]
 [  0   3]]
             precision    recall  f1-score   support

          0       1.00      0.58      0.73       369
          1       0.02      1.00      0.04         3

avg / total       0.99      0.58      0.73       372


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.1, class_weight={1: 50}, dual=False,
          fit_intercept=True, intercept_scaling=0.01, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='sag', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.565 	0.101 	0.020 	0.780 	0.749 	0.586
[[207 162]
 [  0   3]]
             precision    recall  f1-score   support

          0       1.00      0.56      0.72       369
          1       0.02      1.00      0.04         3

avg / total       0.99      0.56      0.71       372


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.1, average=False, class_weight={1: 15}, epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='constant', loss='perceptron', n_iter=5, n_jobs=4,
       penalty='none', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.973 	-0.012 	-0.011 	0.491 	0.000 	0.000
[[362   7]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.98      0.99       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.97      0.98       372


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 50}, criterion='gini',
           max_depth=8, max_features='auto', max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.968 	-0.014 	-0.012 	0.488 	0.000 	0.000
[[360   9]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.98      0.98       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.97      0.98       372


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 500},
            criterion='gini', max_depth=8, max_features=0.33,
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.973 	-0.012 	-0.011 	0.491 	0.000 	0.000
[[362   7]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.98      0.99       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.97      0.98       372


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.978 	-0.011 	-0.010 	0.493 	0.000 	0.000
[[364   5]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.98      0.98       372


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 50}, criterion='entropy', max_depth=8,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=0.5, n_estimators=15, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.981 	-0.009 	-0.009 	0.495 	0.000 	0.000
[[365   4]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.98      0.98       372


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.1, cache_size=200, class_weight={1: 50}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.957 	-0.017 	-0.013 	0.482 	0.000 	0.000
[[356  13]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.96      0.98       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.96      0.97       372


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.992 	0.000 	0.000 	0.500 	0.000 	0.000
[[369   0]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      1.00       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.99      0.99       372


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=2,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	-0.007 	-0.006 	0.497 	0.000 	0.000
[[367   2]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.99      0.99       372


                estimator   min_score   mean_score  max_score    sd_score  \
0              GaussianNB   0.0855639    0.0855639  0.0855639           0   
1      LogisticRegression  -0.0591094    0.0203866   0.121326   0.0377495   
8        VotingClassifier -0.00908019  -0.00288925          0  0.00305329   
9    KNeighborsClassifier -0.00683786     0.023089   0.150774   0.0512083   
6      AdaBoostClassifier  -0.0227458   0.00464454    0.19716   0.0336098   
5           MLPClassifier   -0.014239   0.00230966   0.153108   0.0316943   
2           SGDClassifier  -0.0749578    0.0270273   0.170904   0.0374308   
4  RandomForestClassifier  -0.0173345 -3.24579e-05  0.0525767  0.00475468   
3    ExtraTreesClassifier  -0.0214616 -0.000923388  0.0867133  0.00965177   
7                     SVC  -0.0472278    0.0286749   0.182872    0.040344   

        acc       auc           conf_matrix     f1_c0      f1_c1       kappa  \
0  0.583333  0.789973  [[214, 155], [0, 3]]  0.734134  0.0372671   0.0217834   
1  0.564516  0.780488  [[207, 162], [0, 3]]   0.71875  0.0357143   0.0201932   
8  0.991935       0.5    [[369, 0], [3, 0]]  0.995951          0           0   
9  0.986559   0.49729    [[367, 2], [3, 0]]  0.993234          0 -0.00649351   
6  0.981183   0.49458    [[365, 4], [3, 0]]  0.990502          0 -0.00930233   
5  0.978495  0.493225    [[364, 5], [3, 0]]   0.98913          0  -0.0101833   
2  0.973118  0.490515    [[362, 7], [3, 0]]  0.986376          0  -0.0114192   
4  0.973118  0.490515    [[362, 7], [3, 0]]  0.986376          0  -0.0114192   
3  0.967742  0.487805    [[360, 9], [3, 0]]  0.983607          0  -0.0122449   
7  0.956989  0.482385   [[356, 13], [3, 0]]  0.978022          0  -0.0132789   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
0    0.104936         1  0.0189873  0.579946      1  
1    0.100993         1  0.0181818  0.560976      1  
8           0  0.991935          0         1      0  
9 -0.00662921  0.991892          0   0.99458      0  
6 -0.00940056  0.991848          0   0.98916      0  
5  -0.0105245  0.991826          0   0.98645      0  
2  -0.0124868  0.991781          0   0.98103      0  
4  -0.0124868  0.991781          0   0.98103      0  
3  -0.0141976  0.991736          0   0.97561      0  
7  -0.0171582  0.991643          0   0.96477      0  
Elapsed time 25.51 mins 

************************************************************

pre/post: 25/0  win/stride: 500/25  label:start 
filename: stm_sb_modified.csv 
datetime: 2017-05-06 14:28:20.519000 
pca_target: 0 	 poly degree: 0 	 kselect: 20 
Imbalance: SMOTE(k=None, k_neighbors=5, kind='regular', m=None, m_neighbors=10, n_jobs=1,
   out_step=0.5, random_state=None, ratio='auto', svm_estimator=None) 
Extended target (count):  31485 325
('Total : Processed (count): ', (1240L, 38L), 13)
Final feature (count):  (1240L, 38L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.581 	0.104 	0.022 	0.789 	0.760 	0.602
[[213 156]
 [  0   3]]
             precision    recall  f1-score   support

          0       1.00      0.58      0.73       369
          1       0.02      1.00      0.04         3

avg / total       0.99      0.58      0.73       372


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=10, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.790 	0.028 	0.010 	0.564 	0.514 	0.252
[[293  76]
 [  2   1]]
             precision    recall  f1-score   support

          0       0.99      0.79      0.88       369
          1       0.01      0.33      0.03         3

avg / total       0.99      0.79      0.88       372


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.001, average=False, class_weight='balanced',
       epsilon=0.1, eta0=0.001, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='modified_huber', n_iter=5, n_jobs=4,
       penalty='none', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.772 	0.093 	0.030 	0.720 	0.718 	0.509
[[285  84]
 [  1   2]]
             precision    recall  f1-score   support

          0       1.00      0.77      0.87       369
          1       0.02      0.67      0.04         3

avg / total       0.99      0.77      0.86       372


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 500}, criterion='gini',
           max_depth=None, max_features=0.33, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=30, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.965 	-0.015 	-0.013 	0.486 	0.000 	0.000
[[359  10]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.97      0.98       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.97      0.97       372


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 50}, criterion='gini',
            max_depth=None, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=50, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.952 	-0.018 	-0.014 	0.480 	0.000 	0.000
[[354  15]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.96      0.98       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.95      0.97       372


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.1, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.962 	0.147 	0.113 	0.650 	0.568 	0.302
[[357  12]
 [  2   1]]
             precision    recall  f1-score   support

          0       0.99      0.97      0.98       369
          1       0.08      0.33      0.12         3

avg / total       0.99      0.96      0.97       372


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 50}, criterion='gini', max_depth=16,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=1.0, n_estimators=80, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.957 	-0.017 	-0.013 	0.482 	0.000 	0.000
[[356  13]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.96      0.98       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.96      0.97       372


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=1, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=10, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.968 	-0.014 	-0.012 	0.488 	0.000 	0.000
[[360   9]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.98      0.98       369
          1       0.00      0.00      0.00         3

avg / total       0.98      0.97      0.98       372


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=10.0, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', ...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.944 	0.232 	0.148 	0.806 	0.794 	0.613
[[349  20]
 [  1   2]]
             precision    recall  f1-score   support

          0       1.00      0.95      0.97       369
          1       0.09      0.67      0.16         3

avg / total       0.99      0.94      0.96       372


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=4,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.949 	0.245 	0.162 	0.809 	0.796 	0.616
[[351  18]
 [  1   2]]
             precision    recall  f1-score   support

          0       1.00      0.95      0.97       369
          1       0.10      0.67      0.17         3

avg / total       0.99      0.95      0.97       372


                estimator min_score mean_score max_score   sd_score       acc  \
9    KNeighborsClassifier  0.826923   0.892737  0.940012  0.0346138  0.948925   
8        VotingClassifier  0.812612   0.872118  0.927354  0.0274854  0.943548   
0              GaussianNB  0.627486   0.627486  0.627486          0  0.580645   
2           SGDClassifier -0.173589   0.466719  0.734412   0.194472  0.771505   
5           MLPClassifier  0.885074   0.933457  0.958791  0.0171641  0.962366   
1      LogisticRegression  0.179356   0.573622  0.751227    0.12916  0.790323   
7                     SVC         0   0.671684  0.967569   0.196044  0.967742   
3    ExtraTreesClassifier  0.632336   0.860517  0.967438   0.116229  0.965054   
6      AdaBoostClassifier  0.731597   0.894186  0.958422  0.0452655  0.956989   
4  RandomForestClassifier  0.714965    0.86949  0.943486  0.0753496  0.951613   

        auc           conf_matrix     f1_c0      f1_c1       kappa  \
9  0.808943   [[351, 18], [1, 2]]  0.973648   0.173913    0.162162   
8  0.806233   [[349, 20], [1, 2]]  0.970793       0.16    0.147906   
0  0.788618  [[213, 156], [0, 3]]  0.731959   0.037037   0.0215478   
2  0.719512   [[285, 84], [1, 2]]  0.870229  0.0449438   0.0298233   
5  0.650407   [[357, 12], [2, 1]]  0.980769      0.125    0.113381   
1  0.563686   [[293, 76], [2, 1]]   0.88253      0.025  0.00962523   
7  0.487805    [[360, 9], [3, 0]]  0.983607          0  -0.0122449   
3   0.48645   [[359, 10], [3, 0]]  0.982216          0  -0.0125628   
6  0.482385   [[356, 13], [3, 0]]  0.978022          0  -0.0132789   
4  0.479675   [[354, 15], [3, 0]]  0.975207          0   -0.013624   

  model_score   prec_c0    prec_c1    rec_c0    rec_c1  
9    0.245017  0.997159        0.1   0.95122  0.666667  
8    0.232226  0.997143  0.0909091  0.945799  0.666667  
0    0.104361         1  0.0188679  0.577236         1  
2   0.0931387  0.996503  0.0232558  0.772358  0.666667  
5    0.146505  0.994429  0.0769231   0.96748  0.333333  
1   0.0281183   0.99322   0.012987  0.794038  0.333333  
7  -0.0141976  0.991736          0   0.97561         0  
3  -0.0149863  0.991713          0    0.9729         0  
6  -0.0171582  0.991643          0   0.96477         0  
4  -0.0184824  0.991597          0   0.95935         0  
Elapsed time 45.29 mins 

************************************************************

pre/post: 25/0  win/stride: 500/25  label:start 
filename: stm_sb_modified.csv 
datetime: 2017-05-06 15:13:38.219000 
pca_target: 0 	 poly degree: 0 	 kselect: 20 
Imbalance: ClusterCentroids(estimator=None, n_jobs=1, random_state=None, ratio='auto') 
Extended target (count):  31485 325
('Total : Processed (count): ', (1240L, 38L), 13)
Final feature (count):  (1240L, 38L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.573 	0.103 	0.021 	0.785 	0.754 	0.594
[[210 159]
 [  0   3]]
             precision    recall  f1-score   support

          0       1.00      0.57      0.73       369
          1       0.02      1.00      0.04         3

avg / total       0.99      0.57      0.72       372


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.001, class_weight={1: 3}, dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.403 	0.073 	0.011 	0.699 	0.631 	0.422
[[147 222]
 [  0   3]]
             precision    recall  f1-score   support

          0       1.00      0.40      0.57       369
          1       0.01      1.00      0.03         3

avg / total       0.99      0.40      0.57       372


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.0001, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='modified_huber', n_iter=5, n_jobs=4,
       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.651 	0.059 	0.014 	0.659 	0.658 	0.434
[[240 129]
 [  1   2]]
             precision    recall  f1-score   support

          0       1.00      0.65      0.79       369
          1       0.02      0.67      0.03         3

avg / total       0.99      0.65      0.78       372


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=8, max_features=0.75, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.626 	0.115 	0.026 	0.812 	0.789 	0.647
[[230 139]
 [  0   3]]
             precision    recall  f1-score   support

          0       1.00      0.62      0.77       369
          1       0.02      1.00      0.04         3

avg / total       0.99      0.63      0.76       372


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=32, max_features=0.75, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.651 	0.121 	0.029 	0.824 	0.805 	0.671
[[239 130]
 [  0   3]]
             precision    recall  f1-score   support

          0       1.00      0.65      0.79       369
          1       0.02      1.00      0.04         3

avg / total       0.99      0.65      0.78       372


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.661 	0.062 	0.015 	0.664 	0.664 	0.441
[[244 125]
 [  1   2]]
             precision    recall  f1-score   support

          0       1.00      0.66      0.79       369
          1       0.02      0.67      0.03         3

avg / total       0.99      0.66      0.79       372


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 50}, criterion='gini', max_depth=16,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=2.0, n_estimators=15, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.637 	0.117 	0.027 	0.817 	0.796 	0.657
[[234 135]
 [  0   3]]
             precision    recall  f1-score   support

          0       1.00      0.63      0.78       369
          1       0.02      1.00      0.04         3

avg / total       0.99      0.64      0.77       372


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='linear',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.618 	0.052 	0.012 	0.642 	0.642 	0.414
[[228 141]
 [  1   2]]
             precision    recall  f1-score   support

          0       1.00      0.62      0.76       369
          1       0.01      0.67      0.03         3

avg / total       0.99      0.62      0.76       372


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=1.0, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...owski',
           metric_params=None, n_jobs=4, n_neighbors=4, p=2,
           weights='uniform'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.575 	0.103 	0.021 	0.786 	0.756 	0.596
[[211 158]
 [  0   3]]
             precision    recall  f1-score   support

          0       1.00      0.57      0.73       369
          1       0.02      1.00      0.04         3

avg / total       0.99      0.58      0.72       372


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=4, p=1,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.892 	0.067 	0.033 	0.615 	0.547 	0.282
[[331  38]
 [  2   1]]
             precision    recall  f1-score   support

          0       0.99      0.90      0.94       369
          1       0.03      0.33      0.05         3

avg / total       0.99      0.89      0.94       372


                estimator  min_score mean_score max_score   sd_score  \
4  RandomForestClassifier -0.0309401   0.405183   0.71547   0.158196   
6      AdaBoostClassifier   -0.23094    0.36233   0.74641    0.14551   
3    ExtraTreesClassifier   -0.11547   0.318018   0.71547   0.189009   
8        VotingClassifier   -0.46188 -0.0884057   0.23094   0.148143   
0              GaussianNB    0.71547    0.71547   0.71547          0   
1      LogisticRegression   -0.43094    0.15456   0.46188   0.161389   
5           MLPClassifier        0.2   0.380687   0.54641  0.0758964   
2           SGDClassifier   -0.34641   0.161127   0.57735   0.131432   
7                     SVC   -0.23094   0.147173   0.54641   0.186336   
9    KNeighborsClassifier   -0.57735  -0.202844   0.57735   0.233365   

        acc       auc           conf_matrix     f1_c0      f1_c1      kappa  \
4  0.650538  0.823848  [[239, 130], [0, 3]]  0.786184  0.0441176  0.0287987   
6  0.637097  0.817073  [[234, 135], [0, 3]]  0.776119  0.0425532  0.0271967   
3  0.626344  0.811653  [[230, 139], [0, 3]]  0.767947  0.0413793  0.0259946   
8  0.575269  0.785908  [[211, 158], [0, 3]]  0.727586  0.0365854  0.0210852   
0  0.572581  0.784553  [[210, 159], [0, 3]]  0.725389  0.0363636  0.0208582   
1  0.403226  0.699187  [[147, 222], [0, 3]]  0.569767  0.0263158  0.0105672   
5   0.66129  0.663957  [[244, 125], [1, 2]]  0.794788  0.0307692  0.0152527   
2  0.650538  0.658537  [[240, 129], [1, 2]]  0.786885  0.0298507  0.0143084   
7   0.61828  0.642276  [[228, 141], [1, 2]]  0.762542  0.0273973  0.0117858   
9  0.892473  0.615176   [[331, 38], [2, 1]]   0.94302   0.047619  0.0331384   

  model_score   prec_c0    prec_c1    rec_c0    rec_c1  
4    0.120871         1  0.0225564  0.647696         1  
6    0.117413         1  0.0217391  0.634146         1  
3    0.114754         1  0.0211268  0.623306         1  
8    0.103223         1  0.0186335  0.571816         1  
0     0.10266         1  0.0185185  0.569106         1  
1   0.0728811         1  0.0133333  0.398374         1  
5   0.0618512  0.995918   0.015748  0.661247  0.666667  
2    0.059373  0.995851  0.0152672  0.650407  0.666667  
7    0.052318  0.995633   0.013986  0.617886  0.666667  
9    0.067253  0.993994   0.025641  0.897019  0.333333  
Elapsed time 14.97 mins 

************************************************************

