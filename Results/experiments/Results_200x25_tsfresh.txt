







pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-15 20:51:09.817000 
pca_target: 0 	 poly degree: 0 	 kselect: 0 
Imbalance: None 
Extended target (count):  31485 13
('Total : Processed (count): ', (1252L, 222L), 13)
Final feature (count):  (1252L, 222L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.691 	0.151 	0.045 	0.844 	0.830 	0.710
[[256 116]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.69      0.82       372
        1.0       0.03      1.00      0.06         4

avg / total       0.99      0.69      0.81       376


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.01, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='sag', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.737 	0.056 	0.019 	0.620 	0.608 	0.361
[[275  97]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      0.74      0.85       372
        1.0       0.02      0.50      0.04         4

avg / total       0.98      0.74      0.84       376


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=1, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='perceptron', n_iter=5, n_jobs=4,
       penalty='l2', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.973 	-0.013 	-0.013 	0.492 	0.000 	0.000
[[366   6]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.98      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.97      0.98       376


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 500}, criterion='gini',
           max_depth=8, max_features=0.33, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=30, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.936 	0.185 	0.127 	0.720 	0.686 	0.450
[[350  22]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      0.94      0.97       372
        1.0       0.08      0.50      0.14         4

avg / total       0.98      0.94      0.96       376


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 32 candidates, totalling 160 fits
BEST: MLPClassifier(activation='tanh', alpha=0.01, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.349 	0.329 	0.624 	0.499 	0.231
[[371   1]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.50      0.25      0.33         4

avg / total       0.99      0.99      0.99       376


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='entropy', max_depth=8,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=1.0, n_estimators=50, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	-0.005 	-0.004 	0.499 	0.000 	0.000
[[371   1]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.01, cache_size=200, class_weight={1: 500}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.412 	0.085 	0.014 	0.703 	0.637 	0.430
[[151 221]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.41      0.58       372
        1.0       0.02      1.00      0.03         4

avg / total       0.99      0.41      0.57       376


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 192 candidates, totalling 960 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=1,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


                estimator   min_score   mean_score   max_score     sd_score  \
0              GaussianNB   0.0939808    0.0939808   0.0939808            0   
3    ExtraTreesClassifier  -0.0321875  -0.00141169   0.0281841   0.00468898   
7                     SVC  -0.0308908  -0.00739318   0.0790875    0.0143459   
5           MLPClassifier  -0.0100594  -0.00563281 -0.00162828    0.0020977   
1      LogisticRegression  -0.0418487  -0.00166087    0.112843    0.0303806   
4  RandomForestClassifier -0.00230935 -5.21668e-05           0   0.00028635   
8        VotingClassifier -0.00325665  -0.00014323           0  0.000487089   
9    KNeighborsClassifier          -1    -0.501265           0     0.498743   
6      AdaBoostClassifier  -0.0168245    0.0179422    0.135413    0.0375252   
2           SGDClassifier  -0.0991271    0.0103687    0.137209     0.038516   

        acc       auc           conf_matrix     f1_c0      f1_c1      kappa  \
0  0.691489  0.844086  [[256, 116], [0, 4]]  0.815287  0.0645161  0.0448493   
3   0.93617   0.72043   [[350, 22], [2, 2]]  0.966851   0.142857   0.126935   
7  0.412234  0.702957  [[151, 221], [0, 4]]  0.577438  0.0349345  0.0143291   
5  0.989362  0.623656    [[371, 1], [3, 1]]  0.994638   0.333333   0.328571   
1  0.736702  0.619624   [[275, 97], [2, 2]]  0.847458   0.038835  0.0187685   
4  0.989362       0.5    [[372, 0], [4, 0]]  0.994652          0          0   
8  0.989362       0.5    [[372, 0], [4, 0]]  0.994652          0          0   
9  0.989362       0.5    [[372, 0], [4, 0]]  0.994652          0          0   
6  0.986702  0.498656    [[371, 1], [4, 0]]  0.993307          0 -0.0042735   
2  0.973404  0.491935    [[366, 6], [4, 0]]  0.986523          0  -0.012931   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
0    0.151456         1  0.0333333  0.688172      1  
3    0.185023  0.994318  0.0833333   0.94086    0.5  
7   0.0849485         1  0.0177778  0.405914      1  
5    0.348815  0.991979        0.5  0.997312   0.25  
1   0.0557303   0.99278   0.020202  0.739247    0.5  
4           0  0.989362          0         1      0  
8           0  0.989362          0         1      0  
9           0  0.989362          0         1      0  
6  -0.0053548  0.989333          0  0.997312      0  
2  -0.0132048  0.989189          0  0.983871      0  
Elapsed time 35.10 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-15 22:22:37.674000 
pca_target: 0 	 poly degree: 0 	 kselect: 0 
Imbalance: SMOTE(k=None, k_neighbors=5, kind='regular', m=None, m_neighbors=10, n_jobs=1,
   out_step=0.5, random_state=None, ratio='auto', svm_estimator=None) 
Extended target (count):  31485 13
('Total : Processed (count): ', (1252L, 222L), 13)
Final feature (count):  (1252L, 222L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.739 	0.170 	0.056 	0.868 	0.858 	0.756
[[274  98]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.74      0.85       372
        1.0       0.04      1.00      0.08         4

avg / total       0.99      0.74      0.84       376


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=10, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.960 	-0.018 	-0.016 	0.485 	0.000 	0.000
[[361  11]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.97      0.98       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.96      0.97       376


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.0001, average=False, class_weight='balanced',
       epsilon=0.1, eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='perceptron', n_iter=5, n_jobs=4,
       penalty='l1', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.968 	-0.015 	-0.014 	0.489 	0.000 	0.000
[[364   8]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.98      0.98       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.97      0.97       376


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3},
           criterion='entropy', max_depth=32, max_features='auto',
           max_leaf_nodes=None, min_impurity_split=1e-07,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=15, n_jobs=4,
           oob_score=False, random_state=None, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight='balanced',
            criterion='gini', max_depth=16, max_features='auto',
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 32 candidates, totalling 160 fits
BEST: MLPClassifier(activation='relu', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.981 	0.214 	0.213 	0.620 	0.497 	0.229
[[368   4]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       372
        1.0       0.20      0.25      0.22         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=1.0, n_estimators=50, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	-0.005 	-0.004 	0.499 	0.000 	0.000
[[371   1]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.1, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=10.0, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', ...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.981 	-0.009 	-0.009 	0.496 	0.000 	0.000
[[369   3]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 192 candidates, totalling 960 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=1,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.944 	0.094 	0.071 	0.601 	0.488 	0.221
[[354  18]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.95      0.97       372
        1.0       0.05      0.25      0.09         4

avg / total       0.98      0.94      0.96       376


                estimator min_score mean_score max_score    sd_score  \
0              GaussianNB  0.703565   0.703565  0.703565           0   
5           MLPClassifier  0.975023   0.983797  0.990838  0.00467254   
9    KNeighborsClassifier        -1 -0.0682002  0.934243    0.932264   
3    ExtraTreesClassifier  0.738767   0.972687         1   0.0474626   
4  RandomForestClassifier  0.970353   0.989281   0.99885  0.00499846   
7                     SVC         0   0.831192         1    0.295762   
6      AdaBoostClassifier  0.917524   0.981193         1    0.013874   
8        VotingClassifier  0.913972   0.965519  0.991988   0.0195866   
2           SGDClassifier -0.102873   0.636173   0.97617    0.259336   
1      LogisticRegression  0.543131   0.835572  0.966007    0.131864   

        acc       auc          conf_matrix     f1_c0      f1_c1       kappa  \
0  0.739362   0.86828  [[274, 98], [0, 4]]  0.848297  0.0754717   0.0561475   
5  0.981383  0.619624   [[368, 4], [3, 1]]  0.990579   0.222222    0.212919   
9  0.944149  0.600806  [[354, 18], [3, 1]]  0.971193  0.0869565   0.0706215   
3  0.989362       0.5   [[372, 0], [4, 0]]  0.994652          0           0   
4  0.989362       0.5   [[372, 0], [4, 0]]  0.994652          0           0   
7  0.989362       0.5   [[372, 0], [4, 0]]  0.994652          0           0   
6  0.986702  0.498656   [[371, 1], [4, 0]]  0.993307          0  -0.0042735   
8  0.981383  0.495968   [[369, 3], [4, 0]]  0.990604          0 -0.00920245   
2  0.968085  0.489247   [[364, 8], [4, 0]]  0.983784          0  -0.0143885   
1  0.960106  0.485215  [[361, 11], [4, 0]]  0.979647          0  -0.0158501   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
0    0.169955         1  0.0392157  0.736559      1  
5    0.214278  0.991914        0.2  0.989247   0.25  
9   0.0944298  0.991597  0.0526316  0.951613   0.25  
3           0  0.989362          0         1      0  
4           0  0.989362          0         1      0  
7           0  0.989362          0         1      0  
6  -0.0053548  0.989333          0  0.997312      0  
8 -0.00929961  0.989276          0  0.991935      0  
2   -0.015289   0.98913          0  0.978495      0  
1  -0.0180015  0.989041          0   0.97043      0  
Elapsed time 98.86 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-16 00:01:29.137000 
pca_target: 0 	 poly degree: 0 	 kselect: 0 
Imbalance: SMOTE(k=None, k_neighbors=3, kind='regular', m=None, m_neighbors=10, n_jobs=1,
   out_step=0.5, random_state=None, ratio='auto', svm_estimator=None) 
Extended target (count):  31485 13
('Total : Processed (count): ', (1252L, 222L), 13)
Final feature (count):  (1252L, 222L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.731 	0.167 	0.054 	0.864 	0.854 	0.748
[[271 101]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.73      0.84       372
        1.0       0.04      1.00      0.07         4

avg / total       0.99      0.73      0.83       376


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=10, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.960 	-0.018 	-0.016 	0.485 	0.000 	0.000
[[361  11]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.97      0.98       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.96      0.97       376


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.0001, average=False, class_weight='balanced',
       epsilon=0.1, eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='perceptron', n_iter=5, n_jobs=4,
       penalty='l1', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.957 	-0.019 	-0.016 	0.484 	0.000 	0.000
[[360  12]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.97      0.98       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.96      0.97       376


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=None, max_features='auto', max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=30, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight='balanced',
            criterion='gini', max_depth=16, max_features='auto',
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 32 candidates, totalling 160 fits
BEST: MLPClassifier(activation='relu', alpha=0.01, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.976 	0.178 	0.171 	0.617 	0.496 	0.228
[[366   6]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.98      0.99       372
        1.0       0.14      0.25      0.18         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=1.0, n_estimators=80, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.1, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=10.0, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', ...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.976 	-0.012 	-0.012 	0.493 	0.000 	0.000
[[367   5]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 192 candidates, totalling 960 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=1,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.947 	0.098 	0.075 	0.602 	0.488 	0.222
[[355  17]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.95      0.97       372
        1.0       0.06      0.25      0.09         4

avg / total       0.98      0.95      0.96       376


                estimator  min_score mean_score max_score    sd_score  \
0              GaussianNB   0.703564   0.703564  0.703564           0   
5           MLPClassifier   0.977236   0.985624  0.991988  0.00370584   
9    KNeighborsClassifier         -1 -0.0640052  0.941773    0.936504   
3    ExtraTreesClassifier   0.731232   0.974219         1   0.0472693   
4  RandomForestClassifier   0.964535   0.984023  0.995419  0.00472078   
6      AdaBoostClassifier   0.939673   0.982248         1   0.0127894   
7                     SVC          0   0.843943         1     0.29064   
8        VotingClassifier   0.922428   0.969246  0.991988   0.0169283   
1      LogisticRegression   0.536897   0.834082  0.966007    0.133101   
2           SGDClassifier -0.0608378   0.633935  0.971636     0.25972   

        acc       auc           conf_matrix     f1_c0      f1_c1      kappa  \
0  0.731383  0.864247  [[271, 101], [0, 4]]  0.842924  0.0733945  0.0540056   
5  0.976064  0.616935    [[366, 6], [3, 1]]  0.987854   0.181818   0.170588   
9  0.946809  0.602151   [[355, 17], [3, 1]]  0.972603  0.0909091  0.0748031   
3  0.989362       0.5    [[372, 0], [4, 0]]  0.994652          0          0   
4  0.989362       0.5    [[372, 0], [4, 0]]  0.994652          0          0   
6  0.989362       0.5    [[372, 0], [4, 0]]  0.994652          0          0   
7  0.989362       0.5    [[372, 0], [4, 0]]  0.994652          0          0   
8  0.976064   0.49328    [[367, 5], [4, 0]]  0.987887          0 -0.0119617   
1  0.960106  0.485215   [[361, 11], [4, 0]]  0.979647          0 -0.0158501   
2  0.957447  0.483871   [[360, 12], [4, 0]]  0.978261          0 -0.0162162   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
0     0.16659         1  0.0380952  0.728495      1  
5    0.177507   0.99187   0.142857  0.983871   0.25  
9   0.0981735   0.99162  0.0555556  0.954301   0.25  
3           0  0.989362          0         1      0  
4           0  0.989362          0         1      0  
6           0  0.989362          0         1      0  
7           0  0.989362          0         1      0  
8  -0.0120381  0.989218          0  0.986559      0  
1  -0.0180015  0.989041          0   0.97043      0  
2  -0.0188278  0.989011          0  0.967742      0  
Elapsed time 96.09 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-16 01:37:34.391000 
pca_target: 0 	 poly degree: 0 	 kselect: 0 
Imbalance: ClusterCentroids(estimator=None, n_jobs=1, random_state=None, ratio='auto') 
Extended target (count):  31485 13
('Total : Processed (count): ', (1252L, 222L), 13)
Final feature (count):  (1252L, 222L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.689 	0.151 	0.044 	0.843 	0.828 	0.707
[[255 117]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.69      0.81       372
        1.0       0.03      1.00      0.06         4

avg / total       0.99      0.69      0.81       376


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=1, class_weight={1: 500}, dual=False, fit_intercept=True,
          intercept_scaling=5, max_iter=100, multi_class='ovr', n_jobs=4,
          penalty='l2', random_state=None, solver='sag', tol=0.0001,
          verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.505 	0.103 	0.021 	0.750 	0.707 	0.525
[[186 186]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.50      0.67       372
        1.0       0.02      1.00      0.04         4

avg / total       0.99      0.51      0.66       376


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.001, average=False, class_weight={1: 50}, epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='invscaling', loss='squared_hinge', n_iter=5,
       n_jobs=4, penalty='l2', power_t=0.5, random_state=None,
       shuffle=True, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.588 	0.070 	0.017 	0.668 	0.663 	0.447
[[218 154]
 [  1   3]]
             precision    recall  f1-score   support

        0.0       1.00      0.59      0.74       372
        1.0       0.02      0.75      0.04         4

avg / total       0.99      0.59      0.73       376


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=8, max_features=0.75, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=50, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.540 	0.110 	0.024 	0.767 	0.731 	0.560
[[199 173]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.53      0.70       372
        1.0       0.02      1.00      0.04         4

avg / total       0.99      0.54      0.69       376


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=16, max_features=0.75, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=50, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.609 	0.127 	0.032 	0.802 	0.778 	0.629
[[225 147]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.60      0.75       372
        1.0       0.03      1.00      0.05         4

avg / total       0.99      0.61      0.75       376


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 32 candidates, totalling 160 fits
BEST: MLPClassifier(activation='relu', alpha=0.01, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.886 	0.126 	0.067 	0.695 	0.667 	0.428
[[331  41]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      0.89      0.94       372
        1.0       0.05      0.50      0.09         4

avg / total       0.98      0.89      0.93       376


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=0.5, n_estimators=15, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.609 	0.127 	0.032 	0.802 	0.778 	0.629
[[225 147]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.60      0.75       372
        1.0       0.03      1.00      0.05         4

avg / total       0.99      0.61      0.75       376


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.633 	0.081 	0.021 	0.691 	0.688 	0.479
[[235 137]
 [  1   3]]
             precision    recall  f1-score   support

        0.0       1.00      0.63      0.77       372
        1.0       0.02      0.75      0.04         4

avg / total       0.99      0.63      0.77       376


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 500}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Ran...owski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='uniform'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.662 	0.036 	0.010 	0.582 	0.576 	0.327
[[247 125]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      0.66      0.80       372
        1.0       0.02      0.50      0.03         4

avg / total       0.98      0.66      0.79       376


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 192 candidates, totalling 960 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=5, p=2,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.803 	-0.050 	-0.021 	0.406 	0.000 	0.000
[[302  70]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.81      0.89       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.80      0.88       376


                estimator  min_score mean_score max_score  sd_score       acc  \
0              GaussianNB   0.812156   0.812156  0.812156         0   0.68883   
4  RandomForestClassifier    -0.1283   0.642985         1    0.2672  0.609043   
6      AdaBoostClassifier -0.0171889   0.765853         1  0.240787  0.609043   
3    ExtraTreesClassifier   0.427255   0.808095         1  0.116739  0.539894   
1      LogisticRegression  -0.701045  -0.132381  0.478822  0.269066  0.505319   
5           MLPClassifier  -0.478822  -0.137642    0.1283  0.143395  0.885638   
7                     SVC  -0.273789 -0.0577427  0.367711  0.108857  0.632979   
2           SGDClassifier  -0.812156  0.0907972  0.589933  0.262362  0.587766   
8        VotingClassifier  -0.812156   -0.33845    0.2566   0.29295  0.662234   
9    KNeighborsClassifier         -1  -0.602402  0.145489  0.420604  0.803191   

        auc           conf_matrix     f1_c0      f1_c1      kappa model_score  \
0  0.842742  [[255, 117], [0, 4]]  0.813397      0.064   0.044317    0.150534   
4  0.802419  [[225, 147], [0, 4]]  0.753769  0.0516129  0.0315391    0.126579   
6  0.802419  [[225, 147], [0, 4]]  0.753769  0.0516129  0.0315391    0.126579   
3  0.767473  [[199, 173], [0, 4]]  0.697023  0.0441989  0.0238896    0.109951   
1      0.75  [[186, 186], [0, 4]]  0.666667  0.0412371  0.0208333    0.102598   
5  0.694892   [[331, 41], [2, 2]]  0.939007  0.0851064  0.0669437    0.125652   
7   0.69086  [[235, 137], [1, 3]]  0.773026  0.0416667  0.0214243   0.0810078   
2  0.668011  [[218, 154], [1, 3]]  0.737733  0.0372671  0.0168691   0.0699031   
8  0.581989  [[247, 125], [2, 2]]  0.795491  0.0305344  0.0101161   0.0355702   
9  0.405914   [[302, 70], [4, 0]]  0.890855          0 -0.0205399   -0.049596   

    prec_c0    prec_c1    rec_c0 rec_c1  
0         1  0.0330579  0.685484      1  
4         1  0.0264901  0.604839      1  
6         1  0.0264901  0.604839      1  
3         1  0.0225989  0.534946      1  
1         1  0.0210526       0.5      1  
5  0.993994  0.0465116  0.889785    0.5  
7  0.995763  0.0214286   0.63172   0.75  
2  0.995434  0.0191083  0.586022   0.75  
8  0.991968   0.015748  0.663978    0.5  
9  0.986928          0  0.811828      0  
Elapsed time 15.70 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-16 01:53:16.657000 
pca_target: 0 	 poly degree: 0 	 kselect: 0 
Imbalance: None 
Extended target (count):  31485 13
('Total : Processed (count): ', (1252L, 222L), 13)
Final feature (count):  (1252L, 222L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.691 	0.151 	0.045 	0.844 	0.830 	0.710
[[256 116]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.69      0.82       372
        1.0       0.03      1.00      0.06         4

avg / total       0.99      0.69      0.81       376


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.001, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='sag', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.745 	0.116 	0.039 	0.747 	0.747 	0.559
[[277  95]
 [  1   3]]
             precision    recall  f1-score   support

        0.0       1.00      0.74      0.85       372
        1.0       0.03      0.75      0.06         4

avg / total       0.99      0.74      0.84       376


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.5, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='perceptron', n_iter=5, n_jobs=4,
       penalty='none', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.715 	-0.064 	-0.021 	0.362 	0.000 	0.000
[[269 103]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.72      0.83       372
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.72      0.83       376


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 500}, criterion='gini',
           max_depth=8, max_features=0.33, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=30, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.944 	0.201 	0.145 	0.724 	0.689 	0.453
[[353  19]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      0.95      0.97       372
        1.0       0.10      0.50      0.16         4

avg / total       0.98      0.94      0.96       376


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 32 candidates, totalling 160 fits
BEST: MLPClassifier(activation='tanh', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	-0.005 	-0.004 	0.499 	0.000 	0.000
[[371   1]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 500}, criterion='gini', max_depth=16,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=0.5, n_estimators=15, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	-0.005 	-0.004 	0.499 	0.000 	0.000
[[371   1]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.01, cache_size=200, class_weight={1: 500}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.412 	0.085 	0.014 	0.703 	0.637 	0.430
[[151 221]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.41      0.58       372
        1.0       0.02      1.00      0.03         4

avg / total       0.99      0.41      0.57       376


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 192 candidates, totalling 960 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=1,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


                estimator   min_score   mean_score   max_score     sd_score  \
0              GaussianNB   0.0939808    0.0939808   0.0939808            0   
1      LogisticRegression  -0.0418487  -0.00241688    0.129292    0.0301938   
3    ExtraTreesClassifier  -0.0366615  -0.00156716   0.0774103   0.00643602   
7                     SVC  -0.0308908  -0.00739318   0.0790875    0.0143459   
4  RandomForestClassifier -0.00230935 -4.71219e-05           0  0.000280849   
8        VotingClassifier -0.00230935  -0.00010869           0  0.000415268   
9    KNeighborsClassifier          -1    -0.501265           0     0.498743   
5           MLPClassifier  -0.0109131  -0.00490166 -0.00162828   0.00204109   
6      AdaBoostClassifier  -0.0176987    0.0195567    0.141661    0.0388359   
2           SGDClassifier    -0.13477    0.0105975    0.142482    0.0388208   

        acc       auc           conf_matrix     f1_c0      f1_c1      kappa  \
0  0.691489  0.844086  [[256, 116], [0, 4]]  0.815287  0.0645161  0.0448493   
1  0.744681  0.747312   [[277, 95], [1, 3]]  0.852308  0.0588235  0.0391823   
3  0.944149  0.724462   [[353, 19], [2, 2]]  0.971114       0.16   0.144714   
7  0.412234  0.702957  [[151, 221], [0, 4]]  0.577438  0.0349345  0.0143291   
4  0.989362       0.5    [[372, 0], [4, 0]]  0.994652          0          0   
8  0.989362       0.5    [[372, 0], [4, 0]]  0.994652          0          0   
9  0.989362       0.5    [[372, 0], [4, 0]]  0.994652          0          0   
5  0.986702  0.498656    [[371, 1], [4, 0]]  0.993307          0 -0.0042735   
6  0.986702  0.498656    [[371, 1], [4, 0]]  0.993307          0 -0.0042735   
2  0.715426  0.361559  [[269, 103], [4, 0]]  0.834109          0 -0.0209095   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
0    0.151456         1  0.0333333  0.688172      1  
1    0.115595  0.996403  0.0306122  0.744624   0.75  
3    0.200563  0.994366  0.0952381  0.948925    0.5  
7   0.0849485         1  0.0177778  0.405914      1  
4           0  0.989362          0         1      0  
8           0  0.989362          0         1      0  
9           0  0.989362          0         1      0  
5  -0.0053548  0.989333          0  0.997312      0  
6  -0.0053548  0.989333          0  0.997312      0  
2  -0.0636936  0.985348          0  0.723118      0  
Elapsed time 34.91 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-16 02:28:11.093000 
pca_target: 0 	 poly degree: 0 	 kselect: 40 
Imbalance: SMOTE(k=None, k_neighbors=5, kind='regular', m=None, m_neighbors=10, n_jobs=1,
   out_step=0.5, random_state=None, ratio='auto', svm_estimator=None) 
Extended target (count):  31485 13
('Total : Processed (count): ', (1252L, 222L), 13)
Final feature (count):  (1252L, 222L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.715 	0.160 	0.050 	0.856 	0.844 	0.733
[[265 107]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.71      0.83       372
        1.0       0.04      1.00      0.07         4

avg / total       0.99      0.72      0.82       376


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=10, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=5, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.910 	-0.031 	-0.019 	0.460 	0.000 	0.000
[[342  30]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.92      0.95       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.91      0.94       376


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.001, average=False, class_weight='balanced',
       epsilon=0.1, eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='squared_hinge', n_iter=5, n_jobs=4,
       penalty='none', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.949 	-0.021 	-0.017 	0.480 	0.000 	0.000
[[357  15]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.96      0.97       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.95      0.96       376


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 50},
           criterion='entropy', max_depth=None, max_features='auto',
           max_leaf_nodes=None, min_impurity_split=1e-07,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=4,
           oob_score=False, random_state=None, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight='balanced',
            criterion='entropy', max_depth=None, max_features='auto',
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.981 	-0.009 	-0.009 	0.496 	0.000 	0.000
[[369   3]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 32 candidates, totalling 160 fits
BEST: MLPClassifier(activation='relu', alpha=0.01, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.979 	-0.011 	-0.011 	0.495 	0.000 	0.000
[[368   4]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight='balanced', criterion='gini',
            max_depth=16, max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=1.0, n_estimators=80, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.5, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=10.0, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', ...owski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='uniform'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.968 	0.144 	0.130 	0.613 	0.494 	0.226
[[363   9]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.98      0.98       372
        1.0       0.10      0.25      0.14         4

avg / total       0.98      0.97      0.97       376


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 192 candidates, totalling 960 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.957 	-0.019 	-0.016 	0.484 	0.000 	0.000
[[360  12]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.97      0.98       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.96      0.97       376


                estimator min_score mean_score max_score    sd_score  \
0              GaussianNB  0.633135   0.633135  0.633135           0   
8        VotingClassifier  0.863009   0.934284  0.969344   0.0229514   
3    ExtraTreesClassifier  0.695363   0.940016    0.9977   0.0735562   
6      AdaBoostClassifier  0.879202    0.96538    0.9977    0.020314   
7                     SVC         0   0.833793         1     0.22286   
4  RandomForestClassifier    0.9125   0.956819  0.982914   0.0204627   
5           MLPClassifier  0.971714   0.978911  0.987459  0.00290597   
9    KNeighborsClassifier        -1 -0.0541956  0.944039      0.9461   
2           SGDClassifier -0.189366    0.59641  0.925581    0.236739   
1      LogisticRegression  0.401514   0.758469  0.937551    0.145225   

        acc       auc           conf_matrix     f1_c0      f1_c1       kappa  \
0  0.715426  0.856183  [[265, 107], [0, 4]]  0.832025  0.0695652   0.0500567   
8  0.968085  0.612903    [[363, 9], [3, 1]]   0.98374   0.142857     0.12963   
3  0.989362       0.5    [[372, 0], [4, 0]]  0.994652          0           0   
6  0.989362       0.5    [[372, 0], [4, 0]]  0.994652          0           0   
7  0.989362       0.5    [[372, 0], [4, 0]]  0.994652          0           0   
4  0.981383  0.495968    [[369, 3], [4, 0]]  0.990604          0 -0.00920245   
5  0.978723  0.494624    [[368, 4], [4, 0]]  0.989247          0  -0.0107527   
9  0.957447  0.483871   [[360, 12], [4, 0]]  0.978261          0  -0.0162162   
2  0.949468  0.479839   [[357, 15], [4, 0]]  0.974079          0  -0.0170843   
1  0.909574  0.459677   [[342, 30], [4, 0]]  0.952646          0  -0.0191327   

  model_score   prec_c0   prec_c1    rec_c0 rec_c1  
0    0.160221         1  0.036036  0.712366      1  
8    0.143978  0.991803       0.1  0.975806   0.25  
3           0  0.989362         0         1      0  
6           0  0.989362         0         1      0  
7           0  0.989362         0         1      0  
4 -0.00929961  0.989276         0  0.991935      0  
5  -0.0107527  0.989247         0  0.989247      0  
9  -0.0188278  0.989011         0  0.967742      0  
2  -0.0211374   0.98892         0  0.959677      0  
1  -0.0305338  0.988439         0  0.919355      0  
Elapsed time 39.40 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-16 03:07:35.079000 
pca_target: 0 	 poly degree: 0 	 kselect: 40 
Imbalance: SMOTE(k=None, k_neighbors=3, kind='regular', m=None, m_neighbors=10, n_jobs=1,
   out_step=0.5, random_state=None, ratio='auto', svm_estimator=None) 
Extended target (count):  31485 13
('Total : Processed (count): ', (1252L, 222L), 13)
Final feature (count):  (1252L, 222L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.723 	0.163 	0.052 	0.860 	0.849 	0.741
[[268 104]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.72      0.84       372
        1.0       0.04      1.00      0.07         4

avg / total       0.99      0.72      0.83       376


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=10, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.926 	-0.027 	-0.019 	0.468 	0.000 	0.000
[[348  24]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.94      0.96       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.93      0.95       376


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.001, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.001, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='modified_huber', n_iter=5, n_jobs=4,
       penalty='none', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.926 	-0.027 	-0.019 	0.468 	0.000 	0.000
[[348  24]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.94      0.96       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.93      0.95       376


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3},
           criterion='entropy', max_depth=None, max_features='auto',
           max_leaf_nodes=None, min_impurity_split=1e-07,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=4,
           oob_score=False, random_state=None, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight='balanced',
            criterion='entropy', max_depth=32, max_features='auto',
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.981 	-0.009 	-0.009 	0.496 	0.000 	0.000
[[369   3]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 32 candidates, totalling 160 fits
BEST: MLPClassifier(activation='tanh', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.976 	-0.012 	-0.012 	0.493 	0.000 	0.000
[[367   5]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 50}, criterion='entropy',
            max_depth=16, max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=1.0, n_estimators=80, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.1, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=10.0, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', ...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.976 	-0.012 	-0.012 	0.493 	0.000 	0.000
[[367   5]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 192 candidates, totalling 960 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=4,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.957 	0.117 	0.096 	0.608 	0.491 	0.224
[[359  13]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.97      0.98       372
        1.0       0.07      0.25      0.11         4

avg / total       0.98      0.96      0.97       376


                estimator  min_score mean_score max_score    sd_score  \
0              GaussianNB   0.646024   0.646024  0.646024           0   
9    KNeighborsClassifier         -1  -0.050263  0.951712    0.950057   
3    ExtraTreesClassifier   0.699963   0.948362   0.99885    0.067024   
6      AdaBoostClassifier   0.922994   0.970707   0.99885   0.0179868   
7                     SVC          0   0.842728         1    0.222611   
4  RandomForestClassifier   0.917265   0.961445  0.985118   0.0176245   
5           MLPClassifier   0.969398   0.979116  0.987427  0.00463528   
8        VotingClassifier   0.871245   0.937643  0.971721   0.0238953   
1      LogisticRegression   0.417086   0.756633  0.934458    0.143009   
2           SGDClassifier -0.0314271   0.594542  0.940583    0.233712   

        acc       auc           conf_matrix     f1_c0      f1_c1       kappa  \
0  0.723404  0.860215  [[268, 104], [0, 4]]    0.8375  0.0714286   0.0519783   
9  0.957447  0.607527   [[359, 13], [3, 1]]  0.978202   0.111111   0.0961538   
3  0.989362       0.5    [[372, 0], [4, 0]]  0.994652          0           0   
6  0.989362       0.5    [[372, 0], [4, 0]]  0.994652          0           0   
7  0.989362       0.5    [[372, 0], [4, 0]]  0.994652          0           0   
4  0.981383  0.495968    [[369, 3], [4, 0]]  0.990604          0 -0.00920245   
5  0.976064   0.49328    [[367, 5], [4, 0]]  0.987887          0  -0.0119617   
8  0.976064   0.49328    [[367, 5], [4, 0]]  0.987887          0  -0.0119617   
1  0.925532  0.467742   [[348, 24], [4, 0]]  0.961326          0  -0.0185759   
2  0.925532  0.467742   [[348, 24], [4, 0]]  0.961326          0  -0.0185759   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
0    0.163348         1   0.037037   0.72043      1  
9    0.116528  0.991713  0.0714286  0.965054   0.25  
3           0  0.989362          0         1      0  
6           0  0.989362          0         1      0  
7           0  0.989362          0         1      0  
4 -0.00929961  0.989276          0  0.991935      0  
5  -0.0120381  0.989218          0  0.986559      0  
8  -0.0120381  0.989218          0  0.986559      0  
1  -0.0270765  0.988636          0  0.935484      0  
2  -0.0270765  0.988636          0  0.935484      0  
Elapsed time 37.55 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-16 03:45:08.259000 
pca_target: 0 	 poly degree: 0 	 kselect: 40 
Imbalance: ClusterCentroids(estimator=None, n_jobs=1, random_state=None, ratio='auto') 
Extended target (count):  31485 13
('Total : Processed (count): ', (1252L, 222L), 13)
Final feature (count):  (1252L, 222L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.676 	0.146 	0.042 	0.836 	0.820 	0.694
[[250 122]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.67      0.80       372
        1.0       0.03      1.00      0.06         4

avg / total       0.99      0.68      0.80       376


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=1, class_weight={1: 3}, dual=False, fit_intercept=True,
          intercept_scaling=0.1, max_iter=100, multi_class='ovr', n_jobs=4,
          penalty='l2', random_state=None, solver='sag', tol=0.0001,
          verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.745 	0.058 	0.020 	0.624 	0.611 	0.364
[[278  94]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      0.75      0.85       372
        1.0       0.02      0.50      0.04         4

avg / total       0.98      0.74      0.84       376


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.0001, average=False, class_weight={1: 15}, epsilon=0.1,
       eta0=0.001, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='squared_hinge', n_iter=5, n_jobs=4,
       penalty='l2', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.487 	0.099 	0.019 	0.741 	0.694 	0.506
[[179 193]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.48      0.65       372
        1.0       0.02      1.00      0.04         4

avg / total       0.99      0.49      0.64       376


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=16, max_features='auto', max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.577 	0.119 	0.028 	0.786 	0.757 	0.597
[[213 159]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.57      0.73       372
        1.0       0.02      1.00      0.05         4

avg / total       0.99      0.58      0.72       376


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features=0.75, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=30, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.609 	0.127 	0.032 	0.802 	0.778 	0.629
[[225 147]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.60      0.75       372
        1.0       0.03      1.00      0.05         4

avg / total       0.99      0.61      0.75       376


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 32 candidates, totalling 160 fits
BEST: MLPClassifier(activation='relu', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.790 	0.135 	0.051 	0.770 	0.770 	0.590
[[294  78]
 [  1   3]]
             precision    recall  f1-score   support

        0.0       1.00      0.79      0.88       372
        1.0       0.04      0.75      0.07         4

avg / total       0.99      0.79      0.87       376


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=0.5, n_estimators=15, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.609 	0.127 	0.032 	0.802 	0.778 	0.629
[[225 147]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.60      0.75       372
        1.0       0.03      1.00      0.05         4

avg / total       0.99      0.61      0.75       376


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=10, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.351 	0.074 	0.011 	0.672 	0.587 	0.367
[[128 244]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.34      0.51       372
        1.0       0.02      1.00      0.03         4

avg / total       0.99      0.35      0.51       376


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 500}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Ran...owski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='uniform'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.524 	0.106 	0.022 	0.759 	0.720 	0.544
[[193 179]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.52      0.68       372
        1.0       0.02      1.00      0.04         4

avg / total       0.99      0.52      0.68       376


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 192 candidates, totalling 960 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=5, p=1,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.766 	0.005 	0.002 	0.511 	0.439 	0.183
[[287  85]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.77      0.87       372
        1.0       0.01      0.25      0.02         4

avg / total       0.98      0.77      0.86       376


                estimator min_score mean_score max_score   sd_score       acc  \
0              GaussianNB  0.906078   0.906078  0.906078          0  0.675532   
4  RandomForestClassifier  0.367711   0.883104         1   0.121826  0.609043   
6      AdaBoostClassifier  0.111111    0.85291         1   0.143932  0.609043   
3    ExtraTreesClassifier  0.461633   0.794157         1   0.099792  0.577128   
5           MLPClassifier  0.273789   0.373946  0.478822  0.0412176  0.789894   
8        VotingClassifier  0.444444   0.706745         1   0.126801  0.523936   
2           SGDClassifier -0.496011    0.25033  0.624311   0.163818  0.486702   
7                     SVC         0   0.247495  0.589933    0.15132  0.351064   
1      LogisticRegression -0.111111   0.268937  0.589933   0.172289  0.744681   
9    KNeighborsClassifier        -1  -0.393755  0.555556   0.620358  0.765957   

        auc           conf_matrix     f1_c0      f1_c1      kappa model_score  \
0  0.836022  [[250, 122], [0, 4]]  0.803859  0.0615385  0.0417781    0.146064   
4  0.802419  [[225, 147], [0, 4]]  0.753769  0.0516129  0.0315391    0.126579   
6  0.802419  [[225, 147], [0, 4]]  0.753769  0.0516129  0.0315391    0.126579   
3   0.78629  [[213, 159], [0, 4]]  0.728205  0.0479042  0.0277127    0.118537   
5  0.770161   [[294, 78], [1, 3]]  0.881559  0.0705882  0.0513541    0.134835   
8  0.759409  [[193, 179], [0, 4]]  0.683186  0.0427807  0.0224262    0.106491   
2  0.740591  [[179, 193], [0, 4]]  0.649728   0.039801  0.0193514   0.0988444   
7  0.672043  [[128, 244], [0, 4]]     0.512   0.031746  0.0110383   0.0744968   
1  0.623656   [[278, 94], [2, 2]]  0.852761       0.04  0.0199826   0.0581878   
9  0.510753   [[287, 85], [3, 1]]  0.867069  0.0222222  0.0019305  0.00525291   

    prec_c0    prec_c1    rec_c0 rec_c1  
0         1   0.031746  0.672043      1  
4         1  0.0264901  0.604839      1  
6         1  0.0264901  0.604839      1  
3         1  0.0245399  0.572581      1  
5   0.99661   0.037037  0.790323   0.75  
8         1  0.0218579  0.518817      1  
2         1  0.0203046  0.481183      1  
7         1   0.016129  0.344086      1  
1  0.992857  0.0208333  0.747312    0.5  
9  0.989655  0.0116279  0.771505   0.25  
Elapsed time 14.28 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-16 03:59:24.874000 
pca_target: 0 	 poly degree: 0 	 kselect: 40 
Imbalance: None 
Extended target (count):  31485 13
('Total : Processed (count): ', (1252L, 222L), 13)
Final feature (count):  (1252L, 222L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.710 	0.158 	0.049 	0.853 	0.841 	0.728
[[263 109]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.71      0.83       372
        1.0       0.04      1.00      0.07         4

avg / total       0.99      0.71      0.82       376


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.1, class_weight={1: 500}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='sag', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.561 	0.115 	0.026 	0.778 	0.746 	0.581
[[207 165]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.56      0.72       372
        1.0       0.02      1.00      0.05         4

avg / total       0.99      0.56      0.71       376


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=1, average=False, class_weight={1: 50}, epsilon=0.1,
       eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='perceptron', n_iter=5, n_jobs=4,
       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.500 	0.102 	0.020 	0.747 	0.703 	0.520
[[184 188]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.49      0.66       372
        1.0       0.02      1.00      0.04         4

avg / total       0.99      0.50      0.66       376


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 500},
           criterion='entropy', max_depth=8, max_features='auto',
           max_leaf_nodes=None, min_impurity_split=1e-07,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=15, n_jobs=4,
           oob_score=False, random_state=None, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.880 	0.268 	0.134 	0.940 	0.938 	0.890
[[327  45]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.88      0.94       372
        1.0       0.08      1.00      0.15         4

avg / total       0.99      0.88      0.93       376


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=50, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 32 candidates, totalling 160 fits
BEST: MLPClassifier(activation='relu', alpha=0.5, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	-0.005 	-0.004 	0.499 	0.000 	0.000
[[371   1]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 500}, criterion='gini', max_depth=8,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=2.0, n_estimators=80, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.979 	0.194 	0.190 	0.618 	0.497 	0.228
[[367   5]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       372
        1.0       0.17      0.25      0.20         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.593 	0.122 	0.030 	0.794 	0.767 	0.613
[[219 153]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.59      0.74       372
        1.0       0.03      1.00      0.05         4

avg / total       0.99      0.59      0.73       376


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 192 candidates, totalling 960 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=1,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


                estimator   min_score   mean_score   max_score    sd_score  \
3    ExtraTreesClassifier  -0.0384046  -0.00245606   0.0237947  0.00658607   
0              GaussianNB   0.0721204    0.0721204   0.0721204           0   
7                     SVC  -0.0482356   0.00455535    0.088503   0.0277808   
1      LogisticRegression  -0.0409022    0.0194195    0.109012   0.0386538   
2           SGDClassifier   -0.114014    0.0290598    0.176511   0.0375439   
6      AdaBoostClassifier  -0.0166687  -0.00504666    0.130998   0.0144809   
4  RandomForestClassifier -0.00950394 -0.000317716           0  0.00107857   
8        VotingClassifier   -0.012458  -0.00220235           0  0.00292921   
9    KNeighborsClassifier          -1    -0.501674           0     0.49834   
5           MLPClassifier  -0.0126319  -0.00836551 -0.00325665  0.00195322   

        acc       auc           conf_matrix     f1_c0      f1_c1      kappa  \
3  0.880319  0.939516   [[327, 45], [0, 4]]  0.935622   0.150943   0.133907   
0  0.710106  0.853495  [[263, 109], [0, 4]]  0.828346  0.0683761  0.0488303   
7  0.593085  0.794355  [[219, 153], [0, 4]]  0.741117  0.0496894  0.0295547   
1   0.56117  0.778226  [[207, 165], [0, 4]]  0.715026  0.0462428  0.0259985   
2       0.5  0.747312  [[184, 188], [0, 4]]  0.661871  0.0408163  0.0203991   
6  0.978723   0.61828    [[367, 5], [3, 1]]  0.989218        0.2   0.189655   
4  0.989362       0.5    [[372, 0], [4, 0]]  0.994652          0          0   
8  0.989362       0.5    [[372, 0], [4, 0]]  0.994652          0          0   
9  0.989362       0.5    [[372, 0], [4, 0]]  0.994652          0          0   
5  0.986702  0.498656    [[371, 1], [4, 0]]  0.993307          0 -0.0042735   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
3    0.267876         1  0.0816327  0.879032      1  
0    0.158197         1  0.0353982  0.706989      1  
7     0.12247         1  0.0254777   0.58871      1  
1    0.114763         1  0.0236686  0.556452      1  
2    0.101512         1  0.0208333  0.494624      1  
6    0.193671  0.991892   0.166667  0.986559   0.25  
4           0  0.989362          0         1      0  
8           0  0.989362          0         1      0  
9           0  0.989362          0         1      0  
5  -0.0053548  0.989333          0  0.997312      0  
Elapsed time 20.47 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-16 04:19:52.868000 
pca_target: 0 	 poly degree: 0 	 kselect: 80 
Imbalance: SMOTE(k=None, k_neighbors=5, kind='regular', m=None, m_neighbors=10, n_jobs=1,
   out_step=0.5, random_state=None, ratio='auto', svm_estimator=None) 
Extended target (count):  31485 13
('Total : Processed (count): ', (1252L, 222L), 13)
Final feature (count):  (1252L, 222L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.707 	0.157 	0.048 	0.852 	0.839 	0.725
[[262 110]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.70      0.83       372
        1.0       0.04      1.00      0.07         4

avg / total       0.99      0.71      0.82       376


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=10, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.955 	-0.020 	-0.017 	0.483 	0.000 	0.000
[[359  13]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.97      0.98       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.95      0.97       376


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.001, average=False, class_weight='balanced',
       epsilon=0.1, eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='modified_huber', n_iter=5, n_jobs=4,
       penalty='l1', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.949 	-0.021 	-0.017 	0.480 	0.000 	0.000
[[357  15]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.96      0.97       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.95      0.96       376


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3},
           criterion='entropy', max_depth=32, max_features='auto',
           max_leaf_nodes=None, min_impurity_split=1e-07,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=4,
           oob_score=False, random_state=None, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	-0.005 	-0.004 	0.499 	0.000 	0.000
[[371   1]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 50},
            criterion='entropy', max_depth=32, max_features='auto',
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.349 	0.329 	0.624 	0.499 	0.231
[[371   1]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.50      0.25      0.33         4

avg / total       0.99      0.99      0.99       376


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 32 candidates, totalling 160 fits
BEST: MLPClassifier(activation='tanh', alpha=0.1, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.984 	-0.008 	-0.007 	0.497 	0.000 	0.000
[[370   2]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='entropy', max_depth=16,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=1.0, n_estimators=80, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	-0.005 	-0.004 	0.499 	0.000 	0.000
[[371   1]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.5, cache_size=200, class_weight='balanced', coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	-0.005 	-0.004 	0.499 	0.000 	0.000
[[371   1]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=10.0, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', ...owski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='uniform'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.981 	-0.009 	-0.009 	0.496 	0.000 	0.000
[[369   3]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 192 candidates, totalling 960 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=1,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.952 	-0.020 	-0.017 	0.481 	0.000 	0.000
[[358  14]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.96      0.98       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.95      0.97       376


                estimator  min_score mean_score max_score    sd_score  \
0              GaussianNB   0.651084   0.651084  0.651084           0   
4  RandomForestClassifier   0.929518   0.973064  0.994263   0.0117398   
3    ExtraTreesClassifier   0.701859   0.954902   0.99885   0.0591225   
6      AdaBoostClassifier    0.90653   0.974295   0.99885   0.0170154   
7                     SVC          0   0.845636    0.9977    0.250713   
5           MLPClassifier   0.976105   0.982849  0.991969  0.00391336   
8        VotingClassifier   0.904376   0.957431  0.986264   0.0194993   
1      LogisticRegression   0.511864   0.793087  0.961569    0.143899   
9    KNeighborsClassifier         -1 -0.0487639  0.951652    0.951492   
2           SGDClassifier -0.0607747   0.609669  0.955903    0.245992   

        acc       auc           conf_matrix     f1_c0      f1_c1       kappa  \
0  0.707447  0.852151  [[262, 110], [0, 4]]  0.826498  0.0677966   0.0482327   
4  0.989362  0.623656    [[371, 1], [3, 1]]  0.994638   0.333333    0.328571   
3  0.986702  0.498656    [[371, 1], [4, 0]]  0.993307          0  -0.0042735   
6  0.986702  0.498656    [[371, 1], [4, 0]]  0.993307          0  -0.0042735   
7  0.986702  0.498656    [[371, 1], [4, 0]]  0.993307          0  -0.0042735   
5  0.984043  0.497312    [[370, 2], [4, 0]]  0.991957          0 -0.00714286   
8  0.981383  0.495968    [[369, 3], [4, 0]]  0.990604          0 -0.00920245   
1  0.954787  0.482527   [[359, 13], [4, 0]]  0.976871          0  -0.0165394   
9  0.952128  0.481183   [[358, 14], [4, 0]]  0.975477          0  -0.0168269   
2  0.949468  0.479839   [[357, 15], [4, 0]]  0.974079          0  -0.0170843   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
0    0.157202         1  0.0350877  0.704301      1  
4    0.348815  0.991979        0.5  0.997312   0.25  
3  -0.0053548  0.989333          0  0.997312      0  
6  -0.0053548  0.989333          0  0.997312      0  
7  -0.0053548  0.989333          0  0.997312      0  
5 -0.00758294  0.989305          0  0.994624      0  
8 -0.00929961  0.989276          0  0.991935      0  
1  -0.0196235  0.988981          0  0.965054      0  
9  -0.0203924   0.98895          0  0.962366      0  
2  -0.0211374   0.98892          0  0.959677      0  
Elapsed time 53.73 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-16 05:13:36.490000 
pca_target: 0 	 poly degree: 0 	 kselect: 80 
Imbalance: SMOTE(k=None, k_neighbors=3, kind='regular', m=None, m_neighbors=10, n_jobs=1,
   out_step=0.5, random_state=None, ratio='auto', svm_estimator=None) 
Extended target (count):  31485 13
('Total : Processed (count): ', (1252L, 222L), 13)
Final feature (count):  (1252L, 222L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.707 	0.157 	0.048 	0.852 	0.839 	0.725
[[262 110]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.70      0.83       372
        1.0       0.04      1.00      0.07         4

avg / total       0.99      0.71      0.82       376


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=10, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.941 	-0.023 	-0.018 	0.476 	0.000 	0.000
[[354  18]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.95      0.97       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.94      0.96       376


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.001, average=False, class_weight='balanced',
       epsilon=0.1, eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='perceptron', n_iter=5, n_jobs=4,
       penalty='none', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.955 	-0.020 	-0.017 	0.483 	0.000 	0.000
[[359  13]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.97      0.98       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.95      0.97       376


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=32, max_features='auto', max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=30, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight='balanced',
            criterion='entropy', max_depth=16, max_features='auto',
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.349 	0.329 	0.624 	0.499 	0.231
[[371   1]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.50      0.25      0.33         4

avg / total       0.99      0.99      0.99       376


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 32 candidates, totalling 160 fits
BEST: MLPClassifier(activation='tanh', alpha=0.1, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.971 	-0.014 	-0.014 	0.491 	0.000 	0.000
[[365   7]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.98      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.97      0.97       376


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='entropy', max_depth=16,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=1.0, n_estimators=80, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=10, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=10.0, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', ...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.984 	-0.008 	-0.007 	0.497 	0.000 	0.000
[[370   2]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 192 candidates, totalling 960 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=1,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.955 	-0.020 	-0.017 	0.483 	0.000 	0.000
[[359  13]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.97      0.98       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.95      0.97       376


                estimator min_score mean_score max_score    sd_score  \
0              GaussianNB  0.656599   0.656599  0.656599           0   
4  RandomForestClassifier   0.94142   0.973914  0.989668   0.0092189   
3    ExtraTreesClassifier  0.701734   0.957114         1   0.0601917   
6      AdaBoostClassifier  0.938392   0.976014         1   0.0149352   
7                     SVC         0   0.856358   0.99885    0.240265   
8        VotingClassifier  0.913788   0.961536  0.988557   0.0173461   
5           MLPClassifier   0.98061   0.985051  0.989733  0.00241369   
2           SGDClassifier -0.139381   0.603376  0.956091    0.247018   
9    KNeighborsClassifier        -1 -0.0458249  0.950505    0.954362   
1      LogisticRegression  0.505577   0.792744  0.963817    0.147626   

        acc       auc           conf_matrix     f1_c0      f1_c1       kappa  \
0  0.707447  0.852151  [[262, 110], [0, 4]]  0.826498  0.0677966   0.0482327   
4  0.989362  0.623656    [[371, 1], [3, 1]]  0.994638   0.333333    0.328571   
3  0.989362       0.5    [[372, 0], [4, 0]]  0.994652          0           0   
6  0.989362       0.5    [[372, 0], [4, 0]]  0.994652          0           0   
7  0.989362       0.5    [[372, 0], [4, 0]]  0.994652          0           0   
8  0.984043  0.497312    [[370, 2], [4, 0]]  0.991957          0 -0.00714286   
5  0.970745  0.490591    [[365, 7], [4, 0]]  0.985155          0  -0.0137255   
2  0.954787  0.482527   [[359, 13], [4, 0]]  0.976871          0  -0.0165394   
9  0.954787  0.482527   [[359, 13], [4, 0]]  0.976871          0  -0.0165394   
1  0.941489  0.475806   [[354, 18], [4, 0]]  0.969863          0  -0.0177165   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
0    0.157202         1  0.0350877  0.704301      1  
4    0.348815  0.991979        0.5  0.997312   0.25  
3           0  0.989362          0         1      0  
6           0  0.989362          0         1      0  
7           0  0.989362          0         1      0  
8 -0.00758294  0.989305          0  0.994624      0  
5  -0.0142822   0.98916          0  0.981183      0  
2  -0.0196235  0.988981          0  0.965054      0  
9  -0.0196235  0.988981          0  0.965054      0  
1  -0.0232516  0.988827          0  0.951613      0  
Elapsed time 48.47 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-16 06:02:04.628000 
pca_target: 0 	 poly degree: 0 	 kselect: 80 
Imbalance: ClusterCentroids(estimator=None, n_jobs=1, random_state=None, ratio='auto') 
Extended target (count):  31485 13
('Total : Processed (count): ', (1252L, 222L), 13)
Final feature (count):  (1252L, 222L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.699 	0.154 	0.046 	0.848 	0.834 	0.717
[[259 113]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.70      0.82       372
        1.0       0.03      1.00      0.07         4

avg / total       0.99      0.70      0.81       376


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=5, class_weight={1: 500}, dual=False, fit_intercept=True,
          intercept_scaling=5, max_iter=100, multi_class='ovr', n_jobs=4,
          penalty='l2', random_state=None, solver='sag', tol=0.0001,
          verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.524 	0.106 	0.022 	0.759 	0.720 	0.544
[[193 179]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.52      0.68       372
        1.0       0.02      1.00      0.04         4

avg / total       0.99      0.52      0.68       376


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=1, average=False, class_weight='balanced', epsilon=0.1,
       eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='modified_huber', n_iter=5, n_jobs=4,
       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.686 	-0.013 	-0.004 	0.470 	0.416 	0.165
[[257 115]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.69      0.81       372
        1.0       0.01      0.25      0.02         4

avg / total       0.98      0.69      0.80       376


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=8, max_features=0.75, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=30, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.636 	0.134 	0.035 	0.816 	0.795 	0.655
[[235 137]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.63      0.77       372
        1.0       0.03      1.00      0.06         4

avg / total       0.99      0.64      0.77       376


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=None, max_features=0.33, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=50, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.593 	0.122 	0.030 	0.794 	0.767 	0.613
[[219 153]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.59      0.74       372
        1.0       0.03      1.00      0.05         4

avg / total       0.99      0.59      0.73       376


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 32 candidates, totalling 160 fits
BEST: MLPClassifier(activation='tanh', alpha=0.01, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.846 	-0.042 	-0.020 	0.427 	0.000 	0.000
[[318  54]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.85      0.92       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.85      0.91       376


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=0.5, n_estimators=15, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.609 	0.127 	0.032 	0.802 	0.778 	0.629
[[225 147]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.60      0.75       372
        1.0       0.03      1.00      0.05         4

avg / total       0.99      0.61      0.75       376


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.01, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='linear',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.463 	0.094 	0.018 	0.728 	0.676 	0.482
[[170 202]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.46      0.63       372
        1.0       0.02      1.00      0.04         4

avg / total       0.99      0.46      0.62       376


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 500}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Ran...owski',
           metric_params=None, n_jobs=4, n_neighbors=4, p=2,
           weights='uniform'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.566 	0.116 	0.027 	0.781 	0.750 	0.586
[[209 163]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.56      0.72       372
        1.0       0.02      1.00      0.05         4

avg / total       0.99      0.57      0.71       376


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 192 candidates, totalling 960 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=1,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.782 	0.009 	0.004 	0.519 	0.444 	0.186
[[293  79]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.79      0.88       372
        1.0       0.01      0.25      0.02         4

avg / total       0.98      0.78      0.87       376


                estimator  min_score  mean_score max_score   sd_score  \
0              GaussianNB   0.812156    0.812156  0.812156          0   
3    ExtraTreesClassifier   0.572745    0.865126         1  0.0830893   
6      AdaBoostClassifier -0.0939222    0.798003         1   0.208944   
4  RandomForestClassifier   0.205033    0.762573         1   0.130942   
8        VotingClassifier -0.0343779    0.341413  0.906078   0.184956   
1      LogisticRegression  -0.624311 -0.00788243  0.478822   0.216987   
7                     SVC          0    0.145515    0.3849   0.148134   
9    KNeighborsClassifier         -1     -0.4317  0.367711   0.582284   
2           SGDClassifier  -0.607122    0.183764  0.555556   0.182138   
5           MLPClassifier  -0.111111   0.0967622  0.350522   0.119928   

        acc       auc           conf_matrix     f1_c0      f1_c1       kappa  \
0  0.699468  0.848118  [[259, 113], [0, 4]]  0.820919  0.0661157   0.0464991   
3  0.635638   0.81586  [[235, 137], [0, 4]]    0.7743  0.0551724   0.0352113   
6  0.609043  0.802419  [[225, 147], [0, 4]]  0.753769  0.0516129   0.0315391   
4  0.593085  0.794355  [[219, 153], [0, 4]]  0.741117  0.0496894   0.0295547   
8  0.566489  0.780914  [[209, 163], [0, 4]]  0.719449  0.0467836   0.0265565   
1  0.523936  0.759409  [[193, 179], [0, 4]]  0.683186  0.0427807   0.0224262   
7  0.462766  0.728495  [[170, 202], [0, 4]]  0.627306  0.0380952   0.0175911   
9  0.781915  0.518817   [[293, 79], [3, 1]]  0.877246  0.0238095  0.00361944   
2   0.68617   0.47043  [[257, 115], [3, 1]]  0.813291  0.0166667 -0.00398262   
5  0.845745  0.427419   [[318, 54], [4, 0]]  0.916427          0  -0.0202096   

  model_score   prec_c0     prec_c1    rec_c0 rec_c1  
0    0.154282         1    0.034188  0.696237      1  
3     0.13387         1   0.0283688   0.63172      1  
6    0.126579         1   0.0264901  0.604839      1  
4     0.12247         1   0.0254777   0.58871      1  
8    0.116004         1   0.0239521  0.561828      1  
1    0.106491         1   0.0218579  0.518817      1  
7   0.0941997         1   0.0194175  0.456989      1  
9    0.009434  0.989865      0.0125  0.787634   0.25  
2  -0.0131361  0.988462  0.00862069   0.69086   0.25  
5  -0.0424646  0.987578           0  0.854839      0  
Elapsed time 14.44 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-16 06:16:31.117000 
pca_target: 0 	 poly degree: 0 	 kselect: 80 
Imbalance: None 
Extended target (count):  31485 13
('Total : Processed (count): ', (1252L, 222L), 13)
Final feature (count):  (1252L, 222L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.691 	0.151 	0.045 	0.844 	0.830 	0.710
[[256 116]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.69      0.82       372
        1.0       0.03      1.00      0.06         4

avg / total       0.99      0.69      0.81       376


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.01, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='sag', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.809 	0.017 	0.007 	0.532 	0.451 	0.192
[[303  69]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.81      0.89       372
        1.0       0.01      0.25      0.03         4

avg / total       0.98      0.81      0.88       376


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.5, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='perceptron', n_iter=5, n_jobs=4,
       penalty='l2', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.976 	-0.012 	-0.012 	0.493 	0.000 	0.000
[[367   5]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 500}, criterion='gini',
           max_depth=8, max_features=0.75, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=30, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.907 	0.059 	0.036 	0.582 	0.478 	0.213
[[340  32]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.91      0.95       372
        1.0       0.03      0.25      0.05         4

avg / total       0.98      0.91      0.94       376


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 32 candidates, totalling 160 fits
BEST: MLPClassifier(activation='tanh', alpha=0.1, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	-0.005 	-0.004 	0.499 	0.000 	0.000
[[371   1]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight='balanced', criterion='entropy',
            max_depth=16, max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=0.5, n_estimators=80, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.979 	-0.011 	-0.011 	0.495 	0.000 	0.000
[[368   4]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.556 	0.114 	0.025 	0.776 	0.742 	0.576
[[205 167]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.55      0.71       372
        1.0       0.02      1.00      0.05         4

avg / total       0.99      0.56      0.70       376


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 192 candidates, totalling 960 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=2,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.984 	-0.008 	-0.007 	0.497 	0.000 	0.000
[[370   2]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.98      0.98       376


                estimator   min_score   mean_score  max_score     sd_score  \
0              GaussianNB   0.0688539    0.0688539  0.0688539            0   
7                     SVC  -0.0261613   -0.0052323   0.105004    0.0169514   
3    ExtraTreesClassifier  -0.0429603  -0.00211466  0.0416016   0.00660565   
1      LogisticRegression  -0.0373179   0.00568472   0.103264    0.0313088   
4  RandomForestClassifier -0.00230935 -7.47826e-05          0  0.000340516   
8        VotingClassifier -0.00603316  -0.00101062          0   0.00154464   
5           MLPClassifier -0.00972194  -0.00587617 -0.0023095   0.00194709   
9    KNeighborsClassifier          -1     -0.48912   0.133272     0.511993   
6      AdaBoostClassifier  -0.0171891  -0.00594655   0.137723    0.0112268   
2           SGDClassifier   -0.228351    0.0247796   0.193064    0.0374269   

        acc       auc           conf_matrix     f1_c0      f1_c1       kappa  \
0  0.691489  0.844086  [[256, 116], [0, 4]]  0.815287  0.0645161   0.0448493   
7  0.555851  0.775538  [[205, 167], [0, 4]]  0.710572  0.0457143   0.0254532   
3  0.906915  0.581989   [[340, 32], [3, 1]]  0.951049  0.0540541   0.0357562   
1  0.808511  0.532258   [[303, 69], [3, 1]]  0.893805   0.027027  0.00704225   
4  0.989362       0.5    [[372, 0], [4, 0]]  0.994652          0           0   
8  0.989362       0.5    [[372, 0], [4, 0]]  0.994652          0           0   
5  0.986702  0.498656    [[371, 1], [4, 0]]  0.993307          0  -0.0042735   
9  0.984043  0.497312    [[370, 2], [4, 0]]  0.991957          0 -0.00714286   
6  0.978723  0.494624    [[368, 4], [4, 0]]  0.989247          0  -0.0107527   
2  0.976064   0.49328    [[367, 5], [4, 0]]  0.987887          0  -0.0119617   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
0    0.151456         1  0.0333333  0.688172      1  
7    0.113537         1  0.0233918  0.551075      1  
3   0.0594544  0.991254   0.030303  0.913978   0.25  
1   0.0170043  0.990196  0.0142857  0.814516   0.25  
4           0  0.989362          0         1      0  
8           0  0.989362          0         1      0  
5  -0.0053548  0.989333          0  0.997312      0  
9 -0.00758294  0.989305          0  0.994624      0  
6  -0.0107527  0.989247          0  0.989247      0  
2  -0.0120381  0.989218          0  0.986559      0  
Elapsed time 22.00 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-16 14:01:47.877000 
pca_target: 0 	 poly degree: 2 	 kselect: 40 
Imbalance: SMOTE(k=None, k_neighbors=5, kind='regular', m=None, m_neighbors=10, n_jobs=1,
   out_step=0.5, random_state=None, ratio='auto', svm_estimator=None) 
Extended target (count):  31485 13
('Total : Processed (count): ', (1252L, 24976L), 13)
Final feature (count):  (1252L, 24976L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.747 	0.173 	0.058 	0.872 	0.863 	0.764
[[277  95]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.74      0.85       372
        1.0       0.04      1.00      0.08         4

avg / total       0.99      0.75      0.85       376


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=10, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.875 	0.042 	0.022 	0.566 	0.469 	0.207
[[328  44]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.88      0.93       372
        1.0       0.02      0.25      0.04         4

avg / total       0.98      0.88      0.92       376


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.001, average=False, class_weight='balanced',
       epsilon=0.1, eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='modified_huber', n_iter=5, n_jobs=4,
       penalty='none', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.864 	0.037 	0.018 	0.560 	0.467 	0.204
[[324  48]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.87      0.93       372
        1.0       0.02      0.25      0.04         4

avg / total       0.98      0.86      0.92       376


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 500},
           criterion='entropy', max_depth=None, max_features=0.75,
           max_leaf_nodes=None, min_impurity_split=1e-07,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=4,
           oob_score=False, random_state=None, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.968 	-0.015 	-0.014 	0.489 	0.000 	0.000
[[364   8]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.98      0.98       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.97      0.97       376


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 15},
            criterion='entropy', max_depth=32, max_features=0.33,
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.965 	-0.016 	-0.015 	0.488 	0.000 	0.000
[[363   9]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.98      0.98       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.97      0.97       376


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 32 candidates, totalling 160 fits
BEST: MLPClassifier(activation='tanh', alpha=0.1, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.947 	-0.022 	-0.017 	0.478 	0.000 	0.000
[[356  16]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.96      0.97       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.95      0.96       376


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 50}, criterion='entropy',
            max_depth=16, max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=1.0, n_estimators=50, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.968 	0.144 	0.130 	0.613 	0.494 	0.226
[[363   9]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.98      0.98       372
        1.0       0.10      0.25      0.14         4

avg / total       0.98      0.97      0.97       376


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.5, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=10, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=10.0, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', ...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.931 	0.176 	0.117 	0.718 	0.684 	0.447
[[348  24]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      0.94      0.96       372
        1.0       0.08      0.50      0.13         4

avg / total       0.98      0.93      0.96       376


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 192 candidates, totalling 960 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.941 	0.091 	0.067 	0.599 	0.487 	0.221
[[353  19]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.95      0.97       372
        1.0       0.05      0.25      0.08         4

avg / total       0.98      0.94      0.96       376


                estimator min_score mean_score max_score    sd_score  \
0              GaussianNB  0.646274   0.646274  0.646274           0   
8        VotingClassifier   0.82686   0.879862  0.916778    0.021489   
6      AdaBoostClassifier  0.761288   0.928005  0.973899   0.0270845   
9    KNeighborsClassifier        -1 -0.0581429  0.937636    0.942146   
1      LogisticRegression  0.349943   0.708961  0.882483    0.105294   
2           SGDClassifier -0.152231   0.555626  0.851195    0.209388   
7                     SVC  0.297504    0.78105  0.978435    0.149874   
3    ExtraTreesClassifier   0.68706   0.896775  0.962582   0.0703231   
4  RandomForestClassifier  0.807357    0.92488  0.961388   0.0376829   
5           MLPClassifier   0.95064   0.965307  0.979553  0.00595634   

        acc       auc          conf_matrix     f1_c0      f1_c1      kappa  \
0   0.74734  0.872312  [[277, 95], [0, 4]]  0.853621  0.0776699  0.0584142   
8  0.930851  0.717742  [[348, 24], [2, 2]]  0.963989   0.133333   0.117052   
6  0.968085  0.612903   [[363, 9], [3, 1]]   0.98374   0.142857    0.12963   
9  0.941489  0.599462  [[353, 19], [3, 1]]   0.96978  0.0833333   0.066787   
1     0.875   0.56586  [[328, 44], [3, 1]]  0.933144  0.0408163  0.0217006   
2  0.864362  0.560484  [[324, 48], [3, 1]]  0.927039  0.0377358  0.0184275   
7  0.989362       0.5   [[372, 0], [4, 0]]  0.994652          0          0   
3  0.968085  0.489247   [[364, 8], [4, 0]]  0.983784          0 -0.0143885   
4  0.965426  0.487903   [[363, 9], [4, 0]]  0.982409          0 -0.0149502   
5  0.946809  0.478495  [[356, 16], [4, 0]]  0.972678          0  -0.017316   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
0    0.173453         1   0.040404  0.744624      1  
8    0.176097  0.994286  0.0769231  0.935484    0.5  
6    0.143978  0.991803        0.1  0.975806   0.25  
9    0.090939  0.991573       0.05  0.948925   0.25  
1   0.0416327  0.990937  0.0222222   0.88172   0.25  
2   0.0368637  0.990826  0.0204082  0.870968   0.25  
7           0  0.989362          0         1      0  
3   -0.015289   0.98913          0  0.978495      0  
4  -0.0162385  0.989101          0  0.975806      0  
5  -0.0218609  0.988889          0  0.956989      0  
Elapsed time 42.67 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-16 14:44:28.327000 
pca_target: 0 	 poly degree: 2 	 kselect: 40 
Imbalance: SMOTE(k=None, k_neighbors=3, kind='regular', m=None, m_neighbors=10, n_jobs=1,
   out_step=0.5, random_state=None, ratio='auto', svm_estimator=None) 
Extended target (count):  31485 13
('Total : Processed (count): ', (1252L, 24976L), 13)
Final feature (count):  (1252L, 24976L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.753 	0.176 	0.060 	0.875 	0.866 	0.769
[[279  93]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.75      0.86       372
        1.0       0.04      1.00      0.08         4

avg / total       0.99      0.75      0.85       376


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=5, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.848 	0.101 	0.047 	0.676 	0.653 	0.411
[[317  55]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      0.85      0.92       372
        1.0       0.04      0.50      0.07         4

avg / total       0.98      0.85      0.91       376


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.001, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='modified_huber', n_iter=5, n_jobs=4,
       penalty='l1', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.854 	0.032 	0.016 	0.555 	0.464 	0.202
[[320  52]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.86      0.92       372
        1.0       0.02      0.25      0.04         4

avg / total       0.98      0.85      0.91       376


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 50}, criterion='gini',
           max_depth=None, max_features=0.75, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=30, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.979 	-0.011 	-0.011 	0.495 	0.000 	0.000
[[368   4]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 50},
            criterion='entropy', max_depth=32, max_features=0.33,
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.968 	-0.015 	-0.014 	0.489 	0.000 	0.000
[[364   8]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.98      0.98       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.97      0.97       376


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 32 candidates, totalling 160 fits
BEST: MLPClassifier(activation='tanh', alpha=0.1, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.973 	0.164 	0.155 	0.616 	0.495 	0.227
[[365   7]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.98      0.99       372
        1.0       0.12      0.25      0.17         4

avg / total       0.98      0.97      0.98       376


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 500}, criterion='entropy',
            max_depth=16, max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=1.0, n_estimators=80, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.965 	-0.016 	-0.015 	0.488 	0.000 	0.000
[[363   9]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.98      0.98       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.97      0.97       376


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=10, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.981 	0.214 	0.213 	0.620 	0.497 	0.229
[[368   4]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       372
        1.0       0.20      0.25      0.22         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=10.0, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', ...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.941 	0.091 	0.067 	0.599 	0.487 	0.221
[[353  19]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.95      0.97       372
        1.0       0.05      0.25      0.08         4

avg / total       0.98      0.94      0.96       376


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 192 candidates, totalling 960 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=4,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.947 	0.098 	0.075 	0.602 	0.488 	0.222
[[355  17]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.95      0.97       372
        1.0       0.06      0.25      0.09         4

avg / total       0.98      0.95      0.96       376


                estimator  min_score mean_score max_score    sd_score  \
0              GaussianNB    0.67998    0.67998   0.67998           0   
1      LogisticRegression   0.408361   0.675944  0.800612   0.0807967   
7                     SVC   0.337524   0.797323  0.985107    0.148076   
5           MLPClassifier   0.947372   0.961113  0.970686  0.00632079   
9    KNeighborsClassifier         -1  -0.051861   0.94502     0.94845   
8        VotingClassifier   0.851928   0.895006  0.937643   0.0209924   
2           SGDClassifier -0.0989695   0.564862  0.839145    0.206972   
3    ExtraTreesClassifier   0.709091   0.921188  0.981753    0.073044   
4  RandomForestClassifier   0.845284   0.945559  0.973791   0.0324611   
6      AdaBoostClassifier   0.785199    0.93818  0.973771   0.0231859   

        acc       auc          conf_matrix     f1_c0      f1_c1      kappa  \
0   0.75266     0.875  [[279, 93], [0, 4]]  0.857143  0.0792079       0.06   
1  0.848404  0.676075  [[317, 55], [2, 2]]  0.917511  0.0655738  0.0466192   
7  0.981383  0.619624   [[368, 4], [3, 1]]  0.990579   0.222222   0.212919   
5  0.973404  0.615591   [[365, 7], [3, 1]]  0.986486   0.166667   0.154676   
9  0.946809  0.602151  [[355, 17], [3, 1]]  0.972603  0.0909091  0.0748031   
8  0.941489  0.599462  [[353, 19], [3, 1]]   0.96978  0.0833333   0.066787   
2  0.853723  0.555108  [[320, 52], [3, 1]]  0.920863  0.0350877  0.0156131   
3  0.978723  0.494624   [[368, 4], [4, 0]]  0.989247          0 -0.0107527   
4  0.968085  0.489247   [[364, 8], [4, 0]]  0.983784          0 -0.0143885   
6  0.965426  0.487903   [[363, 9], [4, 0]]  0.982409          0 -0.0149502   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
0    0.175863         1  0.0412371      0.75      1  
1    0.100739   0.99373  0.0350877  0.852151    0.5  
7    0.214278  0.991914        0.2  0.989247   0.25  
5    0.164357  0.991848      0.125  0.981183   0.25  
9   0.0981735   0.99162  0.0555556  0.954301   0.25  
8    0.090939  0.991573       0.05  0.948925   0.25  
2    0.032494  0.990712  0.0188679  0.860215   0.25  
3  -0.0107527  0.989247          0  0.989247      0  
4   -0.015289   0.98913          0  0.978495      0  
6  -0.0162385  0.989101          0  0.975806      0  
Elapsed time 41.42 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-16 15:25:53.704000 
pca_target: 0 	 poly degree: 2 	 kselect: 40 
Imbalance: ClusterCentroids(estimator=None, n_jobs=1, random_state=None, ratio='auto') 
Extended target (count):  31485 13
('Total : Processed (count): ', (1252L, 24976L), 13)
Final feature (count):  (1252L, 24976L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.691 	0.151 	0.045 	0.844 	0.830 	0.710
[[256 116]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.69      0.82       372
        1.0       0.03      1.00      0.06         4

avg / total       0.99      0.69      0.81       376


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.1, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.774 	0.128 	0.047 	0.762 	0.762 	0.579
[[288  84]
 [  1   3]]
             precision    recall  f1-score   support

        0.0       1.00      0.77      0.87       372
        1.0       0.03      0.75      0.07         4

avg / total       0.99      0.77      0.86       376


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.5, average=False, class_weight='balanced', epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='modified_huber', n_iter=5, n_jobs=4,
       penalty='l2', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.755 	0.177 	0.061 	0.876 	0.868 	0.771
[[280  92]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.75      0.86       372
        1.0       0.04      1.00      0.08         4

avg / total       0.99      0.76      0.85       376


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=8, max_features='auto', max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.609 	0.127 	0.032 	0.802 	0.778 	0.629
[[225 147]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.60      0.75       372
        1.0       0.03      1.00      0.05         4

avg / total       0.99      0.61      0.75       376


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.609 	0.127 	0.032 	0.802 	0.778 	0.629
[[225 147]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.60      0.75       372
        1.0       0.03      1.00      0.05         4

avg / total       0.99      0.61      0.75       376


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 32 candidates, totalling 160 fits
BEST: MLPClassifier(activation='tanh', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.848 	0.030 	0.014 	0.552 	0.462 	0.201
[[318  54]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.85      0.92       372
        1.0       0.02      0.25      0.03         4

avg / total       0.98      0.85      0.91       376


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=0.5, n_estimators=15, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.609 	0.127 	0.032 	0.802 	0.778 	0.629
[[225 147]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.60      0.75       372
        1.0       0.03      1.00      0.05         4

avg / total       0.99      0.61      0.75       376


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=10, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.777 	-0.054 	-0.021 	0.392 	0.000 	0.000
[[292  80]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.78      0.87       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.78      0.86       376


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.641 	0.135 	0.036 	0.819 	0.798 	0.660
[[237 135]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.64      0.78       372
        1.0       0.03      1.00      0.06         4

avg / total       0.99      0.64      0.77       376


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 192 candidates, totalling 960 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=2,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.681 	0.040 	0.012 	0.591 	0.584 	0.335
[[254 118]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      0.68      0.81       372
        1.0       0.02      0.50      0.03         4

avg / total       0.98      0.68      0.80       376


                estimator min_score mean_score max_score    sd_score  \
2           SGDClassifier   -0.2566   0.343524  0.906078     0.13593   
0              GaussianNB         1          1         1           0   
8        VotingClassifier  0.794967   0.937539         1   0.0499791   
3    ExtraTreesClassifier  0.906078   0.999217         1  0.00853808   
4  RandomForestClassifier  0.906078   0.995304         1   0.0204699   
6      AdaBoostClassifier  0.367711   0.924001         1    0.115347   
1      LogisticRegression         0   0.536939         1     0.34572   
9    KNeighborsClassifier        -1 -0.0375356         1    0.965188   
5           MLPClassifier         1          1         1           0   
7                     SVC         0   0.568593         1    0.356417   

        acc       auc           conf_matrix     f1_c0      f1_c1      kappa  \
2  0.755319  0.876344   [[280, 92], [0, 4]]  0.858896       0.08  0.0608167   
0  0.691489  0.844086  [[256, 116], [0, 4]]  0.815287  0.0645161  0.0448493   
8  0.640957  0.818548  [[237, 135], [0, 4]]  0.778325  0.0559441  0.0360073   
3  0.609043  0.802419  [[225, 147], [0, 4]]  0.753769  0.0516129  0.0315391   
4  0.609043  0.802419  [[225, 147], [0, 4]]  0.753769  0.0516129  0.0315391   
6  0.609043  0.802419  [[225, 147], [0, 4]]  0.753769  0.0516129  0.0315391   
1  0.773936  0.762097   [[288, 84], [1, 3]]  0.871407  0.0659341  0.0465394   
9  0.680851  0.591398  [[254, 118], [2, 2]]  0.808917  0.0322581  0.0119131   
5  0.848404  0.552419   [[318, 54], [3, 1]]  0.917749  0.0338983  0.0143488   
7  0.776596  0.392473   [[292, 80], [4, 0]]  0.874251          0 -0.0206825   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
2    0.177093         1  0.0416667  0.752688      1  
0    0.151456         1  0.0333333  0.688172      1  
8    0.135402         1   0.028777  0.637097      1  
3    0.126579         1  0.0264901  0.604839      1  
4    0.126579         1  0.0264901  0.604839      1  
6    0.126579         1  0.0264901  0.604839      1  
1    0.127522   0.99654  0.0344828  0.774194   0.75  
9   0.0402306  0.992188  0.0166667  0.682796    0.5  
5   0.0304361  0.990654  0.0181818  0.854839   0.25  
7  -0.0539086  0.986486          0  0.784946      0  
Elapsed time 19.54 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-16 15:45:25.897000 
pca_target: 0 	 poly degree: 2 	 kselect: 40 
Imbalance: None 
Extended target (count):  31485 13
('Total : Processed (count): ', (1252L, 24976L), 13)
Final feature (count):  (1252L, 24976L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.859 	-0.040 	-0.020 	0.434 	0.000 	0.000
[[323  49]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.87      0.92       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.86      0.91       376


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.01, class_weight={1: 50}, dual=False,
          fit_intercept=True, intercept_scaling=10, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='sag', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.864 	-0.039 	-0.020 	0.437 	0.000 	0.000
[[325  47]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.87      0.93       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.86      0.92       376


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.001, average=False, class_weight={1: 15}, epsilon=0.1,
       eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='modified_huber', n_iter=5, n_jobs=4,
       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.891 	-0.034 	-0.020 	0.450 	0.000 	0.000
[[335  37]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.90      0.94       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.89      0.93       376


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 500}, criterion='gini',
           max_depth=8, max_features=0.75, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=50, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.936 	0.085 	0.060 	0.597 	0.486 	0.220
[[351  21]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.94      0.97       372
        1.0       0.05      0.25      0.08         4

avg / total       0.98      0.94      0.96       376


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	-0.005 	-0.004 	0.499 	0.000 	0.000
[[371   1]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 32 candidates, totalling 160 fits
BEST: MLPClassifier(activation='relu', alpha=0.1, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	0.282 	0.279 	0.622 	0.499 	0.230
[[370   2]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       372
        1.0       0.33      0.25      0.29         4

avg / total       0.98      0.99      0.99       376


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight='balanced', criterion='entropy',
            max_depth=8, max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=1.0, n_estimators=15, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.739 	0.114 	0.038 	0.745 	0.745 	0.555
[[275  97]
 [  1   3]]
             precision    recall  f1-score   support

        0.0       1.00      0.74      0.85       372
        1.0       0.03      0.75      0.06         4

avg / total       0.99      0.74      0.84       376


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...owski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='uniform'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 192 candidates, totalling 960 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=4,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	0.282 	0.279 	0.622 	0.499 	0.230
[[370   2]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       372
        1.0       0.33      0.25      0.29         4

avg / total       0.98      0.99      0.99       376


                estimator   min_score   mean_score  max_score    sd_score  \
7                     SVC  -0.0320677   0.00975628   0.122799    0.023676   
5           MLPClassifier -0.00772153   0.00361466    0.13448    0.029217   
9    KNeighborsClassifier          -1    -0.499049  0.0525283    0.501041   
3    ExtraTreesClassifier  -0.0182142 -0.000672884   0.069555  0.00704113   
6      AdaBoostClassifier  -0.0152237   0.00911234   0.197002   0.0363585   
8        VotingClassifier -0.00792239  -0.00363045          0  0.00210362   
4  RandomForestClassifier -0.00714612  0.000256972    0.19863   0.0105022   
2           SGDClassifier   -0.140064    0.0529314   0.241732   0.0455492   
1      LogisticRegression    -0.18322     0.050452   0.217918   0.0442169   
0              GaussianNB    0.138293     0.138293   0.138293           0   

        acc       auc          conf_matrix     f1_c0      f1_c1      kappa  \
7  0.739362  0.744624  [[275, 97], [1, 3]]  0.848765  0.0576923  0.0380117   
5  0.986702  0.622312   [[370, 2], [3, 1]]  0.993289   0.285714   0.279141   
9  0.986702  0.622312   [[370, 2], [3, 1]]  0.993289   0.285714   0.279141   
3   0.93617  0.596774  [[351, 21], [3, 1]]  0.966942  0.0769231       0.06   
6  0.989362       0.5   [[372, 0], [4, 0]]  0.994652          0          0   
8  0.989362       0.5   [[372, 0], [4, 0]]  0.994652          0          0   
4  0.986702  0.498656   [[371, 1], [4, 0]]  0.993307          0 -0.0042735   
2  0.890957  0.450269  [[335, 37], [4, 0]]  0.942335          0 -0.0195767   
1  0.864362  0.436828  [[325, 47], [4, 0]]  0.927247          0      -0.02   
0  0.859043   0.43414  [[323, 49], [4, 0]]  0.924177          0 -0.0200655   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
7    0.113599  0.996377       0.03  0.739247   0.75  
5    0.282088  0.991957   0.333333  0.994624   0.25  
9    0.282088  0.991957   0.333333  0.994624   0.25  
3   0.0846015  0.991525  0.0454545  0.943548   0.25  
6           0  0.989362          0         1      0  
8           0  0.989362          0         1      0  
4  -0.0053548  0.989333          0  0.997312      0  
2  -0.0342578  0.988201          0  0.900538      0  
1  -0.0391931  0.987842          0  0.873656      0  
0  -0.0401405  0.987768          0   0.86828      0  
Elapsed time 19.23 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-16 16:04:39.897000 
pca_target: 0 	 poly degree: 2 	 kselect: 80 
Imbalance: SMOTE(k=None, k_neighbors=5, kind='regular', m=None, m_neighbors=10, n_jobs=1,
   out_step=0.5, random_state=None, ratio='auto', svm_estimator=None) 
Extended target (count):  31485 13
('Total : Processed (count): ', (1252L, 24976L), 13)
Final feature (count):  (1252L, 24976L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.734 	0.168 	0.055 	0.866 	0.855 	0.751
[[272 100]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.73      0.84       372
        1.0       0.04      1.00      0.07         4

avg / total       0.99      0.73      0.84       376


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=10, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.928 	0.172 	0.113 	0.716 	0.683 	0.446
[[347  25]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      0.93      0.96       372
        1.0       0.07      0.50      0.13         4

avg / total       0.98      0.93      0.95       376


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.001, average=False, class_weight='balanced',
       epsilon=0.1, eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='squared_hinge', n_iter=5, n_jobs=4,
       penalty='l1', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.886 	0.047 	0.026 	0.571 	0.472 	0.209
[[332  40]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.89      0.94       372
        1.0       0.02      0.25      0.04         4

avg / total       0.98      0.89      0.93       376


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight='balanced',
           criterion='entropy', max_depth=16, max_features=0.75,
           max_leaf_nodes=None, min_impurity_split=1e-07,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=4,
           oob_score=False, random_state=None, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.976 	-0.012 	-0.012 	0.493 	0.000 	0.000
[[367   5]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=32, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=50, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.981 	-0.009 	-0.009 	0.496 	0.000 	0.000
[[369   3]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 32 candidates, totalling 160 fits
BEST: MLPClassifier(activation='tanh', alpha=0.5, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.981 	-0.009 	-0.009 	0.496 	0.000 	0.000
[[369   3]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight='balanced', criterion='gini', max_depth=8,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=1.0, n_estimators=50, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.984 	-0.008 	-0.007 	0.497 	0.000 	0.000
[[370   2]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.5, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.984 	-0.008 	-0.007 	0.497 	0.000 	0.000
[[370   2]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=10.0, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', ...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.952 	0.107 	0.084 	0.605 	0.490 	0.223
[[357  15]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.96      0.98       372
        1.0       0.06      0.25      0.10         4

avg / total       0.98      0.95      0.97       376


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 192 candidates, totalling 960 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=4,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.952 	0.220 	0.167 	0.728 	0.692 	0.457
[[356  16]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      0.96      0.98       372
        1.0       0.11      0.50      0.18         4

avg / total       0.99      0.95      0.97       376


                estimator min_score mean_score max_score    sd_score  \
0              GaussianNB  0.688485   0.688485  0.688485           0   
9    KNeighborsClassifier        -1 -0.0586124   0.93222    0.941616   
1      LogisticRegression  0.524394   0.747914  0.925567    0.116933   
8        VotingClassifier  0.837762    0.89824  0.944051   0.0234021   
2           SGDClassifier   -0.1162   0.569236  0.880414     0.21661   
6      AdaBoostClassifier   0.86846   0.947172  0.985133   0.0226686   
7                     SVC         0   0.809726  0.990779    0.199912   
4  RandomForestClassifier  0.866561   0.942507  0.970328   0.0241589   
5           MLPClassifier  0.963802   0.974375  0.986321  0.00494346   
3    ExtraTreesClassifier  0.712681   0.924926  0.978361   0.0651057   

        acc       auc           conf_matrix     f1_c0      f1_c1       kappa  \
0  0.734043  0.865591  [[272, 100], [0, 4]]   0.84472  0.0740741   0.0547064   
9  0.952128  0.728495   [[356, 16], [2, 2]]  0.975342   0.181818    0.167323   
1  0.928191  0.716398   [[347, 25], [2, 2]]  0.962552   0.129032    0.112587   
8  0.952128  0.604839   [[357, 15], [3, 1]]   0.97541        0.1   0.0844156   
2  0.885638  0.571237   [[332, 40], [3, 1]]   0.93918  0.0444444   0.0255545   
6  0.984043  0.497312    [[370, 2], [4, 0]]  0.991957          0 -0.00714286   
7  0.984043  0.497312    [[370, 2], [4, 0]]  0.991957          0 -0.00714286   
4  0.981383  0.495968    [[369, 3], [4, 0]]  0.990604          0 -0.00920245   
5  0.981383  0.495968    [[369, 3], [4, 0]]  0.990604          0 -0.00920245   
3  0.976064   0.49328    [[367, 5], [4, 0]]  0.987887          0  -0.0119617   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
0    0.167697         1  0.0384615  0.731183      1  
9    0.219599  0.994413   0.111111  0.956989    0.5  
1    0.171985  0.994269  0.0740741  0.932796    0.5  
8    0.106572  0.991667     0.0625  0.959677   0.25  
2   0.0468943  0.991045  0.0243902  0.892473   0.25  
6 -0.00758294  0.989305          0  0.994624      0  
7 -0.00758294  0.989305          0  0.994624      0  
4 -0.00929961  0.989276          0  0.991935      0  
5 -0.00929961  0.989276          0  0.991935      0  
3  -0.0120381  0.989218          0  0.986559      0  
Elapsed time 60.34 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-16 17:05:00.245000 
pca_target: 0 	 poly degree: 2 	 kselect: 80 
Imbalance: SMOTE(k=None, k_neighbors=3, kind='regular', m=None, m_neighbors=10, n_jobs=1,
   out_step=0.5, random_state=None, ratio='auto', svm_estimator=None) 
Extended target (count):  31485 13
('Total : Processed (count): ', (1252L, 24976L), 13)
Final feature (count):  (1252L, 24976L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.734 	0.168 	0.055 	0.866 	0.855 	0.751
[[272 100]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.73      0.84       372
        1.0       0.04      1.00      0.07         4

avg / total       0.99      0.73      0.84       376


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=10, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.902 	0.056 	0.033 	0.579 	0.477 	0.212
[[338  34]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.91      0.95       372
        1.0       0.03      0.25      0.05         4

avg / total       0.98      0.90      0.94       376


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.1, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.001, fit_intercept=True, l1_ratio=0.15,
       learning_rate='invscaling', loss='perceptron', n_iter=5, n_jobs=4,
       penalty='none', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.830 	0.157 	0.067 	0.790 	0.789 	0.618
[[309  63]
 [  1   3]]
             precision    recall  f1-score   support

        0.0       1.00      0.83      0.91       372
        1.0       0.05      0.75      0.09         4

avg / total       0.99      0.83      0.90       376


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3},
           criterion='entropy', max_depth=32, max_features=0.75,
           max_leaf_nodes=None, min_impurity_split=1e-07,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=4,
           oob_score=False, random_state=None, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.984 	-0.008 	-0.007 	0.497 	0.000 	0.000
[[370   2]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3},
            criterion='entropy', max_depth=None, max_features=0.33,
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.981 	0.214 	0.213 	0.620 	0.497 	0.229
[[368   4]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       372
        1.0       0.20      0.25      0.22         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 32 candidates, totalling 160 fits
BEST: MLPClassifier(activation='relu', alpha=0.01, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.976 	-0.012 	-0.012 	0.493 	0.000 	0.000
[[367   5]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight='balanced', criterion='gini', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=1.0, n_estimators=80, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	-0.005 	-0.004 	0.499 	0.000 	0.000
[[371   1]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.5, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	-0.005 	-0.004 	0.499 	0.000 	0.000
[[371   1]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=10.0, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', ...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.947 	-0.022 	-0.017 	0.478 	0.000 	0.000
[[356  16]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.96      0.97       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.95      0.96       376


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 192 candidates, totalling 960 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=4,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.952 	0.107 	0.084 	0.605 	0.490 	0.223
[[357  15]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.96      0.98       372
        1.0       0.06      0.25      0.10         4

avg / total       0.98      0.95      0.97       376


                estimator min_score mean_score max_score    sd_score  \
0              GaussianNB  0.702692   0.702692  0.702692           0   
2           SGDClassifier -0.120052    0.56887  0.848847    0.207227   
4  RandomForestClassifier  0.879614   0.951622  0.977139   0.0227878   
9    KNeighborsClassifier        -1 -0.0486399  0.950536    0.951623   
1      LogisticRegression  0.545784   0.745275  0.902316     0.10685   
6      AdaBoostClassifier  0.906343   0.958873  0.991969   0.0187785   
7                     SVC  0.200095   0.814886  0.995393    0.171223   
3    ExtraTreesClassifier  0.703461   0.937133  0.985172   0.0655429   
5           MLPClassifier  0.965858   0.973259   0.98404  0.00437084   
8        VotingClassifier  0.860942   0.916691  0.948424   0.0201309   

        acc       auc           conf_matrix     f1_c0      f1_c1       kappa  \
0  0.734043  0.865591  [[272, 100], [0, 4]]   0.84472  0.0740741   0.0547064   
2  0.829787  0.790323   [[309, 63], [1, 3]]  0.906158  0.0857143   0.0669975   
4  0.981383  0.619624    [[368, 4], [3, 1]]  0.990579   0.222222    0.212919   
9  0.952128  0.604839   [[357, 15], [3, 1]]   0.97541        0.1   0.0844156   
1  0.901596  0.579301   [[338, 34], [3, 1]]  0.948107  0.0512821   0.0328142   
6  0.986702  0.498656    [[371, 1], [4, 0]]  0.993307          0  -0.0042735   
7  0.986702  0.498656    [[371, 1], [4, 0]]  0.993307          0  -0.0042735   
3  0.984043  0.497312    [[370, 2], [4, 0]]  0.991957          0 -0.00714286   
5  0.976064   0.49328    [[367, 5], [4, 0]]  0.987887          0  -0.0119617   
8  0.946809  0.478495   [[356, 16], [4, 0]]  0.972678          0   -0.017316   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
0    0.167697         1  0.0384615  0.731183      1  
2    0.156588  0.996774  0.0454545  0.830645   0.75  
4    0.214278  0.991914        0.2  0.989247   0.25  
9    0.106572  0.991667     0.0625  0.959677   0.25  
1   0.0560015  0.991202  0.0285714  0.908602   0.25  
6  -0.0053548  0.989333          0  0.997312      0  
7  -0.0053548  0.989333          0  0.997312      0  
3 -0.00758294  0.989305          0  0.994624      0  
5  -0.0120381  0.989218          0  0.986559      0  
8  -0.0218609  0.988889          0  0.956989      0  
Elapsed time 54.46 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-16 17:59:27.545000 
pca_target: 0 	 poly degree: 2 	 kselect: 80 
Imbalance: ClusterCentroids(estimator=None, n_jobs=1, random_state=None, ratio='auto') 
Extended target (count):  31485 13
('Total : Processed (count): ', (1252L, 24976L), 13)
Final feature (count):  (1252L, 24976L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.684 	0.149 	0.043 	0.840 	0.825 	0.702
[[253 119]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.68      0.81       372
        1.0       0.03      1.00      0.06         4

avg / total       0.99      0.68      0.80       376


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=1, class_weight={1: 15}, dual=False, fit_intercept=True,
          intercept_scaling=0.1, max_iter=100, multi_class='ovr', n_jobs=4,
          penalty='l2', random_state=None, solver='lbfgs', tol=0.0001,
          verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.742 	0.115 	0.039 	0.746 	0.746 	0.557
[[276  96]
 [  1   3]]
             precision    recall  f1-score   support

        0.0       1.00      0.74      0.85       372
        1.0       0.03      0.75      0.06         4

avg / total       0.99      0.74      0.84       376


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.1, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.001, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='modified_huber', n_iter=5, n_jobs=4,
       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.729 	0.053 	0.018 	0.616 	0.605 	0.357
[[272 100]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      0.73      0.84       372
        1.0       0.02      0.50      0.04         4

avg / total       0.98      0.73      0.83       376


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=8, max_features='auto', max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.620 	0.129 	0.033 	0.808 	0.785 	0.639
[[229 143]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.62      0.76       372
        1.0       0.03      1.00      0.05         4

avg / total       0.99      0.62      0.75       376


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.609 	0.127 	0.032 	0.802 	0.778 	0.629
[[225 147]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.60      0.75       372
        1.0       0.03      1.00      0.05         4

avg / total       0.99      0.61      0.75       376


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 32 candidates, totalling 160 fits
BEST: MLPClassifier(activation='tanh', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.824 	0.022 	0.010 	0.540 	0.456 	0.196
[[309  63]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.83      0.90       372
        1.0       0.02      0.25      0.03         4

avg / total       0.98      0.82      0.89       376


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=0.5, n_estimators=15, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.609 	0.127 	0.032 	0.802 	0.778 	0.629
[[225 147]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.60      0.75       372
        1.0       0.03      1.00      0.05         4

avg / total       0.99      0.61      0.75       376


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.468 	-0.057 	-0.011 	0.360 	0.343 	0.115
[[175 197]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.98      0.47      0.64       372
        1.0       0.01      0.25      0.01         4

avg / total       0.97      0.47      0.63       376


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.628 	0.132 	0.034 	0.812 	0.790 	0.647
[[232 140]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.62      0.77       372
        1.0       0.03      1.00      0.05         4

avg / total       0.99      0.63      0.76       376


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 192 candidates, totalling 960 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=1,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.646 	0.085 	0.023 	0.698 	0.696 	0.489
[[240 132]
 [  1   3]]
             precision    recall  f1-score   support

        0.0       1.00      0.65      0.78       372
        1.0       0.02      0.75      0.04         4

avg / total       0.99      0.65      0.78       376


                estimator  min_score mean_score max_score     sd_score  \
0              GaussianNB   0.906078   0.906078  0.906078            0   
8        VotingClassifier   0.718234   0.898438         1    0.0668044   
3    ExtraTreesClassifier   0.812156   0.947038         1    0.0547948   
4  RandomForestClassifier   0.906078   0.906078  0.906078  1.11022e-16   
6      AdaBoostClassifier   0.427255   0.956437         1    0.0895923   
1      LogisticRegression -0.0939222   0.504674         1     0.305364   
9    KNeighborsClassifier         -1  -0.149714  0.906078     0.855116   
2           SGDClassifier  -0.478822   0.385346         1     0.148522   
5           MLPClassifier   0.589933   0.800128         1    0.0714853   
7                     SVC          0   0.600139  0.906078     0.325713   

        acc       auc           conf_matrix     f1_c0       f1_c1       kappa  \
0  0.683511  0.840054  [[253, 119], [0, 4]]    0.8096   0.0629921   0.0432775   
8   0.62766  0.811828  [[232, 140], [0, 4]]  0.768212   0.0540541   0.0340575   
3  0.619681  0.807796  [[229, 143], [0, 4]]  0.762063   0.0529801   0.0329496   
4  0.609043  0.802419  [[225, 147], [0, 4]]  0.753769   0.0516129   0.0315391   
6  0.609043  0.802419  [[225, 147], [0, 4]]  0.753769   0.0516129   0.0315391   
1  0.742021  0.745968   [[276, 96], [1, 3]]  0.850539   0.0582524   0.0385913   
9  0.646277  0.697581  [[240, 132], [1, 3]]  0.783034   0.0431655   0.0229759   
2  0.728723  0.615591  [[272, 100], [2, 2]]  0.842105   0.0377358    0.017623   
5  0.824468  0.540323   [[309, 63], [3, 1]]  0.903509   0.0294118  0.00957854   
7  0.468085  0.360215  [[175, 197], [3, 1]]  0.636364  0.00990099  -0.0111876   

  model_score   prec_c0     prec_c1    rec_c0 rec_c1  
0    0.148719         1   0.0325203  0.680108      1  
8     0.13162         1   0.0277778  0.623656      1  
3    0.129425         1   0.0272109  0.615591      1  
4    0.126579         1   0.0264901  0.604839      1  
6    0.126579         1   0.0264901  0.604839      1  
1    0.114591   0.99639    0.030303  0.741935   0.75  
9   0.0845085  0.995851   0.0222222  0.645161   0.75  
2   0.0533435  0.992701   0.0196078  0.731183    0.5  
5   0.0220147  0.990385    0.015625  0.830645   0.25  
7  -0.0574446  0.983146  0.00505051   0.47043   0.25  
Elapsed time 20.19 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-16 18:19:39.220000 
pca_target: 0 	 poly degree: 2 	 kselect: 80 
Imbalance: None 
Extended target (count):  31485 13
('Total : Processed (count): ', (1252L, 24976L), 13)
Final feature (count):  (1252L, 24976L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.811 	-0.048 	-0.020 	0.410 	0.000 	0.000
[[305  67]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.82      0.90       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.81      0.89       376


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.001, class_weight={1: 50}, dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.904 	-0.032 	-0.019 	0.457 	0.000 	0.000
[[340  32]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.91      0.95       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.90      0.94       376


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=1, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='perceptron', n_iter=5, n_jobs=4,
       penalty='l2', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.981 	-0.009 	-0.009 	0.496 	0.000 	0.000
[[369   3]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight='balanced',
           criterion='gini', max_depth=8, max_features=0.75,
           max_leaf_nodes=None, min_impurity_split=1e-07,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=4,
           oob_score=False, random_state=None, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.960 	-0.018 	-0.016 	0.485 	0.000 	0.000
[[361  11]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.97      0.98       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.96      0.97       376


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=30, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 32 candidates, totalling 160 fits
BEST: MLPClassifier(activation='relu', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.984 	-0.008 	-0.007 	0.497 	0.000 	0.000
[[370   2]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight='balanced', criterion='gini', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=2.0, n_estimators=80, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.976 	-0.012 	-0.012 	0.493 	0.000 	0.000
[[367   5]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=10, cache_size=200, class_weight='balanced', coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='linear',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.968 	-0.015 	-0.014 	0.489 	0.000 	0.000
[[364   8]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.98      0.98       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.97      0.97       376


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 192 candidates, totalling 960 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=1,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


                estimator   min_score   mean_score max_score    sd_score  \
4  RandomForestClassifier  -0.0173937 -0.000387115         0  0.00143903   
8        VotingClassifier -0.00722263  -0.00220644         0  0.00212364   
9    KNeighborsClassifier          -1    -0.500859         0    0.499146   
5           MLPClassifier -0.00902372 -0.000887332  0.132171   0.0240309   
2           SGDClassifier   -0.109461    0.0537108  0.318043   0.0467902   
6      AdaBoostClassifier  -0.0147782   0.00340117  0.276204   0.0381314   
7                     SVC  -0.0220232     0.016961  0.188172   0.0370191   
3    ExtraTreesClassifier  -0.0184431  -0.00135882  0.043044  0.00572563   
1      LogisticRegression   -0.021501    0.0548565  0.166446   0.0446397   
0              GaussianNB    0.106193     0.106193  0.106193           0   

        acc       auc          conf_matrix     f1_c0 f1_c1       kappa  \
4  0.989362       0.5   [[372, 0], [4, 0]]  0.994652     0           0   
8  0.989362       0.5   [[372, 0], [4, 0]]  0.994652     0           0   
9  0.989362       0.5   [[372, 0], [4, 0]]  0.994652     0           0   
5  0.984043  0.497312   [[370, 2], [4, 0]]  0.991957     0 -0.00714286   
2  0.981383  0.495968   [[369, 3], [4, 0]]  0.990604     0 -0.00920245   
6  0.976064   0.49328   [[367, 5], [4, 0]]  0.987887     0  -0.0119617   
7  0.968085  0.489247   [[364, 8], [4, 0]]  0.983784     0  -0.0143885   
3  0.960106  0.485215  [[361, 11], [4, 0]]  0.979647     0  -0.0158501   
1  0.904255  0.456989  [[340, 32], [4, 0]]  0.949721     0  -0.0192771   
0   0.81117  0.409946  [[305, 67], [4, 0]]  0.895742     0  -0.0204893   

  model_score   prec_c0 prec_c1    rec_c0 rec_c1  
4           0  0.989362       0         1      0  
8           0  0.989362       0         1      0  
9           0  0.989362       0         1      0  
5 -0.00758294  0.989305       0  0.994624      0  
2 -0.00929961  0.989276       0  0.991935      0  
6  -0.0120381  0.989218       0  0.986559      0  
7   -0.015289   0.98913       0  0.978495      0  
3  -0.0180015  0.989041       0   0.97043      0  
1  -0.0316267  0.988372       0  0.913978      0  
0  -0.0482855  0.987055       0  0.819892      0  
Elapsed time 21.73 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-16 18:41:23.226000 
pca_target: 0 	 poly degree: 2 	 kselect: 200 
Imbalance: SMOTE(k=None, k_neighbors=5, kind='regular', m=None, m_neighbors=10, n_jobs=1,
   out_step=0.5, random_state=None, ratio='auto', svm_estimator=None) 
Extended target (count):  31485 13
('Total : Processed (count): ', (1252L, 24976L), 13)
Final feature (count):  (1252L, 24976L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.734 	0.168 	0.055 	0.866 	0.855 	0.751
[[272 100]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.73      0.84       372
        1.0       0.04      1.00      0.07         4

avg / total       0.99      0.73      0.84       376


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=10, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.957 	0.117 	0.096 	0.608 	0.491 	0.224
[[359  13]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.97      0.98       372
        1.0       0.07      0.25      0.11         4

avg / total       0.98      0.96      0.97       376


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.001, average=False, class_weight='balanced',
       epsilon=0.1, eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='squared_hinge', n_iter=5, n_jobs=4,
       penalty='none', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.899 	0.054 	0.031 	0.578 	0.476 	0.212
[[337  35]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.91      0.95       372
        1.0       0.03      0.25      0.05         4

avg / total       0.98      0.90      0.94       376


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight='balanced',
           criterion='gini', max_depth=32, max_features=0.33,
           max_leaf_nodes=None, min_impurity_split=1e-07,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=4,
           oob_score=False, random_state=None, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.984 	-0.008 	-0.007 	0.497 	0.000 	0.000
[[370   2]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight='balanced',
            criterion='gini', max_depth=None, max_features='auto',
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	-0.005 	-0.004 	0.499 	0.000 	0.000
[[371   1]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 32 candidates, totalling 160 fits
BEST: MLPClassifier(activation='relu', alpha=0.01, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.984 	-0.008 	-0.007 	0.497 	0.000 	0.000
[[370   2]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=8,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=1.0, n_estimators=80, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.984 	-0.008 	-0.007 	0.497 	0.000 	0.000
[[370   2]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.5, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=10.0, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', ...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.979 	-0.011 	-0.011 	0.495 	0.000 	0.000
[[368   4]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 192 candidates, totalling 960 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=1,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.963 	0.129 	0.111 	0.610 	0.493 	0.225
[[361  11]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.97      0.98       372
        1.0       0.08      0.25      0.12         4

avg / total       0.98      0.96      0.97       376


                estimator min_score mean_score max_score    sd_score  \
0              GaussianNB  0.693756   0.693756  0.693756           0   
9    KNeighborsClassifier        -1 -0.0457328  0.951608    0.954475   
1      LogisticRegression   0.55736   0.784258  0.952747    0.116138   
2           SGDClassifier -0.206581   0.586672  0.906838     0.21956   
7                     SVC         0   0.822429  0.991982    0.247251   
4  RandomForestClassifier  0.902726    0.95857  0.981701   0.0180328   
3    ExtraTreesClassifier  0.722002   0.940343  0.989708    0.063023   
5           MLPClassifier  0.973893   0.979943  0.985197  0.00308691   
6      AdaBoostClassifier  0.896012   0.961226  0.989701   0.0187384   
8        VotingClassifier  0.877307   0.931893   0.96943    0.023074   

        acc       auc           conf_matrix     f1_c0      f1_c1       kappa  \
0  0.734043  0.865591  [[272, 100], [0, 4]]   0.84472  0.0740741   0.0547064   
9  0.962766  0.610215   [[361, 11], [3, 1]]  0.980978      0.125    0.110811   
1  0.957447  0.607527   [[359, 13], [3, 1]]  0.978202   0.111111   0.0961538   
2  0.898936  0.577957   [[337, 35], [3, 1]]  0.946629       0.05   0.0314534   
7  0.989362       0.5    [[372, 0], [4, 0]]  0.994652          0           0   
4  0.986702  0.498656    [[371, 1], [4, 0]]  0.993307          0  -0.0042735   
3  0.984043  0.497312    [[370, 2], [4, 0]]  0.991957          0 -0.00714286   
5  0.984043  0.497312    [[370, 2], [4, 0]]  0.991957          0 -0.00714286   
6  0.984043  0.497312    [[370, 2], [4, 0]]  0.991957          0 -0.00714286   
8  0.978723  0.494624    [[368, 4], [4, 0]]  0.989247          0  -0.0107527   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
0    0.167697         1  0.0384615  0.731183      1  
9    0.128656  0.991758  0.0833333   0.97043   0.25  
1    0.116528  0.991713  0.0714286  0.965054   0.25  
2    0.054362  0.991176  0.0277778  0.905914   0.25  
7           0  0.989362          0         1      0  
4  -0.0053548  0.989333          0  0.997312      0  
3 -0.00758294  0.989305          0  0.994624      0  
5 -0.00758294  0.989305          0  0.994624      0  
6 -0.00758294  0.989305          0  0.994624      0  
8  -0.0107527  0.989247          0  0.989247      0  
Elapsed time 107.51 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-16 20:28:54.069000 
pca_target: 0 	 poly degree: 2 	 kselect: 200 
Imbalance: SMOTE(k=None, k_neighbors=3, kind='regular', m=None, m_neighbors=10, n_jobs=1,
   out_step=0.5, random_state=None, ratio='auto', svm_estimator=None) 
Extended target (count):  31485 13
('Total : Processed (count): ', (1252L, 24976L), 13)
Final feature (count):  (1252L, 24976L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.747 	0.173 	0.058 	0.872 	0.863 	0.764
[[277  95]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.74      0.85       372
        1.0       0.04      1.00      0.08         4

avg / total       0.99      0.75      0.85       376


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=10, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.947 	0.098 	0.075 	0.602 	0.488 	0.222
[[355  17]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.95      0.97       372
        1.0       0.06      0.25      0.09         4

avg / total       0.98      0.95      0.96       376


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.001, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='modified_huber', n_iter=5, n_jobs=4,
       penalty='l1', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.920 	0.069 	0.045 	0.589 	0.482 	0.216
[[345  27]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.93      0.96       372
        1.0       0.04      0.25      0.06         4

avg / total       0.98      0.92      0.95       376


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 500}, criterion='gini',
           max_depth=None, max_features='auto', max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=30, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight='balanced',
            criterion='entropy', max_depth=32, max_features='auto',
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.984 	-0.008 	-0.007 	0.497 	0.000 	0.000
[[370   2]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 32 candidates, totalling 160 fits
BEST: MLPClassifier(activation='relu', alpha=0.1, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.981 	-0.009 	-0.009 	0.496 	0.000 	0.000
[[369   3]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=8,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=1.0, n_estimators=50, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.5, cache_size=200, class_weight={1: 50}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=10.0, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', ...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.979 	-0.011 	-0.011 	0.495 	0.000 	0.000
[[368   4]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 192 candidates, totalling 960 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=3,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.960 	-0.018 	-0.016 	0.485 	0.000 	0.000
[[361  11]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.97      0.98       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.96      0.97       376


                estimator  min_score mean_score max_score    sd_score  \
0              GaussianNB   0.707031   0.707031  0.707031           0   
1      LogisticRegression   0.557355   0.790535  0.959397    0.120423   
2           SGDClassifier -0.0790175   0.594565  0.919089    0.222428   
3    ExtraTreesClassifier   0.797476   0.954306  0.991975    0.049575   
6      AdaBoostClassifier   0.913843   0.971474  0.996556   0.0135849   
7                     SVC          0   0.839865  0.997706    0.246432   
4  RandomForestClassifier   0.924048   0.965501  0.984028   0.0115936   
5           MLPClassifier   0.970543   0.980461  0.989708  0.00414381   
8        VotingClassifier   0.907503   0.946697  0.978399   0.0165266   
9    KNeighborsClassifier         -1 -0.0358534  0.958243    0.964263   

        acc       auc          conf_matrix     f1_c0      f1_c1       kappa  \
0   0.74734  0.872312  [[277, 95], [0, 4]]  0.853621  0.0776699   0.0584142   
1  0.946809  0.602151  [[355, 17], [3, 1]]  0.972603  0.0909091   0.0748031   
2  0.920213   0.58871  [[345, 27], [3, 1]]  0.958333     0.0625   0.0447154   
3  0.989362       0.5   [[372, 0], [4, 0]]  0.994652          0           0   
6  0.989362       0.5   [[372, 0], [4, 0]]  0.994652          0           0   
7  0.989362       0.5   [[372, 0], [4, 0]]  0.994652          0           0   
4  0.984043  0.497312   [[370, 2], [4, 0]]  0.991957          0 -0.00714286   
5  0.981383  0.495968   [[369, 3], [4, 0]]  0.990604          0 -0.00920245   
8  0.978723  0.494624   [[368, 4], [4, 0]]  0.989247          0  -0.0107527   
9  0.960106  0.485215  [[361, 11], [4, 0]]  0.979647          0  -0.0158501   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
0    0.173453         1   0.040404  0.744624      1  
1   0.0981735   0.99162  0.0555556  0.954301   0.25  
2    0.069332  0.991379  0.0357143  0.927419   0.25  
3           0  0.989362          0         1      0  
6           0  0.989362          0         1      0  
7           0  0.989362          0         1      0  
4 -0.00758294  0.989305          0  0.994624      0  
5 -0.00929961  0.989276          0  0.991935      0  
8  -0.0107527  0.989247          0  0.989247      0  
9  -0.0180015  0.989041          0   0.97043      0  
Elapsed time 94.53 mins 

************************************************************



TomekLinks added, SMOTE removed.



pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-16 22:03:26.021000 
pca_target: 0 	 poly degree: 2 	 kselect: 200 
Imbalance: ClusterCentroids(estimator=None, n_jobs=1, random_state=None, ratio='auto') 
Extended target (count):  31485 13
('Total : Processed (count): ', (1252L, 24976L), 13)
Final feature (count):  (1252L, 24976L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.691 	0.151 	0.045 	0.844 	0.830 	0.710
[[256 116]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.69      0.82       372
        1.0       0.03      1.00      0.06         4

avg / total       0.99      0.69      0.81       376


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=1, class_weight={1: 3}, dual=False, fit_intercept=True,
          intercept_scaling=0.1, max_iter=100, multi_class='ovr', n_jobs=4,
          penalty='l2', random_state=None, solver='lbfgs', tol=0.0001,
          verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.793 	0.075 	0.029 	0.648 	0.631 	0.386
[[296  76]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      0.80      0.88       372
        1.0       0.03      0.50      0.05         4

avg / total       0.98      0.79      0.87       376


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.1, average=False, class_weight='balanced', epsilon=0.1,
       eta0=0.001, fit_intercept=True, l1_ratio=0.15,
       learning_rate='invscaling', loss='perceptron', n_iter=5, n_jobs=4,
       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.543 	0.060 	0.013 	0.645 	0.637 	0.414
[[201 171]
 [  1   3]]
             precision    recall  f1-score   support

        0.0       1.00      0.54      0.70       372
        1.0       0.02      0.75      0.03         4

avg / total       0.98      0.54      0.69       376


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=8, max_features=0.75, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.609 	0.127 	0.032 	0.802 	0.778 	0.629
[[225 147]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.60      0.75       372
        1.0       0.03      1.00      0.05         4

avg / total       0.99      0.61      0.75       376


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.609 	0.127 	0.032 	0.802 	0.778 	0.629
[[225 147]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.60      0.75       372
        1.0       0.03      1.00      0.05         4

avg / total       0.99      0.61      0.75       376


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 32 candidates, totalling 160 fits
BEST: MLPClassifier(activation='tanh', alpha=0.5, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.854 	0.104 	0.049 	0.679 	0.655 	0.413
[[319  53]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      0.86      0.92       372
        1.0       0.04      0.50      0.07         4

avg / total       0.98      0.85      0.91       376


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=2.0, n_estimators=80, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.609 	0.127 	0.032 	0.802 	0.778 	0.629
[[225 147]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.60      0.75       372
        1.0       0.03      1.00      0.05         4

avg / total       0.99      0.61      0.75       376


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=10, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.598 	-0.031 	-0.008 	0.426 	0.388 	0.145
[[224 148]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.60      0.75       372
        1.0       0.01      0.25      0.01         4

avg / total       0.98      0.60      0.74       376


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.694 	0.044 	0.013 	0.598 	0.590 	0.341
[[259 113]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      0.70      0.82       372
        1.0       0.02      0.50      0.03         4

avg / total       0.98      0.69      0.81       376


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 192 candidates, totalling 960 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=5, p=1,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.854 	-0.041 	-0.020 	0.431 	0.000 	0.000
[[321  51]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.86      0.92       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.85      0.91       376


                estimator min_score mean_score max_score    sd_score  \
0              GaussianNB         1          1         1           0   
3    ExtraTreesClassifier  0.812156   0.939994         1   0.0456529   
4  RandomForestClassifier  0.812156   0.905034  0.906078  0.00984511   
6      AdaBoostClassifier  0.205033   0.828185         1    0.149979   
5           MLPClassifier  0.333333   0.730683  0.906078    0.154051   
1      LogisticRegression         0   0.612507         1    0.310064   
2           SGDClassifier   -0.1283   0.441325         1    0.167403   
8        VotingClassifier  0.666667   0.929339         1    0.071595   
9    KNeighborsClassifier        -1  -0.207898  0.812156    0.798353   
7                     SVC         0   0.533307  0.906078    0.320134   

        acc       auc           conf_matrix     f1_c0      f1_c1       kappa  \
0  0.691489  0.844086  [[256, 116], [0, 4]]  0.815287  0.0645161   0.0448493   
3  0.609043  0.802419  [[225, 147], [0, 4]]  0.753769  0.0516129   0.0315391   
4  0.609043  0.802419  [[225, 147], [0, 4]]  0.753769  0.0516129   0.0315391   
6  0.609043  0.802419  [[225, 147], [0, 4]]  0.753769  0.0516129   0.0315391   
5  0.853723  0.678763   [[319, 53], [2, 2]]  0.920635  0.0677966    0.048933   
1  0.792553  0.647849   [[296, 76], [2, 2]]  0.883582  0.0487805   0.0291314   
2  0.542553  0.645161  [[201, 171], [1, 3]]  0.700348  0.0337079   0.0131836   
8  0.694149  0.598118  [[259, 113], [2, 2]]  0.818325  0.0336134    0.013326   
9  0.853723  0.431452   [[321, 51], [4, 0]]   0.92109          0  -0.0201263   
7  0.598404  0.426075  [[224, 148], [3, 1]]  0.747913  0.0130719 -0.00781028   

  model_score   prec_c0     prec_c1    rec_c0 rec_c1  
0    0.151456         1   0.0333333  0.688172      1  
3    0.126579         1   0.0264901  0.604839      1  
4    0.126579         1   0.0264901  0.604839      1  
6    0.126579         1   0.0264901  0.604839      1  
5    0.103795  0.993769   0.0363636  0.857527    0.5  
1   0.0748162  0.993289    0.025641  0.795699    0.5  
2   0.0597354   0.99505   0.0172414  0.540323   0.75  
8    0.043693  0.992337   0.0173913  0.696237    0.5  
9  -0.0410773  0.987692           0  0.862903      0  
7   -0.031011  0.986784  0.00671141  0.602151   0.25  
Elapsed time 21.45 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-16 22:24:52.874000 
pca_target: 0 	 poly degree: 2 	 kselect: 200 
Imbalance: None 
Extended target (count):  31485 13
('Total : Processed (count): ', (1252L, 24976L), 13)
Final feature (count):  (1252L, 24976L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.771 	0.007 	0.002 	0.513 	0.441 	0.184
[[289  83]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.78      0.87       372
        1.0       0.01      0.25      0.02         4

avg / total       0.98      0.77      0.86       376


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.001, class_weight={1: 3}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.976 	-0.012 	-0.012 	0.493 	0.000 	0.000
[[367   5]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.001, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.001, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='squared_hinge', n_iter=5, n_jobs=4,
       penalty='l2', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	-0.005 	-0.004 	0.499 	0.000 	0.000
[[371   1]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight='balanced',
           criterion='gini', max_depth=8, max_features=0.33,
           max_leaf_nodes=None, min_impurity_split=1e-07,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=4,
           oob_score=False, random_state=None, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.963 	-0.017 	-0.015 	0.487 	0.000 	0.000
[[362  10]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.97      0.98       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.96      0.97       376


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 32 candidates, totalling 160 fits
BEST: MLPClassifier(activation='relu', alpha=0.01, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.981 	-0.009 	-0.009 	0.496 	0.000 	0.000
[[369   3]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='entropy', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=2.0, n_estimators=15, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.971 	0.153 	0.141 	0.614 	0.495 	0.227
[[364   8]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.98      0.99       372
        1.0       0.11      0.25      0.15         4

avg / total       0.98      0.97      0.98       376


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.01, cache_size=200, class_weight={1: 500}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.487 	0.099 	0.019 	0.741 	0.694 	0.506
[[179 193]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.48      0.65       372
        1.0       0.02      1.00      0.04         4

avg / total       0.99      0.49      0.64       376


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 192 candidates, totalling 960 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=1,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


                estimator   min_score   mean_score   max_score     sd_score  \
7                     SVC   -0.015284    0.0117866   0.0943467    0.0261786   
6      AdaBoostClassifier  -0.0153973   0.00814245    0.275714    0.0404093   
0              GaussianNB    0.108471     0.108471    0.108471            0   
4  RandomForestClassifier -0.00773894 -0.000260474           0  0.000907374   
8        VotingClassifier -0.00892977  -0.00315479           0    0.0027118   
9    KNeighborsClassifier          -1     -0.50101           0     0.498995   
2           SGDClassifier   -0.104537    0.0497709    0.312307    0.0442095   
5           MLPClassifier  -0.0111889  -0.00729622 -0.00461885   0.00139622   
1      LogisticRegression  -0.0255708    0.0412577    0.132519    0.0404093   
3    ExtraTreesClassifier  -0.0288299  -0.00229382   0.0583776   0.00653991   

        acc       auc           conf_matrix     f1_c0      f1_c1       kappa  \
7  0.486702  0.740591  [[179, 193], [0, 4]]  0.649728   0.039801   0.0193514   
6  0.970745  0.614247    [[364, 8], [3, 1]]  0.985115   0.153846    0.141196   
0  0.771277  0.513441   [[289, 83], [3, 1]]  0.870482  0.0227273  0.00246792   
4  0.989362       0.5    [[372, 0], [4, 0]]  0.994652          0           0   
8  0.989362       0.5    [[372, 0], [4, 0]]  0.994652          0           0   
9  0.989362       0.5    [[372, 0], [4, 0]]  0.994652          0           0   
2  0.986702  0.498656    [[371, 1], [4, 0]]  0.993307          0  -0.0042735   
5  0.981383  0.495968    [[369, 3], [4, 0]]  0.990604          0 -0.00920245   
1  0.976064   0.49328    [[367, 5], [4, 0]]  0.987887          0  -0.0119617   
3  0.962766  0.486559   [[362, 10], [4, 0]]   0.98103          0  -0.0154321   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
7   0.0988444         1  0.0203046  0.481183      1  
6    0.153364  0.991826   0.111111  0.978495   0.25  
0  0.00662106  0.989726  0.0119048  0.776882   0.25  
4           0  0.989362          0         1      0  
8           0  0.989362          0         1      0  
9           0  0.989362          0         1      0  
2  -0.0053548  0.989333          0  0.997312      0  
5 -0.00929961  0.989276          0  0.991935      0  
1  -0.0120381  0.989218          0  0.986559      0  
3  -0.0171403  0.989071          0  0.973118      0  
Elapsed time 32.63 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-16 22:57:30.884000 
pca_target: 40 	 poly degree: 2 	 kselect: 40 
Imbalance: SMOTE(k=None, k_neighbors=5, kind='regular', m=None, m_neighbors=10, n_jobs=1,
   out_step=0.5, random_state=None, ratio='auto', svm_estimator=None) 
Extended target (count):  31485 13
('Total : Processed (count): ', (1252L, 24976L), 13)
Final feature (count):  (1252L, 24976L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.984 	-0.008 	-0.007 	0.497 	0.000 	0.000
[[370   2]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=1, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=5, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.955 	0.111 	0.090 	0.606 	0.491 	0.223
[[358  14]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.96      0.98       372
        1.0       0.07      0.25      0.11         4

avg / total       0.98      0.95      0.97       376


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.001, average=False, class_weight='balanced',
       epsilon=0.1, eta0=0.001, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='perceptron', n_iter=5, n_jobs=4,
       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.965 	-0.016 	-0.015 	0.488 	0.000 	0.000
[[363   9]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.98      0.98       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.97      0.97       376


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=8, max_features=0.75, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=30, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=16, max_features=0.33, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=30, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 32 candidates, totalling 160 fits
BEST: MLPClassifier(activation='relu', alpha=0.01, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.979 	-0.011 	-0.011 	0.495 	0.000 	0.000
[[368   4]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=0.5, n_estimators=15, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	-0.005 	-0.004 	0.499 	0.000 	0.000
[[371   1]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.1, cache_size=200, class_weight='balanced', coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=10.0, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Ran...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.979 	-0.011 	-0.011 	0.495 	0.000 	0.000
[[368   4]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 192 candidates, totalling 960 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=4,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.971 	-0.014 	-0.014 	0.491 	0.000 	0.000
[[365   7]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.98      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.97      0.97       376


                estimator min_score mean_score max_score    sd_score  \
1      LogisticRegression  0.559131   0.875323  0.974955    0.118913   
3    ExtraTreesClassifier  0.860361   0.993441         1   0.0211375   
4  RandomForestClassifier  0.995406   0.998389         1  0.00103762   
7                     SVC         0   0.872216         1    0.254607   
6      AdaBoostClassifier  0.925911   0.991505         1  0.00738017   
0              GaussianNB  0.943653   0.943653  0.943653           0   
5           MLPClassifier   0.97383   0.984377    0.9954  0.00644905   
8        VotingClassifier  0.956033   0.982748  0.994263  0.00888678   
9    KNeighborsClassifier        -1 -0.0296358  0.977229     0.97071   
2           SGDClassifier -0.108879   0.698868  0.986276    0.274159   

        acc       auc          conf_matrix     f1_c0     f1_c1       kappa  \
1  0.954787  0.606183  [[358, 14], [3, 1]]  0.976808  0.105263   0.0899772   
3  0.989362       0.5   [[372, 0], [4, 0]]  0.994652         0           0   
4  0.989362       0.5   [[372, 0], [4, 0]]  0.994652         0           0   
7  0.989362       0.5   [[372, 0], [4, 0]]  0.994652         0           0   
6  0.986702  0.498656   [[371, 1], [4, 0]]  0.993307         0  -0.0042735   
0  0.984043  0.497312   [[370, 2], [4, 0]]  0.991957         0 -0.00714286   
5  0.978723  0.494624   [[368, 4], [4, 0]]  0.989247         0  -0.0107527   
8  0.978723  0.494624   [[368, 4], [4, 0]]  0.989247         0  -0.0107527   
9  0.970745  0.490591   [[365, 7], [4, 0]]  0.985155         0  -0.0137255   
2  0.965426  0.487903   [[363, 9], [4, 0]]  0.982409         0  -0.0149502   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
1    0.111323   0.99169  0.0666667  0.962366   0.25  
3           0  0.989362          0         1      0  
4           0  0.989362          0         1      0  
7           0  0.989362          0         1      0  
6  -0.0053548  0.989333          0  0.997312      0  
0 -0.00758294  0.989305          0  0.994624      0  
5  -0.0107527  0.989247          0  0.989247      0  
8  -0.0107527  0.989247          0  0.989247      0  
9  -0.0142822   0.98916          0  0.981183      0  
2  -0.0162385  0.989101          0  0.975806      0  
Elapsed time 38.29 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-16 23:35:48.221000 
pca_target: 40 	 poly degree: 2 	 kselect: 40 
Imbalance: SMOTE(k=None, k_neighbors=3, kind='regular', m=None, m_neighbors=10, n_jobs=1,
   out_step=0.5, random_state=None, ratio='auto', svm_estimator=None) 
Extended target (count):  31485 13
('Total : Processed (count): ', (1252L, 24976L), 13)
Final feature (count):  (1252L, 24976L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.976 	-0.012 	-0.012 	0.493 	0.000 	0.000
[[367   5]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=10, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.960 	-0.018 	-0.016 	0.485 	0.000 	0.000
[[361  11]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.97      0.98       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.96      0.97       376


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.001, average=False, class_weight='balanced',
       epsilon=0.1, eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='perceptron', n_iter=5, n_jobs=4,
       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.976 	-0.012 	-0.012 	0.493 	0.000 	0.000
[[367   5]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=16, max_features='auto', max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=50, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	-0.005 	-0.004 	0.499 	0.000 	0.000
[[371   1]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=None, max_features=0.33, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=30, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 32 candidates, totalling 160 fits
BEST: MLPClassifier(activation='relu', alpha=0.01, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.981 	-0.009 	-0.009 	0.496 	0.000 	0.000
[[369   3]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=1.0, n_estimators=50, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.1, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=10.0, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', ...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.981 	-0.009 	-0.009 	0.496 	0.000 	0.000
[[369   3]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 192 candidates, totalling 960 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=4,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.971 	-0.014 	-0.014 	0.491 	0.000 	0.000
[[365   7]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.98      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.97      0.97       376


                estimator min_score mean_score max_score    sd_score  \
4  RandomForestClassifier  0.990812   0.996826         1  0.00140796   
6      AdaBoostClassifier  0.919987    0.98984         1  0.00779496   
7                     SVC         0   0.882139         1    0.251003   
3    ExtraTreesClassifier  0.845941   0.992726         1   0.0221757   
5           MLPClassifier  0.972718   0.986324  0.994263  0.00559149   
8        VotingClassifier  0.957094   0.982969  0.995406   0.0090834   
0              GaussianNB  0.957537   0.957537  0.957537           0   
2           SGDClassifier -0.118693   0.698926  0.987414    0.272213   
9    KNeighborsClassifier        -1 -0.0308649  0.979516     0.96944   
1      LogisticRegression  0.560018   0.874716  0.976098    0.119287   

        acc       auc          conf_matrix     f1_c0 f1_c1       kappa  \
4  0.989362       0.5   [[372, 0], [4, 0]]  0.994652     0           0   
6  0.989362       0.5   [[372, 0], [4, 0]]  0.994652     0           0   
7  0.989362       0.5   [[372, 0], [4, 0]]  0.994652     0           0   
3  0.986702  0.498656   [[371, 1], [4, 0]]  0.993307     0  -0.0042735   
5  0.981383  0.495968   [[369, 3], [4, 0]]  0.990604     0 -0.00920245   
8  0.981383  0.495968   [[369, 3], [4, 0]]  0.990604     0 -0.00920245   
0  0.976064   0.49328   [[367, 5], [4, 0]]  0.987887     0  -0.0119617   
2  0.976064   0.49328   [[367, 5], [4, 0]]  0.987887     0  -0.0119617   
9  0.970745  0.490591   [[365, 7], [4, 0]]  0.985155     0  -0.0137255   
1  0.960106  0.485215  [[361, 11], [4, 0]]  0.979647     0  -0.0158501   

  model_score   prec_c0 prec_c1    rec_c0 rec_c1  
4           0  0.989362       0         1      0  
6           0  0.989362       0         1      0  
7           0  0.989362       0         1      0  
3  -0.0053548  0.989333       0  0.997312      0  
5 -0.00929961  0.989276       0  0.991935      0  
8 -0.00929961  0.989276       0  0.991935      0  
0  -0.0120381  0.989218       0  0.986559      0  
2  -0.0120381  0.989218       0  0.986559      0  
9  -0.0142822   0.98916       0  0.981183      0  
1  -0.0180015  0.989041       0   0.97043      0  
Elapsed time 37.53 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-17 00:13:20.113000 
pca_target: 40 	 poly degree: 2 	 kselect: 40 
Imbalance: ClusterCentroids(estimator=None, n_jobs=1, random_state=None, ratio='auto') 
Extended target (count):  31485 13
('Total : Processed (count): ', (1252L, 24976L), 13)
Final feature (count):  (1252L, 24976L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.011 	0.000 	0.000 	0.500 	0.000 	0.000
[[  0 372]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       0.00      0.00      0.00       372
        1.0       0.01      1.00      0.02         4

avg / total       0.00      0.01      0.00       376


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=1, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.487 	0.048 	0.009 	0.617 	0.602 	0.373
[[180 192]
 [  1   3]]
             precision    recall  f1-score   support

        0.0       0.99      0.48      0.65       372
        1.0       0.02      0.75      0.03         4

avg / total       0.98      0.49      0.64       376


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.5, average=False, class_weight='balanced', epsilon=0.1,
       eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='invscaling', loss='modified_huber', n_iter=5,
       n_jobs=4, penalty='l2', power_t=0.5, random_state=None,
       shuffle=True, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.535 	0.007 	0.002 	0.517 	0.517 	0.267
[[199 173]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      0.53      0.69       372
        1.0       0.01      0.50      0.02         4

avg / total       0.98      0.53      0.69       376


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=8, max_features='auto', max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.614 	0.128 	0.032 	0.805 	0.781 	0.634
[[227 145]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.61      0.76       372
        1.0       0.03      1.00      0.05         4

avg / total       0.99      0.61      0.75       376


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.609 	0.127 	0.032 	0.802 	0.778 	0.629
[[225 147]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.60      0.75       372
        1.0       0.03      1.00      0.05         4

avg / total       0.99      0.61      0.75       376


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 32 candidates, totalling 160 fits
BEST: MLPClassifier(activation='tanh', alpha=0.1, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.476 	-0.106 	-0.021 	0.241 	0.000 	0.000
[[179 193]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.98      0.48      0.65       372
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.48      0.64       376


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=1.0, n_estimators=15, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.654 	0.087 	0.024 	0.702 	0.700 	0.495
[[243 129]
 [  1   3]]
             precision    recall  f1-score   support

        0.0       1.00      0.65      0.79       372
        1.0       0.02      0.75      0.04         4

avg / total       0.99      0.65      0.78       376


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.1, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='linear',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.524 	0.005 	0.001 	0.512 	0.512 	0.261
[[195 177]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      0.52      0.69       372
        1.0       0.01      0.50      0.02         4

avg / total       0.98      0.52      0.68       376


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.540 	0.008 	0.002 	0.520 	0.520 	0.269
[[201 171]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      0.54      0.70       372
        1.0       0.01      0.50      0.02         4

avg / total       0.98      0.54      0.69       376


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 192 candidates, totalling 960 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=1,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.819 	0.020 	0.009 	0.538 	0.454 	0.194
[[307  65]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.83      0.90       372
        1.0       0.02      0.25      0.03         4

avg / total       0.98      0.82      0.89       376


                estimator min_score mean_score max_score     sd_score  \
3    ExtraTreesClassifier  0.906078   0.998435         1    0.0120238   
4  RandomForestClassifier  0.906078   0.906078  0.906078  1.11022e-16   
6      AdaBoostClassifier  0.555556   0.874575         1    0.0908734   
1      LogisticRegression         0   0.351774  0.683856     0.190412   
9    KNeighborsClassifier        -1  -0.263121  0.906078     0.778835   
8        VotingClassifier  0.906078   0.906078  0.906078  2.22045e-16   
2           SGDClassifier   -0.3849   0.334683  0.812156     0.115959   
7                     SVC         0   0.581101  0.906078     0.356324   
0              GaussianNB         1          1         1            0   
5           MLPClassifier  0.350522   0.706627  0.812156     0.157969   

         acc       auc           conf_matrix     f1_c0      f1_c1       kappa  \
3   0.614362  0.805108  [[227, 145], [0, 4]]   0.75793  0.0522876   0.0322352   
4   0.609043  0.802419  [[225, 147], [0, 4]]  0.753769  0.0516129   0.0315391   
6   0.654255  0.701613  [[243, 129], [1, 3]]  0.788961  0.0441176   0.0239617   
1   0.486702  0.616935  [[180, 192], [1, 3]]  0.650995  0.0301508  0.00949989   
9   0.819149  0.537634   [[307, 65], [3, 1]]  0.900293  0.0285714  0.00868486   
8   0.539894  0.520161  [[201, 171], [2, 2]]   0.69913  0.0225989  0.00184139   
2   0.534574  0.517473  [[199, 173], [2, 2]]   0.69459  0.0223464  0.00157805   
7   0.523936  0.512097  [[195, 177], [2, 2]]  0.685413  0.0218579  0.00106863   
0  0.0106383       0.5    [[0, 372], [0, 4]]         0  0.0210526           0   
5   0.476064  0.240591  [[179, 193], [4, 0]]  0.645045          0  -0.0212883   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
3    0.127991         1  0.0268456  0.610215      1  
4    0.126579         1  0.0264901  0.604839      1  
6   0.0866698  0.995902  0.0227273  0.653226   0.75  
1   0.0480199  0.994475  0.0153846  0.483871   0.75  
9   0.0202985  0.990323  0.0151515  0.825269   0.25  
8  0.00830001  0.990148  0.0115607  0.540323    0.5  
2  0.00718762   0.99005  0.0114286  0.534946    0.5  
7  0.00496983  0.989848  0.0111732  0.524194    0.5  
0           0         0  0.0106383         0      1  
5   -0.106491  0.978142          0  0.481183      0  
Elapsed time 19.88 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-17 00:33:12.998000 
pca_target: 40 	 poly degree: 2 	 kselect: 40 
Imbalance: None 
Extended target (count):  31485 13
('Total : Processed (count): ', (1252L, 24976L), 13)
Final feature (count):  (1252L, 24976L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.902 	-0.032 	-0.019 	0.456 	0.000 	0.000
[[339  33]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.91      0.95       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.90      0.94       376


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=1, class_weight={1: 3}, dual=False, fit_intercept=True,
          intercept_scaling=0.1, max_iter=100, multi_class='ovr', n_jobs=4,
          penalty='l2', random_state=None, solver='sag', tol=0.0001,
          verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.973 	-0.013 	-0.013 	0.492 	0.000 	0.000
[[366   6]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.98      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.97      0.98       376


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.1, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='squared_hinge', n_iter=5, n_jobs=4,
       penalty='l2', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.979 	-0.011 	-0.011 	0.495 	0.000 	0.000
[[368   4]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=8, max_features='auto', max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 32 candidates, totalling 160 fits
BEST: MLPClassifier(activation='tanh', alpha=0.5, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.971 	-0.014 	-0.014 	0.491 	0.000 	0.000
[[365   7]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.98      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.97      0.97       376


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight='balanced', criterion='gini', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=2.0, n_estimators=15, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	0.282 	0.279 	0.622 	0.499 	0.230
[[370   2]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       372
        1.0       0.33      0.25      0.29         4

avg / total       0.98      0.99      0.99       376


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.1, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='linear',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.976 	-0.012 	-0.012 	0.493 	0.000 	0.000
[[367   5]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...wski',
           metric_params=None, n_jobs=4, n_neighbors=4, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 192 candidates, totalling 960 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=4,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


                estimator   min_score   mean_score  max_score     sd_score  \
6      AdaBoostClassifier  -0.0157787   0.00322201    0.20775    0.0297168   
3    ExtraTreesClassifier  -0.0114051  -0.00092912          0   0.00164093   
4  RandomForestClassifier -0.00277643 -7.95009e-05          0  0.000332486   
8        VotingClassifier  -0.0034575  -0.00105377          0  0.000836972   
9    KNeighborsClassifier          -1    -0.501677          0     0.498333   
2           SGDClassifier   -0.103627    0.0412324   0.317407    0.0439419   
7                     SVC  -0.0155588    0.0178995   0.215529    0.0420274   
1      LogisticRegression  -0.0443483    0.0811564   0.294675    0.0637466   
5           MLPClassifier -0.00902372  0.000430919  0.0946831    0.0239705   
0              GaussianNB    0.107511     0.107511   0.107511            0   

        acc       auc          conf_matrix     f1_c0     f1_c1      kappa  \
6  0.986702  0.622312   [[370, 2], [3, 1]]  0.993289  0.285714   0.279141   
3  0.989362       0.5   [[372, 0], [4, 0]]  0.994652         0          0   
4  0.989362       0.5   [[372, 0], [4, 0]]  0.994652         0          0   
8  0.989362       0.5   [[372, 0], [4, 0]]  0.994652         0          0   
9  0.989362       0.5   [[372, 0], [4, 0]]  0.994652         0          0   
2  0.978723  0.494624   [[368, 4], [4, 0]]  0.989247         0 -0.0107527   
7  0.976064   0.49328   [[367, 5], [4, 0]]  0.987887         0 -0.0119617   
1  0.973404  0.491935   [[366, 6], [4, 0]]  0.986523         0  -0.012931   
5  0.970745  0.490591   [[365, 7], [4, 0]]  0.985155         0 -0.0137255   
0  0.901596  0.455645  [[339, 33], [4, 0]]  0.948252         0 -0.0193435   

  model_score   prec_c0   prec_c1    rec_c0 rec_c1  
6    0.282088  0.991957  0.333333  0.994624   0.25  
3           0  0.989362         0         1      0  
4           0  0.989362         0         1      0  
8           0  0.989362         0         1      0  
9           0  0.989362         0         1      0  
2  -0.0107527  0.989247         0  0.989247      0  
7  -0.0120381  0.989218         0  0.986559      0  
1  -0.0132048  0.989189         0  0.983871      0  
5  -0.0142822   0.98916         0  0.981183      0  
0  -0.0321639  0.988338         0   0.91129      0  
Elapsed time 23.35 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-17 00:56:34.090000 
pca_target: 40 	 poly degree: 2 	 kselect: 80 
Imbalance: SMOTE(k=None, k_neighbors=5, kind='regular', m=None, m_neighbors=10, n_jobs=1,
   out_step=0.5, random_state=None, ratio='auto', svm_estimator=None) 
Extended target (count):  31485 13
('Total : Processed (count): ', (1252L, 24976L), 13)
Final feature (count):  (1252L, 24976L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.963 	-0.017 	-0.015 	0.487 	0.000 	0.000
[[362  10]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.97      0.98       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.96      0.97       376


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=5, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.960 	0.122 	0.103 	0.609 	0.492 	0.225
[[360  12]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.97      0.98       372
        1.0       0.08      0.25      0.12         4

avg / total       0.98      0.96      0.97       376


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.001, average=False, class_weight='balanced',
       epsilon=0.1, eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='modified_huber', n_iter=5, n_jobs=4,
       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.968 	-0.015 	-0.014 	0.489 	0.000 	0.000
[[364   8]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.98      0.98       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.97      0.97       376


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=8, max_features=0.75, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=30, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 32 candidates, totalling 160 fits
BEST: MLPClassifier(activation='relu', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.973 	-0.013 	-0.013 	0.492 	0.000 	0.000
[[366   6]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.98      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.97      0.98       376


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=0.5, n_estimators=15, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.1, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=10.0, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Ran...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.979 	-0.011 	-0.011 	0.495 	0.000 	0.000
[[368   4]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 192 candidates, totalling 960 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=4,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.968 	-0.015 	-0.014 	0.489 	0.000 	0.000
[[364   8]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.98      0.98       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.97      0.97       376


                estimator  min_score mean_score max_score     sd_score  \
1      LogisticRegression   0.560909   0.876918  0.977217     0.119552   
3    ExtraTreesClassifier   0.856876   0.992655         1    0.0241971   
4  RandomForestClassifier   0.994263    0.99947         1  0.000917513   
6      AdaBoostClassifier   0.888844    0.99301         1   0.00775246   
7                     SVC          0   0.857909         1     0.278904   
8        VotingClassifier    0.95382   0.981167  0.993119   0.00956703   
5           MLPClassifier   0.974943   0.985436  0.991962   0.00460141   
2           SGDClassifier -0.0909265   0.692442  0.987433      0.27271   
9    KNeighborsClassifier         -1 -0.0369759  0.973874     0.963488   
0              GaussianNB   0.924164   0.924164  0.924164            0   

        acc       auc          conf_matrix     f1_c0     f1_c1      kappa  \
1  0.960106  0.608871  [[360, 12], [3, 1]]  0.979592  0.117647   0.103053   
3  0.989362       0.5   [[372, 0], [4, 0]]  0.994652         0          0   
4  0.989362       0.5   [[372, 0], [4, 0]]  0.994652         0          0   
6  0.989362       0.5   [[372, 0], [4, 0]]  0.994652         0          0   
7  0.989362       0.5   [[372, 0], [4, 0]]  0.994652         0          0   
8  0.978723  0.494624   [[368, 4], [4, 0]]  0.989247         0 -0.0107527   
5  0.973404  0.491935   [[366, 6], [4, 0]]  0.986523         0  -0.012931   
2  0.968085  0.489247   [[364, 8], [4, 0]]  0.983784         0 -0.0143885   
9  0.968085  0.489247   [[364, 8], [4, 0]]  0.983784         0 -0.0143885   
0  0.962766  0.486559  [[362, 10], [4, 0]]   0.98103         0 -0.0154321   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
1     0.12227  0.991736  0.0769231  0.967742   0.25  
3           0  0.989362          0         1      0  
4           0  0.989362          0         1      0  
6           0  0.989362          0         1      0  
7           0  0.989362          0         1      0  
8  -0.0107527  0.989247          0  0.989247      0  
5  -0.0132048  0.989189          0  0.983871      0  
2   -0.015289   0.98913          0  0.978495      0  
9   -0.015289   0.98913          0  0.978495      0  
0  -0.0171403  0.989071          0  0.973118      0  
Elapsed time 48.49 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-17 01:45:03.368000 
pca_target: 40 	 poly degree: 2 	 kselect: 80 
Imbalance: SMOTE(k=None, k_neighbors=3, kind='regular', m=None, m_neighbors=10, n_jobs=1,
   out_step=0.5, random_state=None, ratio='auto', svm_estimator=None) 
Extended target (count):  31485 13
('Total : Processed (count): ', (1252L, 24976L), 13)
Final feature (count):  (1252L, 24976L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.944 	0.298 	0.208 	0.848 	0.842 	0.696
[[352  20]
 [  1   3]]
             precision    recall  f1-score   support

        0.0       1.00      0.95      0.97       372
        1.0       0.13      0.75      0.22         4

avg / total       0.99      0.94      0.96       376


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=10, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=10, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.963 	-0.017 	-0.015 	0.487 	0.000 	0.000
[[362  10]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.97      0.98       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.96      0.97       376


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.001, average=False, class_weight='balanced',
       epsilon=0.1, eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='perceptron', n_iter=5, n_jobs=4,
       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.973 	-0.013 	-0.013 	0.492 	0.000 	0.000
[[366   6]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.98      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.97      0.98       376


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=8, max_features=0.75, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=30, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=None, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 32 candidates, totalling 160 fits
BEST: MLPClassifier(activation='relu', alpha=0.01, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.979 	0.194 	0.190 	0.618 	0.497 	0.228
[[367   5]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       372
        1.0       0.17      0.25      0.20         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=1.0, n_estimators=50, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.1, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=10.0, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', ...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	-0.005 	-0.004 	0.499 	0.000 	0.000
[[371   1]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 192 candidates, totalling 960 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=3,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.971 	0.153 	0.141 	0.614 	0.495 	0.227
[[364   8]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.98      0.99       372
        1.0       0.11      0.25      0.15         4

avg / total       0.98      0.97      0.98       376


                estimator  min_score mean_score max_score    sd_score  \
0              GaussianNB   0.900035   0.900035  0.900035           0   
5           MLPClassifier    0.97385   0.985332  0.994256  0.00535148   
9    KNeighborsClassifier         -1 -0.0373951  0.969392    0.962967   
3    ExtraTreesClassifier   0.824384   0.992286         1   0.0257163   
4  RandomForestClassifier   0.986302   0.995335         1  0.00235461   
6      AdaBoostClassifier   0.940083   0.989511         1  0.00778779   
7                     SVC          0   0.874886         1    0.266539   
8        VotingClassifier   0.951645   0.981386  0.993112  0.00948583   
2           SGDClassifier -0.0113854   0.697979  0.987414    0.269889   
1      LogisticRegression   0.567129   0.876317   0.97726    0.118812   

        acc       auc          conf_matrix     f1_c0     f1_c1      kappa  \
0  0.944149  0.848118  [[352, 20], [1, 3]]  0.971034  0.222222   0.207865   
5  0.978723   0.61828   [[367, 5], [3, 1]]  0.989218       0.2   0.189655   
9  0.970745  0.614247   [[364, 8], [3, 1]]  0.985115  0.153846   0.141196   
3  0.989362       0.5   [[372, 0], [4, 0]]  0.994652         0          0   
4  0.989362       0.5   [[372, 0], [4, 0]]  0.994652         0          0   
6  0.989362       0.5   [[372, 0], [4, 0]]  0.994652         0          0   
7  0.989362       0.5   [[372, 0], [4, 0]]  0.994652         0          0   
8  0.986702  0.498656   [[371, 1], [4, 0]]  0.993307         0 -0.0042735   
2  0.973404  0.491935   [[366, 6], [4, 0]]  0.986523         0  -0.012931   
1  0.962766  0.486559  [[362, 10], [4, 0]]   0.98103         0 -0.0154321   

  model_score   prec_c0   prec_c1    rec_c0 rec_c1  
0    0.298062  0.997167  0.130435  0.946237   0.75  
5    0.193671  0.991892  0.166667  0.986559   0.25  
9    0.153364  0.991826  0.111111  0.978495   0.25  
3           0  0.989362         0         1      0  
4           0  0.989362         0         1      0  
6           0  0.989362         0         1      0  
7           0  0.989362         0         1      0  
8  -0.0053548  0.989333         0  0.997312      0  
2  -0.0132048  0.989189         0  0.983871      0  
1  -0.0171403  0.989071         0  0.973118      0  
Elapsed time 46.00 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-17 02:31:03.192000 
pca_target: 40 	 poly degree: 2 	 kselect: 80 
Imbalance: ClusterCentroids(estimator=None, n_jobs=1, random_state=None, ratio='auto') 
Extended target (count):  31485 13
('Total : Processed (count): ', (1252L, 24976L), 13)
Final feature (count):  (1252L, 24976L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.011 	0.000 	0.000 	0.500 	0.000 	0.000
[[  0 372]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       0.00      0.00      0.00       372
        1.0       0.01      1.00      0.02         4

avg / total       0.00      0.01      0.00       376


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=5, class_weight={1: 3}, dual=False, fit_intercept=True,
          intercept_scaling=0.1, max_iter=100, multi_class='ovr', n_jobs=4,
          penalty='l2', random_state=None, solver='lbfgs', tol=0.0001,
          verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.500 	0.000 	0.000 	0.500 	0.500 	0.250
[[186 186]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      0.50      0.66       372
        1.0       0.01      0.50      0.02         4

avg / total       0.98      0.50      0.66       376


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.0001, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='modified_huber', n_iter=5, n_jobs=4,
       penalty='l2', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.500 	-0.000 	0.000 	0.500 	0.500 	0.250
[[186 186]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      0.50      0.66       372
        1.0       0.01      0.50      0.02         4

avg / total       0.98      0.50      0.66       376


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=8, max_features='auto', max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.609 	0.127 	0.032 	0.802 	0.778 	0.629
[[225 147]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.60      0.75       372
        1.0       0.03      1.00      0.05         4

avg / total       0.99      0.61      0.75       376


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.609 	0.127 	0.032 	0.802 	0.778 	0.629
[[225 147]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.60      0.75       372
        1.0       0.03      1.00      0.05         4

avg / total       0.99      0.61      0.75       376


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 32 candidates, totalling 160 fits
BEST: MLPClassifier(activation='relu', alpha=0.01, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.497 	-0.001 	-0.000 	0.499 	0.499 	0.249
[[185 187]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      0.50      0.66       372
        1.0       0.01      0.50      0.02         4

avg / total       0.98      0.50      0.66       376


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=0.5, n_estimators=15, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.641 	0.135 	0.036 	0.819 	0.798 	0.660
[[237 135]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.64      0.78       372
        1.0       0.03      1.00      0.06         4

avg / total       0.99      0.64      0.77       376


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.011 	0.000 	0.000 	0.500 	0.000 	0.000
[[  0 372]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       0.00      0.00      0.00       372
        1.0       0.01      1.00      0.02         4

avg / total       0.00      0.01      0.00       376


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.274 	0.062 	0.008 	0.633 	0.516 	0.286
[[ 99 273]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.27      0.42       372
        1.0       0.01      1.00      0.03         4

avg / total       0.99      0.27      0.42       376


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 192 candidates, totalling 960 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=5, p=1,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.809 	0.081 	0.033 	0.656 	0.637 	0.393
[[302  70]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      0.81      0.89       372
        1.0       0.03      0.50      0.05         4

avg / total       0.98      0.81      0.88       376


                estimator min_score mean_score max_score   sd_score  \
6      AdaBoostClassifier  0.555556   0.903658         1  0.0623973   
3    ExtraTreesClassifier  0.906078   0.997652         1  0.0146636   
4  RandomForestClassifier  0.812156   0.996087         1  0.0200312   
9    KNeighborsClassifier        -1  -0.229806  0.906078   0.788451   
8        VotingClassifier  0.777778   0.964788         1   0.077635   
0              GaussianNB         1          1         1          0   
1      LogisticRegression         0   0.380024  0.906078   0.238871   
2           SGDClassifier -0.239411   0.411664  0.812156   0.144451   
7                     SVC         0   0.430034  0.906078   0.258225   
5           MLPClassifier  0.367711   0.805959         1   0.171881   

         acc       auc           conf_matrix     f1_c0      f1_c1  \
6   0.640957  0.818548  [[237, 135], [0, 4]]  0.778325  0.0559441   
3   0.609043  0.802419  [[225, 147], [0, 4]]  0.753769  0.0516129   
4   0.609043  0.802419  [[225, 147], [0, 4]]  0.753769  0.0516129   
9   0.808511  0.655914   [[302, 70], [2, 2]]  0.893491  0.0526316   
8   0.273936  0.633065   [[99, 273], [0, 4]]  0.420382  0.0284698   
0  0.0106383       0.5    [[0, 372], [0, 4]]         0  0.0210526   
1        0.5       0.5  [[186, 186], [2, 2]]  0.664286  0.0208333   
2        0.5       0.5  [[186, 186], [2, 2]]  0.664286  0.0208333   
7  0.0106383       0.5    [[0, 372], [0, 4]]         0  0.0210526   
5    0.49734  0.498656  [[185, 187], [2, 2]]  0.661896  0.0207254   

         kappa  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
6    0.0360073     0.135402         1   0.028777  0.637097      1  
3    0.0315391     0.126579         1  0.0264901  0.604839      1  
4    0.0315391     0.126579         1  0.0264901  0.604839      1  
9    0.0331429    0.0813043  0.993421  0.0277778  0.811828    0.5  
8   0.00765661    0.0619921         1  0.0144404  0.266129      1  
0            0            0         0  0.0106383         0      1  
1            0            0  0.989362  0.0106383       0.5    0.5  
2            0 -5.75624e-18  0.989362  0.0106383       0.5    0.5  
7            0            0         0  0.0106383         0      1  
5 -0.000112587 -0.000551578  0.989305   0.010582  0.497312    0.5  
Elapsed time 20.00 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-17 02:51:03.041000 
pca_target: 40 	 poly degree: 2 	 kselect: 80 
Imbalance: None 
Extended target (count):  31485 13
('Total : Processed (count): ', (1252L, 24976L), 13)
Final feature (count):  (1252L, 24976L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.830 	-0.045 	-0.020 	0.419 	0.000 	0.000
[[312  60]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.84      0.91       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.83      0.90       376


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.1, class_weight={1: 3}, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=4,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.984 	-0.008 	-0.007 	0.497 	0.000 	0.000
[[370   2]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.1, average=False, class_weight={1: 15}, epsilon=0.1,
       eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='invscaling', loss='perceptron', n_iter=5, n_jobs=4,
       penalty='l2', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.963 	-0.017 	-0.015 	0.487 	0.000 	0.000
[[362  10]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.97      0.98       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.96      0.97       376


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=None, max_features=0.33, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=30, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 32 candidates, totalling 160 fits
BEST: MLPClassifier(activation='relu', alpha=0.5, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.981 	-0.009 	-0.009 	0.496 	0.000 	0.000
[[369   3]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=32,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=1.0, n_estimators=50, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.976 	-0.012 	-0.012 	0.493 	0.000 	0.000
[[367   5]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.01, cache_size=200, class_weight={1: 500}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.492 	0.100 	0.020 	0.743 	0.698 	0.512
[[181 191]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.49      0.65       372
        1.0       0.02      1.00      0.04         4

avg / total       0.99      0.49      0.65       376


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 192 candidates, totalling 960 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=1,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


                estimator   min_score   mean_score  max_score     sd_score  \
7                     SVC  -0.0150663  0.000789989  0.0961898    0.0176109   
3    ExtraTreesClassifier  -0.0183194 -0.000615602   0.112386   0.00813498   
4  RandomForestClassifier -0.00325657 -8.75038e-05          0  0.000395659   
8        VotingClassifier  -0.0034575  -0.00043644          0  0.000831787   
9    KNeighborsClassifier          -1    -0.501765          0     0.498245   
1      LogisticRegression  -0.0435113    0.0547687    0.19863    0.0580214   
5           MLPClassifier  -0.0107123  -0.00487405          0   0.00239601   
6      AdaBoostClassifier  -0.0182531  0.000101505   0.354456     0.032472   
2           SGDClassifier    -0.13604    0.0372809   0.267513    0.0437232   
0              GaussianNB   0.0958143    0.0958143  0.0958143            0   

        acc       auc           conf_matrix     f1_c0     f1_c1       kappa  \
7  0.492021   0.74328  [[181, 191], [0, 4]]  0.654611  0.040201   0.0197641   
3  0.989362       0.5    [[372, 0], [4, 0]]  0.994652         0           0   
4  0.989362       0.5    [[372, 0], [4, 0]]  0.994652         0           0   
8  0.989362       0.5    [[372, 0], [4, 0]]  0.994652         0           0   
9  0.989362       0.5    [[372, 0], [4, 0]]  0.994652         0           0   
1  0.984043  0.497312    [[370, 2], [4, 0]]  0.991957         0 -0.00714286   
5  0.981383  0.495968    [[369, 3], [4, 0]]  0.990604         0 -0.00920245   
6  0.976064   0.49328    [[367, 5], [4, 0]]  0.987887         0  -0.0119617   
2  0.962766  0.486559   [[362, 10], [4, 0]]   0.98103         0  -0.0154321   
0  0.829787  0.419355   [[312, 60], [4, 0]]  0.906977         0  -0.0203528   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
7   0.0999035         1  0.0205128  0.486559      1  
3           0  0.989362          0         1      0  
4           0  0.989362          0         1      0  
8           0  0.989362          0         1      0  
9           0  0.989362          0         1      0  
1 -0.00758294  0.989305          0  0.994624      0  
5 -0.00929961  0.989276          0  0.991935      0  
6  -0.0120381  0.989218          0  0.986559      0  
2  -0.0171403  0.989071          0  0.973118      0  
0  -0.0451846  0.987342          0   0.83871      0  
Elapsed time 27.01 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-17 23:22:43.784000 
pca_target: 0 	 poly degree: 3 	 kselect: 40 
Imbalance: ClusterCentroids(estimator=None, n_jobs=1, random_state=None, ratio='auto') 
Extended target (count):  31485 13
pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-17 23:24:43.694000 
pca_target: 0 	 poly degree: 2 	 kselect: 200 
Imbalance: ClusterCentroids(estimator=None, n_jobs=1, random_state=None, ratio='auto') 
Extended target (count):  31485 13
('Total : Processed (count): ', (1252L, 24976L), 13)
Final feature (count):  (1252L, 24976L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.755 	0.120 	0.042 	0.753 	0.753 	0.566
[[281  91]
 [  1   3]]
             precision    recall  f1-score   support

        0.0       1.00      0.76      0.86       372
        1.0       0.03      0.75      0.06         4

avg / total       0.99      0.76      0.85       376


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=5, class_weight={1: 3}, dual=False, fit_intercept=True,
          intercept_scaling=10, max_iter=100, multi_class='ovr', n_jobs=4,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.864 	0.037 	0.018 	0.560 	0.467 	0.204
[[324  48]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.87      0.93       372
        1.0       0.02      0.25      0.04         4

avg / total       0.98      0.86      0.92       376


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.1, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='constant', loss='modified_huber', n_iter=5, n_jobs=4,
       penalty='l1', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.681 	-0.069 	-0.021 	0.344 	0.000 	0.000
[[256 116]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.98      0.69      0.81       372
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.68      0.80       376


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=8, max_features=0.75, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.609 	0.127 	0.032 	0.802 	0.778 	0.629
[[225 147]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.60      0.75       372
        1.0       0.03      1.00      0.05         4

avg / total       0.99      0.61      0.75       376


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.609 	0.127 	0.032 	0.802 	0.778 	0.629
[[225 147]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.60      0.75       372
        1.0       0.03      1.00      0.05         4

avg / total       0.99      0.61      0.75       376


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 32 candidates, totalling 160 fits
BEST: MLPClassifier(activation='relu', alpha=0.01, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.859 	-0.040 	-0.020 	0.434 	0.000 	0.000
[[323  49]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.87      0.92       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.86      0.91       376


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=1.0, n_estimators=15, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.620 	0.129 	0.033 	0.808 	0.785 	0.639
[[229 143]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.62      0.76       372
        1.0       0.03      1.00      0.05         4

avg / total       0.99      0.62      0.75       376


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.854 	-0.041 	-0.020 	0.431 	0.000 	0.000
[[321  51]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.86      0.92       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.85      0.91       376


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.697 	0.099 	0.030 	0.723 	0.723 	0.525
[[259 113]
 [  1   3]]
             precision    recall  f1-score   support

        0.0       1.00      0.70      0.82       372
        1.0       0.03      0.75      0.05         4

avg / total       0.99      0.70      0.81       376


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 192 candidates, totalling 960 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=1,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.721 	0.051 	0.017 	0.612 	0.601 	0.353
[[269 103]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      0.72      0.84       372
        1.0       0.02      0.50      0.04         4

avg / total       0.98      0.72      0.83       376


                estimator min_score mean_score max_score     sd_score  \
6      AdaBoostClassifier  0.461633   0.899046         1     0.101092   
3    ExtraTreesClassifier  0.683856   0.907805         1    0.0833462   
4  RandomForestClassifier  0.906078   0.906078  0.906078  1.11022e-16   
0              GaussianNB         1          1         1            0   
8        VotingClassifier  0.812156   0.940429         1    0.0579068   
9    KNeighborsClassifier        -1  -0.210174  0.812156      0.79997   
1      LogisticRegression         0   0.500594  0.906078      0.24768   
5           MLPClassifier    0.1283   0.514791  0.812156     0.156972   
7                     SVC         0   0.578242         1     0.354454   
2           SGDClassifier   -0.3849   0.392099  0.906078     0.152824   

        acc       auc           conf_matrix     f1_c0      f1_c1      kappa  \
6  0.619681  0.807796  [[229, 143], [0, 4]]  0.762063  0.0529801  0.0329496   
3  0.609043  0.802419  [[225, 147], [0, 4]]  0.753769  0.0516129  0.0315391   
4  0.609043  0.802419  [[225, 147], [0, 4]]  0.753769  0.0516129  0.0315391   
0  0.755319  0.752688   [[281, 91], [1, 3]]  0.859327  0.0612245  0.0416667   
8  0.696809  0.723118  [[259, 113], [1, 3]]   0.81962       0.05  0.0300507   
9  0.720745  0.611559  [[269, 103], [2, 2]]  0.836703  0.0366972  0.0165405   
1  0.864362  0.560484   [[324, 48], [3, 1]]  0.927039  0.0377358  0.0184275   
5  0.859043   0.43414   [[323, 49], [4, 0]]  0.924177          0 -0.0200655   
7  0.853723  0.431452   [[321, 51], [4, 0]]   0.92109          0 -0.0201263   
2  0.680851  0.344086  [[256, 116], [4, 0]]  0.810127          0 -0.0209993   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
6    0.129425         1  0.0272109  0.615591      1  
3    0.126579         1  0.0264901  0.604839      1  
4    0.126579         1  0.0264901  0.604839      1  
0    0.119737  0.996454  0.0319149  0.755376   0.75  
8   0.0991176  0.996154  0.0258621  0.696237   0.75  
9    0.051022   0.99262  0.0190476  0.723118    0.5  
1   0.0368637  0.990826  0.0204082  0.870968   0.25  
5  -0.0401405  0.987768          0   0.86828      0  
7  -0.0410773  0.987692          0  0.862903      0  
2  -0.0692629  0.984615          0  0.688172      0  
Elapsed time 21.12 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-17 23:45:51.120000 
pca_target: 0 	 poly degree: 2 	 kselect: 200 
Imbalance: TomekLinks(n_jobs=1, random_state=None, return_indices=False) 
Extended target (count):  31485 13
('Total : Processed (count): ', (1252L, 24976L), 13)
Final feature (count):  (1252L, 24976L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.787 	0.011 	0.004 	0.522 	0.445 	0.187
[[295  77]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.79      0.88       372
        1.0       0.01      0.25      0.02         4

avg / total       0.98      0.79      0.87       376


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.01, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=5, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='sag', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.886 	-0.035 	-0.020 	0.448 	0.000 	0.000
[[333  39]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.90      0.94       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.89      0.93       376


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=1, average=False, class_weight={1: 15}, epsilon=0.1,
       eta0=0.001, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='modified_huber', n_iter=5, n_jobs=4,
       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.971 	-0.014 	-0.014 	0.491 	0.000 	0.000
[[365   7]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.98      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.97      0.97       376


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight='balanced',
           criterion='gini', max_depth=8, max_features=0.75,
           max_leaf_nodes=None, min_impurity_split=1e-07,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=4,
           oob_score=False, random_state=None, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.960 	-0.018 	-0.016 	0.485 	0.000 	0.000
[[361  11]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.97      0.98       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.96      0.97       376


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 32 candidates, totalling 160 fits
BEST: MLPClassifier(activation='relu', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.973 	-0.013 	-0.013 	0.492 	0.000 	0.000
[[366   6]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.98      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.97      0.98       376


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='entropy', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=2.0, n_estimators=15, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.976 	0.178 	0.171 	0.617 	0.496 	0.228
[[366   6]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.98      0.99       372
        1.0       0.14      0.25      0.18         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.01, cache_size=200, class_weight={1: 500}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.492 	0.100 	0.020 	0.743 	0.698 	0.512
[[181 191]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.49      0.65       372
        1.0       0.02      1.00      0.04         4

avg / total       0.99      0.49      0.65       376


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...owski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='uniform'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 192 candidates, totalling 960 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=1,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


                estimator  min_score   mean_score  max_score    sd_score  \
7                     SVC -0.0186982    0.0117985  0.0944904    0.025983   
6      AdaBoostClassifier -0.0149095   0.00530789   0.214666   0.0349794   
0              GaussianNB   0.116039     0.116039   0.116039           0   
4  RandomForestClassifier -0.0135948 -0.000294347          0   0.0012373   
8        VotingClassifier -0.0102252  -0.00349554          0  0.00316338   
9    KNeighborsClassifier         -1    -0.500985          0    0.499021   
5           MLPClassifier -0.0100712  -0.00469918  0.0637657   0.0123906   
2           SGDClassifier   -0.19833    0.0424065   0.212002   0.0437404   
3    ExtraTreesClassifier -0.0185166 -0.000583491    0.06012   0.0087117   
1      LogisticRegression -0.0311242    0.0279368   0.154503   0.0398003   

        acc       auc           conf_matrix     f1_c0      f1_c1       kappa  \
7  0.492021   0.74328  [[181, 191], [0, 4]]  0.654611   0.040201   0.0197641   
6  0.976064  0.616935    [[366, 6], [3, 1]]  0.987854   0.181818    0.170588   
0  0.787234  0.521505   [[295, 77], [3, 1]]  0.880597  0.0243902  0.00423729   
4  0.989362       0.5    [[372, 0], [4, 0]]  0.994652          0           0   
8  0.989362       0.5    [[372, 0], [4, 0]]  0.994652          0           0   
9  0.989362       0.5    [[372, 0], [4, 0]]  0.994652          0           0   
5  0.973404  0.491935    [[366, 6], [4, 0]]  0.986523          0   -0.012931   
2  0.970745  0.490591    [[365, 7], [4, 0]]  0.985155          0  -0.0137255   
3  0.960106  0.485215   [[361, 11], [4, 0]]  0.979647          0  -0.0158501   
1  0.885638  0.447581   [[333, 39], [4, 0]]  0.939351          0  -0.0196771   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
7   0.0999035         1  0.0205128  0.486559      1  
6    0.177507   0.99187   0.142857  0.983871   0.25  
0   0.0108824  0.989933  0.0128205  0.793011   0.25  
4           0  0.989362          0         1      0  
8           0  0.989362          0         1      0  
9           0  0.989362          0         1      0  
5  -0.0132048  0.989189          0  0.983871      0  
2  -0.0142822   0.98916          0  0.981183      0  
3  -0.0180015  0.989041          0   0.97043      0  
1  -0.0352757  0.988131          0  0.895161      0  
Elapsed time 39.10 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-18 00:24:57.182000 
pca_target: 0 	 poly degree: 2 	 kselect: 200 
Imbalance: None 
Extended target (count):  31485 13
('Total : Processed (count): ', (1252L, 24976L), 13)
Final feature (count):  (1252L, 24976L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.771 	0.007 	0.002 	0.513 	0.441 	0.184
[[289  83]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.78      0.87       372
        1.0       0.01      0.25      0.02         4

avg / total       0.98      0.77      0.86       376


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.001, class_weight={1: 3}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.976 	-0.012 	-0.012 	0.493 	0.000 	0.000
[[367   5]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=1, average=False, class_weight={1: 15}, epsilon=0.1,
       eta0=0.001, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='modified_huber', n_iter=5, n_jobs=4,
       penalty='l2', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.944 	-0.023 	-0.018 	0.477 	0.000 	0.000
[[355  17]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.95      0.97       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.94      0.96       376


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight='balanced',
           criterion='entropy', max_depth=8, max_features=0.75,
           max_leaf_nodes=None, min_impurity_split=1e-07,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=4,
           oob_score=False, random_state=None, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.968 	-0.015 	-0.014 	0.489 	0.000 	0.000
[[364   8]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.98      0.98       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.97      0.97       376


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 32 candidates, totalling 160 fits
BEST: MLPClassifier(activation='relu', alpha=0.01, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.976 	-0.012 	-0.012 	0.493 	0.000 	0.000
[[367   5]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=8,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=0.5, n_estimators=80, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.965 	-0.016 	-0.015 	0.488 	0.000 	0.000
[[363   9]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.98      0.98       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.97      0.97       376


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.01, cache_size=200, class_weight={1: 500}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.487 	0.099 	0.019 	0.741 	0.694 	0.506
[[179 193]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.48      0.65       372
        1.0       0.02      1.00      0.04         4

avg / total       0.99      0.49      0.64       376


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...owski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='uniform'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 192 candidates, totalling 960 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=1,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


                estimator   min_score   mean_score   max_score    sd_score  \
7                     SVC   -0.015284    0.0117866   0.0943467   0.0261786   
0              GaussianNB    0.108471     0.108471    0.108471           0   
4  RandomForestClassifier -0.00856838 -0.000339457           0  0.00108999   
8        VotingClassifier -0.00892977  -0.00309776           0  0.00275885   
9    KNeighborsClassifier          -1     -0.50101           0    0.498995   
1      LogisticRegression  -0.0176178    0.0418761    0.132519   0.0400393   
5           MLPClassifier -0.00908381  -0.00694166 -0.00393778  0.00135939   
3    ExtraTreesClassifier  -0.0231054  -0.00130629   0.0637248  0.00822456   
6      AdaBoostClassifier  -0.0152905   0.00519046    0.279397   0.0387468   
2           SGDClassifier   -0.149006    0.0490326    0.253224   0.0439711   

        acc       auc           conf_matrix     f1_c0      f1_c1       kappa  \
7  0.486702  0.740591  [[179, 193], [0, 4]]  0.649728   0.039801   0.0193514   
0  0.771277  0.513441   [[289, 83], [3, 1]]  0.870482  0.0227273  0.00246792   
4  0.989362       0.5    [[372, 0], [4, 0]]  0.994652          0           0   
8  0.989362       0.5    [[372, 0], [4, 0]]  0.994652          0           0   
9  0.989362       0.5    [[372, 0], [4, 0]]  0.994652          0           0   
1  0.976064   0.49328    [[367, 5], [4, 0]]  0.987887          0  -0.0119617   
5  0.976064   0.49328    [[367, 5], [4, 0]]  0.987887          0  -0.0119617   
3  0.968085  0.489247    [[364, 8], [4, 0]]  0.983784          0  -0.0143885   
6  0.965426  0.487903    [[363, 9], [4, 0]]  0.982409          0  -0.0149502   
2  0.944149  0.477151   [[355, 17], [4, 0]]  0.971272          0  -0.0175258   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
7   0.0988444         1  0.0203046  0.481183      1  
0  0.00662106  0.989726  0.0119048  0.776882   0.25  
4           0  0.989362          0         1      0  
8           0  0.989362          0         1      0  
9           0  0.989362          0         1      0  
1  -0.0120381  0.989218          0  0.986559      0  
5  -0.0120381  0.989218          0  0.986559      0  
3   -0.015289   0.98913          0  0.978495      0  
6  -0.0162385  0.989101          0  0.975806      0  
2   -0.022565  0.988858          0  0.954301      0  
Elapsed time 31.73 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-18 00:56:41.064000 
pca_target: 0 	 poly degree: 2 	 kselect: 40 
Imbalance: ClusterCentroids(estimator=None, n_jobs=1, random_state=None, ratio='auto') 
Extended target (count):  31485 13
('Total : Processed (count): ', (1252L, 24976L), 13)
Final feature (count):  (1252L, 24976L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.686 	0.150 	0.044 	0.841 	0.826 	0.704
[[254 118]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.68      0.81       372
        1.0       0.03      1.00      0.06         4

avg / total       0.99      0.69      0.80       376


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=1, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='sag', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.827 	0.155 	0.066 	0.789 	0.788 	0.616
[[308  64]
 [  1   3]]
             precision    recall  f1-score   support

        0.0       1.00      0.83      0.90       372
        1.0       0.04      0.75      0.08         4

avg / total       0.99      0.83      0.90       376


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=1, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='squared_hinge', n_iter=5, n_jobs=4,
       penalty='l2', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.676 	0.146 	0.042 	0.836 	0.820 	0.694
[[250 122]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.67      0.80       372
        1.0       0.03      1.00      0.06         4

avg / total       0.99      0.68      0.80       376


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=8, max_features='auto', max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.609 	0.127 	0.032 	0.802 	0.778 	0.629
[[225 147]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.60      0.75       372
        1.0       0.03      1.00      0.05         4

avg / total       0.99      0.61      0.75       376


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features=0.75, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.609 	0.127 	0.032 	0.802 	0.778 	0.629
[[225 147]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.60      0.75       372
        1.0       0.03      1.00      0.05         4

avg / total       0.99      0.61      0.75       376


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 32 candidates, totalling 160 fits
BEST: MLPClassifier(activation='tanh', alpha=0.1, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.811 	0.208 	0.083 	0.905 	0.900 	0.825
[[301  71]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.81      0.89       372
        1.0       0.05      1.00      0.10         4

avg / total       0.99      0.81      0.89       376


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=1.0, n_estimators=15, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.777 	0.129 	0.047 	0.763 	0.763 	0.581
[[289  83]
 [  1   3]]
             precision    recall  f1-score   support

        0.0       1.00      0.78      0.87       372
        1.0       0.03      0.75      0.07         4

avg / total       0.99      0.78      0.86       376


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.1, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='linear',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.787 	-0.052 	-0.021 	0.398 	0.000 	0.000
[[296  76]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.80      0.88       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.79      0.87       376


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.612 	0.127 	0.032 	0.804 	0.779 	0.631
[[226 146]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.61      0.76       372
        1.0       0.03      1.00      0.05         4

avg / total       0.99      0.61      0.75       376


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 192 candidates, totalling 960 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=1,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.622 	0.078 	0.020 	0.685 	0.682 	0.472
[[231 141]
 [  1   3]]
             precision    recall  f1-score   support

        0.0       1.00      0.62      0.76       372
        1.0       0.02      0.75      0.04         4

avg / total       0.99      0.62      0.76       376


                estimator min_score mean_score max_score   sd_score       acc  \
5           MLPClassifier  0.683856   0.858042  0.906078  0.0556342   0.81117   
0              GaussianNB         1          1         1          0   0.68617   
2           SGDClassifier -0.239411   0.424418         1     0.1454  0.675532   
8        VotingClassifier  0.906078   0.993478         1  0.0238758  0.611702   
3    ExtraTreesClassifier  0.888889   0.917284         1  0.0484637  0.609043   
4  RandomForestClassifier  0.794967   0.891714         1  0.0189593  0.609043   
1      LogisticRegression         0   0.418111  0.812156   0.265222  0.827128   
6      AdaBoostClassifier  0.461633   0.903107         1  0.0782502  0.776596   
9    KNeighborsClassifier        -1  -0.136279         1   0.872702   0.62234   
7                     SVC         0   0.521179  0.906078    0.33296  0.787234   

        auc           conf_matrix     f1_c0      f1_c1      kappa model_score  \
5   0.90457   [[301, 71], [0, 4]]  0.894502   0.101266  0.0827378    0.207736   
0  0.841398  [[254, 118], [0, 4]]  0.811502  0.0634921  0.0437931    0.149622   
2  0.836022  [[250, 122], [0, 4]]  0.803859  0.0615385  0.0417781    0.146064   
8  0.803763  [[226, 146], [0, 4]]  0.755853  0.0519481  0.0318849    0.127282   
3  0.802419  [[225, 147], [0, 4]]  0.753769  0.0516129  0.0315391    0.126579   
4  0.802419  [[225, 147], [0, 4]]  0.753769  0.0516129  0.0315391    0.126579   
1  0.788978   [[308, 64], [1, 3]]  0.904552   0.084507  0.0657492    0.154946   
6  0.763441   [[289, 83], [1, 3]]  0.873112  0.0666667  0.0472973    0.128696   
9  0.685484  [[231, 141], [1, 3]]  0.764901  0.0405405  0.0202584   0.0782911   
7  0.397849   [[296, 76], [4, 0]]  0.880952          0 -0.0206298  -0.0521921   

    prec_c0    prec_c1    rec_c0 rec_c1  
5         1  0.0533333   0.80914      1  
0         1  0.0327869  0.682796      1  
2         1   0.031746  0.672043      1  
8         1  0.0266667  0.607527      1  
3         1  0.0264901  0.604839      1  
4         1  0.0264901  0.604839      1  
1  0.996764  0.0447761  0.827957   0.75  
6  0.996552  0.0348837  0.776882   0.75  
9   0.99569  0.0208333  0.620968   0.75  
7  0.986667          0  0.795699      0  
Elapsed time 19.92 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-18 01:16:36.145000 
pca_target: 0 	 poly degree: 2 	 kselect: 40 
Imbalance: TomekLinks(n_jobs=1, random_state=None, return_indices=False) 
Extended target (count):  31485 13
('Total : Processed (count): ', (1252L, 24976L), 13)
Final feature (count):  (1252L, 24976L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.867 	-0.039 	-0.020 	0.438 	0.000 	0.000
[[326  46]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.88      0.93       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.87      0.92       376


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.001, class_weight={1: 50}, dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='sag', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.907 	-0.031 	-0.019 	0.458 	0.000 	0.000
[[341  31]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.92      0.95       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.91      0.94       376


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.5, average=False, class_weight={1: 15}, epsilon=0.1,
       eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='modified_huber', n_iter=5, n_jobs=4,
       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.973 	-0.013 	-0.013 	0.492 	0.000 	0.000
[[366   6]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.98      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.97      0.98       376


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=8, max_features=0.33, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 32 candidates, totalling 160 fits
BEST: MLPClassifier(activation='relu', alpha=0.5, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.981 	-0.009 	-0.009 	0.496 	0.000 	0.000
[[369   3]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 50}, criterion='gini', max_depth=8,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=0.5, n_estimators=15, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.984 	-0.008 	-0.007 	0.497 	0.000 	0.000
[[370   2]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.737 	0.113 	0.037 	0.743 	0.743 	0.553
[[274  98]
 [  1   3]]
             precision    recall  f1-score   support

        0.0       1.00      0.74      0.85       372
        1.0       0.03      0.75      0.06         4

avg / total       0.99      0.74      0.84       376


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...wski',
           metric_params=None, n_jobs=4, n_neighbors=4, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 192 candidates, totalling 960 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=4,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.984 	-0.008 	-0.007 	0.497 	0.000 	0.000
[[370   2]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.98      0.98       376


                estimator   min_score  mean_score  max_score    sd_score  \
7                     SVC  -0.0174145   0.0114188   0.123312   0.0232883   
3    ExtraTreesClassifier  -0.0179219  -0.0006618   0.196545   0.0126898   
4  RandomForestClassifier  -0.0100207 -0.00054913          0   0.0011856   
8        VotingClassifier -0.00720273 -0.00284226          0  0.00180874   
6      AdaBoostClassifier  -0.0167867  0.00775753   0.196545   0.0440645   
9    KNeighborsClassifier          -1   -0.498805  0.0580711    0.501301   
5           MLPClassifier  -0.0121525 -0.00627556          0  0.00290996   
2           SGDClassifier   -0.137272   0.0592213     0.3363   0.0493602   
1      LogisticRegression  -0.0531066   0.0522599   0.248003   0.0430779   
0              GaussianNB    0.142156    0.142156   0.142156           0   

        acc       auc          conf_matrix     f1_c0      f1_c1       kappa  \
7  0.736702   0.74328  [[274, 98], [1, 3]]  0.846986  0.0571429   0.0374431   
3  0.989362       0.5   [[372, 0], [4, 0]]  0.994652          0           0   
4  0.989362       0.5   [[372, 0], [4, 0]]  0.994652          0           0   
8  0.989362       0.5   [[372, 0], [4, 0]]  0.994652          0           0   
6  0.984043  0.497312   [[370, 2], [4, 0]]  0.991957          0 -0.00714286   
9  0.984043  0.497312   [[370, 2], [4, 0]]  0.991957          0 -0.00714286   
5  0.981383  0.495968   [[369, 3], [4, 0]]  0.990604          0 -0.00920245   
2  0.973404  0.491935   [[366, 6], [4, 0]]  0.986523          0   -0.012931   
1  0.906915  0.458333  [[341, 31], [4, 0]]  0.951185          0  -0.0192069   
0  0.867021  0.438172  [[326, 46], [4, 0]]  0.928775          0  -0.0199653   

  model_score   prec_c0   prec_c1    rec_c0 rec_c1  
7    0.112619  0.996364  0.029703  0.736559   0.75  
3           0  0.989362         0         1      0  
4           0  0.989362         0         1      0  
8           0  0.989362         0         1      0  
6 -0.00758294  0.989305         0  0.994624      0  
9 -0.00758294  0.989305         0  0.994624      0  
5 -0.00929961  0.989276         0  0.991935      0  
2  -0.0132048  0.989189         0  0.983871      0  
1  -0.0310835  0.988406         0  0.916667      0  
0  -0.0387151  0.987879         0  0.876344      0  
Elapsed time 26.94 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-18 01:43:32.695000 
pca_target: 0 	 poly degree: 2 	 kselect: 40 
Imbalance: None 
Extended target (count):  31485 13
('Total : Processed (count): ', (1252L, 24976L), 13)
Final feature (count):  (1252L, 24976L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.859 	-0.040 	-0.020 	0.434 	0.000 	0.000
[[323  49]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.87      0.92       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.86      0.91       376


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.01, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='sag', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.979 	-0.011 	-0.011 	0.495 	0.000 	0.000
[[368   4]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.5, average=False, class_weight={1: 15}, epsilon=0.1,
       eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='perceptron', n_iter=5, n_jobs=4,
       penalty='l2', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.896 	-0.033 	-0.019 	0.453 	0.000 	0.000
[[337  35]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.91      0.95       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.90      0.94       376


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 500}, criterion='gini',
           max_depth=8, max_features=0.33, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.934 	0.082 	0.057 	0.595 	0.485 	0.219
[[350  22]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.94      0.97       372
        1.0       0.04      0.25      0.07         4

avg / total       0.98      0.93      0.96       376


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 32 candidates, totalling 160 fits
BEST: MLPClassifier(activation='tanh', alpha=0.1, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	0.441 	0.438 	0.746 	0.704 	0.472
[[369   3]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       372
        1.0       0.40      0.50      0.44         4

avg / total       0.99      0.99      0.99       376


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=32,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=0.5, n_estimators=50, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.981 	-0.009 	-0.009 	0.496 	0.000 	0.000
[[369   3]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.739 	0.114 	0.038 	0.745 	0.745 	0.555
[[275  97]
 [  1   3]]
             precision    recall  f1-score   support

        0.0       1.00      0.74      0.85       372
        1.0       0.03      0.75      0.06         4

avg / total       0.99      0.74      0.84       376


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...wski',
           metric_params=None, n_jobs=4, n_neighbors=4, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 192 candidates, totalling 960 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=4,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	0.282 	0.279 	0.622 	0.499 	0.230
[[370   2]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       372
        1.0       0.33      0.25      0.29         4

avg / total       0.98      0.99      0.99       376


                estimator   min_score   mean_score  max_score    sd_score  \
5           MLPClassifier  -0.0102319  -0.00302198  0.0787398    0.014841   
7                     SVC  -0.0320677   0.00975628   0.122799    0.023676   
9    KNeighborsClassifier          -1    -0.499049  0.0525283    0.501041   
3    ExtraTreesClassifier  -0.0175627 -0.000842422   0.105892   0.0090744   
4  RandomForestClassifier -0.00730983 -0.000287541          0  0.00087301   
8        VotingClassifier -0.00792239  -0.00363728          0  0.00205693   
6      AdaBoostClassifier  -0.0138323   0.00785343   0.189098   0.0339968   
1      LogisticRegression  -0.0298598    0.0524385   0.198808   0.0421594   
2           SGDClassifier   -0.138472    0.0541619   0.314736   0.0475416   
0              GaussianNB    0.138293     0.138293   0.138293           0   

        acc       auc          conf_matrix     f1_c0      f1_c1       kappa  \
5  0.986702  0.745968   [[369, 3], [2, 2]]  0.993271   0.444444    0.437799   
7  0.739362  0.744624  [[275, 97], [1, 3]]  0.848765  0.0576923   0.0380117   
9  0.986702  0.622312   [[370, 2], [3, 1]]  0.993289   0.285714    0.279141   
3  0.933511   0.59543  [[350, 22], [3, 1]]  0.965517  0.0740741   0.0569823   
4  0.989362       0.5   [[372, 0], [4, 0]]  0.994652          0           0   
8  0.989362       0.5   [[372, 0], [4, 0]]  0.994652          0           0   
6  0.981383  0.495968   [[369, 3], [4, 0]]  0.990604          0 -0.00920245   
1  0.978723  0.494624   [[368, 4], [4, 0]]  0.989247          0  -0.0107527   
2  0.896277  0.452957  [[337, 35], [4, 0]]  0.945302          0  -0.0194661   
0  0.859043   0.43414  [[323, 49], [4, 0]]  0.924177          0  -0.0200655   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
5    0.440593  0.994609        0.4  0.991935    0.5  
7    0.113599  0.996377       0.03  0.739247   0.75  
9    0.282088  0.991957   0.333333  0.994624   0.25  
3   0.0817082  0.991501  0.0434783   0.94086   0.25  
4           0  0.989362          0         1      0  
8           0  0.989362          0         1      0  
6 -0.00929961  0.989276          0  0.991935      0  
1  -0.0107527  0.989247          0  0.989247      0  
2  -0.0332212   0.98827          0  0.905914      0  
0  -0.0401405  0.987768          0   0.86828      0  
Elapsed time 19.04 mins 

************************************************************

[4;33mReloaded modules[24m: migraine_processing, classifiers[0m
Finished.

CC and None only.





pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-18 09:51:13.810000 
pca_target: 0 	 poly degree: 2 	 kselect: 300 
Imbalance: ClusterCentroids(estimator=None, n_jobs=1, random_state=None, ratio='auto') 
Extended target (count):  31485 13
('Total : Processed (count): ', (1252L, 24976L), 13)
Final feature (count):  (1252L, 24976L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.705 	0.156 	0.048 	0.851 	0.838 	0.723
[[261 111]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.70      0.82       372
        1.0       0.03      1.00      0.07         4

avg / total       0.99      0.70      0.82       376


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.1, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=10, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.787 	-0.052 	-0.021 	0.398 	0.000 	0.000
[[296  76]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.80      0.88       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.79      0.87       376


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.5, average=False, class_weight='balanced', epsilon=0.1,
       eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='modified_huber', n_iter=5, n_jobs=4,
       penalty='l2', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.803 	-0.050 	-0.021 	0.406 	0.000 	0.000
[[302  70]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.81      0.89       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.80      0.88       376


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=8, max_features='auto', max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.617 	0.129 	0.033 	0.806 	0.783 	0.637
[[228 144]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.61      0.76       372
        1.0       0.03      1.00      0.05         4

avg / total       0.99      0.62      0.75       376


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.609 	0.127 	0.032 	0.802 	0.778 	0.629
[[225 147]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.60      0.75       372
        1.0       0.03      1.00      0.05         4

avg / total       0.99      0.61      0.75       376


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 32 candidates, totalling 160 fits
BEST: MLPClassifier(activation='tanh', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.649 	-0.021 	-0.006 	0.452 	0.404 	0.157
[[243 129]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.65      0.79       372
        1.0       0.01      0.25      0.01         4

avg / total       0.98      0.65      0.78       376


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=0.5, n_estimators=15, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.609 	0.127 	0.032 	0.802 	0.778 	0.629
[[225 147]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.60      0.75       372
        1.0       0.03      1.00      0.05         4

avg / total       0.99      0.61      0.75       376


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='linear',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.747 	0.001 	0.000 	0.501 	0.434 	0.179
[[280  92]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.75      0.85       372
        1.0       0.01      0.25      0.02         4

avg / total       0.98      0.75      0.85       376


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.694 	0.152 	0.045 	0.845 	0.831 	0.712
[[257 115]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.69      0.82       372
        1.0       0.03      1.00      0.07         4

avg / total       0.99      0.69      0.81       376


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 192 candidates, totalling 960 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=1,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.545 	0.111 	0.024 	0.770 	0.735 	0.565
[[201 171]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.54      0.70       372
        1.0       0.02      1.00      0.04         4

avg / total       0.99      0.55      0.69       376


                estimator min_score mean_score max_score    sd_score  \
0              GaussianNB  0.906078   0.906078  0.906078           0   
8        VotingClassifier  0.906078   0.974345         1   0.0418495   
3    ExtraTreesClassifier  0.906078   0.998174         1   0.0129689   
4  RandomForestClassifier  0.906078   0.999478         1  0.00698107   
6      AdaBoostClassifier  0.666667   0.954742         1   0.0751335   
9    KNeighborsClassifier        -1   -0.13745         1    0.871616   
7                     SVC         0   0.678008         1    0.404332   
5           MLPClassifier  0.812156   0.979455         1   0.0510904   
2           SGDClassifier   -0.2566   0.440782         1    0.145544   
1      LogisticRegression         0   0.524509         1    0.298401   

        acc       auc           conf_matrix     f1_c0      f1_c1        kappa  \
0  0.704787  0.850806  [[261, 111], [0, 4]]  0.824645  0.0672269    0.0476451   
8  0.694149   0.84543  [[257, 115], [0, 4]]   0.81717  0.0650407    0.0453903   
3  0.617021  0.806452  [[228, 144], [0, 4]]      0.76  0.0526316    0.0325901   
4  0.609043  0.802419  [[225, 147], [0, 4]]  0.753769  0.0516129    0.0315391   
6  0.609043  0.802419  [[225, 147], [0, 4]]  0.753769  0.0516129    0.0315391   
9  0.545213  0.770161  [[201, 171], [0, 4]]  0.701571  0.0446927    0.0243991   
7   0.74734  0.501344   [[280, 92], [3, 1]]  0.854962  0.0206186  0.000223914   
5  0.648936  0.451613  [[243, 129], [3, 1]]  0.786408  0.0149254  -0.00583658   
2  0.803191  0.405914   [[302, 70], [4, 0]]  0.890855          0   -0.0205399   
1  0.787234  0.397849   [[296, 76], [4, 0]]  0.880952          0   -0.0206298   

   model_score   prec_c0     prec_c1    rec_c0 rec_c1  
0     0.156218         1   0.0347826  0.701613      1  
8     0.152388         1   0.0336134   0.69086      1  
3     0.128705         1    0.027027  0.612903      1  
4     0.126579         1   0.0264901  0.604839      1  
6     0.126579         1   0.0264901  0.604839      1  
9     0.111132         1   0.0228571  0.540323      1  
7  0.000639181  0.989399   0.0107527  0.752688   0.25  
5   -0.0208748  0.987805  0.00769231  0.653226   0.25  
2    -0.049596  0.986928           0  0.811828      0  
1   -0.0521921  0.986667           0  0.795699      0  
Elapsed time 21.41 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-18 10:12:38.499000 
pca_target: 0 	 poly degree: 2 	 kselect: 300 
Imbalance: None 
Extended target (count):  31485 13
('Total : Processed (count): ', (1252L, 24976L), 13)
Final feature (count):  (1252L, 24976L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.763 	0.064 	0.023 	0.633 	0.619 	0.373
[[285  87]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      0.77      0.86       372
        1.0       0.02      0.50      0.04         4

avg / total       0.98      0.76      0.86       376


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.001, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=5, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='sag', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.886 	0.047 	0.026 	0.571 	0.472 	0.209
[[332  40]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.89      0.94       372
        1.0       0.02      0.25      0.04         4

avg / total       0.98      0.89      0.93       376


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.1, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='modified_huber', n_iter=5, n_jobs=4,
       penalty='l1', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.979 	-0.011 	-0.011 	0.495 	0.000 	0.000
[[368   4]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 500}, criterion='gini',
           max_depth=8, max_features=0.33, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.939 	-0.024 	-0.018 	0.474 	0.000 	0.000
[[353  19]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.95      0.97       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.94      0.96       376


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=30, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 32 candidates, totalling 160 fits
BEST: MLPClassifier(activation='relu', alpha=0.01, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.981 	-0.009 	-0.009 	0.496 	0.000 	0.000
[[369   3]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='entropy', max_depth=8,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=1.0, n_estimators=80, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.976 	0.178 	0.171 	0.617 	0.496 	0.228
[[366   6]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.98      0.99       372
        1.0       0.14      0.25      0.18         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.561 	0.115 	0.026 	0.778 	0.746 	0.581
[[207 165]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.56      0.72       372
        1.0       0.02      1.00      0.05         4

avg / total       0.99      0.56      0.71       376


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...owski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='uniform'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 192 candidates, totalling 960 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=1,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


                estimator   min_score   mean_score  max_score     sd_score  \
7                     SVC  -0.0137429   0.00416904    0.10498    0.0234246   
0              GaussianNB    0.130429     0.130429   0.130429            0   
6      AdaBoostClassifier  -0.0190677   0.00322447   0.274085    0.0373718   
1      LogisticRegression  -0.0401759    0.0263395   0.158296    0.0346741   
4  RandomForestClassifier  -0.0075664 -0.000224753          0  0.000877522   
8        VotingClassifier -0.00892977  -0.00273086          0   0.00272731   
9    KNeighborsClassifier          -1    -0.501031          0     0.498976   
5           MLPClassifier  -0.0102921  -0.00508859  0.0504198    0.0101273   
2           SGDClassifier   -0.109283    0.0374303   0.201189    0.0436623   
3    ExtraTreesClassifier  -0.0247036   -0.0015632  0.0771279   0.00825056   

        acc       auc           conf_matrix     f1_c0      f1_c1       kappa  \
7   0.56117  0.778226  [[207, 165], [0, 4]]  0.715026  0.0462428   0.0259985   
0  0.763298  0.633065   [[285, 87], [2, 2]]  0.864947  0.0430108     0.02312   
6  0.976064  0.616935    [[366, 6], [3, 1]]  0.987854   0.181818    0.170588   
1  0.885638  0.571237   [[332, 40], [3, 1]]   0.93918  0.0444444   0.0255545   
4  0.989362       0.5    [[372, 0], [4, 0]]  0.994652          0           0   
8  0.989362       0.5    [[372, 0], [4, 0]]  0.994652          0           0   
9  0.989362       0.5    [[372, 0], [4, 0]]  0.994652          0           0   
5  0.981383  0.495968    [[369, 3], [4, 0]]  0.990604          0 -0.00920245   
2  0.978723  0.494624    [[368, 4], [4, 0]]  0.989247          0  -0.0107527   
3   0.93883  0.474462   [[353, 19], [4, 0]]   0.96845          0  -0.0178908   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
7    0.114763         1  0.0236686  0.556452      1  
0   0.0642329  0.993031  0.0224719  0.766129    0.5  
6    0.177507   0.99187   0.142857  0.983871   0.25  
1   0.0468943  0.991045  0.0243902  0.892473   0.25  
4           0  0.989362          0         1      0  
8           0  0.989362          0         1      0  
9           0  0.989362          0         1      0  
5 -0.00929961  0.989276          0  0.991935      0  
2  -0.0107527  0.989247          0  0.989247      0  
3  -0.0239222  0.988796          0  0.948925      0  
Elapsed time 42.04 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-18 10:54:40.735000 
pca_target: 0 	 poly degree: 2 	 kselect: 80 
Imbalance: ClusterCentroids(estimator=None, n_jobs=1, random_state=None, ratio='auto') 
Extended target (count):  31485 13
('Total : Processed (count): ', (1252L, 24976L), 13)
Final feature (count):  (1252L, 24976L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.691 	0.151 	0.045 	0.844 	0.830 	0.710
[[256 116]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.69      0.82       372
        1.0       0.03      1.00      0.06         4

avg / total       0.99      0.69      0.81       376


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=5, class_weight={1: 3}, dual=False, fit_intercept=True,
          intercept_scaling=0.1, max_iter=100, multi_class='ovr', n_jobs=4,
          penalty='l2', random_state=None, solver='sag', tol=0.0001,
          verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.795 	0.013 	0.005 	0.526 	0.448 	0.189
[[298  74]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.80      0.89       372
        1.0       0.01      0.25      0.03         4

avg / total       0.98      0.80      0.88       376


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.5, average=False, class_weight='balanced', epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='constant', loss='modified_huber', n_iter=5, n_jobs=4,
       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.753 	0.119 	0.041 	0.751 	0.751 	0.564
[[280  92]
 [  1   3]]
             precision    recall  f1-score   support

        0.0       1.00      0.75      0.86       372
        1.0       0.03      0.75      0.06         4

avg / total       0.99      0.75      0.85       376


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=8, max_features=0.75, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=50, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.620 	0.129 	0.033 	0.808 	0.785 	0.639
[[229 143]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.62      0.76       372
        1.0       0.03      1.00      0.05         4

avg / total       0.99      0.62      0.75       376


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.609 	0.127 	0.032 	0.802 	0.778 	0.629
[[225 147]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.60      0.75       372
        1.0       0.03      1.00      0.05         4

avg / total       0.99      0.61      0.75       376


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 32 candidates, totalling 160 fits
BEST: MLPClassifier(activation='tanh', alpha=0.01, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.843 	0.098 	0.044 	0.673 	0.651 	0.409
[[315  57]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      0.85      0.91       372
        1.0       0.03      0.50      0.06         4

avg / total       0.98      0.84      0.91       376


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=1.0, n_estimators=80, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.609 	0.127 	0.032 	0.802 	0.778 	0.629
[[225 147]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.60      0.75       372
        1.0       0.03      1.00      0.05         4

avg / total       0.99      0.61      0.75       376


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.1, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='linear',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.785 	0.072 	0.027 	0.644 	0.628 	0.382
[[293  79]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      0.79      0.88       372
        1.0       0.02      0.50      0.05         4

avg / total       0.98      0.78      0.87       376


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.612 	0.127 	0.032 	0.804 	0.779 	0.631
[[226 146]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.61      0.76       372
        1.0       0.03      1.00      0.05         4

avg / total       0.99      0.61      0.75       376


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 192 candidates, totalling 960 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=4, p=1,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.726 	0.053 	0.017 	0.614 	0.604 	0.356
[[271 101]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      0.73      0.84       372
        1.0       0.02      0.50      0.04         4

avg / total       0.98      0.73      0.83       376


                estimator min_score mean_score max_score   sd_score       acc  \
0              GaussianNB         1          1         1          0  0.691489   
3    ExtraTreesClassifier  0.812156   0.914948         1  0.0496962  0.619681   
8        VotingClassifier  0.888889   0.946704         1  0.0549003  0.611702   
4  RandomForestClassifier  0.777778    0.89503  0.906078  0.0359918  0.609043   
6      AdaBoostClassifier  0.555556   0.911995         1  0.0643042  0.609043   
2           SGDClassifier -0.367711   0.371976  0.906078   0.136083   0.75266   
5           MLPClassifier  0.496011   0.837996         1   0.123917  0.843085   
7                     SVC         0    0.55038         1   0.325178  0.784574   
9    KNeighborsClassifier        -1  -0.100509         1   0.902397  0.726064   
1      LogisticRegression         0   0.463628  0.812156   0.232158  0.795213   

        auc           conf_matrix     f1_c0      f1_c1       kappa  \
0  0.844086  [[256, 116], [0, 4]]  0.815287  0.0645161   0.0448493   
3  0.807796  [[229, 143], [0, 4]]  0.762063  0.0529801   0.0329496   
8  0.803763  [[226, 146], [0, 4]]  0.755853  0.0519481   0.0318849   
4  0.802419  [[225, 147], [0, 4]]  0.753769  0.0516129   0.0315391   
6  0.802419  [[225, 147], [0, 4]]  0.753769  0.0516129   0.0315391   
2  0.751344   [[280, 92], [1, 3]]   0.85758  0.0606061   0.0410268   
5  0.673387   [[315, 57], [2, 2]]  0.914369  0.0634921   0.0444521   
7  0.643817   [[293, 79], [2, 2]]  0.878561  0.0470588   0.0273378   
9  0.614247  [[271, 101], [2, 2]]   0.84031  0.0373832   0.0172554   
1  0.525538   [[298, 74], [3, 1]]  0.885587  0.0253165  0.00522265   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
0    0.151456         1  0.0333333  0.688172      1  
3    0.129425         1  0.0272109  0.615591      1  
8    0.127282         1  0.0266667  0.607527      1  
4    0.126579         1  0.0264901  0.604839      1  
6    0.126579         1  0.0264901  0.604839      1  
2    0.118682  0.996441  0.0315789  0.752688   0.75  
5   0.0978121  0.993691  0.0338983  0.846774    0.5  
7   0.0717776   0.99322  0.0246914  0.787634    0.5  
9   0.0525627  0.992674  0.0194175  0.728495    0.5  
1   0.0131129  0.990033  0.0133333  0.801075   0.25  
Elapsed time 19.95 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-18 11:14:37.975000 
pca_target: 0 	 poly degree: 2 	 kselect: 80 
Imbalance: None 
Extended target (count):  31485 13
('Total : Processed (count): ', (1252L, 24976L), 13)
Final feature (count):  (1252L, 24976L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.811 	-0.048 	-0.020 	0.410 	0.000 	0.000
[[305  67]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.82      0.90       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.81      0.89       376


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=10, class_weight={1: 15}, dual=False, fit_intercept=True,
          intercept_scaling=5, max_iter=100, multi_class='ovr', n_jobs=4,
          penalty='l2', random_state=None, solver='sag', tol=0.0001,
          verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.963 	-0.017 	-0.015 	0.487 	0.000 	0.000
[[362  10]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.97      0.98       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.96      0.97       376


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=1, average=False, class_weight={1: 15}, epsilon=0.1,
       eta0=0.001, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='perceptron', n_iter=5, n_jobs=4,
       penalty='l2', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.973 	-0.013 	-0.013 	0.492 	0.000 	0.000
[[366   6]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.98      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.97      0.98       376


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=16, max_features='auto', max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 500},
            criterion='gini', max_depth=8, max_features='auto',
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=15, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.968 	-0.015 	-0.014 	0.489 	0.000 	0.000
[[364   8]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.98      0.98       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.97      0.97       376


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 32 candidates, totalling 160 fits
BEST: MLPClassifier(activation='relu', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.979 	-0.011 	-0.011 	0.495 	0.000 	0.000
[[368   4]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=16,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=1.0, n_estimators=15, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.979 	0.194 	0.190 	0.618 	0.497 	0.228
[[367   5]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       372
        1.0       0.17      0.25      0.20         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=10, cache_size=200, class_weight='balanced', coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='linear',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.968 	-0.015 	-0.014 	0.489 	0.000 	0.000
[[364   8]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.98      0.98       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.97      0.97       376


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 192 candidates, totalling 960 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=1,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


                estimator   min_score   mean_score  max_score    sd_score  \
6      AdaBoostClassifier  -0.0155786   0.00497988   0.230833   0.0398793   
3    ExtraTreesClassifier  -0.0212973 -0.000472453   0.196321   0.0122573   
8        VotingClassifier -0.00745537  -0.00223603          0  0.00215309   
9    KNeighborsClassifier          -1    -0.500859          0    0.499146   
5           MLPClassifier  -0.0085683 -0.000305673   0.138884   0.0250791   
2           SGDClassifier    -0.15543    0.0518485   0.301621   0.0451228   
4  RandomForestClassifier  -0.0132918 -0.000220555  0.0436648  0.00263963   
7                     SVC  -0.0220232     0.016961   0.188172   0.0370191   
1      LogisticRegression   -0.013282    0.0557854    0.17694   0.0453311   
0              GaussianNB    0.106193     0.106193   0.106193           0   

        acc       auc          conf_matrix     f1_c0 f1_c1      kappa  \
6  0.978723   0.61828   [[367, 5], [3, 1]]  0.989218   0.2   0.189655   
3  0.989362       0.5   [[372, 0], [4, 0]]  0.994652     0          0   
8  0.989362       0.5   [[372, 0], [4, 0]]  0.994652     0          0   
9  0.989362       0.5   [[372, 0], [4, 0]]  0.994652     0          0   
5  0.978723  0.494624   [[368, 4], [4, 0]]  0.989247     0 -0.0107527   
2  0.973404  0.491935   [[366, 6], [4, 0]]  0.986523     0  -0.012931   
4  0.968085  0.489247   [[364, 8], [4, 0]]  0.983784     0 -0.0143885   
7  0.968085  0.489247   [[364, 8], [4, 0]]  0.983784     0 -0.0143885   
1  0.962766  0.486559  [[362, 10], [4, 0]]   0.98103     0 -0.0154321   
0   0.81117  0.409946  [[305, 67], [4, 0]]  0.895742     0 -0.0204893   

  model_score   prec_c0   prec_c1    rec_c0 rec_c1  
6    0.193671  0.991892  0.166667  0.986559   0.25  
3           0  0.989362         0         1      0  
8           0  0.989362         0         1      0  
9           0  0.989362         0         1      0  
5  -0.0107527  0.989247         0  0.989247      0  
2  -0.0132048  0.989189         0  0.983871      0  
4   -0.015289   0.98913         0  0.978495      0  
7   -0.015289   0.98913         0  0.978495      0  
1  -0.0171403  0.989071         0  0.973118      0  
0  -0.0482855  0.987055         0  0.819892      0  
Elapsed time 21.72 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-18 11:36:20.940000 
pca_target: 400 	 poly degree: 2 	 kselect: 300 
Imbalance: ClusterCentroids(estimator=None, n_jobs=1, random_state=None, ratio='auto') 
Extended target (count):  31485 13
('Total : Processed (count): ', (1252L, 24976L), 13)
Final feature (count):  (1252L, 24976L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.011 	0.000 	0.000 	0.500 	0.000 	0.000
[[  0 372]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       0.00      0.00      0.00       372
        1.0       0.01      1.00      0.02         4

avg / total       0.00      0.01      0.00       376


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=1, class_weight={1: 3}, dual=False, fit_intercept=True,
          intercept_scaling=0.1, max_iter=100, multi_class='ovr', n_jobs=4,
          penalty='l2', random_state=None, solver='lbfgs', tol=0.0001,
          verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.527 	0.107 	0.023 	0.761 	0.722 	0.546
[[194 178]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.52      0.69       372
        1.0       0.02      1.00      0.04         4

avg / total       0.99      0.53      0.68       376


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.001, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='invscaling', loss='squared_hinge', n_iter=5,
       n_jobs=4, penalty='l1', power_t=0.5, random_state=None,
       shuffle=True, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.449 	0.041 	0.007 	0.598 	0.579 	0.345
[[166 206]
 [  1   3]]
             precision    recall  f1-score   support

        0.0       0.99      0.45      0.62       372
        1.0       0.01      0.75      0.03         4

avg / total       0.98      0.45      0.61       376


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=8, max_features='auto', max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=30, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.646 	0.137 	0.037 	0.821 	0.802 	0.665
[[239 133]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.64      0.78       372
        1.0       0.03      1.00      0.06         4

avg / total       0.99      0.65      0.77       376


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.609 	0.127 	0.032 	0.802 	0.778 	0.629
[[225 147]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.60      0.75       372
        1.0       0.03      1.00      0.05         4

avg / total       0.99      0.61      0.75       376


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 32 candidates, totalling 160 fits
BEST: MLPClassifier(activation='tanh', alpha=0.01, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=0.5, n_estimators=15, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.609 	0.127 	0.032 	0.802 	0.778 	0.629
[[225 147]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.60      0.75       372
        1.0       0.03      1.00      0.05         4

avg / total       0.99      0.61      0.75       376


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.011 	0.000 	0.000 	0.500 	0.000 	0.000
[[  0 372]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       0.00      0.00      0.00       372
        1.0       0.01      1.00      0.02         4

avg / total       0.00      0.01      0.00       376


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.540 	-0.043 	-0.010 	0.397 	0.368 	0.132
[[202 170]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.54      0.70       372
        1.0       0.01      0.25      0.01         4

avg / total       0.97      0.54      0.69       376


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 192 candidates, totalling 960 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=1,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.691 	-0.012 	-0.004 	0.473 	0.417 	0.166
[[259 113]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.70      0.82       372
        1.0       0.01      0.25      0.02         4

avg / total       0.98      0.69      0.81       376


                estimator min_score mean_score max_score   sd_score  \
3    ExtraTreesClassifier  0.701045   0.919774         1  0.0494801   
4  RandomForestClassifier  0.906078   0.997391         1  0.0154348   
6      AdaBoostClassifier  0.333333   0.889591         1  0.0981816   
1      LogisticRegression         0   0.514073         1   0.245034   
2           SGDClassifier -0.350522   0.498664  0.906078   0.167338   
0              GaussianNB         1          1         1          0   
5           MLPClassifier  0.683856   0.879087         1  0.0927609   
7                     SVC         0   0.621106  0.906078    0.36742   
9    KNeighborsClassifier        -1  -0.142866  0.906078   0.862941   
8        VotingClassifier  0.649478   0.969497         1  0.0744259   

         acc       auc           conf_matrix     f1_c0      f1_c1       kappa  \
3   0.646277  0.821237  [[239, 133], [0, 4]]  0.782324  0.0567376   0.0368259   
4   0.609043  0.802419  [[225, 147], [0, 4]]  0.753769  0.0516129   0.0315391   
6   0.609043  0.802419  [[225, 147], [0, 4]]  0.753769  0.0516129   0.0315391   
1   0.526596  0.760753  [[194, 178], [0, 4]]  0.685512  0.0430108   0.0226636   
2   0.449468  0.598118  [[166, 206], [1, 3]]  0.615955   0.028169  0.00744746   
0  0.0106383       0.5    [[0, 372], [0, 4]]         0  0.0210526           0   
5   0.989362       0.5    [[372, 0], [4, 0]]  0.994652          0           0   
7  0.0106383       0.5    [[0, 372], [0, 4]]         0  0.0210526           0   
9   0.691489  0.473118  [[259, 113], [3, 1]]  0.817035  0.0169492 -0.00368189   
8   0.539894  0.396505  [[202, 170], [3, 1]]  0.700173  0.0114286 -0.00956047   

  model_score   prec_c0     prec_c1    rec_c0 rec_c1  
3    0.136961         1   0.0291971  0.642473      1  
4    0.126579         1   0.0264901  0.604839      1  
6    0.126579         1   0.0264901  0.604839      1  
1    0.107059         1    0.021978  0.521505      1  
2   0.0405182  0.994012   0.0143541  0.446237   0.75  
0           0         0   0.0106383         0      1  
5           0  0.989362           0         1      0  
7           0         0   0.0106383         0      1  
9  -0.0120001   0.98855  0.00877193  0.696237   0.25  
8  -0.0426456  0.985366  0.00584795  0.543011   0.25  
Elapsed time 21.07 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-18 11:57:25.258000 
pca_target: 400 	 poly degree: 2 	 kselect: 300 
Imbalance: None 
Extended target (count):  31485 13
('Total : Processed (count): ', (1252L, 24976L), 13)
Final feature (count):  (1252L, 24976L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.793 	0.075 	0.029 	0.648 	0.631 	0.386
[[296  76]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      0.80      0.88       372
        1.0       0.03      0.50      0.05         4

avg / total       0.98      0.79      0.87       376


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.001, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=0.01, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='sag', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.960 	0.122 	0.103 	0.609 	0.492 	0.225
[[360  12]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.97      0.98       372
        1.0       0.08      0.25      0.12         4

avg / total       0.98      0.96      0.97       376


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=1, average=False, class_weight={1: 50}, epsilon=0.1,
       eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='perceptron', n_iter=5, n_jobs=4,
       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.941 	-0.023 	-0.018 	0.476 	0.000 	0.000
[[354  18]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.95      0.97       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.94      0.96       376


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=8, max_features='auto', max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 32 candidates, totalling 160 fits
BEST: MLPClassifier(activation='tanh', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 50}, criterion='entropy',
            max_depth=32, max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=2.0, n_estimators=15, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.968 	-0.015 	-0.014 	0.489 	0.000 	0.000
[[364   8]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.98      0.98       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.97      0.97       376


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.01, cache_size=200, class_weight={1: 500}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.444 	0.091 	0.016 	0.719 	0.662 	0.463
[[163 209]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.44      0.61       372
        1.0       0.02      1.00      0.04         4

avg / total       0.99      0.44      0.60       376


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...wski',
           metric_params=None, n_jobs=4, n_neighbors=4, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.984 	-0.008 	-0.007 	0.497 	0.000 	0.000
[[370   2]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 192 candidates, totalling 960 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=1,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


                estimator   min_score   mean_score  max_score     sd_score  \
7                     SVC -0.00325665 -0.000373771  0.0914714    0.0088156   
0              GaussianNB   0.0913983    0.0913983  0.0913983            0   
1      LogisticRegression  -0.0160258     0.027743   0.229264    0.0356678   
3    ExtraTreesClassifier  -0.0111605 -8.56578e-05          0  0.000728993   
4  RandomForestClassifier -0.00162828 -4.52301e-06          0  8.56988e-05   
5           MLPClassifier  -0.0101382  -0.00303676          0   0.00271935   
9    KNeighborsClassifier          -1    -0.501551          0     0.498464   
8        VotingClassifier  -0.0132698   -0.0042486          0   0.00445594   
6      AdaBoostClassifier  -0.0150482 -0.000936796   0.214407     0.026722   
2           SGDClassifier   -0.169258    0.0184284   0.157964    0.0416378   

        acc       auc           conf_matrix     f1_c0      f1_c1       kappa  \
7  0.444149  0.719086  [[163, 209], [0, 4]]  0.609346  0.0368664   0.0163229   
0  0.792553  0.647849   [[296, 76], [2, 2]]  0.883582  0.0487805   0.0291314   
1  0.960106  0.608871   [[360, 12], [3, 1]]  0.979592   0.117647    0.103053   
3  0.989362       0.5    [[372, 0], [4, 0]]  0.994652          0           0   
4  0.989362       0.5    [[372, 0], [4, 0]]  0.994652          0           0   
5  0.989362       0.5    [[372, 0], [4, 0]]  0.994652          0           0   
9  0.989362       0.5    [[372, 0], [4, 0]]  0.994652          0           0   
8  0.984043  0.497312    [[370, 2], [4, 0]]  0.991957          0 -0.00714286   
6  0.968085  0.489247    [[364, 8], [4, 0]]  0.983784          0  -0.0143885   
2  0.941489  0.475806   [[354, 18], [4, 0]]  0.969863          0  -0.0177165   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
7   0.0907115         1  0.0187793  0.438172      1  
0   0.0748162  0.993289   0.025641  0.795699    0.5  
1     0.12227  0.991736  0.0769231  0.967742   0.25  
3           0  0.989362          0         1      0  
4           0  0.989362          0         1      0  
5           0  0.989362          0         1      0  
9           0  0.989362          0         1      0  
8 -0.00758294  0.989305          0  0.994624      0  
6   -0.015289   0.98913          0  0.978495      0  
2  -0.0232516  0.988827          0  0.951613      0  
Elapsed time 91.37 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-18 13:28:47.722000 
pca_target: 400 	 poly degree: 2 	 kselect: 80 
Imbalance: ClusterCentroids(estimator=None, n_jobs=1, random_state=None, ratio='auto') 
Extended target (count):  31485 13
('Total : Processed (count): ', (1252L, 24976L), 13)
Final feature (count):  (1252L, 24976L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.011 	0.000 	0.000 	0.500 	0.000 	0.000
[[  0 372]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       0.00      0.00      0.00       372
        1.0       0.01      1.00      0.02         4

avg / total       0.00      0.01      0.00       376


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.1, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.505 	0.001 	0.000 	0.503 	0.503 	0.253
[[188 184]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      0.51      0.67       372
        1.0       0.01      0.50      0.02         4

avg / total       0.98      0.51      0.66       376


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.1, average=False, class_weight='balanced', epsilon=0.1,
       eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='modified_huber', n_iter=5, n_jobs=4,
       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.465 	-0.007 	-0.001 	0.483 	0.482 	0.233
[[173 199]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      0.47      0.63       372
        1.0       0.01      0.50      0.02         4

avg / total       0.98      0.47      0.63       376


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=32, max_features=0.33, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.609 	0.127 	0.032 	0.802 	0.778 	0.629
[[225 147]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.60      0.75       372
        1.0       0.03      1.00      0.05         4

avg / total       0.99      0.61      0.75       376


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.609 	0.127 	0.032 	0.802 	0.778 	0.629
[[225 147]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.60      0.75       372
        1.0       0.03      1.00      0.05         4

avg / total       0.99      0.61      0.75       376


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 32 candidates, totalling 160 fits
BEST: MLPClassifier(activation='tanh', alpha=0.01, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.479 	-0.055 	-0.011 	0.366 	0.347 	0.118
[[179 193]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.98      0.48      0.65       372
        1.0       0.01      0.25      0.01         4

avg / total       0.97      0.48      0.64       376


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=0.5, n_estimators=15, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.609 	0.127 	0.032 	0.802 	0.778 	0.629
[[225 147]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.60      0.75       372
        1.0       0.03      1.00      0.05         4

avg / total       0.99      0.61      0.75       376


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.1, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='linear',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.500 	0.102 	0.020 	0.747 	0.703 	0.520
[[184 188]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.49      0.66       372
        1.0       0.02      1.00      0.04         4

avg / total       0.99      0.50      0.66       376


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 500}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Ran...owski',
           metric_params=None, n_jobs=4, n_neighbors=4, p=2,
           weights='uniform'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.577 	0.016 	0.004 	0.539 	0.538 	0.287
[[215 157]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      0.58      0.73       372
        1.0       0.01      0.50      0.02         4

avg / total       0.98      0.58      0.72       376


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 192 candidates, totalling 960 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=1,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.689 	-0.013 	-0.004 	0.472 	0.416 	0.166
[[258 114]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.69      0.82       372
        1.0       0.01      0.25      0.02         4

avg / total       0.98      0.69      0.81       376


                estimator min_score mean_score max_score     sd_score  \
3    ExtraTreesClassifier  0.777778   0.826412         1    0.0635567   
4  RandomForestClassifier  0.906078   0.906078  0.906078  1.11022e-16   
6      AdaBoostClassifier  0.461633   0.878055         1     0.104543   
7                     SVC         0   0.648051         1     0.394817   
8        VotingClassifier  0.350522   0.546789  0.812156    0.0925139   
1      LogisticRegression         0   0.544774  0.906078     0.252085   
0              GaussianNB         1          1         1            0   
2           SGDClassifier   -0.3849   0.363458  0.718234     0.125581   
9    KNeighborsClassifier        -1  -0.198626         1     0.827177   
5           MLPClassifier  0.367711   0.703193  0.812156     0.111753   

         acc       auc           conf_matrix     f1_c0      f1_c1  \
3   0.609043  0.802419  [[225, 147], [0, 4]]  0.753769  0.0516129   
4   0.609043  0.802419  [[225, 147], [0, 4]]  0.753769  0.0516129   
6   0.609043  0.802419  [[225, 147], [0, 4]]  0.753769  0.0516129   
7        0.5  0.747312  [[184, 188], [0, 4]]  0.661871  0.0408163   
8   0.577128  0.538978  [[215, 157], [2, 2]]  0.730051  0.0245399   
1   0.505319  0.502688  [[188, 184], [2, 2]]  0.669039  0.0210526   
0  0.0106383       0.5    [[0, 372], [0, 4]]         0  0.0210526   
2   0.465426  0.482527  [[173, 199], [2, 2]]  0.632541  0.0195122   
9    0.68883  0.471774  [[258, 114], [3, 1]]  0.815166  0.0168067   
5   0.478723  0.365591  [[179, 193], [3, 1]]  0.646209   0.010101   

         kappa model_score   prec_c0     prec_c1    rec_c0 rec_c1  
3    0.0315391    0.126579         1   0.0264901  0.604839      1  
4    0.0315391    0.126579         1   0.0264901  0.604839      1  
6    0.0315391    0.126579         1   0.0264901  0.604839      1  
7    0.0203991    0.101512         1   0.0208333  0.494624      1  
8   0.00386564   0.0161893  0.990783   0.0125786  0.577957    0.5  
1  0.000228728   0.0011032  0.989474   0.0107527  0.505376    0.5  
0            0           0         0   0.0106383         0      1  
2  -0.00137799 -0.00718762  0.988571  0.00995025  0.465054    0.5  
9  -0.00383352  -0.0125692  0.988506  0.00869565  0.693548   0.25  
5   -0.0109745  -0.0551851  0.983516  0.00515464  0.481183   0.25  
Elapsed time 20.09 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-18 13:48:52.869000 
pca_target: 400 	 poly degree: 2 	 kselect: 80 
Imbalance: None 
Extended target (count):  31485 13
('Total : Processed (count): ', (1252L, 24976L), 13)
Final feature (count):  (1252L, 24976L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.859 	-0.040 	-0.020 	0.434 	0.000 	0.000
[[323  49]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.87      0.92       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.86      0.91       376


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.001, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.949 	0.102 	0.079 	0.603 	0.489 	0.222
[[356  16]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.96      0.97       372
        1.0       0.06      0.25      0.10         4

avg / total       0.98      0.95      0.96       376


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.5, average=False, class_weight={1: 15}, epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='modified_huber', n_iter=5, n_jobs=4,
       penalty='l1', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.662 	0.089 	0.025 	0.706 	0.704 	0.500
[[246 126]
 [  1   3]]
             precision    recall  f1-score   support

        0.0       1.00      0.66      0.79       372
        1.0       0.02      0.75      0.05         4

avg / total       0.99      0.66      0.79       376


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=8, max_features='auto', max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.981 	-0.009 	-0.009 	0.496 	0.000 	0.000
[[369   3]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 32 candidates, totalling 160 fits
BEST: MLPClassifier(activation='tanh', alpha=0.01, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.957 	-0.019 	-0.016 	0.484 	0.000 	0.000
[[360  12]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.97      0.98       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.96      0.97       376


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 50}, criterion='gini', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=2.0, n_estimators=50, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.957 	-0.019 	-0.016 	0.484 	0.000 	0.000
[[360  12]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.97      0.98       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.96      0.97       376


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.01, cache_size=200, class_weight={1: 500}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.476 	0.097 	0.019 	0.735 	0.686 	0.495
[[175 197]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.47      0.64       372
        1.0       0.02      1.00      0.04         4

avg / total       0.99      0.48      0.63       376


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 500}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Ran...owski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='uniform'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	-0.005 	-0.004 	0.499 	0.000 	0.000
[[371   1]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 192 candidates, totalling 960 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=3,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.971 	-0.014 	-0.014 	0.491 	0.000 	0.000
[[365   7]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.98      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.97      0.97       376


                estimator   min_score   mean_score  max_score     sd_score  \
7                     SVC -0.00162836  0.000351653  0.0772767     0.007667   
2           SGDClassifier  -0.0993019    0.0246713   0.164544    0.0385742   
1      LogisticRegression  -0.0395111    0.0299612    0.19045    0.0436124   
3    ExtraTreesClassifier -0.00277643 -3.21832e-05          0  0.000239082   
8        VotingClassifier -0.00816993  0.000562145   0.141661    0.0213351   
4  RandomForestClassifier -0.00162828  -2.2615e-05          0  0.000190558   
9    KNeighborsClassifier          -1    -0.498142  0.0913794      0.50212   
5           MLPClassifier  -0.0128341   0.00454355   0.192089    0.0355933   
6      AdaBoostClassifier   -0.015095   0.00532657   0.156618    0.0355823   
0              GaussianNB    0.138151     0.138151   0.138151            0   

        acc       auc           conf_matrix     f1_c0      f1_c1       kappa  \
7  0.476064  0.735215  [[175, 197], [0, 4]]  0.639854  0.0390244   0.0185499   
2  0.662234  0.705645  [[246, 126], [1, 3]]   0.79483  0.0451128   0.0249918   
1  0.949468  0.603495   [[356, 16], [3, 1]]  0.974008  0.0952381   0.0793814   
3  0.989362       0.5    [[372, 0], [4, 0]]  0.994652          0           0   
8  0.986702  0.498656    [[371, 1], [4, 0]]  0.993307          0  -0.0042735   
4  0.981383  0.495968    [[369, 3], [4, 0]]  0.990604          0 -0.00920245   
9  0.970745  0.490591    [[365, 7], [4, 0]]  0.985155          0  -0.0137255   
5  0.957447  0.483871   [[360, 12], [4, 0]]  0.978261          0  -0.0162162   
6  0.957447  0.483871   [[360, 12], [4, 0]]  0.978261          0  -0.0162162   
0  0.859043   0.43414   [[323, 49], [4, 0]]  0.924177          0  -0.0200655   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
7   0.0967564         1  0.0199005   0.47043      1  
2   0.0888805  0.995951  0.0232558   0.66129   0.75  
1    0.102206  0.991643  0.0588235  0.956989   0.25  
3           0  0.989362          0         1      0  
8  -0.0053548  0.989333          0  0.997312      0  
4 -0.00929961  0.989276          0  0.991935      0  
9  -0.0142822   0.98916          0  0.981183      0  
5  -0.0188278  0.989011          0  0.967742      0  
6  -0.0188278  0.989011          0  0.967742      0  
0  -0.0401405  0.987768          0   0.86828      0  
Elapsed time 66.65 mins 

************************************************************

Lagged allx1














pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-18 16:10:52.235000 
pca_target: 0 	 poly degree: 0 	 kselect: 200 
Imbalance: ClusterCentroids(estimator=None, n_jobs=1, random_state=None, ratio='auto') 
Extended target (count):  31485 13
('Total : Processed (count): ', (1252L, 438L), 13)
Final feature (count):  (1252L, 438L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.694 	0.152 	0.045 	0.845 	0.831 	0.712
[[257 115]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.69      0.82       372
        1.0       0.03      1.00      0.07         4

avg / total       0.99      0.69      0.81       376


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=1, class_weight={1: 500}, dual=False, fit_intercept=True,
          intercept_scaling=0.1, max_iter=100, multi_class='ovr', n_jobs=4,
          penalty='l2', random_state=None, solver='lbfgs', tol=0.0001,
          verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.758 	0.003 	0.001 	0.507 	0.437 	0.181
[[284  88]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.76      0.86       372
        1.0       0.01      0.25      0.02         4

avg / total       0.98      0.76      0.85       376


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.1, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='constant', loss='modified_huber', n_iter=5, n_jobs=4,
       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.524 	0.106 	0.022 	0.759 	0.720 	0.544
[[193 179]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.52      0.68       372
        1.0       0.02      1.00      0.04         4

avg / total       0.99      0.52      0.68       376


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=8, max_features=0.33, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=50, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.596 	0.123 	0.030 	0.796 	0.769 	0.616
[[220 152]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.59      0.74       372
        1.0       0.03      1.00      0.05         4

avg / total       0.99      0.60      0.74       376


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=16, max_features=0.33, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.521 	0.106 	0.022 	0.758 	0.718 	0.541
[[192 180]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.52      0.68       372
        1.0       0.02      1.00      0.04         4

avg / total       0.99      0.52      0.67       376


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 32 candidates, totalling 160 fits
BEST: MLPClassifier(activation='tanh', alpha=0.01, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.830 	-0.045 	-0.020 	0.419 	0.000 	0.000
[[312  60]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.84      0.91       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.83      0.90       376


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=0.5, n_estimators=50, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.532 	0.108 	0.023 	0.763 	0.726 	0.552
[[196 176]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.53      0.69       372
        1.0       0.02      1.00      0.04         4

avg / total       0.99      0.53      0.68       376


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=1, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.311 	0.068 	0.009 	0.652 	0.551 	0.325
[[113 259]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.30      0.47       372
        1.0       0.02      1.00      0.03         4

avg / total       0.99      0.31      0.46       376


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...wski',
           metric_params=None, n_jobs=4, n_neighbors=4, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.707 	-0.009 	-0.003 	0.481 	0.422 	0.170
[[265 107]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.71      0.83       372
        1.0       0.01      0.25      0.02         4

avg / total       0.98      0.71      0.82       376


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 192 candidates, totalling 960 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=4,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.896 	-0.033 	-0.019 	0.453 	0.000 	0.000
[[337  35]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.91      0.95       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.90      0.94       376


                estimator  min_score mean_score max_score  sd_score       acc  \
0              GaussianNB   0.906078   0.906078  0.906078         0  0.694149   
3    ExtraTreesClassifier   0.222222   0.721531  0.906078  0.134359  0.595745   
6      AdaBoostClassifier  -0.239411   0.466566  0.906078  0.175409  0.531915   
2           SGDClassifier  -0.572745   0.269628  0.718234  0.212125  0.523936   
4  RandomForestClassifier   0.145489   0.733129         1  0.173521  0.521277   
7                     SVC -0.0171889   0.249386  0.812156  0.201406   0.31117   
1      LogisticRegression  -0.350522    0.12769  0.572745   0.22439  0.757979   
8        VotingClassifier -0.0171889   0.539076  0.812156  0.121859  0.707447   
9    KNeighborsClassifier         -1  -0.457687    0.2566  0.547836  0.896277   
5           MLPClassifier  -0.239411    0.18915  0.478822  0.156374  0.829787   

        auc           conf_matrix     f1_c0      f1_c1       kappa  \
0   0.84543  [[257, 115], [0, 4]]   0.81717  0.0650407   0.0453903   
3  0.795699  [[220, 152], [0, 4]]  0.743243       0.05   0.0298751   
6  0.763441  [[196, 176], [0, 4]]  0.690141  0.0434783    0.023146   
2  0.759409  [[193, 179], [0, 4]]  0.683186  0.0427807   0.0224262   
4  0.758065  [[192, 180], [0, 4]]  0.680851  0.0425532   0.0221914   
7  0.651882  [[113, 259], [0, 4]]  0.465979  0.0299625  0.00919746   
1   0.50672   [[284, 88], [3, 1]]  0.861912  0.0215054  0.00116768   
8  0.481183  [[265, 107], [3, 1]]  0.828125  0.0178571 -0.00271528   
9  0.452957   [[337, 35], [4, 0]]  0.945302          0  -0.0194661   
5  0.419355   [[312, 60], [4, 0]]  0.906977          0  -0.0203528   

  model_score   prec_c0     prec_c1    rec_c0 rec_c1  
0    0.152388         1   0.0336134   0.69086      1  
3    0.123142         1    0.025641  0.591398      1  
6    0.108206         1   0.0222222  0.526882      1  
2    0.106491         1   0.0218579  0.518817      1  
4    0.105925         1   0.0217391  0.516129      1  
7   0.0679704         1   0.0152091  0.303763      1  
1  0.00324409  0.989547    0.011236  0.763441   0.25  
8 -0.00853311  0.988806  0.00925926  0.712366   0.25  
9  -0.0332212   0.98827           0  0.905914      0  
5  -0.0451846  0.987342           0   0.83871      0  
Elapsed time 15.16 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-18 16:26:01.885000 
pca_target: 0 	 poly degree: 0 	 kselect: 200 
Imbalance: SMOTE(k=None, k_neighbors=5, kind='regular', m=None, m_neighbors=10, n_jobs=1,
   out_step=0.5, random_state=None, ratio='auto', svm_estimator=None) 
Extended target (count):  31485 13
('Total : Processed (count): ', (1252L, 438L), 13)
Final feature (count):  (1252L, 438L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.729 	0.165 	0.053 	0.863 	0.852 	0.746
[[270 102]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.73      0.84       372
        1.0       0.04      1.00      0.07         4

avg / total       0.99      0.73      0.83       376


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=10, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=5, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.952 	-0.020 	-0.017 	0.481 	0.000 	0.000
[[358  14]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.96      0.98       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.95      0.97       376


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.0001, average=False, class_weight='balanced',
       epsilon=0.1, eta0=0.001, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='squared_hinge', n_iter=5, n_jobs=4,
       penalty='l1', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.971 	-0.014 	-0.014 	0.491 	0.000 	0.000
[[365   7]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.98      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.97      0.97       376


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=32, max_features='auto', max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=30, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight='balanced',
            criterion='gini', max_depth=None, max_features='auto',
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 32 candidates, totalling 160 fits
BEST: MLPClassifier(activation='relu', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.981 	-0.009 	-0.009 	0.496 	0.000 	0.000
[[369   3]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=1.0, n_estimators=80, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.992 	0.498 	0.397 	0.625 	0.500 	0.231
[[372   0]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      1.00       372
        1.0       1.00      0.25      0.40         4

avg / total       0.99      0.99      0.99       376


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.1, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=10.0, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', ...owski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='uniform'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.976 	-0.012 	-0.012 	0.493 	0.000 	0.000
[[367   5]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 192 candidates, totalling 960 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=1,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.963 	0.253 	0.209 	0.734 	0.696 	0.461
[[360  12]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      0.97      0.98       372
        1.0       0.14      0.50      0.22         4

avg / total       0.99      0.96      0.97       376


                estimator min_score mean_score max_score    sd_score  \
0              GaussianNB  0.676114   0.676114  0.676114           0   
9    KNeighborsClassifier        -1 -0.0606958  0.941862    0.939621   
6      AdaBoostClassifier  0.919434   0.985538         1   0.0108156   
3    ExtraTreesClassifier  0.767741   0.981621         1   0.0395253   
4  RandomForestClassifier  0.985106   0.993203         1  0.00285741   
7                     SVC         0   0.836983         1    0.294039   
5           MLPClassifier  0.973861    0.98361  0.990838  0.00453277   
8        VotingClassifier   0.93536   0.971298  0.988583   0.0122501   
2           SGDClassifier  -0.20718    0.66006  0.986321     0.26658   
1      LogisticRegression  0.524297   0.852259  0.969375    0.135524   

        acc       auc           conf_matrix     f1_c0      f1_c1       kappa  \
0  0.728723  0.862903  [[270, 102], [0, 4]]  0.841121  0.0727273   0.0533175   
9  0.962766  0.733871   [[360, 12], [2, 2]]  0.980926   0.222222    0.209135   
6  0.992021     0.625    [[372, 0], [3, 1]]  0.995984        0.4    0.397436   
3  0.989362       0.5    [[372, 0], [4, 0]]  0.994652          0           0   
4  0.989362       0.5    [[372, 0], [4, 0]]  0.994652          0           0   
7  0.989362       0.5    [[372, 0], [4, 0]]  0.994652          0           0   
5  0.981383  0.495968    [[369, 3], [4, 0]]  0.990604          0 -0.00920245   
8  0.976064   0.49328    [[367, 5], [4, 0]]  0.987887          0  -0.0119617   
2  0.970745  0.490591    [[365, 7], [4, 0]]  0.985155          0  -0.0137255   
1  0.952128  0.481183   [[358, 14], [4, 0]]  0.975477          0  -0.0168269   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
0    0.165496         1  0.0377358  0.725806      1  
9    0.253448  0.994475   0.142857  0.967742    0.5  
6    0.497996     0.992          1         1   0.25  
3           0  0.989362          0         1      0  
4           0  0.989362          0         1      0  
7           0  0.989362          0         1      0  
5 -0.00929961  0.989276          0  0.991935      0  
8  -0.0120381  0.989218          0  0.986559      0  
2  -0.0142822   0.98916          0  0.981183      0  
1  -0.0203924   0.98895          0  0.962366      0  
Elapsed time 82.08 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-18 17:48:06.951000 
pca_target: 0 	 poly degree: 0 	 kselect: 200 
Imbalance: None 
Extended target (count):  31485 13
('Total : Processed (count): ', (1252L, 438L), 13)
Final feature (count):  (1252L, 438L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.670 	0.144 	0.041 	0.833 	0.816 	0.689
[[248 124]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.67      0.80       372
        1.0       0.03      1.00      0.06         4

avg / total       0.99      0.67      0.79       376


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.001, class_weight={1: 500}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.588 	0.121 	0.029 	0.792 	0.764 	0.608
[[217 155]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.58      0.74       372
        1.0       0.03      1.00      0.05         4

avg / total       0.99      0.59      0.73       376


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.5, average=False, class_weight='balanced', epsilon=0.1,
       eta0=0.001, fit_intercept=True, l1_ratio=0.15,
       learning_rate='invscaling', loss='squared_hinge', n_iter=5,
       n_jobs=4, penalty='l2', power_t=0.5, random_state=None,
       shuffle=True, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.588 	0.121 	0.029 	0.792 	0.764 	0.608
[[217 155]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.58      0.74       372
        1.0       0.03      1.00      0.05         4

avg / total       0.99      0.59      0.73       376


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 500}, criterion='gini',
           max_depth=8, max_features=0.33, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.931 	-0.026 	-0.018 	0.470 	0.000 	0.000
[[350  22]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.94      0.96       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.93      0.95       376


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 32 candidates, totalling 160 fits
BEST: MLPClassifier(activation='relu', alpha=0.5, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.981 	-0.009 	-0.009 	0.496 	0.000 	0.000
[[369   3]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 50}, criterion='gini', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=0.5, n_estimators=50, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	-0.005 	-0.004 	0.499 	0.000 	0.000
[[371   1]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.01, cache_size=200, class_weight={1: 500}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.569 	0.117 	0.027 	0.782 	0.751 	0.589
[[210 162]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.56      0.72       372
        1.0       0.02      1.00      0.05         4

avg / total       0.99      0.57      0.71       376


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 192 candidates, totalling 960 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=1,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


                estimator   min_score   mean_score   max_score     sd_score  \
0              GaussianNB   0.0562966    0.0562966   0.0562966            0   
1      LogisticRegression  -0.0760812  -0.00418341     0.11236    0.0290311   
2           SGDClassifier  -0.0926785   0.00947556    0.117054    0.0409008   
7                     SVC  -0.0262661  -0.00647481   0.0885935    0.0140226   
4  RandomForestClassifier -0.00162828 -2.81819e-05           0  0.000189489   
8        VotingClassifier -0.00325665 -0.000375568           0  0.000749206   
9    KNeighborsClassifier          -1    -0.500968           0     0.499038   
6      AdaBoostClassifier  -0.0186667   0.00738693    0.140853    0.0393537   
5           MLPClassifier -0.00970478  -0.00603893 -0.00162836   0.00209434   
3    ExtraTreesClassifier  -0.0329835   0.00126537   0.0822045    0.0108823   

        acc       auc           conf_matrix     f1_c0      f1_c1       kappa  \
0  0.670213  0.833333  [[248, 124], [0, 4]]       0.8  0.0606061   0.0408163   
1  0.587766  0.791667  [[217, 155], [0, 4]]  0.736842  0.0490798   0.0289256   
2  0.587766  0.791667  [[217, 155], [0, 4]]  0.736842  0.0490798   0.0289256   
7  0.569149  0.782258  [[210, 162], [0, 4]]  0.721649  0.0470588   0.0268405   
4  0.989362       0.5    [[372, 0], [4, 0]]  0.994652          0           0   
8  0.989362       0.5    [[372, 0], [4, 0]]  0.994652          0           0   
9  0.989362       0.5    [[372, 0], [4, 0]]  0.994652          0           0   
6  0.986702  0.498656    [[371, 1], [4, 0]]  0.993307          0  -0.0042735   
5  0.981383  0.495968    [[369, 3], [4, 0]]  0.990604          0 -0.00920245   
3  0.930851   0.47043   [[350, 22], [4, 0]]  0.964187          0  -0.0183333   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
0    0.144338         1    0.03125  0.666667      1  
1    0.121141         1  0.0251572  0.583333      1  
2    0.121141         1  0.0251572  0.583333      1  
7    0.116631         1  0.0240964  0.564516      1  
4           0  0.989362          0         1      0  
8           0  0.989362          0         1      0  
9           0  0.989362          0         1      0  
6  -0.0053548  0.989333          0  0.997312      0  
5 -0.00929961  0.989276          0  0.991935      0  
3  -0.0258505  0.988701          0   0.94086      0  
Elapsed time 33.26 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-18 18:21:22.482000 
pca_target: 0 	 poly degree: 0 	 kselect: 80 
Imbalance: ClusterCentroids(estimator=None, n_jobs=1, random_state=None, ratio='auto') 
Extended target (count):  31485 13
('Total : Processed (count): ', (1252L, 438L), 13)
Final feature (count):  (1252L, 438L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.633 	0.133 	0.035 	0.815 	0.793 	0.652
[[234 138]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.63      0.77       372
        1.0       0.03      1.00      0.05         4

avg / total       0.99      0.63      0.76       376


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=5, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=5, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.838 	-0.044 	-0.020 	0.423 	0.000 	0.000
[[315  57]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.85      0.91       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.84      0.90       376


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.0001, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='constant', loss='squared_hinge', n_iter=5, n_jobs=4,
       penalty='l2', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.601 	-0.030 	-0.008 	0.427 	0.389 	0.146
[[225 147]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.60      0.75       372
        1.0       0.01      0.25      0.01         4

avg / total       0.98      0.60      0.74       376


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=8, max_features=0.75, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.617 	0.129 	0.033 	0.806 	0.783 	0.637
[[228 144]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.61      0.76       372
        1.0       0.03      1.00      0.05         4

avg / total       0.99      0.62      0.75       376


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features=0.33, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=50, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.622 	0.130 	0.033 	0.809 	0.786 	0.642
[[230 142]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.62      0.76       372
        1.0       0.03      1.00      0.05         4

avg / total       0.99      0.62      0.76       376


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 32 candidates, totalling 160 fits
BEST: MLPClassifier(activation='tanh', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.835 	0.026 	0.012 	0.546 	0.459 	0.198
[[313  59]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.84      0.91       372
        1.0       0.02      0.25      0.03         4

avg / total       0.98      0.84      0.90       376


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=0.5, n_estimators=50, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.609 	0.127 	0.032 	0.802 	0.778 	0.629
[[225 147]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.60      0.75       372
        1.0       0.03      1.00      0.05         4

avg / total       0.99      0.61      0.75       376


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=1, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.479 	0.046 	0.009 	0.613 	0.597 	0.367
[[177 195]
 [  1   3]]
             precision    recall  f1-score   support

        0.0       0.99      0.48      0.64       372
        1.0       0.02      0.75      0.03         4

avg / total       0.98      0.48      0.64       376


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 500}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Ran...wski',
           metric_params=None, n_jobs=4, n_neighbors=4, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.641 	-0.022 	-0.006 	0.448 	0.402 	0.155
[[240 132]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.65      0.78       372
        1.0       0.01      0.25      0.01         4

avg / total       0.98      0.64      0.77       376


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 192 candidates, totalling 960 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=5, p=1,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.870 	0.039 	0.020 	0.563 	0.468 	0.205
[[326  46]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.88      0.93       372
        1.0       0.02      0.25      0.04         4

avg / total       0.98      0.87      0.92       376


                estimator min_score mean_score max_score   sd_score       acc  \
0              GaussianNB  0.906078   0.906078  0.906078          0  0.632979   
4  RandomForestClassifier  0.222222    0.82463         1   0.145592   0.62234   
3    ExtraTreesClassifier  0.555556    0.85573         1  0.0874337  0.617021   
6      AdaBoostClassifier  0.111111   0.753675         1     0.1937  0.609043   
7                     SVC         0    0.42853  0.812156   0.285564  0.478723   
9    KNeighborsClassifier        -1  -0.433491  0.461633   0.575544  0.869681   
5           MLPClassifier  0.367711   0.632004  0.718234  0.0836465  0.835106   
8        VotingClassifier    0.3849   0.704219         1   0.135723  0.640957   
2           SGDClassifier -0.350522   0.336566  0.812156   0.154092  0.601064   
1      LogisticRegression   -0.1283   0.361807  0.718234   0.238865  0.837766   

        auc           conf_matrix     f1_c0      f1_c1       kappa  \
0  0.814516  [[234, 138], [0, 4]]  0.772277  0.0547945   0.0348214   
4   0.80914  [[230, 142], [0, 4]]   0.76412  0.0533333    0.033314   
3  0.806452  [[228, 144], [0, 4]]      0.76  0.0526316   0.0325901   
6  0.802419  [[225, 147], [0, 4]]  0.753769  0.0516129   0.0315391   
7  0.612903  [[177, 195], [1, 3]]  0.643636   0.029703  0.00903614   
9  0.563172   [[326, 46], [3, 1]]    0.9301  0.0392157        0.02   
5  0.545699   [[313, 59], [3, 1]]  0.909884    0.03125   0.0115332   
8  0.447581  [[240, 132], [3, 1]]  0.780488  0.0145985 -0.00618459   
2  0.427419  [[225, 147], [3, 1]]      0.75  0.0131579  -0.0077187   
1  0.423387   [[315, 57], [4, 0]]  0.911722          0  -0.0202847   

  model_score   prec_c0     prec_c1    rec_c0 rec_c1  
0    0.133114         1    0.028169  0.629032      1  
4    0.130151         1   0.0273973   0.61828      1  
3    0.128705         1    0.027027  0.612903      1  
6    0.126579         1   0.0264901  0.604839      1  
7   0.0463976  0.994382   0.0151515  0.475806   0.75  
9   0.0391931  0.990881   0.0212766  0.876344   0.25  
5   0.0256046  0.990506   0.0166667  0.841398   0.25  
8  -0.0224954  0.987654   0.0075188  0.645161   0.25  
2  -0.0304827  0.986842  0.00675676  0.604839   0.25  
1  -0.0438329  0.987461           0  0.846774      0  
Elapsed time 14.25 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-18 18:35:37.554000 
pca_target: 0 	 poly degree: 0 	 kselect: 80 
Imbalance: SMOTE(k=None, k_neighbors=5, kind='regular', m=None, m_neighbors=10, n_jobs=1,
   out_step=0.5, random_state=None, ratio='auto', svm_estimator=None) 
Extended target (count):  31485 13
('Total : Processed (count): ', (1252L, 438L), 13)
Final feature (count):  (1252L, 438L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.713 	0.159 	0.049 	0.855 	0.842 	0.730
[[264 108]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.71      0.83       372
        1.0       0.04      1.00      0.07         4

avg / total       0.99      0.71      0.82       376


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=10, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.955 	-0.020 	-0.017 	0.483 	0.000 	0.000
[[359  13]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.97      0.98       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.95      0.97       376


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.001, average=False, class_weight='balanced',
       epsilon=0.1, eta0=0.001, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='squared_hinge', n_iter=5, n_jobs=4,
       penalty='l1', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.955 	-0.020 	-0.017 	0.483 	0.000 	0.000
[[359  13]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.97      0.98       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.95      0.97       376


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 50},
           criterion='entropy', max_depth=None, max_features='auto',
           max_leaf_nodes=None, min_impurity_split=1e-07,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=4,
           oob_score=False, random_state=None, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight='balanced',
            criterion='gini', max_depth=None, max_features='auto',
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=15, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	-0.005 	-0.004 	0.499 	0.000 	0.000
[[371   1]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 32 candidates, totalling 160 fits
BEST: MLPClassifier(activation='relu', alpha=0.1, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.979 	-0.011 	-0.011 	0.495 	0.000 	0.000
[[368   4]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=1.0, n_estimators=80, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.5, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=10.0, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', ...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.979 	-0.011 	-0.011 	0.495 	0.000 	0.000
[[368   4]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 192 candidates, totalling 960 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=1,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.968 	0.144 	0.130 	0.613 	0.494 	0.226
[[363   9]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.98      0.98       372
        1.0       0.10      0.25      0.14         4

avg / total       0.98      0.97      0.97       376


                estimator  min_score mean_score max_score    sd_score  \
0              GaussianNB   0.630897   0.630897  0.630897           0   
9    KNeighborsClassifier         -1 -0.0489003  0.959388    0.951368   
3    ExtraTreesClassifier   0.682566   0.951397  0.997706   0.0668199   
6      AdaBoostClassifier   0.907007   0.969966         1   0.0189402   
7                     SVC          0   0.844241  0.996556    0.244365   
4  RandomForestClassifier   0.931509   0.964552  0.985113    0.013304   
5           MLPClassifier   0.973855   0.981696  0.989682  0.00408143   
8        VotingClassifier   0.895064   0.958773  0.984015    0.019911   
1      LogisticRegression   0.400587    0.78954  0.961598     0.15312   
2           SGDClassifier -0.0476683   0.601286  0.958236    0.252122   

        acc       auc           conf_matrix     f1_c0      f1_c1      kappa  \
0  0.712766  0.854839  [[264, 108], [0, 4]]  0.830189  0.0689655  0.0494382   
9  0.968085  0.612903    [[363, 9], [3, 1]]   0.98374   0.142857    0.12963   
3  0.989362       0.5    [[372, 0], [4, 0]]  0.994652          0          0   
6  0.989362       0.5    [[372, 0], [4, 0]]  0.994652          0          0   
7  0.989362       0.5    [[372, 0], [4, 0]]  0.994652          0          0   
4  0.986702  0.498656    [[371, 1], [4, 0]]  0.993307          0 -0.0042735   
5  0.978723  0.494624    [[368, 4], [4, 0]]  0.989247          0 -0.0107527   
8  0.978723  0.494624    [[368, 4], [4, 0]]  0.989247          0 -0.0107527   
1  0.954787  0.482527   [[359, 13], [4, 0]]  0.976871          0 -0.0165394   
2  0.954787  0.482527   [[359, 13], [4, 0]]  0.976871          0 -0.0165394   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
0    0.159203         1  0.0357143  0.709677      1  
9    0.143978  0.991803        0.1  0.975806   0.25  
3           0  0.989362          0         1      0  
6           0  0.989362          0         1      0  
7           0  0.989362          0         1      0  
4  -0.0053548  0.989333          0  0.997312      0  
5  -0.0107527  0.989247          0  0.989247      0  
8  -0.0107527  0.989247          0  0.989247      0  
1  -0.0196235  0.988981          0  0.965054      0  
2  -0.0196235  0.988981          0  0.965054      0  
Elapsed time 55.65 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-18 19:31:16.468000 
pca_target: 0 	 poly degree: 0 	 kselect: 80 
Imbalance: None 
Extended target (count):  31485 13
('Total : Processed (count): ', (1252L, 438L), 13)
Final feature (count):  (1252L, 438L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.710 	0.158 	0.049 	0.853 	0.841 	0.728
[[263 109]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.71      0.83       372
        1.0       0.04      1.00      0.07         4

avg / total       0.99      0.71      0.82       376


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.01, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=10, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='sag', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.612 	0.127 	0.032 	0.804 	0.779 	0.631
[[226 146]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.61      0.76       372
        1.0       0.03      1.00      0.05         4

avg / total       0.99      0.61      0.75       376


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=1, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='perceptron', n_iter=5, n_jobs=4,
       penalty='none', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.915 	-0.029 	-0.019 	0.462 	0.000 	0.000
[[344  28]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.92      0.96       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.91      0.95       376


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 500}, criterion='gini',
           max_depth=8, max_features=0.75, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=30, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.870 	0.039 	0.020 	0.563 	0.468 	0.205
[[326  46]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.88      0.93       372
        1.0       0.02      0.25      0.04         4

avg / total       0.98      0.87      0.92       376


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 500},
            criterion='gini', max_depth=8, max_features='auto',
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=15, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.968 	-0.015 	-0.014 	0.489 	0.000 	0.000
[[364   8]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.98      0.98       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.97      0.97       376


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 32 candidates, totalling 160 fits
BEST: MLPClassifier(activation='relu', alpha=0.5, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=2.0, n_estimators=80, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.965 	-0.016 	-0.015 	0.488 	0.000 	0.000
[[363   9]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.98      0.98       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.97      0.97       376


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.559 	0.114 	0.026 	0.777 	0.744 	0.578
[[206 166]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.55      0.71       372
        1.0       0.02      1.00      0.05         4

avg / total       0.99      0.56      0.71       376


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 192 candidates, totalling 960 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=1,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


                estimator   min_score   mean_score   max_score    sd_score  \
0              GaussianNB   0.0667107    0.0667107   0.0667107           0   
1      LogisticRegression  -0.0319409    0.0198478    0.107961   0.0309451   
7                     SVC  -0.0381814    0.0121354   0.0838602   0.0277602   
3    ExtraTreesClassifier  -0.0286373 -2.52655e-05   0.0774071  0.00917382   
5           MLPClassifier -0.00990409  -0.00546011 -0.00230935  0.00180085   
8        VotingClassifier   -0.005767  -0.00134768           0  0.00145342   
9    KNeighborsClassifier          -1    -0.501073           0    0.498932   
4  RandomForestClassifier -0.00603308  9.68939e-05   0.0662686  0.00352865   
6      AdaBoostClassifier  -0.0173449   0.00609159    0.136544   0.0341378   
2           SGDClassifier    -0.19863    0.0224665    0.125455    0.037396   

        acc       auc           conf_matrix     f1_c0      f1_c1      kappa  \
0  0.710106  0.853495  [[263, 109], [0, 4]]  0.828346  0.0683761  0.0488303   
1  0.611702  0.803763  [[226, 146], [0, 4]]  0.755853  0.0519481  0.0318849   
7  0.558511  0.776882  [[206, 166], [0, 4]]  0.712803   0.045977  0.0257243   
3  0.869681  0.563172   [[326, 46], [3, 1]]    0.9301  0.0392157       0.02   
5  0.989362       0.5    [[372, 0], [4, 0]]  0.994652          0          0   
8  0.989362       0.5    [[372, 0], [4, 0]]  0.994652          0          0   
9  0.989362       0.5    [[372, 0], [4, 0]]  0.994652          0          0   
4  0.968085  0.489247    [[364, 8], [4, 0]]  0.983784          0 -0.0143885   
6  0.965426  0.487903    [[363, 9], [4, 0]]  0.982409          0 -0.0149502   
2  0.914894  0.462366   [[344, 28], [4, 0]]  0.955556          0 -0.0189702   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
0    0.158197         1  0.0353982  0.706989      1  
1    0.127282         1  0.0266667  0.607527      1  
7    0.114148         1  0.0235294  0.553763      1  
3   0.0391931  0.990881  0.0212766  0.876344   0.25  
5           0  0.989362          0         1      0  
8           0  0.989362          0         1      0  
9           0  0.989362          0         1      0  
4   -0.015289   0.98913          0  0.978495      0  
6  -0.0162385  0.989101          0  0.975806      0  
2  -0.0294136  0.988506          0  0.924731      0  
Elapsed time 22.31 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-18 19:53:34.916000 
pca_target: 0 	 poly degree: 0 	 kselect: 40 
Imbalance: ClusterCentroids(estimator=None, n_jobs=1, random_state=None, ratio='auto') 
Extended target (count):  31485 13
('Total : Processed (count): ', (1252L, 438L), 13)
Final feature (count):  (1252L, 438L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.660 	0.141 	0.039 	0.828 	0.810 	0.678
[[244 128]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.66      0.79       372
        1.0       0.03      1.00      0.06         4

avg / total       0.99      0.66      0.78       376


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=1, class_weight={1: 15}, dual=False, fit_intercept=True,
          intercept_scaling=0.1, max_iter=100, multi_class='ovr', n_jobs=4,
          penalty='l2', random_state=None, solver='lbfgs', tol=0.0001,
          verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.774 	0.007 	0.003 	0.515 	0.441 	0.185
[[290  82]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.78      0.87       372
        1.0       0.01      0.25      0.02         4

avg / total       0.98      0.77      0.86       376


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.0001, average=False, class_weight='balanced',
       epsilon=0.1, eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='modified_huber', n_iter=5, n_jobs=4,
       penalty='none', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.766 	0.065 	0.024 	0.634 	0.620 	0.374
[[286  86]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      0.77      0.87       372
        1.0       0.02      0.50      0.04         4

avg / total       0.98      0.77      0.86       376


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=16, max_features=0.33, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=30, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.686 	0.150 	0.044 	0.841 	0.826 	0.704
[[254 118]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.68      0.81       372
        1.0       0.03      1.00      0.06         4

avg / total       0.99      0.69      0.80       376


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=16, max_features=0.75, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=50, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.628 	0.132 	0.034 	0.812 	0.790 	0.647
[[232 140]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.62      0.77       372
        1.0       0.03      1.00      0.05         4

avg / total       0.99      0.63      0.76       376


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 32 candidates, totalling 160 fits
BEST: MLPClassifier(activation='tanh', alpha=0.01, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.822 	0.021 	0.009 	0.539 	0.455 	0.195
[[308  64]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.83      0.90       372
        1.0       0.02      0.25      0.03         4

avg / total       0.98      0.82      0.89       376


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 50}, criterion='entropy', max_depth=8,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=0.5, n_estimators=15, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.630 	0.132 	0.034 	0.813 	0.791 	0.650
[[233 139]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.63      0.77       372
        1.0       0.03      1.00      0.05         4

avg / total       0.99      0.63      0.76       376


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.5, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='linear',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.838 	0.027 	0.012 	0.547 	0.459 	0.198
[[314  58]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.84      0.91       372
        1.0       0.02      0.25      0.03         4

avg / total       0.98      0.84      0.90       376


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.697 	0.044 	0.014 	0.599 	0.591 	0.343
[[260 112]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      0.70      0.82       372
        1.0       0.02      0.50      0.03         4

avg / total       0.98      0.70      0.81       376


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 192 candidates, totalling 960 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=4, p=1,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.824 	-0.046 	-0.020 	0.417 	0.000 	0.000
[[310  62]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.83      0.90       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.82      0.89       376


                estimator    min_score mean_score max_score   sd_score  \
3    ExtraTreesClassifier     0.555556   0.888371         1  0.0848873   
0              GaussianNB     0.906078   0.906078  0.906078          0   
6      AdaBoostClassifier -2.46716e-17   0.774971         1   0.151207   
4  RandomForestClassifier     0.555556   0.852229         1  0.0970573   
2           SGDClassifier    -0.350522   0.355958  0.812156   0.146371   
8        VotingClassifier     0.496011   0.772419  0.906078  0.0918465   
7                     SVC            0   0.370278  0.589933   0.223839   
5           MLPClassifier     0.683856   0.843866  0.906078   0.084361   
1      LogisticRegression      -0.2566   0.374316  0.794967   0.254957   
9    KNeighborsClassifier           -1   -0.41627  0.367711   0.589699   

        acc       auc           conf_matrix     f1_c0      f1_c1       kappa  \
3   0.68617  0.841398  [[254, 118], [0, 4]]  0.811502  0.0634921   0.0437931   
0  0.659574  0.827957  [[244, 128], [0, 4]]  0.792208  0.0588235   0.0389776   
6  0.630319  0.813172  [[233, 139], [0, 4]]  0.770248  0.0544218   0.0344369   
4   0.62766  0.811828  [[232, 140], [0, 4]]  0.768212  0.0540541   0.0340575   
2  0.765957  0.634409   [[286, 86], [2, 2]]  0.866667  0.0434783   0.0236072   
8  0.696809  0.599462  [[260, 112], [2, 2]]  0.820189  0.0338983    0.013623   
7  0.837766  0.547043   [[314, 58], [3, 1]]  0.911466   0.031746   0.0120606   
5  0.821809  0.538978   [[308, 64], [3, 1]]  0.901903  0.0289855  0.00912524   
1  0.773936  0.514785   [[290, 82], [3, 1]]   0.87218  0.0229885  0.00274588   
9  0.824468  0.416667   [[310, 62], [4, 0]]   0.90379          0  -0.0203947   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
3    0.149622         1  0.0327869  0.682796      1  
0    0.140983         1   0.030303  0.655914      1  
6    0.132364         1   0.027972  0.626344      1  
4     0.13162         1  0.0277778  0.623656      1  
2    0.065136  0.993056  0.0227273  0.768817    0.5  
8   0.0444004  0.992366  0.0175439  0.698925    0.5  
7   0.0265382  0.990536  0.0169492  0.844086   0.25  
5   0.0211505  0.990354  0.0153846  0.827957   0.25  
1  0.00731439  0.989761  0.0120482   0.77957   0.25  
9  -0.0460776  0.987261          0  0.833333      0  
Elapsed time 14.16 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-18 20:07:44.641000 
pca_target: 0 	 poly degree: 0 	 kselect: 40 
Imbalance: SMOTE(k=None, k_neighbors=5, kind='regular', m=None, m_neighbors=10, n_jobs=1,
   out_step=0.5, random_state=None, ratio='auto', svm_estimator=None) 
Extended target (count):  31485 13
('Total : Processed (count): ', (1252L, 438L), 13)
Final feature (count):  (1252L, 438L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.707 	0.157 	0.048 	0.852 	0.839 	0.725
[[262 110]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.70      0.83       372
        1.0       0.04      1.00      0.07         4

avg / total       0.99      0.71      0.82       376


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=10, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.934 	0.082 	0.057 	0.595 	0.485 	0.219
[[350  22]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.94      0.97       372
        1.0       0.04      0.25      0.07         4

avg / total       0.98      0.93      0.96       376


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.0001, average=False, class_weight='balanced',
       epsilon=0.1, eta0=0.001, fit_intercept=True, l1_ratio=0.15,
       learning_rate='invscaling', loss='perceptron', n_iter=5, n_jobs=4,
       penalty='l2', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.939 	0.088 	0.063 	0.598 	0.486 	0.220
[[352  20]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.95      0.97       372
        1.0       0.05      0.25      0.08         4

avg / total       0.98      0.94      0.96       376


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight='balanced',
           criterion='entropy', max_depth=32, max_features=0.33,
           max_leaf_nodes=None, min_impurity_split=1e-07,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=4,
           oob_score=False, random_state=None, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	-0.005 	-0.004 	0.499 	0.000 	0.000
[[371   1]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight='balanced',
            criterion='gini', max_depth=32, max_features='auto',
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.979 	-0.011 	-0.011 	0.495 	0.000 	0.000
[[368   4]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 32 candidates, totalling 160 fits
BEST: MLPClassifier(activation='tanh', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.971 	-0.014 	-0.014 	0.491 	0.000 	0.000
[[365   7]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.98      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.97      0.97       376


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 50}, criterion='gini', max_depth=8,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=1.0, n_estimators=80, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	-0.005 	-0.004 	0.499 	0.000 	0.000
[[371   1]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.5, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.984 	-0.008 	-0.007 	0.497 	0.000 	0.000
[[370   2]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=10.0, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', ...owski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='uniform'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.971 	0.153 	0.141 	0.614 	0.495 	0.227
[[364   8]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.98      0.99       372
        1.0       0.11      0.25      0.15         4

avg / total       0.98      0.97      0.98       376


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 192 candidates, totalling 960 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=3,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.963 	0.129 	0.111 	0.610 	0.493 	0.225
[[361  11]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.97      0.98       372
        1.0       0.08      0.25      0.12         4

avg / total       0.98      0.96      0.97       376


                estimator min_score mean_score max_score    sd_score  \
0              GaussianNB  0.625642   0.625642  0.625642           0   
8        VotingClassifier  0.872271   0.941123  0.977228   0.0240787   
9    KNeighborsClassifier        -1 -0.0487681  0.958229    0.951626   
2           SGDClassifier -0.118909   0.576587  0.942863    0.235818   
1      LogisticRegression  0.353508   0.730935  0.938535    0.154783   
3    ExtraTreesClassifier  0.695454   0.939212  0.991969   0.0689195   
6      AdaBoostClassifier  0.908125    0.96338  0.991969   0.0185202   
7                     SVC         0   0.822061  0.994243    0.223579   
4  RandomForestClassifier  0.915559   0.958709  0.977087   0.0145972   
5           MLPClassifier  0.973904   0.980485  0.985177  0.00295443   

        acc       auc           conf_matrix     f1_c0      f1_c1       kappa  \
0  0.707447  0.852151  [[262, 110], [0, 4]]  0.826498  0.0677966   0.0482327   
8  0.970745  0.614247    [[364, 8], [3, 1]]  0.985115   0.153846    0.141196   
9  0.962766  0.610215   [[361, 11], [3, 1]]  0.980978      0.125    0.110811   
2   0.93883  0.598118   [[352, 20], [3, 1]]  0.968363       0.08   0.0632582   
1  0.933511   0.59543   [[350, 22], [3, 1]]  0.965517  0.0740741   0.0569823   
3  0.986702  0.498656    [[371, 1], [4, 0]]  0.993307          0  -0.0042735   
6  0.986702  0.498656    [[371, 1], [4, 0]]  0.993307          0  -0.0042735   
7  0.984043  0.497312    [[370, 2], [4, 0]]  0.991957          0 -0.00714286   
4  0.978723  0.494624    [[368, 4], [4, 0]]  0.989247          0  -0.0107527   
5  0.970745  0.490591    [[365, 7], [4, 0]]  0.985155          0  -0.0137255   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
0    0.157202         1  0.0350877  0.704301      1  
8    0.153364  0.991826   0.111111  0.978495   0.25  
9    0.128656  0.991758  0.0833333   0.97043   0.25  
2   0.0876713  0.991549   0.047619  0.946237   0.25  
1   0.0817082  0.991501  0.0434783   0.94086   0.25  
3  -0.0053548  0.989333          0  0.997312      0  
6  -0.0053548  0.989333          0  0.997312      0  
7 -0.00758294  0.989305          0  0.994624      0  
4  -0.0107527  0.989247          0  0.989247      0  
5  -0.0142822   0.98916          0  0.981183      0  
Elapsed time 39.87 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-18 20:47:36.898000 
pca_target: 0 	 poly degree: 0 	 kselect: 40 
Imbalance: None 
Extended target (count):  31485 13
('Total : Processed (count): ', (1252L, 438L), 13)
Final feature (count):  (1252L, 438L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.699 	0.154 	0.046 	0.848 	0.834 	0.717
[[259 113]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.70      0.82       372
        1.0       0.03      1.00      0.07         4

avg / total       0.99      0.70      0.81       376


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.001, class_weight={1: 50}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.628 	0.132 	0.034 	0.812 	0.790 	0.647
[[232 140]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.62      0.77       372
        1.0       0.03      1.00      0.05         4

avg / total       0.99      0.63      0.76       376


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=1, average=False, class_weight={1: 50}, epsilon=0.1,
       eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='perceptron', n_iter=5, n_jobs=4,
       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight='balanced',
           criterion='entropy', max_depth=8, max_features=0.75,
           max_leaf_nodes=None, min_impurity_split=1e-07,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=15, n_jobs=4,
           oob_score=False, random_state=None, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.952 	-0.020 	-0.017 	0.481 	0.000 	0.000
[[358  14]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.96      0.98       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.95      0.97       376


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 32 candidates, totalling 160 fits
BEST: MLPClassifier(activation='relu', alpha=0.5, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 50}, criterion='gini', max_depth=32,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=2.0, n_estimators=50, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.981 	-0.009 	-0.009 	0.496 	0.000 	0.000
[[369   3]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.01, cache_size=200, class_weight={1: 500}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.479 	0.097 	0.019 	0.737 	0.688 	0.498
[[176 196]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.47      0.64       372
        1.0       0.02      1.00      0.04         4

avg / total       0.99      0.48      0.64       376


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 192 candidates, totalling 960 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=1,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


                estimator  min_score   mean_score  max_score    sd_score  \
0              GaussianNB  0.0879457    0.0879457  0.0879457           0   
1      LogisticRegression -0.0418155    0.0162317  0.0950311   0.0330449   
7                     SVC -0.0340947  -0.00319732  0.0952291    0.023602   
2           SGDClassifier   -0.19863     0.025225   0.176049   0.0376786   
4  RandomForestClassifier -0.0109262 -0.000395885          0     0.00146   
5           MLPClassifier -0.0121145  -0.00846191 -0.0044048  0.00198034   
8        VotingClassifier  -0.010185    -0.003144          0  0.00287973   
9    KNeighborsClassifier         -1    -0.501267          0    0.498742   
6      AdaBoostClassifier -0.0232971  -0.00595811  0.0901894   0.0120446   
3    ExtraTreesClassifier -0.0338572    -0.002406  0.0447563  0.00616134   

        acc       auc           conf_matrix     f1_c0      f1_c1       kappa  \
0  0.699468  0.848118  [[259, 113], [0, 4]]  0.820919  0.0661157   0.0464991   
1   0.62766  0.811828  [[232, 140], [0, 4]]  0.768212  0.0540541   0.0340575   
7  0.478723  0.736559  [[176, 196], [0, 4]]  0.642336  0.0392157   0.0187473   
2  0.989362       0.5    [[372, 0], [4, 0]]  0.994652          0           0   
4  0.989362       0.5    [[372, 0], [4, 0]]  0.994652          0           0   
5  0.989362       0.5    [[372, 0], [4, 0]]  0.994652          0           0   
8  0.989362       0.5    [[372, 0], [4, 0]]  0.994652          0           0   
9  0.989362       0.5    [[372, 0], [4, 0]]  0.994652          0           0   
6  0.981383  0.495968    [[369, 3], [4, 0]]  0.990604          0 -0.00920245   
3  0.952128  0.481183   [[358, 14], [4, 0]]  0.975477          0  -0.0168269   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
0    0.154282         1   0.034188  0.696237      1  
1     0.13162         1  0.0277778  0.623656      1  
7   0.0972747         1       0.02  0.473118      1  
2           0  0.989362          0         1      0  
4           0  0.989362          0         1      0  
5           0  0.989362          0         1      0  
8           0  0.989362          0         1      0  
9           0  0.989362          0         1      0  
6 -0.00929961  0.989276          0  0.991935      0  
3  -0.0203924   0.98895          0  0.962366      0  
Elapsed time 20.22 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-18 21:07:50.125000 
pca_target: 0 	 poly degree: 2 	 kselect: 200 
Imbalance: ClusterCentroids(estimator=None, n_jobs=1, random_state=None, ratio='auto') 
Extended target (count):  31485 13
('Total : Processed (count): ', (1252L, 96580L), 13)
Final feature (count):  (1252L, 96580L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.684 	0.095 	0.028 	0.716 	0.716 	0.516
[[254 118]
 [  1   3]]
             precision    recall  f1-score   support

        0.0       1.00      0.68      0.81       372
        1.0       0.02      0.75      0.05         4

avg / total       0.99      0.68      0.80       376


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=1, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.819 	0.020 	0.009 	0.538 	0.454 	0.194
[[307  65]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.83      0.90       372
        1.0       0.02      0.25      0.03         4

avg / total       0.98      0.82      0.89       376


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.0001, average=False, class_weight='balanced',
       epsilon=0.1, eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='constant', loss='modified_huber', n_iter=5, n_jobs=4,
       penalty='none', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.673 	-0.016 	-0.005 	0.464 	0.412 	0.162
[[252 120]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.68      0.80       372
        1.0       0.01      0.25      0.02         4

avg / total       0.98      0.67      0.80       376


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 15}, criterion='gini',
           max_depth=8, max_features='auto', max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.471 	0.045 	0.009 	0.609 	0.592 	0.361
[[174 198]
 [  1   3]]
             precision    recall  f1-score   support

        0.0       0.99      0.47      0.64       372
        1.0       0.01      0.75      0.03         4

avg / total       0.98      0.47      0.63       376


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=None, max_features=0.33, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.809 	-0.049 	-0.021 	0.409 	0.000 	0.000
[[304  68]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.82      0.89       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.81      0.88       376


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 32 candidates, totalling 160 fits
BEST: MLPClassifier(activation='tanh', alpha=0.01, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.870 	0.114 	0.057 	0.687 	0.661 	0.421
[[325  47]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      0.87      0.93       372
        1.0       0.04      0.50      0.08         4

avg / total       0.98      0.87      0.92       376


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=16,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=1.0, n_estimators=80, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.620 	0.129 	0.033 	0.808 	0.785 	0.639
[[229 143]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.62      0.76       372
        1.0       0.03      1.00      0.05         4

avg / total       0.99      0.62      0.75       376


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.01, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='linear',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.811 	0.018 	0.007 	0.534 	0.452 	0.193
[[304  68]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.82      0.90       372
        1.0       0.01      0.25      0.03         4

avg / total       0.98      0.81      0.89       376


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.734 	0.055 	0.018 	0.618 	0.607 	0.360
[[274  98]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      0.74      0.85       372
        1.0       0.02      0.50      0.04         4

avg / total       0.98      0.73      0.84       376


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 192 candidates, totalling 960 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=2,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.652 	0.086 	0.024 	0.700 	0.699 	0.493
[[242 130]
 [  1   3]]
             precision    recall  f1-score   support

        0.0       1.00      0.65      0.79       372
        1.0       0.02      0.75      0.04         4

avg / total       0.99      0.65      0.78       376


                estimator min_score mean_score max_score   sd_score       acc  \
6      AdaBoostClassifier -0.145489   0.591837         1   0.239104  0.619681   
0              GaussianNB         1          1         1          0  0.683511   
9    KNeighborsClassifier        -1  -0.152202  0.777778   0.848407  0.651596   
5           MLPClassifier  0.777778   0.981315         1  0.0479246  0.869681   
8        VotingClassifier  0.683856   0.849283         1  0.0849669  0.734043   
3    ExtraTreesClassifier  0.777778   0.793815  0.906078  0.0424313  0.470745   
1      LogisticRegression   -0.1283   0.530109         1   0.350868  0.819149   
7                     SVC         0   0.656653         1   0.391004   0.81117   
2           SGDClassifier -0.367711   0.415505  0.906078   0.151957  0.672872   
4  RandomForestClassifier  0.350522   0.740685         1   0.129627  0.808511   

        auc           conf_matrix     f1_c0      f1_c1       kappa  \
6  0.807796  [[229, 143], [0, 4]]  0.762063  0.0529801   0.0329496   
0  0.716398  [[254, 118], [1, 3]]  0.810207      0.048   0.0279805   
9  0.700269  [[242, 130], [1, 3]]  0.786992  0.0437956   0.0236283   
5  0.686828   [[325, 47], [2, 2]]    0.9299  0.0754717   0.0569206   
8   0.61828   [[274, 98], [2, 2]]  0.845679  0.0384615   0.0183793   
3  0.608871  [[174, 198], [1, 3]]  0.636197  0.0292683  0.00858597   
1  0.537634   [[307, 65], [3, 1]]  0.900293  0.0285714  0.00868486   
7  0.533602   [[304, 68], [3, 1]]  0.895434  0.0273973  0.00743605   
2   0.46371  [[252, 120], [3, 1]]  0.803828      0.016 -0.00469239   
4  0.408602   [[304, 68], [4, 0]]  0.894118          0  -0.0205066   

  model_score   prec_c0     prec_c1    rec_c0 rec_c1  
6    0.129425         1   0.0272109  0.615591      1  
0   0.0950433  0.996078   0.0247934  0.682796   0.75  
9   0.0859441  0.995885   0.0225564  0.650538   0.75  
5    0.113868  0.993884   0.0408163  0.873656    0.5  
8   0.0549271  0.992754        0.02  0.736559    0.5  
3   0.0447844  0.994286   0.0149254  0.467742   0.75  
1   0.0202985  0.990323   0.0151515  0.825269   0.25  
7   0.0178117  0.990228   0.0144928  0.817204   0.25  
2  -0.0159389  0.988235  0.00826446  0.677419   0.25  
4  -0.0487234  0.987013           0  0.817204      0  
Elapsed time 38.69 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-18 21:46:31.525000 
pca_target: 0 	 poly degree: 2 	 kselect: 200 
Imbalance: SMOTE(k=None, k_neighbors=5, kind='regular', m=None, m_neighbors=10, n_jobs=1,
   out_step=0.5, random_state=None, ratio='auto', svm_estimator=None) 
Extended target (count):  31485 13
('Total : Processed (count): ', (1252L, 96580L), 13)
Final feature (count):  (1252L, 96580L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.726 	0.164 	0.053 	0.862 	0.850 	0.743
[[269 103]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.72      0.84       372
        1.0       0.04      1.00      0.07         4

avg / total       0.99      0.73      0.83       376


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=10, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=10, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.965 	-0.016 	-0.015 	0.488 	0.000 	0.000
[[363   9]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.98      0.98       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.97      0.97       376


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.001, average=False, class_weight='balanced',
       epsilon=0.1, eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='squared_hinge', n_iter=5, n_jobs=4,
       penalty='l1', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.957 	-0.019 	-0.016 	0.484 	0.000 	0.000
[[360  12]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.97      0.98       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.96      0.97       376


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 50},
           criterion='entropy', max_depth=None, max_features=0.33,
           max_leaf_nodes=None, min_impurity_split=1e-07,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=4,
           oob_score=False, random_state=None, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.976 	-0.012 	-0.012 	0.493 	0.000 	0.000
[[367   5]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight='balanced',
            criterion='gini', max_depth=32, max_features='auto',
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.976 	-0.012 	-0.012 	0.493 	0.000 	0.000
[[367   5]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 32 candidates, totalling 160 fits
BEST: MLPClassifier(activation='relu', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.976 	-0.012 	-0.012 	0.493 	0.000 	0.000
[[367   5]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight='balanced', criterion='entropy',
            max_depth=8, max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=1.0, n_estimators=50, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.984 	-0.008 	-0.007 	0.497 	0.000 	0.000
[[370   2]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=1, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.981 	-0.009 	-0.009 	0.496 	0.000 	0.000
[[369   3]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=10.0, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', ...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.976 	-0.012 	-0.012 	0.493 	0.000 	0.000
[[367   5]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 192 candidates, totalling 960 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=4,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.936 	-0.025 	-0.018 	0.473 	0.000 	0.000
[[352  20]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.95      0.97       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.94      0.96       376


                estimator min_score mean_score max_score    sd_score  \
0              GaussianNB   0.69719    0.69719   0.69719           0   
6      AdaBoostClassifier  0.900542   0.961574  0.990832   0.0158179   
7                     SVC         0   0.822368  0.991995    0.252069   
3    ExtraTreesClassifier  0.745149    0.95017  0.990825   0.0505421   
4  RandomForestClassifier  0.914521   0.959276   0.97724   0.0117965   
5           MLPClassifier  0.972712   0.981862  0.987414  0.00387389   
8        VotingClassifier  0.899027   0.941267  0.968249   0.0159613   
1      LogisticRegression  0.551125   0.793374   0.95494    0.123151   
2           SGDClassifier -0.228604   0.591793  0.913596    0.222544   
9    KNeighborsClassifier        -1 -0.0515399   0.94284    0.948688   

        acc       auc           conf_matrix     f1_c0      f1_c1       kappa  \
0  0.726064  0.861559  [[269, 103], [0, 4]]  0.839314  0.0720721   0.0526419   
6  0.984043  0.497312    [[370, 2], [4, 0]]  0.991957          0 -0.00714286   
7  0.981383  0.495968    [[369, 3], [4, 0]]  0.990604          0 -0.00920245   
3  0.976064   0.49328    [[367, 5], [4, 0]]  0.987887          0  -0.0119617   
4  0.976064   0.49328    [[367, 5], [4, 0]]  0.987887          0  -0.0119617   
5  0.976064   0.49328    [[367, 5], [4, 0]]  0.987887          0  -0.0119617   
8  0.976064   0.49328    [[367, 5], [4, 0]]  0.987887          0  -0.0119617   
1  0.965426  0.487903    [[363, 9], [4, 0]]  0.982409          0  -0.0149502   
2  0.957447  0.483871   [[360, 12], [4, 0]]  0.978261          0  -0.0162162   
9   0.93617  0.473118   [[352, 20], [4, 0]]  0.967033          0  -0.0180505   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
0    0.164416         1  0.0373832  0.723118      1  
6 -0.00758294  0.989305          0  0.994624      0  
7 -0.00929961  0.989276          0  0.991935      0  
3  -0.0120381  0.989218          0  0.986559      0  
4  -0.0120381  0.989218          0  0.986559      0  
5  -0.0120381  0.989218          0  0.986559      0  
8  -0.0120381  0.989218          0  0.986559      0  
1  -0.0162385  0.989101          0  0.975806      0  
2  -0.0188278  0.989011          0  0.967742      0  
9  -0.0245781  0.988764          0  0.946237      0  
Elapsed time 106.23 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-18 23:32:45.570000 
pca_target: 0 	 poly degree: 2 	 kselect: 200 
Imbalance: None 
Extended target (count):  31485 13
('Total : Processed (count): ', (1252L, 96580L), 13)
Final feature (count):  (1252L, 96580L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.875 	-0.037 	-0.020 	0.442 	0.000 	0.000
[[329  43]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.88      0.93       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.88      0.92       376


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.01, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='sag', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.979 	-0.011 	-0.011 	0.495 	0.000 	0.000
[[368   4]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.5, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='invscaling', loss='modified_huber', n_iter=5,
       n_jobs=4, penalty='l2', power_t=0.5, random_state=None,
       shuffle=True, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.984 	-0.008 	-0.007 	0.497 	0.000 	0.000
[[370   2]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 500}, criterion='gini',
           max_depth=8, max_features=0.75, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.957 	0.117 	0.096 	0.608 	0.491 	0.224
[[359  13]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.97      0.98       372
        1.0       0.07      0.25      0.11         4

avg / total       0.98      0.96      0.97       376


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 32 candidates, totalling 160 fits
BEST: MLPClassifier(activation='tanh', alpha=0.5, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.976 	-0.012 	-0.012 	0.493 	0.000 	0.000
[[367   5]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 500}, criterion='entropy',
            max_depth=16, max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=0.5, n_estimators=80, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.968 	-0.015 	-0.014 	0.489 	0.000 	0.000
[[364   8]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.98      0.98       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.97      0.97       376


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.1, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='linear',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.973 	-0.013 	-0.013 	0.492 	0.000 	0.000
[[366   6]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.98      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.97      0.98       376


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...owski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='uniform'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 192 candidates, totalling 960 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=1,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


                estimator   min_score   mean_score   max_score     sd_score  \
3    ExtraTreesClassifier  -0.0143774  0.000182237    0.111036   0.00873983   
4  RandomForestClassifier -0.00325665 -0.000128936           0  0.000467489   
8        VotingClassifier -0.00561319  -0.00159094           0   0.00138014   
9    KNeighborsClassifier          -1    -0.500895           0      0.49911   
2           SGDClassifier   -0.192738    0.0464274    0.278856    0.0434132   
1      LogisticRegression  -0.0279849    0.0724596    0.215247    0.0480459   
5           MLPClassifier  -0.0085683    0.0217841   0.0944701    0.0412606   
7                     SVC -0.00913078    0.0323462     0.13472    0.0356553   
6      AdaBoostClassifier  -0.0141137    0.0421378    0.235751    0.0670023   
0              GaussianNB  0.00174733   0.00174733  0.00174733            0   

        acc       auc          conf_matrix     f1_c0     f1_c1       kappa  \
3  0.957447  0.607527  [[359, 13], [3, 1]]  0.978202  0.111111   0.0961538   
4  0.989362       0.5   [[372, 0], [4, 0]]  0.994652         0           0   
8  0.989362       0.5   [[372, 0], [4, 0]]  0.994652         0           0   
9  0.989362       0.5   [[372, 0], [4, 0]]  0.994652         0           0   
2  0.984043  0.497312   [[370, 2], [4, 0]]  0.991957         0 -0.00714286   
1  0.978723  0.494624   [[368, 4], [4, 0]]  0.989247         0  -0.0107527   
5  0.976064   0.49328   [[367, 5], [4, 0]]  0.987887         0  -0.0119617   
7  0.973404  0.491935   [[366, 6], [4, 0]]  0.986523         0   -0.012931   
6  0.968085  0.489247   [[364, 8], [4, 0]]  0.983784         0  -0.0143885   
0     0.875  0.442204  [[329, 43], [4, 0]]  0.933333         0  -0.0198523   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
3    0.116528  0.991713  0.0714286  0.965054   0.25  
4           0  0.989362          0         1      0  
8           0  0.989362          0         1      0  
9           0  0.989362          0         1      0  
2 -0.00758294  0.989305          0  0.994624      0  
1  -0.0107527  0.989247          0  0.989247      0  
5  -0.0120381  0.989218          0  0.986559      0  
7  -0.0132048  0.989189          0  0.983871      0  
6   -0.015289   0.98913          0  0.978495      0  
0  -0.0372624  0.987988          0  0.884409      0  
Elapsed time 33.58 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-19 00:06:20.155000 
pca_target: 0 	 poly degree: 2 	 kselect: 80 
Imbalance: ClusterCentroids(estimator=None, n_jobs=1, random_state=None, ratio='auto') 
Extended target (count):  31485 13
('Total : Processed (count): ', (1252L, 96580L), 13)
Final feature (count):  (1252L, 96580L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.019 	0.009 	0.000 	0.504 	0.090 	0.009
[[  3 369]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.01      0.02       372
        1.0       0.01      1.00      0.02         4

avg / total       0.99      0.02      0.02       376


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=10, class_weight={1: 3}, dual=False, fit_intercept=True,
          intercept_scaling=0.1, max_iter=100, multi_class='ovr', n_jobs=4,
          penalty='l2', random_state=None, solver='lbfgs', tol=0.0001,
          verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.787 	0.011 	0.004 	0.522 	0.445 	0.187
[[295  77]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.79      0.88       372
        1.0       0.01      0.25      0.02         4

avg / total       0.98      0.79      0.87       376


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.001, average=False, class_weight='balanced',
       epsilon=0.1, eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='perceptron', n_iter=5, n_jobs=4,
       penalty='l2', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.878 	0.120 	0.062 	0.691 	0.664 	0.424
[[328  44]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      0.88      0.93       372
        1.0       0.04      0.50      0.08         4

avg / total       0.98      0.88      0.93       376


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 15}, criterion='gini',
           max_depth=16, max_features=0.75, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=30, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.766 	0.005 	0.002 	0.511 	0.439 	0.183
[[287  85]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.77      0.87       372
        1.0       0.01      0.25      0.02         4

avg / total       0.98      0.77      0.86       376


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3},
            criterion='entropy', max_depth=16, max_features=0.33,
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=15, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.694 	0.044 	0.013 	0.598 	0.590 	0.341
[[259 113]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      0.70      0.82       372
        1.0       0.02      0.50      0.03         4

avg / total       0.98      0.69      0.81       376


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 32 candidates, totalling 160 fits
BEST: MLPClassifier(activation='relu', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.779 	0.009 	0.003 	0.517 	0.443 	0.186
[[292  80]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.78      0.88       372
        1.0       0.01      0.25      0.02         4

avg / total       0.98      0.78      0.87       376


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=0.5, n_estimators=50, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.641 	0.135 	0.036 	0.819 	0.798 	0.660
[[237 135]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.64      0.78       372
        1.0       0.03      1.00      0.06         4

avg / total       0.99      0.64      0.77       376


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=10, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.771 	0.067 	0.025 	0.637 	0.622 	0.376
[[288  84]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      0.77      0.87       372
        1.0       0.02      0.50      0.04         4

avg / total       0.98      0.77      0.86       376


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=10.0, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Ran...owski',
           metric_params=None, n_jobs=4, n_neighbors=4, p=2,
           weights='uniform'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.705 	0.047 	0.015 	0.603 	0.595 	0.346
[[263 109]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      0.71      0.83       372
        1.0       0.02      0.50      0.03         4

avg / total       0.98      0.70      0.82       376


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 192 candidates, totalling 960 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=1,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.572 	0.066 	0.015 	0.660 	0.654 	0.435
[[212 160]
 [  1   3]]
             precision    recall  f1-score   support

        0.0       1.00      0.57      0.72       372
        1.0       0.02      0.75      0.04         4

avg / total       0.98      0.57      0.72       376


                estimator min_score mean_score max_score   sd_score       acc  \
6      AdaBoostClassifier  0.350522   0.857201         1   0.128869  0.640957   
2           SGDClassifier -0.222222   0.420607  0.906078   0.157189   0.87766   
9    KNeighborsClassifier        -1  -0.160029  0.777778   0.840404  0.571809   
7                     SVC   -0.1283   0.474414  0.906078   0.349966  0.771277   
8        VotingClassifier    0.2566   0.525764  0.777778   0.138712  0.704787   
4  RandomForestClassifier  0.427255   0.709722         1   0.137946  0.694149   
1      LogisticRegression   -0.1283   0.384137         1   0.308946  0.787234   
5           MLPClassifier  0.478822   0.635322  0.812156  0.0867352  0.779255   
3    ExtraTreesClassifier  0.444444   0.681959         1   0.115399  0.765957   
0              GaussianNB  0.812156   0.812156  0.812156          0  0.018617   

        auc           conf_matrix     f1_c0      f1_c1        kappa  \
6  0.818548  [[237, 135], [0, 4]]  0.778325  0.0559441    0.0360073   
2   0.69086   [[328, 44], [2, 2]]  0.934473       0.08    0.0616319   
9  0.659946  [[212, 160], [1, 3]]  0.724786  0.0359281    0.0154827   
7  0.637097   [[288, 84], [2, 2]]  0.870091  0.0444444    0.0246139   
8  0.603495  [[263, 109], [2, 2]]  0.825746  0.0347826    0.0145448   
4  0.598118  [[259, 113], [2, 2]]  0.818325  0.0336134     0.013326   
1  0.521505   [[295, 77], [3, 1]]  0.880597  0.0243902   0.00423729   
5  0.517473   [[292, 80], [3, 1]]  0.875562  0.0235294   0.00332141   
3  0.510753   [[287, 85], [3, 1]]  0.867069  0.0222222    0.0019305   
0  0.504032    [[3, 369], [0, 4]]     0.016  0.0212202  0.000172951   

  model_score   prec_c0    prec_c1      rec_c0 rec_c1  
6    0.135402         1   0.028777    0.637097      1  
2    0.119512  0.993939  0.0434783     0.88172    0.5  
9    0.066225  0.995305  0.0184049    0.569892   0.75  
7   0.0669747  0.993103  0.0232558    0.774194    0.5  
8   0.0465548  0.992453   0.018018    0.706989    0.5  
4    0.043693  0.992337  0.0173913    0.696237    0.5  
1   0.0108824  0.989933  0.0128205    0.793011   0.25  
5  0.00872064  0.989831  0.0123457    0.784946   0.25  
3  0.00525291  0.989655  0.0116279    0.771505   0.25  
0  0.00929961         1  0.0107239  0.00806452      1  
Elapsed time 38.85 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-19 00:45:11.250000 
pca_target: 0 	 poly degree: 2 	 kselect: 80 
Imbalance: SMOTE(k=None, k_neighbors=5, kind='regular', m=None, m_neighbors=10, n_jobs=1,
   out_step=0.5, random_state=None, ratio='auto', svm_estimator=None) 
Extended target (count):  31485 13
('Total : Processed (count): ', (1252L, 96580L), 13)
Final feature (count):  (1252L, 96580L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.755 	0.177 	0.061 	0.876 	0.868 	0.771
[[280  92]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.75      0.86       372
        1.0       0.04      1.00      0.08         4

avg / total       0.99      0.76      0.85       376


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=10, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.944 	-0.023 	-0.018 	0.477 	0.000 	0.000
[[355  17]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.95      0.97       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.94      0.96       376


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.001, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='squared_hinge', n_iter=5, n_jobs=4,
       penalty='l1', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.878 	0.043 	0.023 	0.567 	0.470 	0.207
[[329  43]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.88      0.93       372
        1.0       0.02      0.25      0.04         4

avg / total       0.98      0.88      0.93       376


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 15}, criterion='gini',
           max_depth=None, max_features=0.33, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=30, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.965 	-0.016 	-0.015 	0.488 	0.000 	0.000
[[363   9]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.98      0.98       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.97      0.97       376


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 15},
            criterion='entropy', max_depth=None, max_features='auto',
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=15, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.963 	-0.017 	-0.015 	0.487 	0.000 	0.000
[[362  10]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.97      0.98       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.96      0.97       376


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 32 candidates, totalling 160 fits
BEST: MLPClassifier(activation='relu', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.981 	0.214 	0.213 	0.620 	0.497 	0.229
[[368   4]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       372
        1.0       0.20      0.25      0.22         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 500}, criterion='gini', max_depth=32,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=0.5, n_estimators=15, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.971 	-0.014 	-0.014 	0.491 	0.000 	0.000
[[365   7]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.98      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.97      0.97       376


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.5, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=10.0, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', ...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.949 	0.102 	0.079 	0.603 	0.489 	0.222
[[356  16]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.96      0.97       372
        1.0       0.06      0.25      0.10         4

avg / total       0.98      0.95      0.96       376


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 192 candidates, totalling 960 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=4,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.934 	-0.025 	-0.018 	0.472 	0.000 	0.000
[[351  21]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.94      0.97       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.93      0.96       376


                estimator min_score mean_score max_score    sd_score  \
0              GaussianNB  0.641471   0.641471  0.641471           0   
5           MLPClassifier  0.968225   0.977878  0.987458  0.00514754   
8        VotingClassifier  0.848896    0.90399  0.944082    0.020729   
2           SGDClassifier -0.240801   0.560321  0.869081    0.218333   
7                     SVC  0.320639   0.803464  0.994236    0.163251   
6      AdaBoostClassifier  0.883027   0.954039  0.985158   0.0185534   
3    ExtraTreesClassifier  0.708068   0.933765  0.989688    0.063282   
4  RandomForestClassifier  0.861509   0.946678  0.974988   0.0264417   
1      LogisticRegression  0.408449    0.74896   0.92773    0.118941   
9    KNeighborsClassifier        -1 -0.0618951   0.94393    0.938595   

        acc       auc          conf_matrix     f1_c0      f1_c1      kappa  \
0  0.755319  0.876344  [[280, 92], [0, 4]]  0.858896       0.08  0.0608167   
5  0.981383  0.619624   [[368, 4], [3, 1]]  0.990579   0.222222   0.212919   
8  0.949468  0.603495  [[356, 16], [3, 1]]  0.974008  0.0952381  0.0793814   
2   0.87766  0.567204  [[329, 43], [3, 1]]  0.934659  0.0416667   0.022604   
7  0.989362       0.5   [[372, 0], [4, 0]]  0.994652          0          0   
6  0.970745  0.490591   [[365, 7], [4, 0]]  0.985155          0 -0.0137255   
3  0.965426  0.487903   [[363, 9], [4, 0]]  0.982409          0 -0.0149502   
4  0.962766  0.486559  [[362, 10], [4, 0]]   0.98103          0 -0.0154321   
1  0.944149  0.477151  [[355, 17], [4, 0]]  0.971272          0 -0.0175258   
9  0.933511  0.471774  [[351, 21], [4, 0]]  0.965612          0 -0.0181976   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
0    0.177093         1  0.0416667  0.752688      1  
5    0.214278  0.991914        0.2  0.989247   0.25  
8    0.102206  0.991643  0.0588235  0.956989   0.25  
2   0.0428976  0.990964  0.0227273  0.884409   0.25  
7           0  0.989362          0         1      0  
6  -0.0142822   0.98916          0  0.981183      0  
3  -0.0162385  0.989101          0  0.975806      0  
4  -0.0171403  0.989071          0  0.973118      0  
1   -0.022565  0.988858          0  0.954301      0  
9  -0.0252205  0.988732          0  0.943548      0  
Elapsed time 59.49 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-19 01:44:40.950000 
pca_target: 0 	 poly degree: 2 	 kselect: 80 
Imbalance: None 
Extended target (count):  31485 13
('Total : Processed (count): ', (1252L, 96580L), 13)
Final feature (count):  (1252L, 96580L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.907 	-0.031 	-0.019 	0.458 	0.000 	0.000
[[341  31]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.92      0.95       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.91      0.94       376


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=1, class_weight={1: 15}, dual=False, fit_intercept=True,
          intercept_scaling=0.1, max_iter=100, multi_class='ovr', n_jobs=4,
          penalty='l2', random_state=None, solver='sag', tol=0.0001,
          verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.965 	-0.016 	-0.015 	0.488 	0.000 	0.000
[[363   9]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.98      0.98       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.97      0.97       376


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=1, average=False, class_weight={1: 15}, epsilon=0.1,
       eta0=0.001, fit_intercept=True, l1_ratio=0.15,
       learning_rate='invscaling', loss='modified_huber', n_iter=5,
       n_jobs=4, penalty='elasticnet', power_t=0.5, random_state=None,
       shuffle=True, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.928 	-0.026 	-0.018 	0.469 	0.000 	0.000
[[349  23]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.94      0.96       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.93      0.95       376


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 500}, criterion='gini',
           max_depth=8, max_features='auto', max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=30, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.952 	-0.020 	-0.017 	0.481 	0.000 	0.000
[[358  14]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.96      0.98       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.95      0.97       376


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=16, max_features=0.75, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	-0.005 	-0.004 	0.499 	0.000 	0.000
[[371   1]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 32 candidates, totalling 160 fits
BEST: MLPClassifier(activation='tanh', alpha=0.1, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.979 	-0.011 	-0.011 	0.495 	0.000 	0.000
[[368   4]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=32,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=1.0, n_estimators=50, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.976 	-0.012 	-0.012 	0.493 	0.000 	0.000
[[367   5]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.01, cache_size=200, class_weight={1: 50}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='linear',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.939 	-0.024 	-0.018 	0.474 	0.000 	0.000
[[353  19]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.95      0.97       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.94      0.96       376


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	-0.005 	-0.004 	0.499 	0.000 	0.000
[[371   1]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 192 candidates, totalling 960 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=1,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


                estimator   min_score   mean_score  max_score    sd_score  \
9    KNeighborsClassifier          -1    -0.500885          0     0.49912   
4  RandomForestClassifier  -0.0118056  0.000124118   0.141661  0.00754092   
8        VotingClassifier -0.00739528  -0.00132898          0  0.00174516   
5           MLPClassifier  -0.0134337    0.0253294   0.197157   0.0568811   
6      AdaBoostClassifier  -0.0167109   0.00126598   0.290992    0.029841   
1      LogisticRegression  -0.0182986    0.0740424   0.252228    0.063932   
3    ExtraTreesClassifier  -0.0222625 -0.000606003  0.0571995  0.00492359   
7                     SVC  -0.0183775    0.0214593   0.173422   0.0496358   
2           SGDClassifier   -0.102412     0.056015   0.238005   0.0446617   
0              GaussianNB  -0.0302675   -0.0302675 -0.0302675           0   

        acc       auc          conf_matrix     f1_c0 f1_c1      kappa  \
9  0.989362       0.5   [[372, 0], [4, 0]]  0.994652     0          0   
4  0.986702  0.498656   [[371, 1], [4, 0]]  0.993307     0 -0.0042735   
8  0.986702  0.498656   [[371, 1], [4, 0]]  0.993307     0 -0.0042735   
5  0.978723  0.494624   [[368, 4], [4, 0]]  0.989247     0 -0.0107527   
6  0.976064   0.49328   [[367, 5], [4, 0]]  0.987887     0 -0.0119617   
1  0.965426  0.487903   [[363, 9], [4, 0]]  0.982409     0 -0.0149502   
3  0.952128  0.481183  [[358, 14], [4, 0]]  0.975477     0 -0.0168269   
7   0.93883  0.474462  [[353, 19], [4, 0]]   0.96845     0 -0.0178908   
2  0.928191  0.469086  [[349, 23], [4, 0]]  0.962759     0 -0.0184591   
0  0.906915  0.458333  [[341, 31], [4, 0]]  0.951185     0 -0.0192069   

  model_score   prec_c0 prec_c1    rec_c0 rec_c1  
9           0  0.989362       0         1      0  
4  -0.0053548  0.989333       0  0.997312      0  
8  -0.0053548  0.989333       0  0.997312      0  
5  -0.0107527  0.989247       0  0.989247      0  
6  -0.0120381  0.989218       0  0.986559      0  
1  -0.0162385  0.989101       0  0.975806      0  
3  -0.0203924   0.98895       0  0.962366      0  
7  -0.0239222  0.988796       0  0.948925      0  
2  -0.0264689  0.988669       0  0.938172      0  
0  -0.0310835  0.988406       0  0.916667      0  
Elapsed time 22.77 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-19 02:07:27.267000 
pca_target: 0 	 poly degree: 2 	 kselect: 40 
Imbalance: ClusterCentroids(estimator=None, n_jobs=1, random_state=None, ratio='auto') 
Extended target (count):  31485 13
('Total : Processed (count): ', (1252L, 96580L), 13)
Final feature (count):  (1252L, 96580L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.697 	0.099 	0.030 	0.723 	0.723 	0.525
[[259 113]
 [  1   3]]
             precision    recall  f1-score   support

        0.0       1.00      0.70      0.82       372
        1.0       0.03      0.75      0.05         4

avg / total       0.99      0.70      0.81       376


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.001, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=10, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.734 	-0.003 	-0.001 	0.495 	0.430 	0.176
[[275  97]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.74      0.85       372
        1.0       0.01      0.25      0.02         4

avg / total       0.98      0.73      0.84       376


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.001, average=False, class_weight='balanced',
       epsilon=0.1, eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='invscaling', loss='perceptron', n_iter=5, n_jobs=4,
       penalty='l2', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.654 	-0.020 	-0.006 	0.454 	0.406 	0.158
[[245 127]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.66      0.79       372
        1.0       0.01      0.25      0.02         4

avg / total       0.98      0.65      0.78       376


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 15}, criterion='gini',
           max_depth=16, max_features=0.75, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.694 	0.044 	0.013 	0.598 	0.590 	0.341
[[259 113]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      0.70      0.82       372
        1.0       0.02      0.50      0.03         4

avg / total       0.98      0.69      0.81       376


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 15}, criterion='gini',
            max_depth=32, max_features=0.33, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=30, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.811 	0.018 	0.007 	0.534 	0.452 	0.193
[[304  68]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.82      0.90       372
        1.0       0.01      0.25      0.03         4

avg / total       0.98      0.81      0.89       376


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 32 candidates, totalling 160 fits
BEST: MLPClassifier(activation='tanh', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.697 	0.099 	0.030 	0.723 	0.723 	0.525
[[259 113]
 [  1   3]]
             precision    recall  f1-score   support

        0.0       1.00      0.70      0.82       372
        1.0       0.03      0.75      0.05         4

avg / total       0.99      0.70      0.81       376


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=0.5, n_estimators=15, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.609 	0.127 	0.032 	0.802 	0.778 	0.629
[[225 147]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.60      0.75       372
        1.0       0.03      1.00      0.05         4

avg / total       0.99      0.61      0.75       376


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.5, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='linear',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.769 	0.066 	0.024 	0.636 	0.621 	0.375
[[287  85]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      0.77      0.87       372
        1.0       0.02      0.50      0.04         4

avg / total       0.98      0.77      0.86       376


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=10.0, class_weight={1: 500}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Ra...wski',
           metric_params=None, n_jobs=4, n_neighbors=4, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.697 	0.099 	0.030 	0.723 	0.723 	0.525
[[259 113]
 [  1   3]]
             precision    recall  f1-score   support

        0.0       1.00      0.70      0.82       372
        1.0       0.03      0.75      0.05         4

avg / total       0.99      0.70      0.81       376


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 192 candidates, totalling 960 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=4, p=1,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.816 	0.019 	0.008 	0.536 	0.453 	0.194
[[306  66]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.82      0.90       372
        1.0       0.01      0.25      0.03         4

avg / total       0.98      0.82      0.89       376


                estimator min_score mean_score max_score   sd_score       acc  \
6      AdaBoostClassifier  0.316144   0.831799         1   0.144175  0.609043   
0              GaussianNB  0.777778   0.777778  0.777778          0  0.696809   
5           MLPClassifier  0.461633   0.612263  0.812156  0.0825621  0.696809   
8        VotingClassifier  0.555556   0.705398  0.906078   0.081339  0.696809   
7                     SVC   -0.1283   0.469828         1   0.383863  0.768617   
3    ExtraTreesClassifier  0.478822   0.590317         1   0.136159  0.694149   
9    KNeighborsClassifier        -1  -0.179718  0.683856   0.821064  0.816489   
4  RandomForestClassifier  0.333333   0.661009         1   0.125487   0.81117   
1      LogisticRegression   -0.1283   0.284752  0.812156   0.267796  0.734043   
2           SGDClassifier   -0.2566   0.374248         1   0.214881  0.654255   

        auc           conf_matrix     f1_c0      f1_c1        kappa  \
6  0.802419  [[225, 147], [0, 4]]  0.753769  0.0516129    0.0315391   
0  0.723118  [[259, 113], [1, 3]]   0.81962       0.05    0.0300507   
5  0.723118  [[259, 113], [1, 3]]   0.81962       0.05    0.0300507   
8  0.723118  [[259, 113], [1, 3]]   0.81962       0.05    0.0300507   
7  0.635753   [[287, 85], [2, 2]]  0.868381   0.043956     0.024105   
3  0.598118  [[259, 113], [2, 2]]  0.818325  0.0336134     0.013326   
9   0.53629   [[306, 66], [3, 1]]  0.898678   0.028169   0.00825688   
4  0.533602   [[304, 68], [3, 1]]  0.895434  0.0273973   0.00743605   
1  0.494624   [[275, 97], [3, 1]]  0.846154  0.0196078 -0.000851789   
2  0.454301  [[245, 127], [3, 1]]  0.790323  0.0151515  -0.00559579   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
6    0.126579         1  0.0264901  0.604839      1  
0   0.0991176  0.996154  0.0258621  0.696237   0.75  
5   0.0991176  0.996154  0.0258621  0.696237   0.75  
8   0.0991176  0.996154  0.0258621  0.696237   0.75  
7   0.0660498   0.99308  0.0229885  0.771505    0.5  
3    0.043693  0.992337  0.0173913  0.696237    0.5  
9   0.0194583  0.990291  0.0149254  0.822581   0.25  
4   0.0178117  0.990228  0.0144928  0.817204   0.25  
1 -0.00251295  0.989209  0.0102041  0.739247   0.25  
2  -0.0197882  0.987903  0.0078125  0.658602   0.25  
Elapsed time 39.09 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-19 02:46:32.372000 
pca_target: 0 	 poly degree: 2 	 kselect: 40 
Imbalance: SMOTE(k=None, k_neighbors=5, kind='regular', m=None, m_neighbors=10, n_jobs=1,
   out_step=0.5, random_state=None, ratio='auto', svm_estimator=None) 
Extended target (count):  31485 13
('Total : Processed (count): ', (1252L, 96580L), 13)
Final feature (count):  (1252L, 96580L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.766 	0.124 	0.044 	0.758 	0.758 	0.574
[[285  87]
 [  1   3]]
             precision    recall  f1-score   support

        0.0       1.00      0.77      0.87       372
        1.0       0.03      0.75      0.06         4

avg / total       0.99      0.77      0.86       376


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=10, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=5, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.936 	-0.025 	-0.018 	0.473 	0.000 	0.000
[[352  20]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.95      0.97       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.94      0.96       376


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.001, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='squared_hinge', n_iter=5, n_jobs=4,
       penalty='none', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.888 	0.048 	0.027 	0.573 	0.473 	0.209
[[333  39]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.90      0.94       372
        1.0       0.03      0.25      0.05         4

avg / total       0.98      0.89      0.93       376


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 50},
           criterion='entropy', max_depth=32, max_features=0.33,
           max_leaf_nodes=None, min_impurity_split=1e-07,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=4,
           oob_score=False, random_state=None, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.984 	-0.008 	-0.007 	0.497 	0.000 	0.000
[[370   2]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=32, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=30, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.965 	-0.016 	-0.015 	0.488 	0.000 	0.000
[[363   9]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.98      0.98       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.97      0.97       376


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 32 candidates, totalling 160 fits
BEST: MLPClassifier(activation='relu', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.968 	-0.015 	-0.014 	0.489 	0.000 	0.000
[[364   8]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.98      0.98       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.97      0.97       376


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=16,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=1.0, n_estimators=80, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.976 	-0.012 	-0.012 	0.493 	0.000 	0.000
[[367   5]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.5, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	-0.005 	-0.004 	0.499 	0.000 	0.000
[[371   1]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=10.0, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', ...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.941 	-0.023 	-0.018 	0.476 	0.000 	0.000
[[354  18]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.95      0.97       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.94      0.96       376


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 192 candidates, totalling 960 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.941 	0.091 	0.067 	0.599 	0.487 	0.221
[[353  19]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.95      0.97       372
        1.0       0.05      0.25      0.08         4

avg / total       0.98      0.94      0.96       376


                estimator min_score mean_score max_score    sd_score  \
0              GaussianNB  0.661915   0.661915  0.661915           0   
9    KNeighborsClassifier        -1 -0.0487565  0.956058    0.951531   
2           SGDClassifier -0.126191   0.576892  0.866977    0.218126   
7                     SVC  0.296994   0.827449  0.997706    0.173468   
3    ExtraTreesClassifier  0.743261    0.94027  0.988589   0.0614692   
6      AdaBoostClassifier  0.889062    0.95169  0.979472   0.0181654   
5           MLPClassifier  0.967136   0.977563  0.987395  0.00490432   
4  RandomForestClassifier  0.886065    0.94821   0.97607   0.0256181   
8        VotingClassifier  0.863906   0.922589  0.957152   0.0222318   
1      LogisticRegression  0.351606   0.742405  0.914872     0.12826   

        acc       auc          conf_matrix     f1_c0      f1_c1       kappa  \
0  0.765957  0.758065  [[285, 87], [1, 3]]  0.866261  0.0638298   0.0443623   
9  0.941489  0.599462  [[353, 19], [3, 1]]   0.96978  0.0833333    0.066787   
2  0.888298  0.572581  [[333, 39], [3, 1]]  0.940678  0.0454545   0.0266272   
7  0.986702  0.498656   [[371, 1], [4, 0]]  0.993307          0  -0.0042735   
3  0.984043  0.497312   [[370, 2], [4, 0]]  0.991957          0 -0.00714286   
6  0.976064   0.49328   [[367, 5], [4, 0]]  0.987887          0  -0.0119617   
5  0.968085  0.489247   [[364, 8], [4, 0]]  0.983784          0  -0.0143885   
4  0.965426  0.487903   [[363, 9], [4, 0]]  0.982409          0  -0.0149502   
8  0.941489  0.475806  [[354, 18], [4, 0]]  0.969863          0  -0.0177165   
1   0.93617  0.473118  [[352, 20], [4, 0]]  0.967033          0  -0.0180505   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
0    0.124095  0.996503  0.0333333  0.766129   0.75  
9    0.090939  0.991573       0.05  0.948925   0.25  
2   0.0483006  0.991071      0.025  0.895161   0.25  
7  -0.0053548  0.989333          0  0.997312      0  
3 -0.00758294  0.989305          0  0.994624      0  
6  -0.0120381  0.989218          0  0.986559      0  
5   -0.015289   0.98913          0  0.978495      0  
4  -0.0162385  0.989101          0  0.975806      0  
8  -0.0232516  0.988827          0  0.951613      0  
1  -0.0245781  0.988764          0  0.946237      0  
Elapsed time 40.10 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-19 03:26:38.498000 
pca_target: 0 	 poly degree: 2 	 kselect: 40 
Imbalance: None 
Extended target (count):  31485 13
('Total : Processed (count): ', (1252L, 96580L), 13)
Final feature (count):  (1252L, 96580L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.936 	-0.025 	-0.018 	0.473 	0.000 	0.000
[[352  20]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.95      0.97       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.94      0.96       376


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.01, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.979 	-0.011 	-0.011 	0.495 	0.000 	0.000
[[368   4]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=1, average=False, class_weight={1: 15}, epsilon=0.1,
       eta0=0.001, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='modified_huber', n_iter=5, n_jobs=4,
       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.984 	-0.008 	-0.007 	0.497 	0.000 	0.000
[[370   2]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=None, max_features=0.75, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 32 candidates, totalling 160 fits
BEST: MLPClassifier(activation='tanh', alpha=0.5, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.971 	-0.014 	-0.014 	0.491 	0.000 	0.000
[[365   7]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.98      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.97      0.97       376


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 50}, criterion='gini', max_depth=8,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=2.0, n_estimators=50, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.976 	-0.012 	-0.012 	0.493 	0.000 	0.000
[[367   5]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.1, cache_size=200, class_weight={1: 50}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.963 	-0.017 	-0.015 	0.487 	0.000 	0.000
[[362  10]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.97      0.98       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.96      0.97       376


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...owski',
           metric_params=None, n_jobs=4, n_neighbors=4, p=2,
           weights='uniform'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	-0.005 	-0.004 	0.499 	0.000 	0.000
[[371   1]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 192 candidates, totalling 960 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=1,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


                estimator   min_score   mean_score   max_score    sd_score  \
3    ExtraTreesClassifier  -0.0170962 -0.000117712    0.141661  0.00959292   
4  RandomForestClassifier -0.00561327 -0.000319073           0  0.00103249   
9    KNeighborsClassifier          -1    -0.501238           0    0.498767   
8        VotingClassifier -0.00792269  -0.00256511           0  0.00173035   
2           SGDClassifier    -0.19863    0.0429971     0.40396   0.0461956   
1      LogisticRegression   -0.109594    0.0505335    0.234668    0.056398   
6      AdaBoostClassifier  -0.0167408   0.00649201     0.23399    0.040199   
5           MLPClassifier  -0.0154906    0.0482473    0.147337   0.0497418   
7                     SVC  -0.0631765    0.0260382    0.172075   0.0395963   
0              GaussianNB  0.00990763   0.00990763  0.00990763           0   

        acc       auc          conf_matrix     f1_c0 f1_c1       kappa  \
3  0.989362       0.5   [[372, 0], [4, 0]]  0.994652     0           0   
4  0.989362       0.5   [[372, 0], [4, 0]]  0.994652     0           0   
9  0.989362       0.5   [[372, 0], [4, 0]]  0.994652     0           0   
8  0.986702  0.498656   [[371, 1], [4, 0]]  0.993307     0  -0.0042735   
2  0.984043  0.497312   [[370, 2], [4, 0]]  0.991957     0 -0.00714286   
1  0.978723  0.494624   [[368, 4], [4, 0]]  0.989247     0  -0.0107527   
6  0.976064   0.49328   [[367, 5], [4, 0]]  0.987887     0  -0.0119617   
5  0.970745  0.490591   [[365, 7], [4, 0]]  0.985155     0  -0.0137255   
7  0.962766  0.486559  [[362, 10], [4, 0]]   0.98103     0  -0.0154321   
0   0.93617  0.473118  [[352, 20], [4, 0]]  0.967033     0  -0.0180505   

  model_score   prec_c0 prec_c1    rec_c0 rec_c1  
3           0  0.989362       0         1      0  
4           0  0.989362       0         1      0  
9           0  0.989362       0         1      0  
8  -0.0053548  0.989333       0  0.997312      0  
2 -0.00758294  0.989305       0  0.994624      0  
1  -0.0107527  0.989247       0  0.989247      0  
6  -0.0120381  0.989218       0  0.986559      0  
5  -0.0142822   0.98916       0  0.981183      0  
7  -0.0171403  0.989071       0  0.973118      0  
0  -0.0245781  0.988764       0  0.946237      0  
Elapsed time 21.05 mins 

************************************************************


lagged(3,4)x1, minMax










pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-19 11:10:36.887000 
pca_target: 100 	 poly degree: 0 	 kselect: 80 
Imbalance: ClusterCentroids(estimator=None, n_jobs=1, random_state=None, ratio='auto') 
Extended target (count):  31485 13
('Total : Processed (count): ', (1252L, 438L), 13)
Final feature (count):  (1252L, 438L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.001, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=10, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.500 	0.102 	0.020 	0.747 	0.703 	0.520
[[184 188]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.49      0.66       372
        1.0       0.02      1.00      0.04         4

avg / total       0.99      0.50      0.66       376


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.1, average=False, class_weight='balanced', epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='constant', loss='squared_hinge', n_iter=5, n_jobs=4,
       penalty='l1', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.428 	-0.015 	-0.003 	0.464 	0.462 	0.215
[[159 213]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      0.43      0.60       372
        1.0       0.01      0.50      0.02         4

avg / total       0.98      0.43      0.59       376


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=32, max_features=0.33, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=50, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.809 	0.081 	0.033 	0.656 	0.637 	0.393
[[302  70]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      0.81      0.89       372
        1.0       0.03      0.50      0.05         4

avg / total       0.98      0.81      0.88       376


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features=0.75, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=50, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.620 	0.129 	0.033 	0.808 	0.785 	0.639
[[229 143]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.62      0.76       372
        1.0       0.03      1.00      0.05         4

avg / total       0.99      0.62      0.75       376


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=1.0, n_estimators=15, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.609 	0.127 	0.032 	0.802 	0.778 	0.629
[[225 147]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.60      0.75       372
        1.0       0.03      1.00      0.05         4

avg / total       0.99      0.61      0.75       376


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='linear',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.527 	0.006 	0.001 	0.513 	0.513 	0.263
[[196 176]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      0.53      0.69       372
        1.0       0.01      0.50      0.02         4

avg / total       0.98      0.53      0.68       376


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', R...wski',
           metric_params=None, n_jobs=4, n_neighbors=4, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.468 	-0.057 	-0.011 	0.360 	0.343 	0.115
[[175 197]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.98      0.47      0.64       372
        1.0       0.01      0.25      0.01         4

avg / total       0.97      0.47      0.63       376


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 192 candidates, totalling 960 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=3, p=1,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.838 	-0.044 	-0.020 	0.423 	0.000 	0.000
[[315  57]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.85      0.91       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.84      0.90       376


                estimator min_score mean_score max_score   sd_score       acc  \
4  RandomForestClassifier  0.333333   0.740874         1   0.160327  0.619681   
6      AdaBoostClassifier  0.205033   0.761514         1   0.137284  0.609043   
1      LogisticRegression         0   0.331616  0.572745   0.247402       0.5   
3    ExtraTreesClassifier  0.333333   0.822364         1   0.107554  0.808511   
7                     SVC   -0.5132   0.292189  0.589933   0.349447  0.526596   
0              GaussianNB  0.906078   0.906078  0.906078          0  0.989362   
5           MLPClassifier  0.350522   0.481137  0.607122  0.0308225  0.989362   
2           SGDClassifier -0.589933   0.192362  0.906078     0.2112  0.428191   
9    KNeighborsClassifier        -1  -0.499917  0.461633     0.5519  0.837766   
8        VotingClassifier -0.145489   0.493115  0.718234   0.178235  0.468085   

        auc           conf_matrix     f1_c0       f1_c1       kappa  \
4  0.807796  [[229, 143], [0, 4]]  0.762063   0.0529801   0.0329496   
6  0.802419  [[225, 147], [0, 4]]  0.753769   0.0516129   0.0315391   
1  0.747312  [[184, 188], [0, 4]]  0.661871   0.0408163   0.0203991   
3  0.655914   [[302, 70], [2, 2]]  0.893491   0.0526316   0.0331429   
7  0.513441  [[196, 176], [2, 2]]  0.687719    0.021978  0.00119389   
0       0.5    [[372, 0], [4, 0]]  0.994652           0           0   
5       0.5    [[372, 0], [4, 0]]  0.994652           0           0   
2   0.46371  [[159, 213], [2, 2]]  0.596623   0.0182648  -0.0026791   
9  0.423387   [[315, 57], [4, 0]]  0.911722           0  -0.0202847   
8  0.360215  [[175, 197], [3, 1]]  0.636364  0.00990099  -0.0111876   

  model_score   prec_c0     prec_c1    rec_c0 rec_c1  
4    0.129425         1   0.0272109  0.615591      1  
6    0.126579         1   0.0264901  0.604839      1  
1    0.101512         1   0.0208333  0.494624      1  
3   0.0813043  0.993421   0.0277778  0.811828    0.5  
7  0.00552352  0.989899    0.011236  0.526882    0.5  
0           0  0.989362           0         1      0  
5           0  0.989362           0         1      0  
2  -0.0150484  0.987578  0.00930233  0.427419    0.5  
9  -0.0438329  0.987461           0  0.846774      0  
8  -0.0574446  0.983146  0.00505051   0.47043   0.25  
Elapsed time 14.87 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-19 11:25:29.284000 
pca_target: 100 	 poly degree: 0 	 kselect: 80 
Imbalance: SMOTE(k=None, k_neighbors=5, kind='regular', m=None, m_neighbors=10, n_jobs=1,
   out_step=0.5, random_state=None, ratio='auto', svm_estimator=None) 
Extended target (count):  31485 13
('Total : Processed (count): ', (1252L, 438L), 13)
Final feature (count):  (1252L, 438L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=5, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.955 	-0.020 	-0.017 	0.483 	0.000 	0.000
[[359  13]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.97      0.98       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.95      0.97       376


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.001, average=False, class_weight='balanced',
       epsilon=0.1, eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='modified_huber', n_iter=5, n_jobs=4,
       penalty='l2', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.979 	-0.011 	-0.011 	0.495 	0.000 	0.000
[[368   4]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=8, max_features='auto', max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=30, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=0.5, n_estimators=50, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=10.0, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', ...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.973 	-0.013 	-0.013 	0.492 	0.000 	0.000
[[366   6]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.98      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.97      0.98       376


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 192 candidates, totalling 960 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=4,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.931 	0.079 	0.054 	0.594 	0.484 	0.218
[[349  23]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.94      0.96       372
        1.0       0.04      0.25      0.07         4

avg / total       0.98      0.93      0.95       376


                estimator  min_score mean_score max_score     sd_score  \
9    KNeighborsClassifier         -1  -0.138256  0.860389     0.863744   
0              GaussianNB   0.987395   0.987395  0.987395            0   
3    ExtraTreesClassifier          1          1         1            0   
4  RandomForestClassifier     0.9977   0.999342         1  0.000581794   
5           MLPClassifier   0.973849   0.990484         1   0.00755533   
6      AdaBoostClassifier   0.876778   0.991119         1   0.00759113   
7                     SVC          0   0.876109         1     0.271549   
2           SGDClassifier  -0.293635   0.670924  0.996556     0.343316   
8        VotingClassifier   0.926883    0.96922  0.990832    0.0161784   
1      LogisticRegression  0.0259884   0.861758  0.977205     0.201715   

        acc       auc          conf_matrix     f1_c0      f1_c1      kappa  \
9  0.930851  0.594086  [[349, 23], [3, 1]]  0.964088  0.0714286  0.0541796   
0  0.989362       0.5   [[372, 0], [4, 0]]  0.994652          0          0   
3  0.989362       0.5   [[372, 0], [4, 0]]  0.994652          0          0   
4  0.989362       0.5   [[372, 0], [4, 0]]  0.994652          0          0   
5  0.989362       0.5   [[372, 0], [4, 0]]  0.994652          0          0   
6  0.989362       0.5   [[372, 0], [4, 0]]  0.994652          0          0   
7  0.989362       0.5   [[372, 0], [4, 0]]  0.994652          0          0   
2  0.978723  0.494624   [[368, 4], [4, 0]]  0.989247          0 -0.0107527   
8  0.973404  0.491935   [[366, 6], [4, 0]]  0.986523          0  -0.012931   
1  0.954787  0.482527  [[359, 13], [4, 0]]  0.976871          0 -0.0165394   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
9   0.0789732  0.991477  0.0416667  0.938172   0.25  
0           0  0.989362          0         1      0  
3           0  0.989362          0         1      0  
4           0  0.989362          0         1      0  
5           0  0.989362          0         1      0  
6           0  0.989362          0         1      0  
7           0  0.989362          0         1      0  
2  -0.0107527  0.989247          0  0.989247      0  
8  -0.0132048  0.989189          0  0.983871      0  
1  -0.0196235  0.988981          0  0.965054      0  
Elapsed time 65.27 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-19 12:30:45.226000 
pca_target: 100 	 poly degree: 0 	 kselect: 80 
Imbalance: None 
Extended target (count):  31485 13
('Total : Processed (count): ', (1252L, 438L), 13)
Final feature (count):  (1252L, 438L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.737 	0.169 	0.055 	0.867 	0.857 	0.753
[[273  99]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.73      0.85       372
        1.0       0.04      1.00      0.07         4

avg / total       0.99      0.74      0.84       376


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=10, class_weight={1: 500}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='sag', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.949 	-0.021 	-0.017 	0.480 	0.000 	0.000
[[357  15]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.96      0.97       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.95      0.96       376


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.1, average=False, class_weight={1: 15}, epsilon=0.1,
       eta0=0.001, fit_intercept=True, l1_ratio=0.15,
       learning_rate='constant', loss='perceptron', n_iter=5, n_jobs=4,
       penalty='l2', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.904 	0.058 	0.034 	0.581 	0.477 	0.213
[[339  33]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.91      0.95       372
        1.0       0.03      0.25      0.05         4

avg / total       0.98      0.90      0.94       376


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 500}, criterion='gini',
           max_depth=8, max_features='auto', max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=30, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.899 	0.216 	0.119 	0.825 	0.822 	0.665
[[335  37]
 [  1   3]]
             precision    recall  f1-score   support

        0.0       1.00      0.90      0.95       372
        1.0       0.07      0.75      0.14         4

avg / total       0.99      0.90      0.94       376


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.1, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(500,), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=16,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=2.0, n_estimators=15, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.979 	0.194 	0.190 	0.618 	0.497 	0.228
[[367   5]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       372
        1.0       0.17      0.25      0.20         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.01, cache_size=200, class_weight={1: 500}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.157 	0.043 	0.004 	0.574 	0.385 	0.160
[[ 55 317]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.15      0.26       372
        1.0       0.01      1.00      0.02         4

avg / total       0.99      0.16      0.26       376


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 192 candidates, totalling 960 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=1,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


                estimator   min_score   mean_score  max_score    sd_score  \
0              GaussianNB   0.0378918    0.0378918  0.0378918           0   
3    ExtraTreesClassifier  -0.0123781 -0.000306785  0.0230201  0.00232405   
6      AdaBoostClassifier  -0.0160724   0.00215249   0.247064   0.0313486   
2           SGDClassifier   -0.270244  -0.00253754     0.1593   0.0307456   
7                     SVC  -0.0119377  -0.00353577  0.0513075  0.00875428   
4  RandomForestClassifier -0.00393771 -5.16472e-05          0  0.00034846   
5           MLPClassifier  -0.0109303  -0.00590137          0  0.00239932   
8        VotingClassifier -0.00277651 -0.000963198          0  0.00111171   
9    KNeighborsClassifier          -1    -0.500879          0    0.499126   
1      LogisticRegression  -0.0911433   -0.0091017  0.0839031   0.0164961   

        acc       auc          conf_matrix     f1_c0      f1_c1       kappa  \
0  0.736702  0.866935  [[273, 99], [0, 4]]  0.846512  0.0747664   0.0554202   
3  0.898936  0.825269  [[335, 37], [1, 3]]  0.946328   0.136364    0.119329   
6  0.978723   0.61828   [[367, 5], [3, 1]]  0.989218        0.2    0.189655   
2  0.904255  0.580645  [[339, 33], [3, 1]]   0.94958  0.0526316   0.0342466   
7  0.156915  0.573925  [[55, 317], [0, 4]]  0.257611  0.0246154  0.00367795   
4  0.989362       0.5   [[372, 0], [4, 0]]  0.994652          0           0   
5  0.989362       0.5   [[372, 0], [4, 0]]  0.994652          0           0   
8  0.989362       0.5   [[372, 0], [4, 0]]  0.994652          0           0   
9  0.989362       0.5   [[372, 0], [4, 0]]  0.994652          0           0   
1  0.949468  0.479839  [[357, 15], [4, 0]]  0.974079          0  -0.0170843   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
0    0.168819         1   0.038835  0.733871      1  
3    0.216458  0.997024      0.075  0.900538   0.75  
6    0.193671  0.991892   0.166667  0.986559   0.25  
2   0.0576975  0.991228  0.0294118   0.91129   0.25  
7   0.0429227         1  0.0124611  0.147849      1  
4           0  0.989362          0         1      0  
5           0  0.989362          0         1      0  
8           0  0.989362          0         1      0  
9           0  0.989362          0         1      0  
1  -0.0211374   0.98892          0  0.959677      0  
Elapsed time 32.91 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-19 13:03:40.080000 
pca_target: 100 	 poly degree: 0 	 kselect: 40 
Imbalance: ClusterCentroids(estimator=None, n_jobs=1, random_state=None, ratio='auto') 
Extended target (count):  31485 13
('Total : Processed (count): ', (1252L, 438L), 13)
Final feature (count):  (1252L, 438L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.001, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=5, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='sag', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.500 	0.102 	0.020 	0.747 	0.703 	0.520
[[184 188]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.49      0.66       372
        1.0       0.02      1.00      0.04         4

avg / total       0.99      0.50      0.66       376


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.5, average=False, class_weight='balanced', epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='constant', loss='modified_huber', n_iter=5, n_jobs=4,
       penalty='l1', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.851 	0.031 	0.015 	0.554 	0.463 	0.201
[[319  53]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.86      0.92       372
        1.0       0.02      0.25      0.03         4

avg / total       0.98      0.85      0.91       376


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=8, max_features='auto', max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.832 	-0.045 	-0.020 	0.421 	0.000 	0.000
[[313  59]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.84      0.91       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.83      0.90       376


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features=0.75, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=50, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.638 	0.135 	0.036 	0.817 	0.796 	0.658
[[236 136]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.63      0.78       372
        1.0       0.03      1.00      0.06         4

avg / total       0.99      0.64      0.77       376


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(500,), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.495 	-0.001 	-0.000 	0.497 	0.497 	0.247
[[184 188]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      0.49      0.66       372
        1.0       0.01      0.50      0.02         4

avg / total       0.98      0.49      0.65       376


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=0.5, n_estimators=15, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.609 	0.127 	0.032 	0.802 	0.778 	0.629
[[225 147]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.60      0.75       372
        1.0       0.03      1.00      0.05         4

avg / total       0.99      0.61      0.75       376


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.011 	0.000 	0.000 	0.500 	0.000 	0.000
[[  0 372]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       0.00      0.00      0.00       372
        1.0       0.01      1.00      0.02         4

avg / total       0.00      0.01      0.00       376


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=10.0, class_weight={1: 500}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Ra...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.513 	0.054 	0.011 	0.630 	0.619 	0.392
[[190 182]
 [  1   3]]
             precision    recall  f1-score   support

        0.0       0.99      0.51      0.67       372
        1.0       0.02      0.75      0.03         4

avg / total       0.98      0.51      0.67       376


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 192 candidates, totalling 960 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=1,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.941 	-0.023 	-0.018 	0.476 	0.000 	0.000
[[354  18]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.95      0.97       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.94      0.96       376


                estimator min_score mean_score max_score   sd_score  \
4  RandomForestClassifier    0.2566   0.731615         1   0.162886   
6      AdaBoostClassifier  0.111111   0.784597         1    0.15954   
1      LogisticRegression         0   0.224876  0.496011   0.185097   
8        VotingClassifier  0.111111   0.465143  0.683856   0.134402   
2           SGDClassifier   -0.2566    0.19494         1   0.218771   
0              GaussianNB         1          1         1          0   
7                     SVC         0   0.356584  0.701045   0.262774   
5           MLPClassifier  0.367711   0.575328  0.718234  0.0598632   
9    KNeighborsClassifier        -1  -0.522016  0.812156   0.604457   
3    ExtraTreesClassifier  0.589933   0.874842         1  0.0921612   

         acc       auc           conf_matrix     f1_c0      f1_c1  \
4   0.638298  0.817204  [[236, 136], [0, 4]]  0.776316  0.0555556   
6   0.609043  0.802419  [[225, 147], [0, 4]]  0.753769  0.0516129   
1        0.5  0.747312  [[184, 188], [0, 4]]  0.661871  0.0408163   
8   0.513298  0.630376  [[190, 182], [1, 3]]  0.674956   0.031746   
2   0.851064  0.553763   [[319, 53], [3, 1]]  0.919308  0.0344828   
0   0.989362       0.5    [[372, 0], [4, 0]]  0.994652          0   
7  0.0106383       0.5    [[0, 372], [0, 4]]         0  0.0210526   
5   0.494681  0.497312  [[184, 188], [2, 2]]  0.659498  0.0206186   
9   0.941489  0.475806   [[354, 18], [4, 0]]  0.969863          0   
3   0.832447  0.420699   [[313, 59], [4, 0]]  0.908563          0   

         kappa model_score   prec_c0    prec_c1    rec_c0 rec_c1  
4    0.0356065    0.134633         1  0.0285714  0.634409      1  
6    0.0315391    0.126579         1  0.0264901  0.604839      1  
1    0.0203991    0.101512         1  0.0208333  0.494624      1  
8     0.011152   0.0535091  0.994764  0.0162162  0.510753   0.75  
2    0.0149701   0.0314553  0.990683  0.0185185  0.857527   0.25  
0            0           0  0.989362          0         1      0  
7            0           0         0  0.0106383         0      1  
5 -0.000224014  -0.0011032  0.989247  0.0105263  0.494624    0.5  
9   -0.0177165  -0.0232516  0.988827          0  0.951613      0  
3   -0.0203308  -0.0447358  0.987382          0  0.841398      0  
Elapsed time 14.31 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-19 13:17:58.917000 
pca_target: 100 	 poly degree: 0 	 kselect: 40 
Imbalance: SMOTE(k=None, k_neighbors=5, kind='regular', m=None, m_neighbors=10, n_jobs=1,
   out_step=0.5, random_state=None, ratio='auto', svm_estimator=None) 
Extended target (count):  31485 13
('Total : Processed (count): ', (1252L, 438L), 13)
Final feature (count):  (1252L, 438L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=1, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=0.01, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='sag', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.949 	-0.021 	-0.017 	0.480 	0.000 	0.000
[[357  15]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.96      0.97       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.95      0.96       376


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.001, average=False, class_weight='balanced',
       epsilon=0.1, eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='modified_huber', n_iter=5, n_jobs=4,
       penalty='l2', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.976 	-0.012 	-0.012 	0.493 	0.000 	0.000
[[367   5]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=8, max_features='auto', max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=0.5, n_estimators=50, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.1, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=10.0, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', ...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.973 	-0.013 	-0.013 	0.492 	0.000 	0.000
[[366   6]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.98      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.97      0.98       376


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 192 candidates, totalling 960 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=4,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.949 	0.102 	0.079 	0.603 	0.489 	0.222
[[356  16]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.96      0.97       372
        1.0       0.06      0.25      0.10         4

avg / total       0.98      0.95      0.96       376


                estimator  min_score mean_score max_score     sd_score  \
9    KNeighborsClassifier         -1  -0.135654  0.867555     0.866406   
0              GaussianNB          1          1         1            0   
3    ExtraTreesClassifier    0.99885   0.999997         1  6.05307e-05   
4  RandomForestClassifier     0.9977   0.999498         1  0.000576746   
5           MLPClassifier   0.973837   0.990432         1   0.00734072   
6      AdaBoostClassifier   0.907338   0.990943         1     0.006773   
7                     SVC          0   0.880481         1     0.268617   
2           SGDClassifier -0.0772146   0.677871  0.996556     0.331318   
8        VotingClassifier   0.930147   0.970344  0.989695    0.0153526   
1      LogisticRegression          0   0.854795  0.976086     0.222547   

        acc       auc          conf_matrix     f1_c0      f1_c1      kappa  \
9  0.949468  0.603495  [[356, 16], [3, 1]]  0.974008  0.0952381  0.0793814   
0  0.989362       0.5   [[372, 0], [4, 0]]  0.994652          0          0   
3  0.989362       0.5   [[372, 0], [4, 0]]  0.994652          0          0   
4  0.989362       0.5   [[372, 0], [4, 0]]  0.994652          0          0   
5  0.989362       0.5   [[372, 0], [4, 0]]  0.994652          0          0   
6  0.989362       0.5   [[372, 0], [4, 0]]  0.994652          0          0   
7  0.989362       0.5   [[372, 0], [4, 0]]  0.994652          0          0   
2  0.976064   0.49328   [[367, 5], [4, 0]]  0.987887          0 -0.0119617   
8  0.973404  0.491935   [[366, 6], [4, 0]]  0.986523          0  -0.012931   
1  0.949468  0.479839  [[357, 15], [4, 0]]  0.974079          0 -0.0170843   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
9    0.102206  0.991643  0.0588235  0.956989   0.25  
0           0  0.989362          0         1      0  
3           0  0.989362          0         1      0  
4           0  0.989362          0         1      0  
5           0  0.989362          0         1      0  
6           0  0.989362          0         1      0  
7           0  0.989362          0         1      0  
2  -0.0120381  0.989218          0  0.986559      0  
8  -0.0132048  0.989189          0  0.983871      0  
1  -0.0211374   0.98892          0  0.959677      0  
Elapsed time 53.80 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-19 14:11:46.734000 
pca_target: 100 	 poly degree: 0 	 kselect: 40 
Imbalance: None 
Extended target (count):  31485 13
('Total : Processed (count): ', (1252L, 438L), 13)
Final feature (count):  (1252L, 438L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.779 	0.130 	0.048 	0.765 	0.765 	0.583
[[290  82]
 [  1   3]]
             precision    recall  f1-score   support

        0.0       1.00      0.78      0.87       372
        1.0       0.04      0.75      0.07         4

avg / total       0.99      0.78      0.87       376


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.01, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='sag', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.941 	-0.023 	-0.018 	0.476 	0.000 	0.000
[[354  18]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.95      0.97       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.94      0.96       376


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.1, average=False, class_weight={1: 15}, epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='perceptron', n_iter=5, n_jobs=4,
       penalty='l2', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.957 	-0.019 	-0.016 	0.484 	0.000 	0.000
[[360  12]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.97      0.98       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.96      0.97       376


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 500}, criterion='gini',
           max_depth=8, max_features='auto', max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.960 	0.122 	0.103 	0.609 	0.492 	0.225
[[360  12]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.97      0.98       372
        1.0       0.08      0.25      0.12         4

avg / total       0.98      0.96      0.97       376


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=16, max_features=0.33, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	-0.005 	-0.004 	0.499 	0.000 	0.000
[[371   1]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.01, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=32,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=0.5, n_estimators=50, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.960 	-0.018 	-0.016 	0.485 	0.000 	0.000
[[361  11]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.97      0.98       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.96      0.97       376


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.01, cache_size=200, class_weight={1: 500}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.559 	0.114 	0.026 	0.777 	0.744 	0.578
[[206 166]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.55      0.71       372
        1.0       0.02      1.00      0.05         4

avg / total       0.99      0.56      0.71       376


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 192 candidates, totalling 960 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=1,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


                estimator   min_score   mean_score  max_score    sd_score  \
7                     SVC  -0.0135498  -0.00464911   0.066821   0.0102547   
0              GaussianNB   0.0562822    0.0562822  0.0562822           0   
3    ExtraTreesClassifier   -0.016851  -0.00040893  0.0253442  0.00241137   
5           MLPClassifier  -0.0115326  -0.00262439   0.134094     0.02014   
8        VotingClassifier -0.00277651 -0.000849248          0  0.00109329   
9    KNeighborsClassifier          -1    -0.500846          0    0.499159   
4  RandomForestClassifier -0.00230935   0.00163019    0.19863   0.0179896   
6      AdaBoostClassifier  -0.0169898   0.00583345   0.272938   0.0382031   
2           SGDClassifier   -0.226136   -0.0177274  0.0851518   0.0289863   
1      LogisticRegression  -0.0807752  -0.00793518  0.0747622   0.0165647   

        acc       auc           conf_matrix     f1_c0      f1_c1      kappa  \
7  0.558511  0.776882  [[206, 166], [0, 4]]  0.712803   0.045977  0.0257243   
0  0.779255  0.764785   [[290, 82], [1, 3]]  0.874811  0.0674157  0.0480722   
3  0.960106  0.608871   [[360, 12], [3, 1]]  0.979592   0.117647   0.103053   
5  0.989362       0.5    [[372, 0], [4, 0]]  0.994652          0          0   
8  0.989362       0.5    [[372, 0], [4, 0]]  0.994652          0          0   
9  0.989362       0.5    [[372, 0], [4, 0]]  0.994652          0          0   
4  0.986702  0.498656    [[371, 1], [4, 0]]  0.993307          0 -0.0042735   
6  0.960106  0.485215   [[361, 11], [4, 0]]  0.979647          0 -0.0158501   
2  0.957447  0.483871   [[360, 12], [4, 0]]  0.978261          0 -0.0162162   
1  0.941489  0.475806   [[354, 18], [4, 0]]  0.969863          0 -0.0177165   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
7    0.114148         1  0.0235294  0.553763      1  
0    0.129888  0.996564  0.0352941   0.77957   0.75  
3     0.12227  0.991736  0.0769231  0.967742   0.25  
5           0  0.989362          0         1      0  
8           0  0.989362          0         1      0  
9           0  0.989362          0         1      0  
4  -0.0053548  0.989333          0  0.997312      0  
6  -0.0180015  0.989041          0   0.97043      0  
2  -0.0188278  0.989011          0  0.967742      0  
1  -0.0232516  0.988827          0  0.951613      0  
Elapsed time 29.50 mins 

************************************************************

[4;33mReloaded modules[24m: migraine_processing, classifiers[0m
Finished.


Normalize.
    pca = [200]
    poly = [0]
    ksel = [80, 40, 200]
    imb = [ClusterCentroids(), SMOTE(), None]





[5 rows x 23 columns]
pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-19 16:36:55.443000 
pca_target: 200 	 poly degree: 0 	 kselect: 80 
Imbalance: ClusterCentroids(estimator=None, n_jobs=1, random_state=None, ratio='auto') 
Extended target (count):  31485 13
('Total : Processed (count): ', (1252L, 438L), 13)
Final feature (count):  (1252L, 438L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.011 	0.000 	0.000 	0.500 	0.000 	0.000
[[  0 372]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       0.00      0.00      0.00       372
        1.0       0.01      1.00      0.02         4

avg / total       0.00      0.01      0.00       376


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=5, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='sag', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.449 	-0.112 	-0.021 	0.227 	0.000 	0.000
[[169 203]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.98      0.45      0.62       372
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.45      0.61       376


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.0001, average=False, class_weight={1: 500}, epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='constant', loss='squared_hinge', n_iter=5, n_jobs=4,
       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.473 	-0.107 	-0.021 	0.239 	0.000 	0.000
[[178 194]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.98      0.48      0.64       372
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.47      0.64       376


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight='balanced',
           criterion='entropy', max_depth=16, max_features=0.33,
           max_leaf_nodes=None, min_impurity_split=1e-07,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=4,
           oob_score=False, random_state=None, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.705 	0.102 	0.031 	0.727 	0.727 	0.531
[[262 110]
 [  1   3]]
             precision    recall  f1-score   support

        0.0       1.00      0.70      0.83       372
        1.0       0.03      0.75      0.05         4

avg / total       0.99      0.70      0.82       376


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight='balanced',
            criterion='entropy', max_depth=8, max_features='auto',
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=15, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.641 	0.135 	0.036 	0.819 	0.798 	0.660
[[237 135]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.64      0.78       372
        1.0       0.03      1.00      0.06         4

avg / total       0.99      0.64      0.77       376


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.01, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.455 	-0.060 	-0.011 	0.353 	0.338 	0.112
[[170 202]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.98      0.46      0.62       372
        1.0       0.00      0.25      0.01         4

avg / total       0.97      0.45      0.62       376


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 50}, criterion='gini', max_depth=8,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=2.0, n_estimators=15, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.774 	-0.054 	-0.021 	0.391 	0.000 	0.000
[[291  81]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.78      0.87       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.77      0.86       376


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.011 	0.000 	0.000 	0.500 	0.000 	0.000
[[  0 372]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       0.00      0.00      0.00       372
        1.0       0.01      1.00      0.02         4

avg / total       0.00      0.01      0.00       376


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=10.0, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Ran...owski',
           metric_params=None, n_jobs=4, n_neighbors=4, p=2,
           weights='uniform'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.513 	0.104 	0.022 	0.754 	0.713 	0.533
[[189 183]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.51      0.67       372
        1.0       0.02      1.00      0.04         4

avg / total       0.99      0.51      0.67       376


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 192 candidates, totalling 960 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=1,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.859 	-0.040 	-0.020 	0.434 	0.000 	0.000
[[323  49]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.87      0.92       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.86      0.91       376


                estimator  min_score mean_score max_score   sd_score  \
4  RandomForestClassifier  -0.239411   0.124554  0.683856   0.140985   
8        VotingClassifier  0.0939222   0.415036  0.718234   0.167297   
3    ExtraTreesClassifier          0   0.257047  0.718234   0.127509   
0              GaussianNB   0.145489   0.145489  0.145489          0   
7                     SVC  -0.273789  0.0874846  0.367711   0.172271   
9    KNeighborsClassifier         -1  -0.561918    0.3849   0.460638   
6      AdaBoostClassifier  -0.589933 -0.0246381    0.5132   0.174997   
5           MLPClassifier   0.239411   0.373057  0.624311  0.0783853   
2           SGDClassifier  -0.607122 -0.0391469    0.3849    0.14962   
1      LogisticRegression    -0.1283   0.089859  0.572745   0.200253   

         acc       auc           conf_matrix     f1_c0       f1_c1      kappa  \
4   0.640957  0.818548  [[237, 135], [0, 4]]  0.778325   0.0559441  0.0360073   
8   0.513298  0.754032  [[189, 183], [0, 4]]  0.673797   0.0418848  0.0215017   
3   0.704787  0.727151  [[262, 110], [1, 3]]  0.825197   0.0512821  0.0313776   
0  0.0106383       0.5    [[0, 372], [0, 4]]         0   0.0210526          0   
7  0.0106383       0.5    [[0, 372], [0, 4]]         0   0.0210526          0   
9   0.859043   0.43414   [[323, 49], [4, 0]]  0.924177           0 -0.0200655   
6   0.773936  0.391129   [[291, 81], [4, 0]]  0.872564           0 -0.0206949   
5   0.454787  0.353495  [[170, 202], [3, 1]]  0.623853  0.00966184 -0.0114424   
2   0.473404  0.239247  [[178, 194], [4, 0]]  0.642599           0 -0.0212906   
1   0.449468  0.227151  [[169, 203], [4, 0]]  0.620183           0 -0.0213101   

  model_score   prec_c0     prec_c1    rec_c0 rec_c1  
4    0.135402         1    0.028777  0.637097      1  
8    0.104248         1   0.0213904  0.508065      1  
3    0.101655  0.996198   0.0265487  0.704301   0.75  
0           0         0   0.0106383         0      1  
7           0         0   0.0106383         0      1  
9  -0.0401405  0.987768           0   0.86828      0  
6  -0.0543363  0.986441           0  0.782258      0  
5  -0.0603134  0.982659  0.00492611  0.456989   0.25  
2   -0.107059  0.978022           0  0.478495      0  
1   -0.112327  0.976879           0  0.454301      0  
Elapsed time 14.20 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-19 16:51:07.440000 
pca_target: 200 	 poly degree: 0 	 kselect: 80 
Imbalance: SMOTE(k=None, k_neighbors=5, kind='regular', m=None, m_neighbors=10, n_jobs=1,
   out_step=0.5, random_state=None, ratio='auto', svm_estimator=None) 
Extended target (count):  31485 13
('Total : Processed (count): ', (1252L, 438L), 13)
Final feature (count):  (1252L, 438L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.971 	-0.014 	-0.014 	0.491 	0.000 	0.000
[[365   7]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.98      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.97      0.97       376


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=10, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.886 	-0.035 	-0.020 	0.448 	0.000 	0.000
[[333  39]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.90      0.94       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.89      0.93       376


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.001, average=False, class_weight='balanced',
       epsilon=0.1, eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='modified_huber', n_iter=5, n_jobs=4,
       penalty='l2', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.920 	-0.028 	-0.019 	0.465 	0.000 	0.000
[[346  26]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.93      0.96       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.92      0.95       376


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=8, max_features=0.75, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	-0.005 	-0.004 	0.499 	0.000 	0.000
[[371   1]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=0.5, n_estimators=15, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.1, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', R...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.984 	-0.008 	-0.007 	0.497 	0.000 	0.000
[[370   2]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 192 candidates, totalling 960 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=4,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.957 	0.235 	0.186 	0.731 	0.694 	0.459
[[358  14]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      0.96      0.98       372
        1.0       0.12      0.50      0.20         4

avg / total       0.99      0.96      0.97       376


                estimator min_score mean_score max_score    sd_score  \
9    KNeighborsClassifier        -1  -0.100562  0.930104    0.901633   
3    ExtraTreesClassifier   0.94394   0.998539         1  0.00679568   
4  RandomForestClassifier  0.994269   0.999258         1   0.0010336   
6      AdaBoostClassifier  0.943213   0.987037         1  0.00951621   
7                     SVC         0   0.843267         1    0.271594   
5           MLPClassifier  0.885517   0.946509   0.99885   0.0376808   
8        VotingClassifier  0.904385   0.937055  0.959361   0.0125911   
0              GaussianNB   0.97946    0.97946   0.97946           0   
2           SGDClassifier -0.150726   0.594192  0.978244    0.319191   
1      LogisticRegression         0   0.762522   0.92028      0.2483   

        acc       auc          conf_matrix     f1_c0 f1_c1       kappa  \
9  0.957447  0.731183  [[358, 14], [2, 2]]  0.978142   0.2    0.186147   
3  0.989362       0.5   [[372, 0], [4, 0]]  0.994652     0           0   
4  0.989362       0.5   [[372, 0], [4, 0]]  0.994652     0           0   
6  0.989362       0.5   [[372, 0], [4, 0]]  0.994652     0           0   
7  0.989362       0.5   [[372, 0], [4, 0]]  0.994652     0           0   
5  0.986702  0.498656   [[371, 1], [4, 0]]  0.993307     0  -0.0042735   
8  0.984043  0.497312   [[370, 2], [4, 0]]  0.991957     0 -0.00714286   
0  0.970745  0.490591   [[365, 7], [4, 0]]  0.985155     0  -0.0137255   
2  0.920213  0.465054  [[346, 26], [4, 0]]  0.958449     0  -0.0187861   
1  0.885638  0.447581  [[333, 39], [4, 0]]  0.939351     0  -0.0196771   

  model_score   prec_c0 prec_c1    rec_c0 rec_c1  
9    0.235004  0.994444   0.125  0.962366    0.5  
3           0  0.989362       0         1      0  
4           0  0.989362       0         1      0  
6           0  0.989362       0         1      0  
7           0  0.989362       0         1      0  
5  -0.0053548  0.989333       0  0.997312      0  
8 -0.00758294  0.989305       0  0.994624      0  
0  -0.0142822   0.98916       0  0.981183      0  
2  -0.0282625  0.988571       0  0.930108      0  
1  -0.0352757  0.988131       0  0.895161      0  
Elapsed time 101.17 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-19 18:32:17.927000 
pca_target: 200 	 poly degree: 0 	 kselect: 80 
Imbalance: None 
Extended target (count):  31485 13
('Total : Processed (count): ', (1252L, 438L), 13)
Final feature (count):  (1252L, 438L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.457 	0.093 	0.017 	0.726 	0.672 	0.476
[[168 204]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.45      0.62       372
        1.0       0.02      1.00      0.04         4

avg / total       0.99      0.46      0.62       376


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.01, class_weight={1: 500}, dual=False,
          fit_intercept=True, intercept_scaling=0.01, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='sag', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.561 	0.013 	0.003 	0.531 	0.530 	0.279
[[209 163]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      0.56      0.72       372
        1.0       0.01      0.50      0.02         4

avg / total       0.98      0.56      0.71       376


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.0001, average=False, class_weight={1: 500}, epsilon=0.1,
       eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='invscaling', loss='modified_huber', n_iter=5,
       n_jobs=4, penalty='l2', power_t=0.5, random_state=None,
       shuffle=True, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.487 	0.099 	0.019 	0.741 	0.694 	0.506
[[179 193]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.48      0.65       372
        1.0       0.02      1.00      0.04         4

avg / total       0.99      0.49      0.64       376


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 500}, criterion='gini',
           max_depth=8, max_features='auto', max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.715 	0.160 	0.050 	0.856 	0.844 	0.733
[[265 107]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.71      0.83       372
        1.0       0.04      1.00      0.07         4

avg / total       0.99      0.72      0.82       376


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(500,), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=32,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=0.5, n_estimators=80, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.984 	-0.008 	-0.007 	0.497 	0.000 	0.000
[[370   2]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.01, cache_size=200, class_weight={1: 500}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.085 	0.029 	0.002 	0.538 	0.274 	0.082
[[ 28 344]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.08      0.14       372
        1.0       0.01      1.00      0.02         4

avg / total       0.99      0.09      0.14       376


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...wski',
           metric_params=None, n_jobs=4, n_neighbors=4, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 192 candidates, totalling 960 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=1,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


                estimator   min_score   mean_score  max_score     sd_score  \
3    ExtraTreesClassifier  -0.0267511 -0.000752172  0.0642567   0.00473701   
2           SGDClassifier   -0.143716    -0.014754  0.0902066    0.0242159   
0              GaussianNB   0.0683593    0.0683593  0.0683593            0   
7                     SVC  -0.0229247  -0.00792551  0.0332365   0.00979068   
1      LogisticRegression  -0.0703086   -0.0226098  0.0207222    0.0152102   
4  RandomForestClassifier -0.00162828  -2.2615e-05          0  0.000190558   
5           MLPClassifier  -0.0234394   -0.0103522          0   0.00617267   
8        VotingClassifier -0.00629417  -0.00164852          0   0.00175339   
9    KNeighborsClassifier          -1    -0.501284          0     0.498725   
6      AdaBoostClassifier  -0.0186967  -0.00598725   0.133119    0.0136264   

         acc       auc           conf_matrix     f1_c0      f1_c1       kappa  \
3   0.715426  0.856183  [[265, 107], [0, 4]]  0.832025  0.0695652   0.0500567   
2   0.486702  0.740591  [[179, 193], [0, 4]]  0.649728   0.039801   0.0193514   
0   0.457447  0.725806  [[168, 204], [0, 4]]  0.622222  0.0377358   0.0172202   
7  0.0851064  0.537634   [[28, 344], [0, 4]]      0.14  0.0227273  0.00172882   
1    0.56117  0.530914  [[209, 163], [2, 2]]  0.716981  0.0236686  0.00295706   
4   0.989362       0.5    [[372, 0], [4, 0]]  0.994652          0           0   
5   0.989362       0.5    [[372, 0], [4, 0]]  0.994652          0           0   
8   0.989362       0.5    [[372, 0], [4, 0]]  0.994652          0           0   
9   0.989362       0.5    [[372, 0], [4, 0]]  0.994652          0           0   
6   0.984043  0.497312    [[370, 2], [4, 0]]  0.991957          0 -0.00714286   

  model_score   prec_c0    prec_c1     rec_c0 rec_c1  
3    0.160221         1   0.036036   0.712366      1  
2   0.0988444         1  0.0203046   0.481183      1  
0   0.0931926         1  0.0192308   0.451613      1  
7   0.0294136         1  0.0114943  0.0752688      1  
1   0.0127821  0.990521  0.0121212   0.561828    0.5  
4           0  0.989362          0          1      0  
5           0  0.989362          0          1      0  
8           0  0.989362          0          1      0  
9           0  0.989362          0          1      0  
6 -0.00758294  0.989305          0   0.994624      0  
Elapsed time 48.97 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-19 19:21:15.869000 
pca_target: 200 	 poly degree: 0 	 kselect: 40 
Imbalance: ClusterCentroids(estimator=None, n_jobs=1, random_state=None, ratio='auto') 
Extended target (count):  31485 13
('Total : Processed (count): ', (1252L, 438L), 13)
Final feature (count):  (1252L, 438L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.001, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=10, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.582 	-0.034 	-0.008 	0.418 	0.383 	0.142
[[218 154]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.59      0.74       372
        1.0       0.01      0.25      0.01         4

avg / total       0.98      0.58      0.73       376


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.5, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='constant', loss='squared_hinge', n_iter=5, n_jobs=4,
       penalty='l2', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.489 	-0.053 	-0.011 	0.371 	0.351 	0.120
[[183 189]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.98      0.49      0.66       372
        1.0       0.01      0.25      0.01         4

avg / total       0.97      0.49      0.65       376


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 50},
           criterion='entropy', max_depth=8, max_features='auto',
           max_leaf_nodes=None, min_impurity_split=1e-07,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=15, n_jobs=4,
           oob_score=False, random_state=None, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.723 	-0.005 	-0.002 	0.489 	0.427 	0.173
[[271 101]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.73      0.84       372
        1.0       0.01      0.25      0.02         4

avg / total       0.98      0.72      0.83       376


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 500},
            criterion='gini', max_depth=8, max_features='auto',
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.755 	0.062 	0.022 	0.629 	0.616 	0.369
[[282  90]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      0.76      0.86       372
        1.0       0.02      0.50      0.04         4

avg / total       0.98      0.76      0.85       376


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.489 	-0.053 	-0.011 	0.371 	0.351 	0.120
[[183 189]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.98      0.49      0.66       372
        1.0       0.01      0.25      0.01         4

avg / total       0.97      0.49      0.65       376


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=0.5, n_estimators=80, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.662 	-0.072 	-0.021 	0.335 	0.000 	0.000
[[249 123]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.98      0.67      0.80       372
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.66      0.79       376


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='linear',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.566 	0.116 	0.027 	0.781 	0.750 	0.586
[[209 163]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.56      0.72       372
        1.0       0.02      1.00      0.05         4

avg / total       0.99      0.57      0.71       376


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=10.0, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Ran...wski',
           metric_params=None, n_jobs=4, n_neighbors=4, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.660 	-0.073 	-0.021 	0.333 	0.000 	0.000
[[248 124]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.98      0.67      0.79       372
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.66      0.79       376


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 192 candidates, totalling 960 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=3, p=2,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.548 	0.112 	0.025 	0.772 	0.737 	0.568
[[202 170]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.54      0.70       372
        1.0       0.02      1.00      0.04         4

avg / total       0.99      0.55      0.70       376


                estimator min_score  mean_score max_score  sd_score       acc  \
7                     SVC -0.496011  0.00638415    0.1283   0.13729  0.566489   
9    KNeighborsClassifier        -1   -0.653258         0  0.363158  0.547872   
4  RandomForestClassifier -0.239411    0.105614  0.478822  0.134734  0.755319   
0              GaussianNB         0           0         0         0  0.989362   
3    ExtraTreesClassifier   -0.2566    0.185364  0.607122  0.143925  0.723404   
1      LogisticRegression   -0.2566   0.0311711  0.222222  0.102573  0.582447   
2           SGDClassifier -0.812156   -0.275322  0.624311  0.179278  0.489362   
5           MLPClassifier -0.427255 -0.00259579    0.2566  0.192849  0.489362   
6      AdaBoostClassifier   -0.2566    0.244452  0.701045  0.164437  0.662234   
8        VotingClassifier -0.367711   -0.106189    0.2566  0.119791  0.659574   

        auc           conf_matrix     f1_c0      f1_c1       kappa  \
7  0.780914  [[209, 163], [0, 4]]  0.719449  0.0467836   0.0265565   
9  0.771505  [[202, 170], [0, 4]]  0.703833  0.0449438   0.0246582   
4  0.629032   [[282, 90], [2, 2]]  0.859756  0.0416667   0.0217195   
0       0.5    [[372, 0], [4, 0]]  0.994652          0           0   
3  0.489247  [[271, 101], [3, 1]]  0.839009  0.0188679 -0.00163934   
1  0.418011  [[218, 154], [3, 1]]  0.735245  0.0125786 -0.00833561   
2  0.370968  [[183, 189], [3, 1]]  0.655914  0.0103093  -0.0107527   
5  0.370968  [[183, 189], [3, 1]]  0.655914  0.0103093  -0.0107527   
6  0.334677  [[249, 123], [4, 0]]    0.7968          0    -0.02104   
8  0.333333  [[248, 124], [4, 0]]  0.794872          0  -0.0210455   

  model_score   prec_c0     prec_c1    rec_c0 rec_c1  
7    0.116004         1   0.0239521  0.561828      1  
9    0.111727         1   0.0229885  0.543011      1  
4   0.0615852  0.992958   0.0217391  0.758065    0.5  
0           0  0.989362           0         1      0  
3 -0.00496219  0.989051  0.00980392  0.728495   0.25  
1  -0.0341764  0.986425  0.00645161  0.586022   0.25  
2  -0.0529537  0.983871  0.00526316  0.491935   0.25  
5  -0.0529537  0.983871  0.00526316  0.491935   0.25  
6  -0.0723021   0.98419           0  0.669355      0  
8  -0.0727393  0.984127           0  0.666667      0  
Elapsed time 14.09 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-19 19:35:21.499000 
pca_target: 200 	 poly degree: 0 	 kselect: 40 
Imbalance: SMOTE(k=None, k_neighbors=5, kind='regular', m=None, m_neighbors=10, n_jobs=1,
   out_step=0.5, random_state=None, ratio='auto', svm_estimator=None) 
Extended target (count):  31485 13
('Total : Processed (count): ', (1252L, 438L), 13)
Final feature (count):  (1252L, 438L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.984 	-0.008 	-0.007 	0.497 	0.000 	0.000
[[370   2]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=10, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.886 	-0.035 	-0.020 	0.448 	0.000 	0.000
[[333  39]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.90      0.94       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.89      0.93       376


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.001, average=False, class_weight='balanced',
       epsilon=0.1, eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='modified_huber', n_iter=5, n_jobs=4,
       penalty='l2', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.918 	-0.029 	-0.019 	0.464 	0.000 	0.000
[[345  27]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.93      0.96       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.92      0.95       376


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=8, max_features=0.75, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.01, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=1.0, n_estimators=15, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.1, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=1.0, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', R...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.984 	-0.008 	-0.007 	0.497 	0.000 	0.000
[[370   2]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 192 candidates, totalling 960 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=4,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.955 	0.227 	0.176 	0.730 	0.693 	0.458
[[357  15]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      0.96      0.98       372
        1.0       0.12      0.50      0.19         4

avg / total       0.99      0.95      0.97       376


                estimator min_score mean_score max_score     sd_score  \
9    KNeighborsClassifier        -1  -0.102303   0.92689     0.899961   
3    ExtraTreesClassifier  0.940984   0.998938         1   0.00525979   
4  RandomForestClassifier    0.9977   0.999856         1  0.000425836   
5           MLPClassifier  0.886566   0.948382   0.99885     0.038316   
6      AdaBoostClassifier  0.945682   0.988632         1   0.00827205   
7                     SVC         0   0.843786         1     0.273572   
0              GaussianNB  0.991975   0.991975  0.991975            0   
8        VotingClassifier  0.897008   0.931933   0.95058    0.0130066   
2           SGDClassifier  -0.23179   0.591919  0.986277     0.317629   
1      LogisticRegression         0   0.761335  0.920285     0.247428   

        acc       auc          conf_matrix     f1_c0     f1_c1       kappa  \
9  0.954787  0.729839  [[357, 15], [2, 2]]  0.976744  0.190476    0.176289   
3  0.989362       0.5   [[372, 0], [4, 0]]  0.994652         0           0   
4  0.989362       0.5   [[372, 0], [4, 0]]  0.994652         0           0   
5  0.989362       0.5   [[372, 0], [4, 0]]  0.994652         0           0   
6  0.989362       0.5   [[372, 0], [4, 0]]  0.994652         0           0   
7  0.989362       0.5   [[372, 0], [4, 0]]  0.994652         0           0   
0  0.984043  0.497312   [[370, 2], [4, 0]]  0.991957         0 -0.00714286   
8  0.984043  0.497312   [[370, 2], [4, 0]]  0.991957         0 -0.00714286   
2  0.917553   0.46371  [[345, 27], [4, 0]]  0.957004         0  -0.0188811   
1  0.885638  0.447581  [[333, 39], [4, 0]]  0.939351         0  -0.0196771   

  model_score   prec_c0   prec_c1    rec_c0 rec_c1  
9    0.226978  0.994429  0.117647  0.959677    0.5  
3           0  0.989362         0         1      0  
4           0  0.989362         0         1      0  
5           0  0.989362         0         1      0  
6           0  0.989362         0         1      0  
7           0  0.989362         0         1      0  
0 -0.00758294  0.989305         0  0.994624      0  
8 -0.00758294  0.989305         0  0.994624      0  
2  -0.0288422  0.988539         0  0.927419      0  
1  -0.0352757  0.988131         0  0.895161      0  
Elapsed time 89.92 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-19 21:05:16.411000 
pca_target: 200 	 poly degree: 0 	 kselect: 40 
Imbalance: None 
Extended target (count):  31485 13
('Total : Processed (count): ', (1252L, 438L), 13)
Final feature (count):  (1252L, 438L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.497 	0.101 	0.020 	0.746 	0.701 	0.517
[[183 189]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.49      0.66       372
        1.0       0.02      1.00      0.04         4

avg / total       0.99      0.50      0.65       376


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.001, class_weight={1: 500}, dual=False,
          fit_intercept=True, intercept_scaling=5, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='sag', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.186 	-0.019 	-0.002 	0.465 	0.368 	0.143
[[ 67 305]
 [  1   3]]
             precision    recall  f1-score   support

        0.0       0.99      0.18      0.30       372
        1.0       0.01      0.75      0.02         4

avg / total       0.97      0.19      0.30       376


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=1, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='invscaling', loss='squared_hinge', n_iter=5,
       n_jobs=4, penalty='elasticnet', power_t=0.5, random_state=None,
       shuffle=True, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 500}, criterion='gini',
           max_depth=8, max_features='auto', max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=30, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.848 	0.101 	0.047 	0.676 	0.653 	0.411
[[317  55]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      0.85      0.92       372
        1.0       0.04      0.50      0.07         4

avg / total       0.98      0.85      0.91       376


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(500,), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='entropy', max_depth=32,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=1.0, n_estimators=50, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.979 	-0.011 	-0.011 	0.495 	0.000 	0.000
[[368   4]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.01, cache_size=200, class_weight={1: 500}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.085 	0.029 	0.002 	0.538 	0.274 	0.082
[[ 28 344]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.08      0.14       372
        1.0       0.01      1.00      0.02         4

avg / total       0.99      0.09      0.14       376


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...wski',
           metric_params=None, n_jobs=4, n_neighbors=4, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 192 candidates, totalling 960 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=1,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


                estimator   min_score  mean_score   max_score     sd_score  \
0              GaussianNB   0.0772992   0.0772992   0.0772992            0   
3    ExtraTreesClassifier  -0.0432001 -0.00083007  0.00859687   0.00320589   
7                     SVC  -0.0229247 -0.00790363   0.0332365    0.0097628   
2           SGDClassifier   -0.219729  -0.0147711   0.0987311    0.0251937   
4  RandomForestClassifier -0.00162828 -1.3569e-05           0  0.000148021   
5           MLPClassifier   -0.022996  -0.0106363 -0.00162844   0.00616043   
8        VotingClassifier   -0.005767 -0.00169853           0   0.00180903   
9    KNeighborsClassifier          -1   -0.501284           0     0.498725   
6      AdaBoostClassifier  -0.0200634 -0.00602935    0.130747    0.0134288   
1      LogisticRegression  -0.0732539  -0.0222723   0.0348527    0.0157466   

         acc       auc           conf_matrix     f1_c0      f1_c1       kappa  \
0    0.49734  0.745968  [[183, 189], [0, 4]]  0.659459  0.0406091   0.0201853   
3   0.848404  0.676075   [[317, 55], [2, 2]]  0.917511  0.0655738   0.0466192   
7  0.0851064  0.537634   [[28, 344], [0, 4]]      0.14  0.0227273  0.00172882   
2   0.989362       0.5    [[372, 0], [4, 0]]  0.994652          0           0   
4   0.989362       0.5    [[372, 0], [4, 0]]  0.994652          0           0   
5   0.989362       0.5    [[372, 0], [4, 0]]  0.994652          0           0   
8   0.989362       0.5    [[372, 0], [4, 0]]  0.994652          0           0   
9   0.989362       0.5    [[372, 0], [4, 0]]  0.994652          0           0   
6   0.978723  0.494624    [[368, 4], [4, 0]]  0.989247          0  -0.0107527   
1    0.18617  0.465054   [[67, 305], [1, 3]]  0.304545  0.0192308 -0.00181109   

  model_score   prec_c0     prec_c1     rec_c0 rec_c1  
0    0.100973         1   0.0207254   0.491935      1  
3    0.100739   0.99373   0.0350877   0.852151    0.5  
7   0.0294136         1   0.0114943  0.0752688      1  
2           0  0.989362           0          1      0  
4           0  0.989362           0          1      0  
5           0  0.989362           0          1      0  
8           0  0.989362           0          1      0  
9           0  0.989362           0          1      0  
6  -0.0107527  0.989247           0   0.989247      0  
1  -0.0186295  0.985294  0.00974026   0.180108   0.75  
Elapsed time 42.30 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-19 21:47:34.305000 
pca_target: 200 	 poly degree: 0 	 kselect: 200 
Imbalance: ClusterCentroids(estimator=None, n_jobs=1, random_state=None, ratio='auto') 
Extended target (count):  31485 13
('Total : Processed (count): ', (1252L, 438L), 13)
Final feature (count):  (1252L, 438L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.011 	0.000 	0.000 	0.500 	0.000 	0.000
[[  0 372]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       0.00      0.00      0.00       372
        1.0       0.01      1.00      0.02         4

avg / total       0.00      0.01      0.00       376


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=5, class_weight={1: 15}, dual=False, fit_intercept=True,
          intercept_scaling=0.1, max_iter=100, multi_class='ovr', n_jobs=4,
          penalty='l2', random_state=None, solver='sag', tol=0.0001,
          verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.585 	-0.034 	-0.008 	0.419 	0.384 	0.142
[[219 153]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.59      0.74       372
        1.0       0.01      0.25      0.01         4

avg / total       0.98      0.59      0.73       376


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.5, average=False, class_weight='balanced', epsilon=0.1,
       eta0=0.001, fit_intercept=True, l1_ratio=0.15,
       learning_rate='invscaling', loss='modified_huber', n_iter=5,
       n_jobs=4, penalty='l1', power_t=0.5, random_state=None,
       shuffle=True, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.447 	-0.113 	-0.021 	0.226 	0.000 	0.000
[[168 204]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.98      0.45      0.62       372
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.45      0.61       376


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3},
           criterion='entropy', max_depth=16, max_features=0.75,
           max_leaf_nodes=None, min_impurity_split=1e-07,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=15, n_jobs=4,
           oob_score=False, random_state=None, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.641 	0.083 	0.022 	0.695 	0.693 	0.485
[[238 134]
 [  1   3]]
             precision    recall  f1-score   support

        0.0       1.00      0.64      0.78       372
        1.0       0.02      0.75      0.04         4

avg / total       0.99      0.64      0.77       376


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 500},
            criterion='gini', max_depth=None, max_features='auto',
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=15, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.657 	0.034 	0.010 	0.579 	0.574 	0.324
[[245 127]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      0.66      0.79       372
        1.0       0.02      0.50      0.03         4

avg / total       0.98      0.66      0.78       376


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.01, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 50}, criterion='gini', max_depth=16,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=1.0, n_estimators=50, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.830 	0.091 	0.040 	0.667 	0.645 	0.403
[[310  62]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      0.83      0.91       372
        1.0       0.03      0.50      0.06         4

avg / total       0.98      0.83      0.90       376


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=10.0, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', ...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.529 	0.006 	0.001 	0.515 	0.515 	0.264
[[197 175]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      0.53      0.69       372
        1.0       0.01      0.50      0.02         4

avg / total       0.98      0.53      0.68       376


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 192 candidates, totalling 960 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=5, p=2,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.431 	-0.014 	-0.003 	0.465 	0.464 	0.217
[[160 212]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      0.43      0.60       372
        1.0       0.01      0.50      0.02         4

avg / total       0.98      0.43      0.59       376


                estimator min_score mean_score  max_score   sd_score  \
3    ExtraTreesClassifier         0   0.539374   0.812156  0.0983129   
6      AdaBoostClassifier -0.222222   0.319373   0.812156   0.189215   
4  RandomForestClassifier   -0.1283   0.273125   0.683856   0.135483   
8        VotingClassifier    0.1283   0.548477   0.906078   0.142815   
0              GaussianNB    0.5132     0.5132     0.5132          0   
5           MLPClassifier -0.350522 -0.0302331   0.239411   0.121783   
7                     SVC   -0.3849  -0.129202  0.0939222   0.124887   
9    KNeighborsClassifier        -1    -0.5636     0.1283   0.453784   
1      LogisticRegression   -0.5132  -0.142813     0.1283   0.173268   
2           SGDClassifier -0.367711   0.262808   0.683856   0.166548   

         acc       auc           conf_matrix     f1_c0      f1_c1       kappa  \
3   0.640957  0.694892  [[238, 134], [1, 3]]  0.779051  0.0425532   0.0223421   
6   0.829787  0.666667   [[310, 62], [2, 2]]  0.906433  0.0588235   0.0395913   
4   0.656915  0.579301  [[245, 127], [2, 2]]  0.791599  0.0300752  0.00963737   
8   0.529255  0.514785  [[197, 175], [2, 2]]  0.690018  0.0220994  0.00132053   
0  0.0106383       0.5    [[0, 372], [0, 4]]         0  0.0210526           0   
5   0.989362       0.5    [[372, 0], [4, 0]]  0.994652          0           0   
7   0.989362       0.5    [[372, 0], [4, 0]]  0.994652          0           0   
9   0.430851  0.465054  [[160, 212], [2, 2]]  0.599251  0.0183486 -0.00259171   
1   0.585106  0.419355  [[219, 153], [3, 1]]  0.737374  0.0126582 -0.00825083   
2   0.446809  0.225806  [[168, 204], [4, 0]]  0.617647          0  -0.0213122   

  model_score   prec_c0     prec_c1    rec_c0 rec_c1  
3   0.0830935  0.995816   0.0218978  0.639785   0.75  
6    0.090994   0.99359     0.03125  0.833333    0.5  
4   0.0342742  0.991903   0.0155039  0.658602    0.5  
8  0.00607768   0.98995   0.0112994   0.52957    0.5  
0           0         0   0.0106383         0      1  
5           0  0.989362           0         1      0  
7           0  0.989362           0         1      0  
9    -0.01448  0.987654  0.00934579  0.430108    0.5  
1  -0.0336491  0.986486  0.00649351   0.58871   0.25  
2    -0.11293  0.976744           0  0.451613      0  
Elapsed time 15.70 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-19 22:03:16.314000 
pca_target: 200 	 poly degree: 0 	 kselect: 200 
Imbalance: SMOTE(k=None, k_neighbors=5, kind='regular', m=None, m_neighbors=10, n_jobs=1,
   out_step=0.5, random_state=None, ratio='auto', svm_estimator=None) 
Extended target (count):  31485 13
('Total : Processed (count): ', (1252L, 438L), 13)
Final feature (count):  (1252L, 438L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.960 	-0.018 	-0.016 	0.485 	0.000 	0.000
[[361  11]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.97      0.98       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.96      0.97       376


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=10, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.886 	-0.035 	-0.020 	0.448 	0.000 	0.000
[[333  39]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.90      0.94       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.89      0.93       376


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.001, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='modified_huber', n_iter=5, n_jobs=4,
       penalty='l2', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.931 	-0.026 	-0.018 	0.470 	0.000 	0.000
[[350  22]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.94      0.96       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.93      0.95       376


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=8, max_features=0.75, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	-0.005 	-0.004 	0.499 	0.000 	0.000
[[371   1]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=0.5, n_estimators=15, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.1, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', R...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.984 	-0.008 	-0.007 	0.497 	0.000 	0.000
[[370   2]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 192 candidates, totalling 960 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=4,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.957 	0.235 	0.186 	0.731 	0.694 	0.459
[[358  14]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      0.96      0.98       372
        1.0       0.12      0.50      0.20         4

avg / total       0.99      0.96      0.97       376


                estimator min_score mean_score max_score     sd_score  \
9    KNeighborsClassifier        -1  -0.100124  0.930104     0.902068   
3    ExtraTreesClassifier  0.936313   0.998178         1   0.00777653   
4  RandomForestClassifier    0.9977   0.999805         1  0.000487352   
6      AdaBoostClassifier  0.925197    0.98801         1   0.00862466   
7                     SVC         0   0.844098         1     0.271233   
5           MLPClassifier  0.889766   0.946622  0.997706    0.0371103   
8        VotingClassifier  0.903351   0.936724  0.956082    0.0125641   
0              GaussianNB  0.961539   0.961539  0.961539            0   
2           SGDClassifier -0.156145   0.593653  0.980616     0.318042   
1      LogisticRegression         0   0.762988  0.920285     0.248211   

        acc       auc          conf_matrix     f1_c0 f1_c1       kappa  \
9  0.957447  0.731183  [[358, 14], [2, 2]]  0.978142   0.2    0.186147   
3  0.989362       0.5   [[372, 0], [4, 0]]  0.994652     0           0   
4  0.989362       0.5   [[372, 0], [4, 0]]  0.994652     0           0   
6  0.989362       0.5   [[372, 0], [4, 0]]  0.994652     0           0   
7  0.989362       0.5   [[372, 0], [4, 0]]  0.994652     0           0   
5  0.986702  0.498656   [[371, 1], [4, 0]]  0.993307     0  -0.0042735   
8  0.984043  0.497312   [[370, 2], [4, 0]]  0.991957     0 -0.00714286   
0  0.960106  0.485215  [[361, 11], [4, 0]]  0.979647     0  -0.0158501   
2  0.930851   0.47043  [[350, 22], [4, 0]]  0.964187     0  -0.0183333   
1  0.885638  0.447581  [[333, 39], [4, 0]]  0.939351     0  -0.0196771   

  model_score   prec_c0 prec_c1    rec_c0 rec_c1  
9    0.235004  0.994444   0.125  0.962366    0.5  
3           0  0.989362       0         1      0  
4           0  0.989362       0         1      0  
6           0  0.989362       0         1      0  
7           0  0.989362       0         1      0  
5  -0.0053548  0.989333       0  0.997312      0  
8 -0.00758294  0.989305       0  0.994624      0  
0  -0.0180015  0.989041       0   0.97043      0  
2  -0.0258505  0.988701       0   0.94086      0  
1  -0.0352757  0.988131       0  0.895161      0  
Elapsed time 130.98 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-20 00:14:15.356000 
pca_target: 200 	 poly degree: 0 	 kselect: 200 
Imbalance: None 
Extended target (count):  31485 13
('Total : Processed (count): ', (1252L, 438L), 13)
Final feature (count):  (1252L, 438L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.439 	0.090 	0.016 	0.716 	0.658 	0.457
[[161 211]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.43      0.60       372
        1.0       0.02      1.00      0.04         4

avg / total       0.99      0.44      0.60       376


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.001, class_weight={1: 500}, dual=False,
          fit_intercept=True, intercept_scaling=10, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='sag', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.205 	0.051 	0.005 	0.598 	0.443 	0.212
[[ 73 299]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.20      0.33       372
        1.0       0.01      1.00      0.03         4

avg / total       0.99      0.20      0.32       376


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.1, average=False, class_weight={1: 500}, epsilon=0.1,
       eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='modified_huber', n_iter=5, n_jobs=4,
       penalty='l1', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.519 	0.004 	0.001 	0.509 	0.509 	0.259
[[193 179]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      0.52      0.68       372
        1.0       0.01      0.50      0.02         4

avg / total       0.98      0.52      0.67       376


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 500}, criterion='gini',
           max_depth=8, max_features='auto', max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.723 	0.052 	0.017 	0.613 	0.602 	0.355
[[270 102]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      0.73      0.84       372
        1.0       0.02      0.50      0.04         4

avg / total       0.98      0.72      0.83       376


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.01, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(500,), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=16,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=2.0, n_estimators=50, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.979 	-0.011 	-0.011 	0.495 	0.000 	0.000
[[368   4]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.01, cache_size=200, class_weight={1: 500}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.085 	0.029 	0.002 	0.538 	0.274 	0.082
[[ 28 344]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.08      0.14       372
        1.0       0.01      1.00      0.02         4

avg / total       0.99      0.09      0.14       376


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...wski',
           metric_params=None, n_jobs=4, n_neighbors=4, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	-0.005 	-0.004 	0.499 	0.000 	0.000
[[371   1]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 192 candidates, totalling 960 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=1,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


                estimator   min_score   mean_score  max_score     sd_score  \
0              GaussianNB   0.0648656    0.0648656  0.0648656            0   
3    ExtraTreesClassifier  -0.0481715 -0.000844422  0.0415579   0.00439174   
1      LogisticRegression  -0.0766173   -0.0227654  0.0300338    0.0154531   
7                     SVC  -0.0229247  -0.00791026  0.0332365   0.00976853   
2           SGDClassifier   -0.126909   -0.0142469  0.0956943    0.0243169   
4  RandomForestClassifier -0.00162828  -1.3569e-05          0  0.000148021   
5           MLPClassifier  -0.0246267   -0.0105497          0   0.00637296   
9    KNeighborsClassifier          -1    -0.501284          0     0.498725   
8        VotingClassifier   -0.005767   -0.0016252          0   0.00178283   
6      AdaBoostClassifier  -0.0189863  -0.00458881   0.136066    0.0164806   

         acc       auc           conf_matrix     f1_c0      f1_c1  \
0    0.43883  0.716398  [[161, 211], [0, 4]]  0.604128  0.0365297   
3   0.723404  0.612903  [[270, 102], [2, 2]]  0.838509   0.037037   
1   0.204787  0.598118   [[73, 299], [0, 4]]   0.32809  0.0260586   
7  0.0851064  0.537634   [[28, 344], [0, 4]]      0.14  0.0227273   
2   0.518617  0.509409  [[193, 179], [2, 2]]  0.680776  0.0216216   
4   0.989362       0.5    [[372, 0], [4, 0]]  0.994652          0   
5   0.989362       0.5    [[372, 0], [4, 0]]  0.994652          0   
9   0.989362       0.5    [[372, 0], [4, 0]]  0.994652          0   
8   0.986702  0.498656    [[371, 1], [4, 0]]  0.993307          0   
6   0.978723  0.494624    [[368, 4], [4, 0]]  0.989247          0   

         kappa model_score   prec_c0    prec_c1     rec_c0 rec_c1  
0    0.0159754    0.089733         1  0.0186047   0.432796      1  
3    0.0168946   0.0517889  0.992647  0.0192308   0.725806    0.5  
1   0.00516778   0.0508978         1  0.0132013   0.196237      1  
7   0.00172882   0.0294136         1  0.0114943  0.0752688      1  
2  0.000822175  0.00386367  0.989744  0.0110497   0.518817    0.5  
4            0           0  0.989362          0          1      0  
5            0           0  0.989362          0          1      0  
9            0           0  0.989362          0          1      0  
8   -0.0042735  -0.0053548  0.989333          0   0.997312      0  
6   -0.0107527  -0.0107527  0.989247          0   0.989247      0  
Elapsed time 59.06 mins 

************************************************************

[4;33mReloaded modules[24m: migraine_processing, classifiers[0m
Finished.





Minmax, lagged(3,4)x1

    pca = [0, 100]
    poly = [2]
    ksel = [80, 40, 100]
    imb = [ClusterCentroids(), SMOTE(), None]














pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-20 08:45:49.187000 
pca_target: 0 	 poly degree: 2 	 kselect: 80 
Imbalance: ClusterCentroids(estimator=None, n_jobs=1, random_state=None, ratio='auto') 
Extended target (count):  31485 13
('Total : Processed (count): ', (1252L, 24976L), 13)
Final feature (count):  (1252L, 24976L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.686 	0.150 	0.044 	0.841 	0.826 	0.704
[[254 118]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.68      0.81       372
        1.0       0.03      1.00      0.06         4

avg / total       0.99      0.69      0.80       376


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=10, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.753 	0.176 	0.060 	0.875 	0.866 	0.769
[[279  93]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.75      0.86       372
        1.0       0.04      1.00      0.08         4

avg / total       0.99      0.75      0.85       376


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.1, average=False, class_weight={1: 500}, epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='constant', loss='squared_hinge', n_iter=5, n_jobs=4,
       penalty='none', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.806 	0.016 	0.007 	0.531 	0.451 	0.192
[[302  70]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.81      0.89       372
        1.0       0.01      0.25      0.03         4

avg / total       0.98      0.81      0.88       376


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=8, max_features='auto', max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.609 	0.127 	0.032 	0.802 	0.778 	0.629
[[225 147]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.60      0.75       372
        1.0       0.03      1.00      0.05         4

avg / total       0.99      0.61      0.75       376


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.609 	0.127 	0.032 	0.802 	0.778 	0.629
[[225 147]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.60      0.75       372
        1.0       0.03      1.00      0.05         4

avg / total       0.99      0.61      0.75       376


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.5, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.747 	0.173 	0.058 	0.872 	0.863 	0.764
[[277  95]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.74      0.85       372
        1.0       0.04      1.00      0.08         4

avg / total       0.99      0.75      0.85       376


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=0.5, n_estimators=15, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.609 	0.127 	0.032 	0.802 	0.778 	0.629
[[225 147]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.60      0.75       372
        1.0       0.03      1.00      0.05         4

avg / total       0.99      0.61      0.75       376


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=1, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='linear',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.662 	0.142 	0.039 	0.829 	0.812 	0.681
[[245 127]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.66      0.79       372
        1.0       0.03      1.00      0.06         4

avg / total       0.99      0.66      0.79       376


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.609 	0.127 	0.032 	0.802 	0.778 	0.629
[[225 147]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.60      0.75       372
        1.0       0.03      1.00      0.05         4

avg / total       0.99      0.61      0.75       376


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 192 candidates, totalling 960 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=1,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.609 	0.127 	0.032 	0.802 	0.778 	0.629
[[225 147]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.60      0.75       372
        1.0       0.03      1.00      0.05         4

avg / total       0.99      0.61      0.75       376


                estimator min_score mean_score max_score   sd_score       acc  \
1      LogisticRegression         0   0.384799         1   0.316711   0.75266   
5           MLPClassifier  0.496011   0.830623         1    0.10646   0.74734   
0              GaussianNB         1          1         1          0   0.68617   
7                     SVC         0   0.464323  0.888889   0.312533  0.662234   
3    ExtraTreesClassifier         1          1         1          0  0.609043   
4  RandomForestClassifier         1          1         1          0  0.609043   
6      AdaBoostClassifier  0.444444   0.866457         1   0.110226  0.609043   
8        VotingClassifier  0.777778   0.969613         1  0.0741251  0.609043   
9    KNeighborsClassifier        -1  -0.119123         1   0.894198  0.609043   
2           SGDClassifier -0.222222   0.151875  0.906078   0.199729  0.805851   

        auc           conf_matrix     f1_c0      f1_c1       kappa  \
1     0.875   [[279, 93], [0, 4]]  0.857143  0.0792079        0.06   
5  0.872312   [[277, 95], [0, 4]]  0.853621  0.0776699   0.0584142   
0  0.841398  [[254, 118], [0, 4]]  0.811502  0.0634921   0.0437931   
7  0.829301  [[245, 127], [0, 4]]  0.794165  0.0592593   0.0394271   
3  0.802419  [[225, 147], [0, 4]]  0.753769  0.0516129   0.0315391   
4  0.802419  [[225, 147], [0, 4]]  0.753769  0.0516129   0.0315391   
6  0.802419  [[225, 147], [0, 4]]  0.753769  0.0516129   0.0315391   
8  0.802419  [[225, 147], [0, 4]]  0.753769  0.0516129   0.0315391   
9  0.802419  [[225, 147], [0, 4]]  0.753769  0.0516129   0.0315391   
2  0.530914   [[302, 70], [3, 1]]  0.892171  0.0266667  0.00665895   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
1    0.175863         1  0.0412371      0.75      1  
5    0.173453         1   0.040404  0.744624      1  
0    0.149622         1  0.0327869  0.682796      1  
7     0.14181         1  0.0305344  0.658602      1  
3    0.126579         1  0.0264901  0.604839      1  
4    0.126579         1  0.0264901  0.604839      1  
6    0.126579         1  0.0264901  0.604839      1  
8    0.126579         1  0.0264901  0.604839      1  
9    0.126579         1  0.0264901  0.604839      1  
2   0.0162072  0.990164  0.0140845  0.811828   0.25  
Elapsed time 22.56 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-20 09:08:22.867000 
pca_target: 0 	 poly degree: 2 	 kselect: 80 
Imbalance: SMOTE(k=None, k_neighbors=5, kind='regular', m=None, m_neighbors=10, n_jobs=1,
   out_step=0.5, random_state=None, ratio='auto', svm_estimator=None) 
Extended target (count):  31485 13
('Total : Processed (count): ', (1252L, 24976L), 13)
Final feature (count):  (1252L, 24976L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.745 	0.172 	0.058 	0.871 	0.861 	0.761
[[276  96]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.74      0.85       372
        1.0       0.04      1.00      0.08         4

avg / total       0.99      0.74      0.84       376


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=10, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=5, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.848 	0.030 	0.014 	0.552 	0.462 	0.201
[[318  54]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.85      0.92       372
        1.0       0.02      0.25      0.03         4

avg / total       0.98      0.85      0.91       376


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.001, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='modified_huber', n_iter=5, n_jobs=4,
       penalty='l1', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.840 	0.164 	0.072 	0.796 	0.794 	0.625
[[313  59]
 [  1   3]]
             precision    recall  f1-score   support

        0.0       1.00      0.84      0.91       372
        1.0       0.05      0.75      0.09         4

avg / total       0.99      0.84      0.90       376


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 50}, criterion='gini',
           max_depth=None, max_features=0.33, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.984 	-0.008 	-0.007 	0.497 	0.000 	0.000
[[370   2]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight='balanced',
            criterion='gini', max_depth=None, max_features=0.33,
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.984 	-0.008 	-0.007 	0.497 	0.000 	0.000
[[370   2]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.01, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.971 	-0.014 	-0.014 	0.491 	0.000 	0.000
[[365   7]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.98      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.97      0.97       376


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='entropy', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=0.5, n_estimators=15, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	-0.005 	-0.004 	0.499 	0.000 	0.000
[[371   1]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=1, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=10, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.984 	-0.008 	-0.007 	0.497 	0.000 	0.000
[[370   2]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=10.0, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', ...owski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='uniform'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.952 	0.107 	0.084 	0.605 	0.490 	0.223
[[357  15]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.96      0.98       372
        1.0       0.06      0.25      0.10         4

avg / total       0.98      0.95      0.97       376


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 192 candidates, totalling 960 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=4,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.955 	0.111 	0.090 	0.606 	0.491 	0.223
[[358  14]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.96      0.98       372
        1.0       0.07      0.25      0.11         4

avg / total       0.98      0.95      0.97       376


                estimator min_score mean_score max_score   sd_score       acc  \
0              GaussianNB  0.661507   0.661507  0.661507          0  0.744681   
2           SGDClassifier -0.212027   0.440317  0.832901   0.272748  0.840426   
9    KNeighborsClassifier        -1 -0.0455865  0.949649     0.9546  0.954787   
8        VotingClassifier  0.862052   0.900169  0.940844  0.0192777  0.952128   
1      LogisticRegression         0   0.652316  0.875371   0.181927  0.848404   
6      AdaBoostClassifier  0.892828    0.95502  0.987362  0.0201694  0.986702   
3    ExtraTreesClassifier  0.713646   0.932207  0.984028  0.0635336  0.984043   
4  RandomForestClassifier  0.858277   0.946419  0.977215  0.0266449  0.984043   
7                     SVC         0   0.777559  0.993113   0.166744  0.984043   
5           MLPClassifier  0.880466   0.949497  0.976034   0.019671  0.970745   

        auc          conf_matrix     f1_c0      f1_c1       kappa model_score  \
0  0.870968  [[276, 96], [0, 4]]  0.851852  0.0769231   0.0576441    0.172271   
2  0.795699  [[313, 59], [1, 3]]  0.912536  0.0909091   0.0723684    0.163501   
9  0.606183  [[358, 14], [3, 1]]  0.976808   0.105263   0.0899772    0.111323   
8  0.604839  [[357, 15], [3, 1]]   0.97541        0.1   0.0844156    0.106572   
1  0.552419  [[318, 54], [3, 1]]  0.917749  0.0338983   0.0143488   0.0304361   
6  0.498656   [[371, 1], [4, 0]]  0.993307          0  -0.0042735  -0.0053548   
3  0.497312   [[370, 2], [4, 0]]  0.991957          0 -0.00714286 -0.00758294   
4  0.497312   [[370, 2], [4, 0]]  0.991957          0 -0.00714286 -0.00758294   
7  0.497312   [[370, 2], [4, 0]]  0.991957          0 -0.00714286 -0.00758294   
5  0.490591   [[365, 7], [4, 0]]  0.985155          0  -0.0137255  -0.0142822   

    prec_c0    prec_c1    rec_c0 rec_c1  
0         1       0.04  0.741935      1  
2  0.996815  0.0483871  0.841398   0.75  
9   0.99169  0.0666667  0.962366   0.25  
8  0.991667     0.0625  0.959677   0.25  
1  0.990654  0.0181818  0.854839   0.25  
6  0.989333          0  0.997312      0  
3  0.989305          0  0.994624      0  
4  0.989305          0  0.994624      0  
7  0.989305          0  0.994624      0  
5   0.98916          0  0.981183      0  
Elapsed time 70.42 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-20 10:18:47.889000 
pca_target: 0 	 poly degree: 2 	 kselect: 80 
Imbalance: None 
Extended target (count):  31485 13
('Total : Processed (count): ', (1252L, 24976L), 13)
Final feature (count):  (1252L, 24976L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.811 	-0.048 	-0.020 	0.410 	0.000 	0.000
[[305  67]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.82      0.90       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.81      0.89       376


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.001, class_weight={1: 50}, dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.965 	-0.016 	-0.015 	0.488 	0.000 	0.000
[[363   9]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.98      0.98       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.97      0.97       376


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.0001, average=False, class_weight={1: 50}, epsilon=0.1,
       eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='constant', loss='perceptron', n_iter=5, n_jobs=4,
       penalty='l1', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.801 	-0.050 	-0.021 	0.405 	0.000 	0.000
[[301  71]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.81      0.89       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.80      0.88       376


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 500}, criterion='gini',
           max_depth=8, max_features=0.75, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.920 	-0.028 	-0.019 	0.465 	0.000 	0.000
[[346  26]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.93      0.96       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.92      0.95       376


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.984 	-0.008 	-0.007 	0.497 	0.000 	0.000
[[370   2]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight='balanced', criterion='gini', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=2.0, n_estimators=50, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.981 	-0.009 	-0.009 	0.496 	0.000 	0.000
[[369   3]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.1, cache_size=200, class_weight='balanced', coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.739 	0.114 	0.038 	0.745 	0.745 	0.555
[[275  97]
 [  1   3]]
             precision    recall  f1-score   support

        0.0       1.00      0.74      0.85       372
        1.0       0.03      0.75      0.06         4

avg / total       0.99      0.74      0.84       376


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 192 candidates, totalling 960 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=1,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


                estimator  min_score   mean_score  max_score    sd_score  \
7                     SVC -0.0240549    0.0243614   0.124825   0.0336598   
4  RandomForestClassifier -0.0107474 -0.000429109          0   0.0012761   
8        VotingClassifier -0.0112394  -0.00278108          0  0.00297949   
9    KNeighborsClassifier         -1    -0.501322          0    0.498685   
5           MLPClassifier -0.0104029 -0.000100221   0.132852   0.0236103   
6      AdaBoostClassifier -0.0165826   0.00225854   0.194294   0.0328617   
1      LogisticRegression  -0.019605    0.0473292   0.233311   0.0555945   
3    ExtraTreesClassifier -0.0188449  -0.00105007  0.0721122   0.0085003   
0              GaussianNB   0.106193     0.106193   0.106193           0   
2           SGDClassifier -0.0750046    0.0536008    0.30364   0.0551388   

        acc       auc          conf_matrix     f1_c0      f1_c1       kappa  \
7  0.739362  0.744624  [[275, 97], [1, 3]]  0.848765  0.0576923   0.0380117   
4  0.989362       0.5   [[372, 0], [4, 0]]  0.994652          0           0   
8  0.989362       0.5   [[372, 0], [4, 0]]  0.994652          0           0   
9  0.989362       0.5   [[372, 0], [4, 0]]  0.994652          0           0   
5  0.984043  0.497312   [[370, 2], [4, 0]]  0.991957          0 -0.00714286   
6  0.981383  0.495968   [[369, 3], [4, 0]]  0.990604          0 -0.00920245   
1  0.965426  0.487903   [[363, 9], [4, 0]]  0.982409          0  -0.0149502   
3  0.920213  0.465054  [[346, 26], [4, 0]]  0.958449          0  -0.0187861   
0   0.81117  0.409946  [[305, 67], [4, 0]]  0.895742          0  -0.0204893   
2  0.800532   0.40457  [[301, 71], [4, 0]]  0.889217          0  -0.0205559   

  model_score   prec_c0 prec_c1    rec_c0 rec_c1  
7    0.113599  0.996377    0.03  0.739247   0.75  
4           0  0.989362       0         1      0  
8           0  0.989362       0         1      0  
9           0  0.989362       0         1      0  
5 -0.00758294  0.989305       0  0.994624      0  
6 -0.00929961  0.989276       0  0.991935      0  
1  -0.0162385  0.989101       0  0.975806      0  
3  -0.0282625  0.988571       0  0.930108      0  
0  -0.0482855  0.987055       0  0.819892      0  
2  -0.0500308  0.986885       0   0.80914      0  
Elapsed time 30.90 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-20 10:49:41.645000 
pca_target: 0 	 poly degree: 2 	 kselect: 40 
Imbalance: ClusterCentroids(estimator=None, n_jobs=1, random_state=None, ratio='auto') 
Extended target (count):  31485 13
('Total : Processed (count): ', (1252L, 24976L), 13)
Final feature (count):  (1252L, 24976L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.686 	0.150 	0.044 	0.841 	0.826 	0.704
[[254 118]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.68      0.81       372
        1.0       0.03      1.00      0.06         4

avg / total       0.99      0.69      0.80       376


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=5, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.689 	0.151 	0.044 	0.843 	0.828 	0.707
[[255 117]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.69      0.81       372
        1.0       0.03      1.00      0.06         4

avg / total       0.99      0.69      0.81       376


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=1, average=False, class_weight='balanced', epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='squared_hinge', n_iter=5, n_jobs=4,
       penalty='none', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.731 	0.167 	0.054 	0.864 	0.854 	0.748
[[271 101]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.73      0.84       372
        1.0       0.04      1.00      0.07         4

avg / total       0.99      0.73      0.83       376


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=8, max_features='auto', max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.609 	0.127 	0.032 	0.802 	0.778 	0.629
[[225 147]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.60      0.75       372
        1.0       0.03      1.00      0.05         4

avg / total       0.99      0.61      0.75       376


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.609 	0.127 	0.032 	0.802 	0.778 	0.629
[[225 147]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.60      0.75       372
        1.0       0.03      1.00      0.05         4

avg / total       0.99      0.61      0.75       376


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.1, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(500,), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.686 	0.150 	0.044 	0.841 	0.826 	0.704
[[254 118]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.68      0.81       372
        1.0       0.03      1.00      0.06         4

avg / total       0.99      0.69      0.80       376


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=0.5, n_estimators=50, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.609 	0.127 	0.032 	0.802 	0.778 	0.629
[[225 147]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.60      0.75       372
        1.0       0.03      1.00      0.05         4

avg / total       0.99      0.61      0.75       376


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=10, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='linear',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.707 	0.157 	0.048 	0.852 	0.839 	0.725
[[262 110]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.70      0.83       372
        1.0       0.04      1.00      0.07         4

avg / total       0.99      0.71      0.82       376


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.609 	0.127 	0.032 	0.802 	0.778 	0.629
[[225 147]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.60      0.75       372
        1.0       0.03      1.00      0.05         4

avg / total       0.99      0.61      0.75       376


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 192 candidates, totalling 960 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=1,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.609 	0.127 	0.032 	0.802 	0.778 	0.629
[[225 147]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.60      0.75       372
        1.0       0.03      1.00      0.05         4

avg / total       0.99      0.61      0.75       376


                estimator min_score mean_score max_score   sd_score       acc  \
2           SGDClassifier   -0.2566  0.0985986  0.906078   0.154412  0.731383   
7                     SVC         0   0.411211         1   0.312832  0.707447   
1      LogisticRegression   -0.1283   0.285926  0.888889   0.261976   0.68883   
0              GaussianNB         1          1         1          0   0.68617   
5           MLPClassifier  0.683856   0.855178         1  0.0823094   0.68617   
3    ExtraTreesClassifier         1          1         1          0  0.609043   
4  RandomForestClassifier  0.906078   0.998696         1  0.0109917  0.609043   
6      AdaBoostClassifier  0.555556   0.968494         1  0.0778029  0.609043   
8        VotingClassifier  0.906078   0.977389         1  0.0401548  0.609043   
9    KNeighborsClassifier        -1 -0.0519488         1   0.949771  0.609043   

        auc           conf_matrix     f1_c0      f1_c1      kappa model_score  \
2  0.864247  [[271, 101], [0, 4]]  0.842924  0.0733945  0.0540056     0.16659   
7  0.852151  [[262, 110], [0, 4]]  0.826498  0.0677966  0.0482327    0.157202   
1  0.842742  [[255, 117], [0, 4]]  0.813397      0.064   0.044317    0.150534   
0  0.841398  [[254, 118], [0, 4]]  0.811502  0.0634921  0.0437931    0.149622   
5  0.841398  [[254, 118], [0, 4]]  0.811502  0.0634921  0.0437931    0.149622   
3  0.802419  [[225, 147], [0, 4]]  0.753769  0.0516129  0.0315391    0.126579   
4  0.802419  [[225, 147], [0, 4]]  0.753769  0.0516129  0.0315391    0.126579   
6  0.802419  [[225, 147], [0, 4]]  0.753769  0.0516129  0.0315391    0.126579   
8  0.802419  [[225, 147], [0, 4]]  0.753769  0.0516129  0.0315391    0.126579   
9  0.802419  [[225, 147], [0, 4]]  0.753769  0.0516129  0.0315391    0.126579   

  prec_c0    prec_c1    rec_c0 rec_c1  
2       1  0.0380952  0.728495      1  
7       1  0.0350877  0.704301      1  
1       1  0.0330579  0.685484      1  
0       1  0.0327869  0.682796      1  
5       1  0.0327869  0.682796      1  
3       1  0.0264901  0.604839      1  
4       1  0.0264901  0.604839      1  
6       1  0.0264901  0.604839      1  
8       1  0.0264901  0.604839      1  
9       1  0.0264901  0.604839      1  
Elapsed time 21.53 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-20 11:11:13.596000 
pca_target: 0 	 poly degree: 2 	 kselect: 40 
Imbalance: SMOTE(k=None, k_neighbors=5, kind='regular', m=None, m_neighbors=10, n_jobs=1,
   out_step=0.5, random_state=None, ratio='auto', svm_estimator=None) 
Extended target (count):  31485 13
('Total : Processed (count): ', (1252L, 24976L), 13)
Final feature (count):  (1252L, 24976L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.742 	0.171 	0.057 	0.870 	0.860 	0.759
[[275  97]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.74      0.85       372
        1.0       0.04      1.00      0.08         4

avg / total       0.99      0.74      0.84       376


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=10, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='sag', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.843 	0.028 	0.013 	0.550 	0.461 	0.200
[[316  56]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.85      0.91       372
        1.0       0.02      0.25      0.03         4

avg / total       0.98      0.84      0.91       376


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.001, average=False, class_weight='balanced',
       epsilon=0.1, eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='perceptron', n_iter=5, n_jobs=4,
       penalty='l2', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.862 	0.109 	0.053 	0.683 	0.658 	0.417
[[322  50]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      0.87      0.93       372
        1.0       0.04      0.50      0.07         4

avg / total       0.98      0.86      0.92       376


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 15}, criterion='gini',
           max_depth=None, max_features=0.75, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=50, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.979 	-0.011 	-0.011 	0.495 	0.000 	0.000
[[368   4]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 15},
            criterion='entropy', max_depth=None, max_features=0.33,
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=15, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.979 	-0.011 	-0.011 	0.495 	0.000 	0.000
[[368   4]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.01, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.965 	-0.016 	-0.015 	0.488 	0.000 	0.000
[[363   9]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.98      0.98       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.97      0.97       376


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 50}, criterion='gini', max_depth=16,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=1.0, n_estimators=80, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.973 	-0.013 	-0.013 	0.492 	0.000 	0.000
[[366   6]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.98      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.97      0.98       376


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=10, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=10, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.981 	0.214 	0.213 	0.620 	0.497 	0.229
[[368   4]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       372
        1.0       0.20      0.25      0.22         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=10.0, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', ...owski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='uniform'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.949 	0.102 	0.079 	0.603 	0.489 	0.222
[[356  16]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.96      0.97       372
        1.0       0.06      0.25      0.10         4

avg / total       0.98      0.95      0.96       376


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 192 candidates, totalling 960 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=4,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.944 	0.094 	0.071 	0.601 	0.488 	0.221
[[354  18]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.95      0.97       372
        1.0       0.05      0.25      0.09         4

avg / total       0.98      0.94      0.96       376


                estimator min_score mean_score max_score   sd_score       acc  \
0              GaussianNB  0.634486   0.634486  0.634486          0  0.742021   
2           SGDClassifier -0.222376   0.437628  0.812105   0.275746  0.861702   
7                     SVC         0   0.739211  0.981747     0.1611  0.981383   
8        VotingClassifier  0.861934   0.899468  0.929052  0.0162116  0.949468   
9    KNeighborsClassifier        -1 -0.0529633  0.944073   0.947226  0.944149   
1      LogisticRegression         0   0.597163  0.843927   0.223574  0.843085   
3    ExtraTreesClassifier  0.704416   0.920091  0.979478  0.0669613  0.978723   
4  RandomForestClassifier   0.87788   0.946106  0.973841  0.0273908  0.978723   
6      AdaBoostClassifier  0.856372   0.943256  0.985184  0.0225851  0.973404   
5           MLPClassifier  0.874042   0.935348  0.982878  0.0230563  0.965426   

        auc          conf_matrix     f1_c0      f1_c1      kappa model_score  \
0  0.869624  [[275, 97], [0, 4]]  0.850077  0.0761905  0.0568887    0.171106   
2  0.682796  [[322, 50], [2, 2]]  0.925287  0.0714286  0.0527132    0.108648   
7  0.619624   [[368, 4], [3, 1]]  0.990579   0.222222   0.212919    0.214278   
8  0.603495  [[356, 16], [3, 1]]  0.974008  0.0952381  0.0793814    0.102206   
9  0.600806  [[354, 18], [3, 1]]  0.971193  0.0869565  0.0706215   0.0944298   
1  0.549731  [[316, 56], [3, 1]]  0.914616  0.0327869  0.0131673    0.028453   
3  0.494624   [[368, 4], [4, 0]]  0.989247          0 -0.0107527  -0.0107527   
4  0.494624   [[368, 4], [4, 0]]  0.989247          0 -0.0107527  -0.0107527   
6  0.491935   [[366, 6], [4, 0]]  0.986523          0  -0.012931  -0.0132048   
5  0.487903   [[363, 9], [4, 0]]  0.982409          0 -0.0149502  -0.0162385   

    prec_c0    prec_c1    rec_c0 rec_c1  
0         1   0.039604  0.739247      1  
2  0.993827  0.0384615  0.865591    0.5  
7  0.991914        0.2  0.989247   0.25  
8  0.991643  0.0588235  0.956989   0.25  
9  0.991597  0.0526316  0.951613   0.25  
1  0.990596  0.0175439  0.849462   0.25  
3  0.989247          0  0.989247      0  
4  0.989247          0  0.989247      0  
6  0.989189          0  0.983871      0  
5  0.989101          0  0.975806      0  
Elapsed time 52.18 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-20 12:03:24.187000 
pca_target: 0 	 poly degree: 2 	 kselect: 40 
Imbalance: None 
Extended target (count):  31485 13
('Total : Processed (count): ', (1252L, 24976L), 13)
Final feature (count):  (1252L, 24976L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.859 	-0.040 	-0.020 	0.434 	0.000 	0.000
[[323  49]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.87      0.92       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.86      0.91       376


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=5, class_weight={1: 15}, dual=False, fit_intercept=True,
          intercept_scaling=0.1, max_iter=100, multi_class='ovr', n_jobs=4,
          penalty='l2', random_state=None, solver='sag', tol=0.0001,
          verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.936 	-0.025 	-0.018 	0.473 	0.000 	0.000
[[352  20]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.95      0.97       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.94      0.96       376


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=1, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.001, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='squared_hinge', n_iter=5, n_jobs=4,
       penalty='none', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.971 	-0.014 	-0.014 	0.491 	0.000 	0.000
[[365   7]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.98      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.97      0.97       376


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 500}, criterion='gini',
           max_depth=8, max_features=0.75, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=50, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.920 	0.069 	0.045 	0.589 	0.482 	0.216
[[345  27]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.93      0.96       372
        1.0       0.04      0.25      0.06         4

avg / total       0.98      0.92      0.95       376


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.5, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.984 	-0.008 	-0.007 	0.497 	0.000 	0.000
[[370   2]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 500}, criterion='gini', max_depth=8,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=0.5, n_estimators=50, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.981 	-0.009 	-0.009 	0.496 	0.000 	0.000
[[369   3]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.1, cache_size=200, class_weight='balanced', coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.785 	0.010 	0.004 	0.520 	0.445 	0.187
[[294  78]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.79      0.88       372
        1.0       0.01      0.25      0.02         4

avg / total       0.98      0.78      0.87       376


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 192 candidates, totalling 960 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=1,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


                estimator  min_score   mean_score  max_score    sd_score  \
3    ExtraTreesClassifier -0.0201138  -0.00135946  0.0738916  0.00595255   
7                     SVC -0.0222236      0.02842   0.153578   0.0406482   
4  RandomForestClassifier -0.0100596 -0.000331722          0  0.00101511   
8        VotingClassifier -0.0113933   -0.0036939          0  0.00330831   
9    KNeighborsClassifier         -1    -0.501023          0    0.498981   
5           MLPClassifier -0.0132628   0.00365199  0.0927885   0.0281761   
6      AdaBoostClassifier -0.0145518   0.00674947   0.192383   0.0347407   
2           SGDClassifier  -0.114014    0.0619363    0.38248   0.0615593   
1      LogisticRegression -0.0310347    0.0434153   0.171973   0.0488882   
0              GaussianNB   0.138293     0.138293   0.138293           0   

        acc       auc          conf_matrix     f1_c0      f1_c1       kappa  \
3  0.920213   0.58871  [[345, 27], [3, 1]]  0.958333     0.0625   0.0447154   
7  0.784574  0.520161  [[294, 78], [3, 1]]  0.878924  0.0240964  0.00392465   
4  0.989362       0.5   [[372, 0], [4, 0]]  0.994652          0           0   
8  0.989362       0.5   [[372, 0], [4, 0]]  0.994652          0           0   
9  0.989362       0.5   [[372, 0], [4, 0]]  0.994652          0           0   
5  0.984043  0.497312   [[370, 2], [4, 0]]  0.991957          0 -0.00714286   
6  0.981383  0.495968   [[369, 3], [4, 0]]  0.990604          0 -0.00920245   
2  0.970745  0.490591   [[365, 7], [4, 0]]  0.985155          0  -0.0137255   
1   0.93617  0.473118  [[352, 20], [4, 0]]  0.967033          0  -0.0180505   
0  0.859043   0.43414  [[323, 49], [4, 0]]  0.924177          0  -0.0200655   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
3    0.069332  0.991379  0.0357143  0.927419   0.25  
7   0.0101545  0.989899  0.0126582  0.790323   0.25  
4           0  0.989362          0         1      0  
8           0  0.989362          0         1      0  
9           0  0.989362          0         1      0  
5 -0.00758294  0.989305          0  0.994624      0  
6 -0.00929961  0.989276          0  0.991935      0  
2  -0.0142822   0.98916          0  0.981183      0  
1  -0.0245781  0.988764          0  0.946237      0  
0  -0.0401405  0.987768          0   0.86828      0  
Elapsed time 25.73 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-20 12:29:07.811000 
pca_target: 0 	 poly degree: 2 	 kselect: 100 
Imbalance: ClusterCentroids(estimator=None, n_jobs=1, random_state=None, ratio='auto') 
Extended target (count):  31485 13
('Total : Processed (count): ', (1252L, 24976L), 13)
Final feature (count):  (1252L, 24976L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.686 	0.150 	0.044 	0.841 	0.826 	0.704
[[254 118]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.68      0.81       372
        1.0       0.03      1.00      0.06         4

avg / total       0.99      0.69      0.80       376


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=10, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.753 	0.176 	0.060 	0.875 	0.866 	0.769
[[279  93]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.75      0.86       372
        1.0       0.04      1.00      0.08         4

avg / total       0.99      0.75      0.85       376


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=1, average=False, class_weight='balanced', epsilon=0.1,
       eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='squared_hinge', n_iter=5, n_jobs=4,
       penalty='l2', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.718 	0.161 	0.051 	0.858 	0.846 	0.735
[[266 106]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.72      0.83       372
        1.0       0.04      1.00      0.07         4

avg / total       0.99      0.72      0.83       376


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=8, max_features='auto', max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.609 	0.127 	0.032 	0.802 	0.778 	0.629
[[225 147]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.60      0.75       372
        1.0       0.03      1.00      0.05         4

avg / total       0.99      0.61      0.75       376


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.609 	0.127 	0.032 	0.802 	0.778 	0.629
[[225 147]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.60      0.75       372
        1.0       0.03      1.00      0.05         4

avg / total       0.99      0.61      0.75       376


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.5, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.734 	0.168 	0.055 	0.866 	0.855 	0.751
[[272 100]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.73      0.84       372
        1.0       0.04      1.00      0.07         4

avg / total       0.99      0.73      0.84       376


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=0.5, n_estimators=15, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.609 	0.127 	0.032 	0.802 	0.778 	0.629
[[225 147]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.60      0.75       372
        1.0       0.03      1.00      0.05         4

avg / total       0.99      0.61      0.75       376


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=10, cache_size=200, class_weight='balanced', coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.694 	0.152 	0.045 	0.845 	0.831 	0.712
[[257 115]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.69      0.82       372
        1.0       0.03      1.00      0.07         4

avg / total       0.99      0.69      0.81       376


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.609 	0.127 	0.032 	0.802 	0.778 	0.629
[[225 147]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.60      0.75       372
        1.0       0.03      1.00      0.05         4

avg / total       0.99      0.61      0.75       376


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 192 candidates, totalling 960 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=1,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.612 	0.127 	0.032 	0.804 	0.779 	0.631
[[226 146]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.61      0.76       372
        1.0       0.03      1.00      0.05         4

avg / total       0.99      0.61      0.75       376


                estimator min_score mean_score max_score    sd_score  \
1      LogisticRegression         0    0.37284         1     0.30363   
5           MLPClassifier  0.239411   0.576838  0.906078    0.174661   
2           SGDClassifier   -0.2566   0.130931  0.906078    0.181553   
7                     SVC         0   0.442469         1    0.322434   
0              GaussianNB         1          1         1           0   
9    KNeighborsClassifier        -1  -0.173962         1     0.84139   
3    ExtraTreesClassifier  0.906078    0.99113         1   0.0274672   
4  RandomForestClassifier  0.906078   0.999739         1  0.00494325   
6      AdaBoostClassifier  0.589933   0.951198         1   0.0747653   
8        VotingClassifier  0.906078   0.983477         1   0.0357615   

        acc       auc           conf_matrix     f1_c0      f1_c1      kappa  \
1   0.75266     0.875   [[279, 93], [0, 4]]  0.857143  0.0792079       0.06   
5  0.734043  0.865591  [[272, 100], [0, 4]]   0.84472  0.0740741  0.0547064   
2  0.718085  0.857527  [[266, 106], [0, 4]]  0.833856  0.0701754   0.050686   
7  0.694149   0.84543  [[257, 115], [0, 4]]   0.81717  0.0650407  0.0453903   
0   0.68617  0.841398  [[254, 118], [0, 4]]  0.811502  0.0634921  0.0437931   
9  0.611702  0.803763  [[226, 146], [0, 4]]  0.755853  0.0519481  0.0318849   
3  0.609043  0.802419  [[225, 147], [0, 4]]  0.753769  0.0516129  0.0315391   
4  0.609043  0.802419  [[225, 147], [0, 4]]  0.753769  0.0516129  0.0315391   
6  0.609043  0.802419  [[225, 147], [0, 4]]  0.753769  0.0516129  0.0315391   
8  0.609043  0.802419  [[225, 147], [0, 4]]  0.753769  0.0516129  0.0315391   

  model_score prec_c0    prec_c1    rec_c0 rec_c1  
1    0.175863       1  0.0412371      0.75      1  
5    0.167697       1  0.0384615  0.731183      1  
2    0.161251       1  0.0363636  0.715054      1  
7    0.152388       1  0.0336134   0.69086      1  
0    0.149622       1  0.0327869  0.682796      1  
9    0.127282       1  0.0266667  0.607527      1  
3    0.126579       1  0.0264901  0.604839      1  
4    0.126579       1  0.0264901  0.604839      1  
6    0.126579       1  0.0264901  0.604839      1  
8    0.126579       1  0.0264901  0.604839      1  
Elapsed time 23.87 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-20 12:53:00.128000 
pca_target: 0 	 poly degree: 2 	 kselect: 100 
Imbalance: SMOTE(k=None, k_neighbors=5, kind='regular', m=None, m_neighbors=10, n_jobs=1,
   out_step=0.5, random_state=None, ratio='auto', svm_estimator=None) 
Extended target (count):  31485 13
('Total : Processed (count): ', (1252L, 24976L), 13)
Final feature (count):  (1252L, 24976L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.710 	0.158 	0.049 	0.853 	0.841 	0.728
[[263 109]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.71      0.83       372
        1.0       0.04      1.00      0.07         4

avg / total       0.99      0.71      0.82       376


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=10, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.848 	0.030 	0.014 	0.552 	0.462 	0.201
[[318  54]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.85      0.92       372
        1.0       0.02      0.25      0.03         4

avg / total       0.98      0.85      0.91       376


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.001, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='perceptron', n_iter=5, n_jobs=4,
       penalty='l1', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.880 	0.121 	0.063 	0.692 	0.665 	0.425
[[329  43]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      0.88      0.94       372
        1.0       0.04      0.50      0.08         4

avg / total       0.98      0.88      0.93       376


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3},
           criterion='entropy', max_depth=32, max_features=0.75,
           max_leaf_nodes=None, min_impurity_split=1e-07,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=15, n_jobs=4,
           oob_score=False, random_state=None, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	-0.005 	-0.004 	0.499 	0.000 	0.000
[[371   1]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight='balanced',
            criterion='entropy', max_depth=None, max_features='auto',
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.984 	-0.008 	-0.007 	0.497 	0.000 	0.000
[[370   2]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.01, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.918 	0.067 	0.043 	0.587 	0.481 	0.216
[[344  28]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.92      0.96       372
        1.0       0.03      0.25      0.06         4

avg / total       0.98      0.92      0.95       376


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 50}, criterion='entropy', max_depth=8,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=1.0, n_estimators=50, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.984 	-0.008 	-0.007 	0.497 	0.000 	0.000
[[370   2]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.5, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=10, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.984 	-0.008 	-0.007 	0.497 	0.000 	0.000
[[370   2]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=10.0, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', ...owski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='uniform'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.949 	0.102 	0.079 	0.603 	0.489 	0.222
[[356  16]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.96      0.97       372
        1.0       0.06      0.25      0.10         4

avg / total       0.98      0.95      0.96       376


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 192 candidates, totalling 960 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=4,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.957 	0.117 	0.096 	0.608 	0.491 	0.224
[[359  13]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.97      0.98       372
        1.0       0.07      0.25      0.11         4

avg / total       0.98      0.96      0.97       376


                estimator min_score mean_score max_score   sd_score       acc  \
0              GaussianNB  0.688077   0.688077  0.688077          0  0.710106   
2           SGDClassifier -0.235106   0.423844  0.813829   0.264439  0.880319   
9    KNeighborsClassifier        -1 -0.0467221  0.948402   0.953476  0.957447   
8        VotingClassifier  0.858984   0.898101   0.93655  0.0192905  0.949468   
5           MLPClassifier   0.87292   0.932362  0.970511  0.0256759  0.917553   
1      LogisticRegression  0.300884   0.661714  0.863973   0.140848  0.848404   
3    ExtraTreesClassifier   0.71023   0.931224  0.984008  0.0630249  0.986702   
4  RandomForestClassifier  0.881953   0.949527  0.977197  0.0244649  0.984043   
6      AdaBoostClassifier  0.882948   0.954344  0.987427  0.0207201  0.984043   
7                     SVC  0.288508   0.784809    0.9977   0.146038  0.984043   

        auc           conf_matrix     f1_c0      f1_c1       kappa  \
0  0.853495  [[263, 109], [0, 4]]  0.828346  0.0683761   0.0488303   
2  0.692204   [[329, 43], [2, 2]]  0.935989  0.0816327   0.0633304   
9  0.607527   [[359, 13], [3, 1]]  0.978202   0.111111   0.0961538   
8  0.603495   [[356, 16], [3, 1]]  0.974008  0.0952381   0.0793814   
5  0.587366   [[344, 28], [3, 1]]  0.956885  0.0606061    0.042707   
1  0.552419   [[318, 54], [3, 1]]  0.917749  0.0338983   0.0143488   
3  0.498656    [[371, 1], [4, 0]]  0.993307          0  -0.0042735   
4  0.497312    [[370, 2], [4, 0]]  0.991957          0 -0.00714286   
6  0.497312    [[370, 2], [4, 0]]  0.991957          0 -0.00714286   
7  0.497312    [[370, 2], [4, 0]]  0.991957          0 -0.00714286   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
0    0.158197         1  0.0353982  0.706989      1  
2    0.121499  0.993958  0.0444444  0.884409    0.5  
9    0.116528  0.991713  0.0714286  0.965054   0.25  
8    0.102206  0.991643  0.0588235  0.956989   0.25  
5   0.0671905  0.991354  0.0344828  0.924731   0.25  
1   0.0304361  0.990654  0.0181818  0.854839   0.25  
3  -0.0053548  0.989333          0  0.997312      0  
4 -0.00758294  0.989305          0  0.994624      0  
6 -0.00758294  0.989305          0  0.994624      0  
7 -0.00758294  0.989305          0  0.994624      0  
Elapsed time 76.25 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-20 14:09:15.109000 
pca_target: 0 	 poly degree: 2 	 kselect: 100 
Imbalance: None 
Extended target (count):  31485 13
('Total : Processed (count): ', (1252L, 24976L), 13)
Final feature (count):  (1252L, 24976L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.814 	-0.048 	-0.020 	0.411 	0.000 	0.000
[[306  66]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.82      0.90       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.81      0.89       376


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.001, class_weight={1: 50}, dual=False,
          fit_intercept=True, intercept_scaling=10, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.955 	-0.020 	-0.017 	0.483 	0.000 	0.000
[[359  13]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.97      0.98       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.95      0.97       376


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.5, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.001, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='squared_hinge', n_iter=5, n_jobs=4,
       penalty='none', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.965 	-0.016 	-0.015 	0.488 	0.000 	0.000
[[363   9]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.98      0.98       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.97      0.97       376


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight='balanced',
           criterion='gini', max_depth=8, max_features=0.75,
           max_leaf_nodes=None, min_impurity_split=1e-07,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=4,
           oob_score=False, random_state=None, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.965 	-0.016 	-0.015 	0.488 	0.000 	0.000
[[363   9]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.98      0.98       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.97      0.97       376


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.1, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.979 	-0.011 	-0.011 	0.495 	0.000 	0.000
[[368   4]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=16,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=2.0, n_estimators=80, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.981 	-0.009 	-0.009 	0.496 	0.000 	0.000
[[369   3]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.1, cache_size=200, class_weight='balanced', coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.731 	0.111 	0.036 	0.741 	0.741 	0.549
[[272 100]
 [  1   3]]
             precision    recall  f1-score   support

        0.0       1.00      0.73      0.84       372
        1.0       0.03      0.75      0.06         4

avg / total       0.99      0.73      0.84       376


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 192 candidates, totalling 960 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=1,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


                estimator  min_score   mean_score  max_score    sd_score  \
7                     SVC -0.0192015    0.0242919    0.12107   0.0328349   
4  RandomForestClassifier -0.0150053 -0.000523633          0  0.00172413   
8        VotingClassifier -0.0101063  -0.00261346          0  0.00274142   
9    KNeighborsClassifier         -1    -0.501301          0    0.498705   
6      AdaBoostClassifier -0.0199913   0.00600903   0.277789   0.0391469   
5           MLPClassifier -0.0105265   0.00213621  0.0900475   0.0240712   
2           SGDClassifier -0.0547744    0.0534209   0.305079   0.0543555   
3    ExtraTreesClassifier -0.0193622  -0.00122384  0.0584714  0.00644429   
1      LogisticRegression -0.0695082    0.0474054   0.265275   0.0506385   
0              GaussianNB  0.0795122    0.0795122  0.0795122           0   

        acc       auc           conf_matrix     f1_c0      f1_c1       kappa  \
7  0.731383  0.740591  [[272, 100], [1, 3]]  0.843411  0.0560748   0.0363378   
4  0.989362       0.5    [[372, 0], [4, 0]]  0.994652          0           0   
8  0.989362       0.5    [[372, 0], [4, 0]]  0.994652          0           0   
9  0.989362       0.5    [[372, 0], [4, 0]]  0.994652          0           0   
6  0.981383  0.495968    [[369, 3], [4, 0]]  0.990604          0 -0.00920245   
5  0.978723  0.494624    [[368, 4], [4, 0]]  0.989247          0  -0.0107527   
2  0.965426  0.487903    [[363, 9], [4, 0]]  0.982409          0  -0.0149502   
3  0.965426  0.487903    [[363, 9], [4, 0]]  0.982409          0  -0.0149502   
1  0.954787  0.482527   [[359, 13], [4, 0]]  0.976871          0  -0.0165394   
0   0.81383   0.41129   [[306, 66], [4, 0]]  0.897361          0  -0.0204715   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
7    0.110691  0.996337  0.0291262  0.731183   0.75  
4           0  0.989362          0         1      0  
8           0  0.989362          0         1      0  
9           0  0.989362          0         1      0  
6 -0.00929961  0.989276          0  0.991935      0  
5  -0.0107527  0.989247          0  0.989247      0  
2  -0.0162385  0.989101          0  0.975806      0  
3  -0.0162385  0.989101          0  0.975806      0  
1  -0.0196235  0.988981          0  0.965054      0  
0  -0.0478464  0.987097          0  0.822581      0  
Elapsed time 31.15 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-20 14:40:23.831000 
pca_target: 100 	 poly degree: 2 	 kselect: 80 
Imbalance: ClusterCentroids(estimator=None, n_jobs=1, random_state=None, ratio='auto') 
Extended target (count):  31485 13
('Total : Processed (count): ', (1252L, 24976L), 13)
Final feature (count):  (1252L, 24976L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.001, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=10, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='sag', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.529 	0.006 	0.001 	0.515 	0.515 	0.264
[[197 175]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      0.53      0.69       372
        1.0       0.01      0.50      0.02         4

avg / total       0.98      0.53      0.68       376


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.0001, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='perceptron', n_iter=5, n_jobs=4,
       penalty='l2', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.463 	-0.109 	-0.021 	0.234 	0.000 	0.000
[[174 198]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.98      0.47      0.63       372
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.46      0.63       376


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=8, max_features='auto', max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.609 	0.127 	0.032 	0.802 	0.778 	0.629
[[225 147]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.60      0.75       372
        1.0       0.03      1.00      0.05         4

avg / total       0.99      0.61      0.75       376


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.609 	0.127 	0.032 	0.802 	0.778 	0.629
[[225 147]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.60      0.75       372
        1.0       0.03      1.00      0.05         4

avg / total       0.99      0.61      0.75       376


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.1, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.492 	-0.103 	-0.021 	0.249 	0.000 	0.000
[[185 187]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.98      0.50      0.66       372
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.49      0.65       376


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=0.5, n_estimators=15, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.609 	0.127 	0.032 	0.802 	0.778 	0.629
[[225 147]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.60      0.75       372
        1.0       0.03      1.00      0.05         4

avg / total       0.99      0.61      0.75       376


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=10, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.011 	0.000 	0.000 	0.500 	0.000 	0.000
[[  0 372]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       0.00      0.00      0.00       372
        1.0       0.01      1.00      0.02         4

avg / total       0.00      0.01      0.00       376


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.481 	0.047 	0.009 	0.614 	0.599 	0.369
[[178 194]
 [  1   3]]
             precision    recall  f1-score   support

        0.0       0.99      0.48      0.65       372
        1.0       0.02      0.75      0.03         4

avg / total       0.98      0.48      0.64       376


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 192 candidates, totalling 960 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=1,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.912 	0.151 	0.091 	0.708 	0.677 	0.439
[[341  31]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      0.92      0.95       372
        1.0       0.06      0.50      0.11         4

avg / total       0.98      0.91      0.94       376


                estimator min_score mean_score max_score   sd_score  \
3    ExtraTreesClassifier  0.888889   0.990123         1  0.0316204   
4  RandomForestClassifier         1          1         1          0   
6      AdaBoostClassifier  0.555556   0.970269         1  0.0623361   
9    KNeighborsClassifier        -1  -0.263933         1   0.771689   
8        VotingClassifier  0.683856   0.861117  0.906078   0.067989   
1      LogisticRegression   -0.1283    0.24154  0.607122    0.19896   
0              GaussianNB         1          1         1          0   
7                     SVC         0   0.294887  0.683856   0.194324   
5           MLPClassifier    0.1283   0.691235  0.812156   0.177439   
2           SGDClassifier -0.478822   0.138025  0.718234    0.18106   

         acc       auc           conf_matrix     f1_c0      f1_c1       kappa  \
3   0.609043  0.802419  [[225, 147], [0, 4]]  0.753769  0.0516129   0.0315391   
4   0.609043  0.802419  [[225, 147], [0, 4]]  0.753769  0.0516129   0.0315391   
6   0.609043  0.802419  [[225, 147], [0, 4]]  0.753769  0.0516129   0.0315391   
9   0.912234  0.708333   [[341, 31], [2, 2]]  0.953846   0.108108   0.0908558   
8   0.481383  0.614247  [[178, 194], [1, 3]]  0.646098  0.0298507  0.00918919   
1   0.529255  0.514785  [[197, 175], [2, 2]]  0.690018  0.0220994  0.00132053   
0   0.989362       0.5    [[372, 0], [4, 0]]  0.994652          0           0   
7  0.0106383       0.5    [[0, 372], [0, 4]]         0  0.0210526           0   
5   0.492021  0.248656  [[185, 187], [4, 0]]  0.659537          0  -0.0212742   
2   0.462766  0.233871  [[174, 198], [4, 0]]  0.632727          0  -0.0212995   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
3    0.126579         1  0.0264901  0.604839      1  
4    0.126579         1  0.0264901  0.604839      1  
6    0.126579         1  0.0264901  0.604839      1  
9    0.151073  0.994169  0.0606061  0.916667    0.5  
8   0.0469373  0.994413  0.0152284  0.478495   0.75  
1  0.00607768   0.98995  0.0112994   0.52957    0.5  
0           0  0.989362          0         1      0  
7           0         0  0.0106383         0      1  
5   -0.103145  0.978836          0  0.497312      0  
2   -0.109366  0.977528          0  0.467742      0  
Elapsed time 20.97 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-20 15:01:21.951000 
pca_target: 100 	 poly degree: 2 	 kselect: 80 
Imbalance: SMOTE(k=None, k_neighbors=5, kind='regular', m=None, m_neighbors=10, n_jobs=1,
   out_step=0.5, random_state=None, ratio='auto', svm_estimator=None) 
Extended target (count):  31485 13
('Total : Processed (count): ', (1252L, 24976L), 13)
Final feature (count):  (1252L, 24976L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.1, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.976 	0.178 	0.171 	0.617 	0.496 	0.228
[[366   6]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.98      0.99       372
        1.0       0.14      0.25      0.18         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.001, average=False, class_weight='balanced',
       epsilon=0.1, eta0=0.001, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='squared_hinge', n_iter=5, n_jobs=4,
       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.984 	-0.008 	-0.007 	0.497 	0.000 	0.000
[[370   2]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=8, max_features='auto', max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=0.5, n_estimators=15, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', R...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.984 	-0.008 	-0.007 	0.497 	0.000 	0.000
[[370   2]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 192 candidates, totalling 960 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=4,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.947 	0.306 	0.217 	0.849 	0.844 	0.698
[[353  19]
 [  1   3]]
             precision    recall  f1-score   support

        0.0       1.00      0.95      0.97       372
        1.0       0.14      0.75      0.23         4

avg / total       0.99      0.95      0.96       376


                estimator min_score mean_score max_score     sd_score  \
9    KNeighborsClassifier        -1 -0.0916059  0.916966     0.909868   
1      LogisticRegression  0.210765   0.885378  0.984015     0.173436   
0              GaussianNB         1          1         1            0   
3    ExtraTreesClassifier   0.99885   0.999994         1  8.54841e-05   
4  RandomForestClassifier         1          1         1            0   
5           MLPClassifier  0.979516   0.992954         1   0.00608821   
6      AdaBoostClassifier  0.928738   0.991615         1   0.00642289   
7                     SVC         0   0.886342         1     0.264598   
2           SGDClassifier -0.290433    0.68555   0.99885     0.332149   
8        VotingClassifier  0.951652   0.982591  0.994263    0.0100794   

        acc       auc          conf_matrix     f1_c0     f1_c1       kappa  \
9  0.946809  0.849462  [[353, 19], [1, 3]]  0.972452  0.230769    0.216667   
1  0.976064  0.616935   [[366, 6], [3, 1]]  0.987854  0.181818    0.170588   
0  0.989362       0.5   [[372, 0], [4, 0]]  0.994652         0           0   
3  0.989362       0.5   [[372, 0], [4, 0]]  0.994652         0           0   
4  0.989362       0.5   [[372, 0], [4, 0]]  0.994652         0           0   
5  0.989362       0.5   [[372, 0], [4, 0]]  0.994652         0           0   
6  0.989362       0.5   [[372, 0], [4, 0]]  0.994652         0           0   
7  0.989362       0.5   [[372, 0], [4, 0]]  0.994652         0           0   
2  0.984043  0.497312   [[370, 2], [4, 0]]  0.991957         0 -0.00714286   
8  0.984043  0.497312   [[370, 2], [4, 0]]  0.991957         0 -0.00714286   

  model_score   prec_c0   prec_c1    rec_c0 rec_c1  
9    0.305505  0.997175  0.136364  0.948925   0.75  
1    0.177507   0.99187  0.142857  0.983871   0.25  
0           0  0.989362         0         1      0  
3           0  0.989362         0         1      0  
4           0  0.989362         0         1      0  
5           0  0.989362         0         1      0  
6           0  0.989362         0         1      0  
7           0  0.989362         0         1      0  
2 -0.00758294  0.989305         0  0.994624      0  
8 -0.00758294  0.989305         0  0.994624      0  
Elapsed time 65.85 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-20 16:07:12.873000 
pca_target: 100 	 poly degree: 2 	 kselect: 80 
Imbalance: None 
Extended target (count):  31485 13
('Total : Processed (count): ', (1252L, 24976L), 13)
Final feature (count):  (1252L, 24976L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.859 	-0.040 	-0.020 	0.434 	0.000 	0.000
[[323  49]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.87      0.92       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.86      0.91       376


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.01, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='sag', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.896 	0.053 	0.030 	0.577 	0.475 	0.211
[[336  36]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.90      0.95       372
        1.0       0.03      0.25      0.05         4

avg / total       0.98      0.90      0.94       376


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.1, average=False, class_weight='balanced', epsilon=0.1,
       eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='constant', loss='modified_huber', n_iter=5, n_jobs=4,
       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.822 	-0.047 	-0.020 	0.415 	0.000 	0.000
[[309  63]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.83      0.90       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.82      0.89       376


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=8, max_features='auto', max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=32,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=0.5, n_estimators=50, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.976 	-0.012 	-0.012 	0.493 	0.000 	0.000
[[367   5]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.01, cache_size=200, class_weight={1: 500}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.261 	0.060 	0.007 	0.626 	0.503 	0.272
[[ 94 278]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.25      0.40       372
        1.0       0.01      1.00      0.03         4

avg / total       0.99      0.26      0.40       376


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 192 candidates, totalling 960 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=1,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


                estimator  min_score   mean_score  max_score     sd_score  \
7                     SVC -0.0158283  -0.00525815  0.0655476    0.0113752   
1      LogisticRegression  -0.144673    -0.011662  0.0485082    0.0156395   
3    ExtraTreesClassifier -0.0109826 -0.000356484          0   0.00138482   
4  RandomForestClassifier -0.0034575 -6.35908e-05          0  0.000341667   
5           MLPClassifier -0.0116879  -0.00545146          0   0.00316613   
8        VotingClassifier -0.0044048  -0.00100668          0   0.00138586   
9    KNeighborsClassifier         -1    -0.501235          0     0.498773   
6      AdaBoostClassifier -0.0197484    0.0139337   0.211007    0.0397569   
0              GaussianNB  0.0829419    0.0829419  0.0829419            0   
2           SGDClassifier  -0.167371  -0.00772273   0.130011    0.0268996   

        acc       auc          conf_matrix     f1_c0      f1_c1       kappa  \
7  0.260638  0.626344  [[94, 278], [0, 4]]  0.403433   0.027972  0.00714286   
1  0.896277  0.576613  [[336, 36], [3, 1]]  0.945148  0.0487805   0.0301587   
3  0.989362       0.5   [[372, 0], [4, 0]]  0.994652          0           0   
4  0.989362       0.5   [[372, 0], [4, 0]]  0.994652          0           0   
5  0.989362       0.5   [[372, 0], [4, 0]]  0.994652          0           0   
8  0.989362       0.5   [[372, 0], [4, 0]]  0.994652          0           0   
9  0.989362       0.5   [[372, 0], [4, 0]]  0.994652          0           0   
6  0.976064   0.49328   [[367, 5], [4, 0]]  0.987887          0  -0.0119617   
0  0.859043   0.43414  [[323, 49], [4, 0]]  0.924177          0  -0.0200655   
2  0.821809  0.415323  [[309, 63], [4, 0]]   0.90219          0  -0.0204148   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
7   0.0598684         1  0.0141844  0.252688      1  
1   0.0527755   0.99115   0.027027  0.903226   0.25  
3           0  0.989362          0         1      0  
4           0  0.989362          0         1      0  
5           0  0.989362          0         1      0  
8           0  0.989362          0         1      0  
9           0  0.989362          0         1      0  
6  -0.0120381  0.989218          0  0.986559      0  
0  -0.0401405  0.987768          0   0.86828      0  
2  -0.0465218   0.98722          0  0.830645      0  
Elapsed time 33.77 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-20 16:40:58.956000 
pca_target: 100 	 poly degree: 2 	 kselect: 40 
Imbalance: ClusterCentroids(estimator=None, n_jobs=1, random_state=None, ratio='auto') 
Extended target (count):  31485 13
('Total : Processed (count): ', (1252L, 24976L), 13)
Final feature (count):  (1252L, 24976L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.011 	0.000 	0.000 	0.500 	0.000 	0.000
[[  0 372]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       0.00      0.00      0.00       372
        1.0       0.01      1.00      0.02         4

avg / total       0.00      0.01      0.00       376


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.001, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=0.01, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='sag', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.511 	0.104 	0.021 	0.753 	0.711 	0.530
[[188 184]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.51      0.67       372
        1.0       0.02      1.00      0.04         4

avg / total       0.99      0.51      0.66       376


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.5, average=False, class_weight='balanced', epsilon=0.1,
       eta0=0.001, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='perceptron', n_iter=5, n_jobs=4,
       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.824 	0.022 	0.010 	0.540 	0.456 	0.196
[[309  63]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.83      0.90       372
        1.0       0.02      0.25      0.03         4

avg / total       0.98      0.82      0.89       376


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=8, max_features='auto', max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.609 	0.127 	0.032 	0.802 	0.778 	0.629
[[225 147]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.60      0.75       372
        1.0       0.03      1.00      0.05         4

avg / total       0.99      0.61      0.75       376


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.609 	0.127 	0.032 	0.802 	0.778 	0.629
[[225 147]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.60      0.75       372
        1.0       0.03      1.00      0.05         4

avg / total       0.99      0.61      0.75       376


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.1, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.457 	0.093 	0.017 	0.726 	0.672 	0.476
[[168 204]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.45      0.62       372
        1.0       0.02      1.00      0.04         4

avg / total       0.99      0.46      0.62       376


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=0.5, n_estimators=15, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.609 	0.127 	0.032 	0.802 	0.778 	0.629
[[225 147]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.60      0.75       372
        1.0       0.03      1.00      0.05         4

avg / total       0.99      0.61      0.75       376


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.011 	0.000 	0.000 	0.500 	0.000 	0.000
[[  0 372]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       0.00      0.00      0.00       372
        1.0       0.01      1.00      0.02         4

avg / total       0.00      0.01      0.00       376


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.521 	0.106 	0.022 	0.758 	0.718 	0.541
[[192 180]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.52      0.68       372
        1.0       0.02      1.00      0.04         4

avg / total       0.99      0.52      0.67       376


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 192 candidates, totalling 960 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=1,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.915 	-0.029 	-0.019 	0.462 	0.000 	0.000
[[344  28]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.92      0.96       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.91      0.95       376


                estimator min_score mean_score max_score   sd_score  \
3    ExtraTreesClassifier         1          1         1          0   
4  RandomForestClassifier  0.906078   0.995826         1  0.0193555   
6      AdaBoostClassifier  0.555556   0.955934         1  0.0759091   
8        VotingClassifier  0.555556   0.703429  0.812156  0.0629903   
1      LogisticRegression   -0.1283   0.176463  0.572745   0.193028   
5           MLPClassifier -0.367711   0.346635  0.461633   0.171478   
2           SGDClassifier -0.555556   0.101884  0.701045   0.130276   
0              GaussianNB         1          1         1          0   
7                     SVC         0   0.430518  0.812156   0.302312   
9    KNeighborsClassifier        -1  -0.268109  0.906078   0.779215   

         acc       auc           conf_matrix     f1_c0      f1_c1       kappa  \
3   0.609043  0.802419  [[225, 147], [0, 4]]  0.753769  0.0516129   0.0315391   
4   0.609043  0.802419  [[225, 147], [0, 4]]  0.753769  0.0516129   0.0315391   
6   0.609043  0.802419  [[225, 147], [0, 4]]  0.753769  0.0516129   0.0315391   
8   0.521277  0.758065  [[192, 180], [0, 4]]  0.680851  0.0425532   0.0221914   
1   0.510638  0.752688  [[188, 184], [0, 4]]  0.671429  0.0416667   0.0212766   
5   0.457447  0.725806  [[168, 204], [0, 4]]  0.622222  0.0377358   0.0172202   
2   0.824468  0.540323   [[309, 63], [3, 1]]  0.903509  0.0294118  0.00957854   
0  0.0106383       0.5    [[0, 372], [0, 4]]         0  0.0210526           0   
7  0.0106383       0.5    [[0, 372], [0, 4]]         0  0.0210526           0   
9   0.914894  0.462366   [[344, 28], [4, 0]]  0.955556          0  -0.0189702   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
3    0.126579         1  0.0264901  0.604839      1  
4    0.126579         1  0.0264901  0.604839      1  
6    0.126579         1  0.0264901  0.604839      1  
8    0.105925         1  0.0217391  0.516129      1  
1    0.103695         1  0.0212766  0.505376      1  
5   0.0931926         1  0.0192308  0.451613      1  
2   0.0220147  0.990385   0.015625  0.830645   0.25  
0           0         0  0.0106383         0      1  
7           0         0  0.0106383         0      1  
9  -0.0294136  0.988506          0  0.924731      0  
Elapsed time 20.25 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-20 17:01:13.836000 
pca_target: 100 	 poly degree: 2 	 kselect: 40 
Imbalance: SMOTE(k=None, k_neighbors=5, kind='regular', m=None, m_neighbors=10, n_jobs=1,
   out_step=0.5, random_state=None, ratio='auto', svm_estimator=None) 
Extended target (count):  31485 13
('Total : Processed (count): ', (1252L, 24976L), 13)
Final feature (count):  (1252L, 24976L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=10, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='sag', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.981 	0.214 	0.213 	0.620 	0.497 	0.229
[[368   4]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       372
        1.0       0.20      0.25      0.22         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.001, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.001, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='modified_huber', n_iter=5, n_jobs=4,
       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=8, max_features='auto', max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=0.5, n_estimators=50, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.1, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=1.0, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', R...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	-0.005 	-0.004 	0.499 	0.000 	0.000
[[371   1]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 192 candidates, totalling 960 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=2,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.947 	0.098 	0.075 	0.602 	0.488 	0.222
[[355  17]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.95      0.97       372
        1.0       0.06      0.25      0.09         4

avg / total       0.98      0.95      0.96       376


                estimator  min_score mean_score max_score     sd_score  \
1      LogisticRegression  0.0904529   0.878345  0.986283      0.19473   
9    KNeighborsClassifier         -1 -0.0893531   0.91802      0.91216   
0              GaussianNB          1          1         1            0   
2           SGDClassifier -0.0429438   0.688379  0.997706     0.329818   
3    ExtraTreesClassifier     0.9977   0.999994         1  0.000121062   
4  RandomForestClassifier    0.99885    0.99992         1  0.000292367   
5           MLPClassifier   0.979485   0.992546         1   0.00575742   
6      AdaBoostClassifier   0.903687   0.991754         1   0.00692427   
7                     SVC          0   0.884925         1     0.264128   
8        VotingClassifier   0.957129   0.984196  0.995406   0.00913826   

        acc       auc          conf_matrix     f1_c0      f1_c1      kappa  \
1  0.981383  0.619624   [[368, 4], [3, 1]]  0.990579   0.222222   0.212919   
9  0.946809  0.602151  [[355, 17], [3, 1]]  0.972603  0.0909091  0.0748031   
0  0.989362       0.5   [[372, 0], [4, 0]]  0.994652          0          0   
2  0.989362       0.5   [[372, 0], [4, 0]]  0.994652          0          0   
3  0.989362       0.5   [[372, 0], [4, 0]]  0.994652          0          0   
4  0.989362       0.5   [[372, 0], [4, 0]]  0.994652          0          0   
5  0.989362       0.5   [[372, 0], [4, 0]]  0.994652          0          0   
6  0.989362       0.5   [[372, 0], [4, 0]]  0.994652          0          0   
7  0.989362       0.5   [[372, 0], [4, 0]]  0.994652          0          0   
8  0.986702  0.498656   [[371, 1], [4, 0]]  0.993307          0 -0.0042735   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
1    0.214278  0.991914        0.2  0.989247   0.25  
9   0.0981735   0.99162  0.0555556  0.954301   0.25  
0           0  0.989362          0         1      0  
2           0  0.989362          0         1      0  
3           0  0.989362          0         1      0  
4           0  0.989362          0         1      0  
5           0  0.989362          0         1      0  
6           0  0.989362          0         1      0  
7           0  0.989362          0         1      0  
8  -0.0053548  0.989333          0  0.997312      0  
Elapsed time 54.92 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-20 17:56:08.860000 
pca_target: 100 	 poly degree: 2 	 kselect: 40 
Imbalance: None 
Extended target (count):  31485 13
('Total : Processed (count): ', (1252L, 24976L), 13)
Final feature (count):  (1252L, 24976L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.918 	-0.029 	-0.019 	0.464 	0.000 	0.000
[[345  27]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.93      0.96       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.92      0.95       376


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.01, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=5, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='sag', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.891 	0.130 	0.071 	0.698 	0.669 	0.430
[[333  39]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      0.90      0.94       372
        1.0       0.05      0.50      0.09         4

avg / total       0.98      0.89      0.93       376


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=1, average=False, class_weight={1: 50}, epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='constant', loss='perceptron', n_iter=5, n_jobs=4,
       penalty='l2', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.957 	-0.019 	-0.016 	0.484 	0.000 	0.000
[[360  12]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.97      0.98       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.96      0.97       376


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=8, max_features='auto', max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.981 	-0.009 	-0.009 	0.496 	0.000 	0.000
[[369   3]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 50}, criterion='entropy',
            max_depth=16, max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=2.0, n_estimators=80, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	0.282 	0.279 	0.622 	0.499 	0.230
[[370   2]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       372
        1.0       0.33      0.25      0.29         4

avg / total       0.98      0.99      0.99       376


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.01, cache_size=200, class_weight={1: 500}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.250 	0.058 	0.007 	0.621 	0.492 	0.260
[[ 90 282]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.24      0.39       372
        1.0       0.01      1.00      0.03         4

avg / total       0.99      0.25      0.39       376


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 192 candidates, totalling 960 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=1,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


                estimator   min_score   mean_score  max_score     sd_score  \
1      LogisticRegression    -0.14996   -0.0133894  0.0729044    0.0122647   
6      AdaBoostClassifier  -0.0195238    0.0285105   0.428314    0.0555951   
7                     SVC  -0.0168537  -0.00587518  0.0651584    0.0113878   
3    ExtraTreesClassifier   -0.005767 -0.000150072          0  0.000687023   
4  RandomForestClassifier -0.00277643 -4.94634e-05          0  0.000296897   
8        VotingClassifier -0.00277643 -0.000799453          0   0.00103014   
9    KNeighborsClassifier          -1    -0.501103          0     0.498905   
5           MLPClassifier  -0.0109303  -0.00359187  0.0893663    0.0139106   
2           SGDClassifier    -0.17186  -0.00533783   0.184307    0.0292948   
0              GaussianNB    0.134672     0.134672   0.134672            0   

        acc       auc          conf_matrix     f1_c0      f1_c1       kappa  \
1  0.890957  0.697581  [[333, 39], [2, 2]]  0.942008  0.0888889   0.0708775   
6  0.986702  0.622312   [[370, 2], [3, 1]]  0.993289   0.285714    0.279141   
7      0.25  0.620968  [[90, 282], [0, 4]]   0.38961  0.0275862   0.0067446   
3  0.989362       0.5   [[372, 0], [4, 0]]  0.994652          0           0   
4  0.989362       0.5   [[372, 0], [4, 0]]  0.994652          0           0   
8  0.989362       0.5   [[372, 0], [4, 0]]  0.994652          0           0   
9  0.989362       0.5   [[372, 0], [4, 0]]  0.994652          0           0   
5  0.981383  0.495968   [[369, 3], [4, 0]]  0.990604          0 -0.00920245   
2  0.957447  0.483871  [[360, 12], [4, 0]]  0.978261          0  -0.0162162   
0  0.917553   0.46371  [[345, 27], [4, 0]]  0.957004          0  -0.0188811   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
1    0.130065   0.99403  0.0487805  0.895161    0.5  
6    0.282088  0.991957   0.333333  0.994624   0.25  
7   0.0581697         1   0.013986  0.241935      1  
3           0  0.989362          0         1      0  
4           0  0.989362          0         1      0  
8           0  0.989362          0         1      0  
9           0  0.989362          0         1      0  
5 -0.00929961  0.989276          0  0.991935      0  
2  -0.0188278  0.989011          0  0.967742      0  
0  -0.0288422  0.988539          0  0.927419      0  
Elapsed time 29.53 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-20 18:25:40.811000 
pca_target: 100 	 poly degree: 2 	 kselect: 100 
Imbalance: ClusterCentroids(estimator=None, n_jobs=1, random_state=None, ratio='auto') 
Extended target (count):  31485 13
('Total : Processed (count): ', (1252L, 24976L), 13)
Final feature (count):  (1252L, 24976L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.001, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.449 	-0.061 	-0.012 	0.351 	0.336 	0.111
[[168 204]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.98      0.45      0.62       372
        1.0       0.00      0.25      0.01         4

avg / total       0.97      0.45      0.61       376


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.0001, average=False, class_weight='balanced',
       epsilon=0.1, eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='constant', loss='perceptron', n_iter=5, n_jobs=4,
       penalty='l1', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.511 	-0.049 	-0.010 	0.382 	0.358 	0.125
[[191 181]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.98      0.51      0.67       372
        1.0       0.01      0.25      0.01         4

avg / total       0.97      0.51      0.67       376


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=8, max_features='auto', max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.609 	0.127 	0.032 	0.802 	0.778 	0.629
[[225 147]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.60      0.75       372
        1.0       0.03      1.00      0.05         4

avg / total       0.99      0.61      0.75       376


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.609 	0.127 	0.032 	0.802 	0.778 	0.629
[[225 147]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.60      0.75       372
        1.0       0.03      1.00      0.05         4

avg / total       0.99      0.61      0.75       376


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.481 	-0.105 	-0.021 	0.243 	0.000 	0.000
[[181 191]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.98      0.49      0.65       372
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.48      0.64       376


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=0.5, n_estimators=15, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.609 	0.127 	0.032 	0.802 	0.778 	0.629
[[225 147]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.60      0.75       372
        1.0       0.03      1.00      0.05         4

avg / total       0.99      0.61      0.75       376


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=10, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.011 	0.000 	0.000 	0.500 	0.000 	0.000
[[  0 372]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       0.00      0.00      0.00       372
        1.0       0.01      1.00      0.02         4

avg / total       0.00      0.01      0.00       376


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.426 	-0.067 	-0.012 	0.339 	0.327 	0.105
[[159 213]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.98      0.43      0.60       372
        1.0       0.00      0.25      0.01         4

avg / total       0.97      0.43      0.59       376


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 192 candidates, totalling 960 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=1,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.904 	0.058 	0.034 	0.581 	0.477 	0.213
[[339  33]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.91      0.95       372
        1.0       0.03      0.25      0.05         4

avg / total       0.98      0.90      0.94       376


                estimator min_score mean_score max_score   sd_score  \
3    ExtraTreesClassifier  0.906078   0.924601         1  0.0373718   
4  RandomForestClassifier         1          1         1          0   
6      AdaBoostClassifier  0.538367   0.963293         1  0.0708127   
9    KNeighborsClassifier        -1   -0.37963  0.906078   0.677186   
0              GaussianNB         1          1         1          0   
7                     SVC         0   0.346022  0.812156   0.233901   
2           SGDClassifier -0.350522   0.187063  0.812156   0.214699   
1      LogisticRegression   -0.2566   0.193272  0.350522   0.154947   
8        VotingClassifier  0.624311   0.823461         1   0.126668   
5           MLPClassifier  0.367711   0.422731  0.701045  0.0625325   

         acc       auc           conf_matrix     f1_c0       f1_c1      kappa  \
3   0.609043  0.802419  [[225, 147], [0, 4]]  0.753769   0.0516129  0.0315391   
4   0.609043  0.802419  [[225, 147], [0, 4]]  0.753769   0.0516129  0.0315391   
6   0.609043  0.802419  [[225, 147], [0, 4]]  0.753769   0.0516129  0.0315391   
9   0.904255  0.580645   [[339, 33], [3, 1]]   0.94958   0.0526316  0.0342466   
0   0.989362       0.5    [[372, 0], [4, 0]]  0.994652           0          0   
7  0.0106383       0.5    [[0, 372], [0, 4]]         0   0.0210526          0   
2   0.510638   0.38172  [[191, 181], [3, 1]]  0.674912   0.0107527 -0.0102804   
1   0.449468  0.350806  [[168, 204], [3, 1]]  0.618785  0.00956938 -0.0115409   
8   0.425532   0.33871  [[159, 213], [3, 1]]  0.595506  0.00917431 -0.0119617   
5   0.481383   0.24328  [[181, 191], [4, 0]]   0.64991           0 -0.0212837   

  model_score   prec_c0     prec_c1    rec_c0 rec_c1  
3    0.126579         1   0.0264901  0.604839      1  
4    0.126579         1   0.0264901  0.604839      1  
6    0.126579         1   0.0264901  0.604839      1  
9   0.0576975  0.991228   0.0294118   0.91129   0.25  
0           0  0.989362           0         1      0  
7           0         0   0.0106383         0      1  
2  -0.0485629  0.984536  0.00549451  0.513441   0.25  
1  -0.0614761  0.982456  0.00487805  0.451613   0.25  
8  -0.0668306  0.981481   0.0046729  0.427419   0.25  
5   -0.105363  0.978378           0  0.486559      0  
Elapsed time 21.61 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-20 18:47:17.595000 
pca_target: 100 	 poly degree: 2 	 kselect: 100 
Imbalance: SMOTE(k=None, k_neighbors=5, kind='regular', m=None, m_neighbors=10, n_jobs=1,
   out_step=0.5, random_state=None, ratio='auto', svm_estimator=None) 
Extended target (count):  31485 13
('Total : Processed (count): ', (1252L, 24976L), 13)
Final feature (count):  (1252L, 24976L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=1, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='sag', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.976 	0.178 	0.171 	0.617 	0.496 	0.228
[[366   6]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.98      0.99       372
        1.0       0.14      0.25      0.18         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.001, average=False, class_weight='balanced',
       epsilon=0.1, eta0=0.001, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='modified_huber', n_iter=5, n_jobs=4,
       penalty='l2', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	-0.005 	-0.004 	0.499 	0.000 	0.000
[[371   1]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=8, max_features='auto', max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=30, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=0.5, n_estimators=15, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', R...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	-0.005 	-0.004 	0.499 	0.000 	0.000
[[371   1]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 192 candidates, totalling 960 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=4,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.944 	0.298 	0.208 	0.848 	0.842 	0.696
[[352  20]
 [  1   3]]
             precision    recall  f1-score   support

        0.0       1.00      0.95      0.97       372
        1.0       0.13      0.75      0.22         4

avg / total       0.99      0.94      0.96       376


                estimator min_score mean_score max_score     sd_score  \
9    KNeighborsClassifier        -1 -0.0915878  0.911749     0.909855   
1      LogisticRegression  0.392862   0.890226  0.986289      0.15562   
0              GaussianNB         1          1         1            0   
3    ExtraTreesClassifier    0.9977   0.999981         1  0.000170372   
4  RandomForestClassifier         1          1         1            0   
5           MLPClassifier  0.981734   0.992353         1   0.00605193   
6      AdaBoostClassifier  0.934739   0.992369         1    0.0060665   
7                     SVC         0   0.886788         1     0.266271   
2           SGDClassifier -0.216823   0.684882   0.99885      0.33263   
8        VotingClassifier  0.951613    0.98318  0.994263   0.00953014   

        acc       auc          conf_matrix     f1_c0     f1_c1      kappa  \
9  0.944149  0.848118  [[352, 20], [1, 3]]  0.971034  0.222222   0.207865   
1  0.976064  0.616935   [[366, 6], [3, 1]]  0.987854  0.181818   0.170588   
0  0.989362       0.5   [[372, 0], [4, 0]]  0.994652         0          0   
3  0.989362       0.5   [[372, 0], [4, 0]]  0.994652         0          0   
4  0.989362       0.5   [[372, 0], [4, 0]]  0.994652         0          0   
5  0.989362       0.5   [[372, 0], [4, 0]]  0.994652         0          0   
6  0.989362       0.5   [[372, 0], [4, 0]]  0.994652         0          0   
7  0.989362       0.5   [[372, 0], [4, 0]]  0.994652         0          0   
2  0.986702  0.498656   [[371, 1], [4, 0]]  0.993307         0 -0.0042735   
8  0.986702  0.498656   [[371, 1], [4, 0]]  0.993307         0 -0.0042735   

  model_score   prec_c0   prec_c1    rec_c0 rec_c1  
9    0.298062  0.997167  0.130435  0.946237   0.75  
1    0.177507   0.99187  0.142857  0.983871   0.25  
0           0  0.989362         0         1      0  
3           0  0.989362         0         1      0  
4           0  0.989362         0         1      0  
5           0  0.989362         0         1      0  
6           0  0.989362         0         1      0  
7           0  0.989362         0         1      0  
2  -0.0053548  0.989333         0  0.997312      0  
8  -0.0053548  0.989333         0  0.997312      0  
Elapsed time 72.36 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-20 19:59:39.401000 
pca_target: 100 	 poly degree: 2 	 kselect: 100 
Imbalance: None 
Extended target (count):  31485 13
('Total : Processed (count): ', (1252L, 24976L), 13)
Final feature (count):  (1252L, 24976L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.843 	-0.043 	-0.020 	0.426 	0.000 	0.000
[[317  55]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.85      0.91       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.84      0.91       376


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.001, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=0.01, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.867 	0.038 	0.019 	0.562 	0.467 	0.205
[[325  47]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.87      0.93       372
        1.0       0.02      0.25      0.04         4

avg / total       0.98      0.87      0.92       376


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=1, average=False, class_weight={1: 15}, epsilon=0.1,
       eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='invscaling', loss='squared_hinge', n_iter=5,
       n_jobs=4, penalty='l2', power_t=0.5, random_state=None,
       shuffle=True, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	-0.005 	-0.004 	0.499 	0.000 	0.000
[[371   1]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 500}, criterion='gini',
           max_depth=8, max_features='auto', max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=50, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.981 	-0.009 	-0.009 	0.496 	0.000 	0.000
[[369   3]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=30, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(500,), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=32,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=0.5, n_estimators=80, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.965 	-0.016 	-0.015 	0.488 	0.000 	0.000
[[363   9]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.98      0.98       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.97      0.97       376


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.01, cache_size=200, class_weight={1: 500}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.258 	0.059 	0.007 	0.625 	0.500 	0.269
[[ 93 279]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.25      0.40       372
        1.0       0.01      1.00      0.03         4

avg / total       0.99      0.26      0.40       376


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 192 candidates, totalling 960 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=1,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.984 	-0.008 	-0.007 	0.497 	0.000 	0.000
[[370   2]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       372
        1.0       0.00      0.00      0.00         4

avg / total       0.98      0.98      0.98       376


                estimator  min_score   mean_score  max_score     sd_score  \
7                     SVC  -0.016769  -0.00521915   0.065161    0.0112862   
1      LogisticRegression  -0.106882  -0.00890911  0.0867195    0.0179971   
4  RandomForestClassifier -0.0034575 -6.04015e-05          0  0.000351932   
5           MLPClassifier -0.0100312  -0.00582432          0   0.00288828   
8        VotingClassifier -0.0044048  -0.00083021          0   0.00107904   
2           SGDClassifier  -0.160651  -0.00411257   0.183639    0.0297602   
9    KNeighborsClassifier         -1    -0.497572   0.104765     0.502764   
3    ExtraTreesClassifier -0.0114403  0.000473037   0.133351   0.00886274   
6      AdaBoostClassifier -0.0176557   0.00271306   0.188816    0.0340609   
0              GaussianNB  0.0741087    0.0741087  0.0741087            0   

        acc       auc          conf_matrix     f1_c0      f1_c1       kappa  \
7  0.257979     0.625  [[93, 279], [0, 4]]       0.4  0.0278746  0.00704225   
1  0.867021  0.561828  [[325, 47], [3, 1]]  0.928571  0.0384615   0.0191987   
4  0.989362       0.5   [[372, 0], [4, 0]]  0.994652          0           0   
5  0.989362       0.5   [[372, 0], [4, 0]]  0.994652          0           0   
8  0.989362       0.5   [[372, 0], [4, 0]]  0.994652          0           0   
2  0.986702  0.498656   [[371, 1], [4, 0]]  0.993307          0  -0.0042735   
9  0.984043  0.497312   [[370, 2], [4, 0]]  0.991957          0 -0.00714286   
3  0.981383  0.495968   [[369, 3], [4, 0]]  0.990604          0 -0.00920245   
6  0.965426  0.487903   [[363, 9], [4, 0]]  0.982409          0  -0.0149502   
0  0.843085  0.426075  [[317, 55], [4, 0]]  0.914863          0  -0.0202355   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
7   0.0594438         1  0.0141343      0.25      1  
1   0.0380153  0.990854  0.0208333  0.873656   0.25  
4           0  0.989362          0         1      0  
5           0  0.989362          0         1      0  
8           0  0.989362          0         1      0  
2  -0.0053548  0.989333          0  0.997312      0  
9 -0.00758294  0.989305          0  0.994624      0  
3 -0.00929961  0.989276          0  0.991935      0  
6  -0.0162385  0.989101          0  0.975806      0  
0  -0.0429227  0.987539          0  0.852151      0  
Elapsed time 36.19 mins 

************************************************************





