


 X = pd.read_csv("features/X_y_feats_ts500x25_pp25-0_cid2.csv", sep=';')
StandardScaler, lagged (3,4)x1

    pca = [0, 100]
    poly = [0, 2]
    ksel = [40, 80, 100]
    imb = [ClusterCentroids(), SMOTE(), None]
	

pre/post: 25/0  win/stride: 500/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-21 22:45:34.841000 
pca_target: 0 	 poly degree: 0 	 kselect: 40 
Imbalance: ClusterCentroids(estimator=None, n_jobs=1, random_state=None, ratio='auto') 
Extended target (count):  25141 13
('Total : Processed (count): ', (986L, 222L), 13)
Final feature (count):  (986L, 222L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.530 	0.064 	0.016 	0.639 	0.629 	0.404
[[154 138]
 [  1   3]]
             precision    recall  f1-score   support

        0.0       0.99      0.53      0.69       292
        1.0       0.02      0.75      0.04         4

avg / total       0.98      0.53      0.68       296


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=5, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.743 	-0.066 	-0.026 	0.377 	0.000 	0.000
[[220  72]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.98      0.75      0.85       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.74      0.84       296


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.0001, average=False, class_weight={1: 500}, epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='constant', loss='squared_hinge', n_iter=5, n_jobs=4,
       penalty='l1', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.361 	-0.034 	-0.006 	0.430 	0.424 	0.182
[[105 187]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.98      0.36      0.53       292
        1.0       0.01      0.50      0.02         4

avg / total       0.97      0.36      0.52       296


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3},
           criterion='entropy', max_depth=32, max_features=0.75,
           max_leaf_nodes=None, min_impurity_split=1e-07,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=4,
           oob_score=False, random_state=None, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.507 	0.059 	0.014 	0.627 	0.614 	0.387
[[147 145]
 [  1   3]]
             precision    recall  f1-score   support

        0.0       0.99      0.50      0.67       292
        1.0       0.02      0.75      0.04         4

avg / total       0.98      0.51      0.66       296


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight='balanced',
            criterion='gini', max_depth=32, max_features=0.33,
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.443 	-0.014 	-0.003 	0.471 	0.470 	0.222
[[129 163]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.98      0.44      0.61       292
        1.0       0.01      0.50      0.02         4

avg / total       0.97      0.44      0.60       296


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.01, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.726 	-0.069 	-0.026 	0.368 	0.000 	0.000
[[215  77]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.98      0.74      0.84       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.73      0.83       296


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight='balanced', criterion='entropy',
            max_depth=4, max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=1.0, n_estimators=80, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.463 	-0.066 	-0.014 	0.358 	0.341 	0.114
[[136 156]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.98      0.47      0.63       292
        1.0       0.01      0.25      0.01         4

avg / total       0.97      0.46      0.62       296


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='linear',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.679 	0.045 	0.015 	0.591 	0.584 	0.335
[[199  93]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      0.68      0.81       292
        1.0       0.02      0.50      0.04         4

avg / total       0.98      0.68      0.80       296


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=1.0, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', R...owski',
           metric_params=None, n_jobs=4, n_neighbors=4, p=2,
           weights='uniform'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.669 	-0.080 	-0.027 	0.339 	0.000 	0.000
[[198  94]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.98      0.68      0.80       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.67      0.79       296


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=3, p=1,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.831 	-0.050 	-0.025 	0.421 	0.000 	0.000
[[246  46]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.98      0.84      0.91       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.83      0.90       296


                estimator min_score mean_score max_score   sd_score       acc  \
0              GaussianNB  0.812156   0.812156  0.812156          0  0.530405   
3    ExtraTreesClassifier  0.350522   0.747477         1  0.0911116  0.506757   
7                     SVC -0.239411  0.0798344  0.367711   0.148914  0.679054   
4  RandomForestClassifier  0.222222   0.661723         1   0.118118  0.442568   
2           SGDClassifier -0.367711   0.137661    0.5132    0.13681  0.361486   
9    KNeighborsClassifier         0   0.166386  0.478822   0.159094  0.831081   
1      LogisticRegression -0.496011   0.213455  0.607122   0.207685  0.743243   
5           MLPClassifier   -0.1283   0.371828  0.683856   0.263151  0.726351   
6      AdaBoostClassifier -0.111111   0.609953         1   0.201209  0.462838   
8        VotingClassifier -0.222222   0.202204  0.683856   0.170525  0.668919   

        auc           conf_matrix     f1_c0      f1_c1       kappa  \
0  0.638699  [[154, 138], [1, 3]]  0.689038  0.0413793   0.0155054   
3  0.626712  [[147, 145], [1, 3]]  0.668182  0.0394737   0.0135135   
7  0.590753   [[199, 93], [2, 2]]  0.807302   0.040404   0.0148543   
4   0.47089  [[129, 163], [2, 2]]  0.609929  0.0236686 -0.00279238   
2  0.429795  [[105, 187], [2, 2]]  0.526316  0.0207254 -0.00589758   
9  0.421233   [[246, 46], [4, 0]]  0.907749          0  -0.0254989   
1  0.376712   [[220, 72], [4, 0]]  0.852713          0  -0.0262774   
5  0.368151   [[215, 77], [4, 0]]  0.841487          0  -0.0263699   
6  0.357877  [[136, 156], [3, 1]]   0.63109  0.0124224  -0.0143103   
8  0.339041   [[198, 94], [4, 0]]  0.801619          0  -0.0266138   

  model_score   prec_c0     prec_c1    rec_c0 rec_c1  
0   0.0641281  0.993548   0.0212766  0.527397   0.75  
3   0.0585206  0.993243   0.0202703  0.503425   0.75  
7   0.0448905   0.99005   0.0210526  0.681507    0.5  
4  -0.0135335  0.984733   0.0121212  0.441781    0.5  
2  -0.0337442  0.981308    0.010582  0.359589    0.5  
9  -0.0502051     0.984           0  0.842466      0  
1  -0.0663561  0.982143           0  0.753425      0  
5  -0.0694004  0.981735           0  0.736301      0  
6  -0.0657596  0.978417  0.00636943  0.465753   0.25  
8  -0.0798412  0.980198           0  0.678082      0  
Elapsed time 14.48 mins 

************************************************************

pre/post: 25/0  win/stride: 500/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-21 23:00:03.599000 
pca_target: 0 	 poly degree: 0 	 kselect: 40 
Imbalance: SMOTE(k=None, k_neighbors=5, kind='regular', m=None, m_neighbors=10, n_jobs=1,
   out_step=0.5, random_state=None, ratio='auto', svm_estimator=None) 
Extended target (count):  25141 13
('Total : Processed (count): ', (986L, 222L), 13)
Final feature (count):  (986L, 222L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.791 	0.014 	0.006 	0.524 	0.447 	0.189
[[233  59]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.80      0.88       292
        1.0       0.02      0.25      0.03         4

avg / total       0.97      0.79      0.87       296


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=10, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.828 	-0.051 	-0.026 	0.420 	0.000 	0.000
[[245  47]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.98      0.84      0.91       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.83      0.89       296


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.001, average=False, class_weight='balanced',
       epsilon=0.1, eta0=0.001, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='modified_huber', n_iter=5, n_jobs=4,
       penalty='l1', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.872 	0.046 	0.026 	0.565 	0.469 	0.206
[[257  35]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.88      0.93       292
        1.0       0.03      0.25      0.05         4

avg / total       0.98      0.87      0.92       296


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 15}, criterion='gini',
           max_depth=None, max_features='auto', max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=30, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight='balanced',
            criterion='entropy', max_depth=None, max_features='auto',
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.983 	-0.007 	-0.005 	0.498 	0.000 	0.000
[[291   1]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.98       296


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.01, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.976 	-0.012 	-0.012 	0.495 	0.000 	0.000
[[289   3]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.97       296


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='entropy', max_depth=8,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=1.0, n_estimators=80, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.980 	-0.010 	-0.009 	0.497 	0.000 	0.000
[[290   2]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.98       296


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=10, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.976 	-0.012 	-0.012 	0.495 	0.000 	0.000
[[289   3]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.97       296


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=10.0, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', ...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.953 	-0.022 	-0.020 	0.483 	0.000 	0.000
[[282  10]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.97      0.98       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.95      0.96       296


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.929 	-0.029 	-0.022 	0.471 	0.000 	0.000
[[275  17]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.94      0.96       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.93      0.95       296


                estimator  min_score mean_score max_score    sd_score  \
2           SGDClassifier -0.0968819   0.544287  0.850455    0.232784   
0              GaussianNB    0.73498    0.73498   0.73498           0   
3    ExtraTreesClassifier   0.608789   0.957057         1   0.0683978   
4  RandomForestClassifier   0.937224     0.9782  0.992716    0.012371   
6      AdaBoostClassifier   0.850349   0.968104  0.995621   0.0223479   
5           MLPClassifier   0.961189   0.973004  0.986906  0.00650686   
7                     SVC          0   0.770909  0.994169    0.272134   
8        VotingClassifier   0.883668   0.927799  0.956981   0.0167553   
9    KNeighborsClassifier   0.860087   0.900082  0.938896   0.0268133   
1      LogisticRegression    0.02109   0.683495  0.831959    0.163469   

        acc       auc          conf_matrix     f1_c0    f1_c1       kappa  \
2  0.871622  0.565068  [[257, 35], [3, 1]]  0.931159     0.05   0.0263158   
0  0.790541  0.523973  [[233, 59], [3, 1]]  0.882576  0.03125  0.00606586   
3  0.986486       0.5   [[292, 0], [4, 0]]  0.993197        0           0   
4  0.983108  0.498288   [[291, 1], [4, 0]]  0.991482        0 -0.00543478   
6   0.97973  0.496575   [[290, 2], [4, 0]]  0.989761        0 -0.00909091   
5  0.976351  0.494863   [[289, 3], [4, 0]]  0.988034        0  -0.0117188   
7  0.976351  0.494863   [[289, 3], [4, 0]]  0.988034        0  -0.0117188   
8  0.952703  0.482877  [[282, 10], [4, 0]]  0.975779        0   -0.019685   
9  0.929054   0.47089  [[275, 17], [4, 0]]  0.963222        0  -0.0223684   
1  0.827703  0.419521  [[245, 47], [4, 0]]   0.90573        0  -0.0255435   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
2    0.045971  0.988462  0.0277778  0.880137   0.25  
0     0.01377  0.987288  0.0166667  0.797945   0.25  
3           0  0.986486          0         1      0  
4  -0.0068144  0.986441          0  0.996575      0  
6 -0.00965339  0.986395          0  0.993151      0  
5  -0.0118431  0.986348          0  0.989726      0  
7  -0.0118431  0.986348          0  0.989726      0  
8  -0.0218855  0.986014          0  0.965753      0  
9  -0.0288909  0.985663          0  0.941781      0  
1  -0.0508496  0.983936          0  0.839041      0  
Elapsed time 34.05 mins 

************************************************************

pre/post: 25/0  win/stride: 500/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-21 23:34:06.641000 
pca_target: 0 	 poly degree: 0 	 kselect: 40 
Imbalance: None 
Extended target (count):  25141 13
('Total : Processed (count): ', (986L, 222L), 13)
Final feature (count):  (986L, 222L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.618 	0.087 	0.025 	0.683 	0.680 	0.469
[[180 112]
 [  1   3]]
             precision    recall  f1-score   support

        0.0       0.99      0.62      0.76       292
        1.0       0.03      0.75      0.05         4

avg / total       0.98      0.62      0.75       296


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.1, class_weight={1: 50}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='sag', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.764 	-0.063 	-0.026 	0.387 	0.000 	0.000
[[226  66]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.98      0.77      0.87       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.76      0.85       296


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.1, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='constant', loss='squared_hinge', n_iter=5, n_jobs=4,
       penalty='l2', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.956 	-0.021 	-0.019 	0.485 	0.000 	0.000
[[283   9]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.97      0.98       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.96      0.96       296


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 500}, criterion='gini',
           max_depth=16, max_features=0.33, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=50, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.973 	-0.014 	-0.014 	0.493 	0.000 	0.000
[[288   4]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.97      0.97       296


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 500},
            criterion='gini', max_depth=None, max_features=0.33,
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=15, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.983 	-0.007 	-0.005 	0.498 	0.000 	0.000
[[291   1]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.98       296


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 500}, criterion='gini', max_depth=32,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=0.5, n_estimators=80, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.966 	-0.017 	-0.016 	0.490 	0.000 	0.000
[[286   6]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.98      0.98       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.97      0.97       296


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.1, cache_size=200, class_weight='balanced', coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.736 	-0.068 	-0.026 	0.373 	0.000 	0.000
[[218  74]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.98      0.75      0.85       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.74      0.84       296


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', R...owski',
           metric_params=None, n_jobs=4, n_neighbors=4, p=2,
           weights='uniform'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.983 	-0.007 	-0.005 	0.498 	0.000 	0.000
[[291   1]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.98       296


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=1,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


                estimator   min_score  mean_score   max_score    sd_score  \
0              GaussianNB     0.12285     0.12285     0.12285           0   
4  RandomForestClassifier -0.00655668  0.00120343    0.141929   0.0148445   
9    KNeighborsClassifier   -0.014511 -0.00427194           0  0.00526853   
5           MLPClassifier  -0.0151964  -0.0106434 -0.00708559  0.00238262   
8        VotingClassifier  -0.0143163  0.00194303    0.137785   0.0339871   
3    ExtraTreesClassifier  -0.0145728   0.0110812    0.240459   0.0371851   
6      AdaBoostClassifier  -0.0233649   0.0325682    0.332983   0.0579605   
2           SGDClassifier  -0.0977919   0.0309751     0.16385    0.037799   
1      LogisticRegression  -0.0321281   0.0273288    0.133961   0.0368567   
7                     SVC  -0.0249971  0.00893831    0.103642   0.0263264   

        acc       auc           conf_matrix     f1_c0      f1_c1       kappa  \
0  0.618243  0.683219  [[180, 112], [1, 3]]  0.761099  0.0504202   0.0249534   
4  0.986486       0.5    [[292, 0], [4, 0]]  0.993197          0           0   
9  0.986486       0.5    [[292, 0], [4, 0]]  0.993197          0           0   
5  0.983108  0.498288    [[291, 1], [4, 0]]  0.991482          0 -0.00543478   
8  0.983108  0.498288    [[291, 1], [4, 0]]  0.991482          0 -0.00543478   
3  0.972973  0.493151    [[288, 4], [4, 0]]  0.986301          0  -0.0136986   
6  0.966216  0.489726    [[286, 6], [4, 0]]  0.982818          0  -0.0164835   
2  0.956081  0.484589    [[283, 9], [4, 0]]  0.977547          0  -0.0190678   
1  0.763514  0.386986   [[226, 66], [4, 0]]    0.8659          0   -0.026149   
7  0.736486  0.373288   [[218, 74], [4, 0]]  0.848249          0  -0.0263158   

  model_score   prec_c0   prec_c1    rec_c0 rec_c1  
0   0.0868029  0.994475  0.026087  0.616438   0.75  
4           0  0.986486         0         1      0  
9           0  0.986486         0         1      0  
5  -0.0068144  0.986441         0  0.996575      0  
8  -0.0068144  0.986441         0  0.996575      0  
3  -0.0136986  0.986301         0  0.986301      0  
6  -0.0168351  0.986207         0  0.979452      0  
2  -0.0207262  0.986063         0  0.969178      0  
1   -0.062697  0.982609         0  0.773973      0  
7  -0.0675737  0.981982         0  0.746575      0  
Elapsed time 20.62 mins 

************************************************************

pre/post: 25/0  win/stride: 500/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-21 23:54:43.749000 
pca_target: 0 	 poly degree: 0 	 kselect: 80 
Imbalance: ClusterCentroids(estimator=None, n_jobs=1, random_state=None, ratio='auto') 
Extended target (count):  25141 13
('Total : Processed (count): ', (986L, 222L), 13)
Final feature (count):  (986L, 222L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.530 	0.064 	0.016 	0.639 	0.629 	0.404
[[154 138]
 [  1   3]]
             precision    recall  f1-score   support

        0.0       0.99      0.53      0.69       292
        1.0       0.02      0.75      0.04         4

avg / total       0.98      0.53      0.68       296


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.1, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=5, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.703 	-0.010 	-0.004 	0.479 	0.421 	0.169
[[207  85]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.71      0.82       292
        1.0       0.01      0.25      0.02         4

avg / total       0.97      0.70      0.81       296


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.1, average=False, class_weight={1: 15}, epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='constant', loss='modified_huber', n_iter=5, n_jobs=4,
       penalty='none', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.466 	0.049 	0.010 	0.606 	0.589 	0.357
[[135 157]
 [  1   3]]
             precision    recall  f1-score   support

        0.0       0.99      0.46      0.63       292
        1.0       0.02      0.75      0.04         4

avg / total       0.98      0.47      0.62       296


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=8, max_features=0.75, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.541 	0.010 	0.002 	0.521 	0.520 	0.269
[[158 134]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      0.54      0.70       292
        1.0       0.01      0.50      0.03         4

avg / total       0.97      0.54      0.69       296


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 50}, criterion='gini',
            max_depth=32, max_features=0.33, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=50, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.537 	-0.048 	-0.012 	0.396 	0.368 	0.131
[[158 134]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.98      0.54      0.70       292
        1.0       0.01      0.25      0.01         4

avg / total       0.97      0.54      0.69       296


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.5, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.774 	-0.061 	-0.026 	0.392 	0.000 	0.000
[[229  63]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.98      0.78      0.87       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.77      0.86       296


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=8,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=2.0, n_estimators=15, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.470 	0.050 	0.011 	0.608 	0.591 	0.359
[[136 156]
 [  1   3]]
             precision    recall  f1-score   support

        0.0       0.99      0.47      0.63       292
        1.0       0.02      0.75      0.04         4

avg / total       0.98      0.47      0.63       296


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.1, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='linear',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.679 	-0.016 	-0.005 	0.467 	0.414 	0.164
[[200  92]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.68      0.81       292
        1.0       0.01      0.25      0.02         4

avg / total       0.97      0.68      0.80       296


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...wski',
           metric_params=None, n_jobs=4, n_neighbors=4, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.645 	-0.084 	-0.027 	0.327 	0.000 	0.000
[[191 101]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.98      0.65      0.78       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.65      0.77       296


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=3, p=1,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.757 	0.004 	0.001 	0.507 	0.437 	0.181
[[223  69]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.76      0.86       292
        1.0       0.01      0.25      0.03         4

avg / total       0.97      0.76      0.85       296


                estimator min_score mean_score max_score   sd_score       acc  \
0              GaussianNB         1          1         1          0  0.530405   
6      AdaBoostClassifier -0.239411   0.609983         1   0.184122  0.469595   
2           SGDClassifier -0.589933  0.0769399  0.718234   0.155431  0.466216   
3    ExtraTreesClassifier  0.333333   0.664814  0.906078   0.113903  0.540541   
9    KNeighborsClassifier   -0.2566 -0.0215753  0.239411   0.139505  0.756757   
1      LogisticRegression -0.367711  0.0834853  0.461633   0.167721  0.702703   
7                     SVC -0.273789  0.0198202    0.1283  0.0999239  0.679054   
4  RandomForestClassifier   -0.1283   0.594355  0.906078    0.14039  0.537162   
5           MLPClassifier  0.111111   0.297614  0.461633   0.100433  0.773649   
8        VotingClassifier   -0.1283   0.152164  0.496011    0.11775   0.64527   

        auc           conf_matrix     f1_c0      f1_c1       kappa  \
0  0.638699  [[154, 138], [1, 3]]  0.689038  0.0413793   0.0155054   
6  0.607877  [[136, 156], [1, 3]]  0.634033  0.0368098   0.0107289   
2  0.606164  [[135, 157], [1, 3]]  0.630841  0.0365854   0.0104942   
3  0.520548  [[158, 134], [2, 2]]  0.699115  0.0285714  0.00237906   
9  0.506849   [[223, 69], [3, 1]]  0.861004   0.027027  0.00149925   
1  0.479452   [[207, 85], [3, 1]]  0.824701  0.0222222 -0.00369914   
7  0.467466   [[200, 92], [3, 1]]  0.808081  0.0206186 -0.00543478   
4  0.395548  [[158, 134], [3, 1]]  0.697572  0.0143885  -0.0121805   
5  0.392123   [[229, 63], [4, 0]]  0.872381          0  -0.0260762   
8  0.327055  [[191, 101], [4, 0]]  0.784394          0  -0.0266913   

  model_score   prec_c0     prec_c1    rec_c0 rec_c1  
0   0.0641281  0.993548   0.0212766  0.527397   0.75  
6   0.0499598  0.992701   0.0188679  0.465753   0.75  
2   0.0491927  0.992647     0.01875  0.462329   0.75  
3  0.00952117    0.9875   0.0147059  0.541096    0.5  
9  0.00372216  0.986726   0.0142857  0.763699   0.25  
1  -0.0104511  0.985714   0.0116279  0.708904   0.25  
7  -0.0161846  0.985222   0.0107527  0.684932   0.25  
4  -0.0484271  0.981366  0.00740741  0.541096   0.25  
5  -0.0608599  0.982833           0  0.784247      0  
8  -0.0842329  0.979487           0   0.65411      0  
Elapsed time 15.25 mins 

************************************************************

pre/post: 25/0  win/stride: 500/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-22 00:09:58.987000 
pca_target: 0 	 poly degree: 0 	 kselect: 80 
Imbalance: SMOTE(k=None, k_neighbors=5, kind='regular', m=None, m_neighbors=10, n_jobs=1,
   out_step=0.5, random_state=None, ratio='auto', svm_estimator=None) 
Extended target (count):  25141 13
('Total : Processed (count): ', (986L, 222L), 13)
Final feature (count):  (986L, 222L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.770 	0.008 	0.003 	0.514 	0.441 	0.184
[[227  65]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.78      0.87       292
        1.0       0.02      0.25      0.03         4

avg / total       0.97      0.77      0.86       296


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=10, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.939 	-0.026 	-0.021 	0.476 	0.000 	0.000
[[278  14]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.95      0.97       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.94      0.96       296


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.001, average=False, class_weight='balanced',
       epsilon=0.1, eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='squared_hinge', n_iter=5, n_jobs=4,
       penalty='none', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.946 	-0.024 	-0.021 	0.479 	0.000 	0.000
[[280  12]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.96      0.97       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.95      0.96       296


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 50},
           criterion='entropy', max_depth=None, max_features='auto',
           max_leaf_nodes=None, min_impurity_split=1e-07,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=4,
           oob_score=False, random_state=None, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight='balanced',
            criterion='entropy', max_depth=None, max_features='auto',
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.980 	-0.010 	-0.009 	0.497 	0.000 	0.000
[[290   2]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.98       296


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.01, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.980 	-0.010 	-0.009 	0.497 	0.000 	0.000
[[290   2]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.98       296


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 50}, criterion='gini', max_depth=8,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=1.0, n_estimators=50, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.1, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=10.0, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', ...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.970 	-0.015 	-0.015 	0.491 	0.000 	0.000
[[287   5]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.98      0.98       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.97      0.97       296


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.926 	-0.030 	-0.023 	0.469 	0.000 	0.000
[[274  18]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.94      0.96       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.93      0.95       296


                estimator  min_score mean_score max_score   sd_score  \
0              GaussianNB   0.727181   0.727181  0.727181          0   
3    ExtraTreesClassifier   0.616539   0.960708         1   0.064227   
6      AdaBoostClassifier   0.881052   0.969585  0.998537  0.0197438   
7                     SVC          0   0.790969         1   0.307154   
4  RandomForestClassifier   0.917979   0.976342  0.998537  0.0134628   
5           MLPClassifier   0.949952   0.972873  0.994158  0.0114107   
8        VotingClassifier   0.883845   0.949194  0.973954  0.0200107   
2           SGDClassifier -0.0514852   0.568438  0.945552   0.255515   
1      LogisticRegression  0.0599869    0.74707  0.933303   0.176972   
9    KNeighborsClassifier   0.818375   0.884634  0.943073  0.0381372   

        acc       auc          conf_matrix     f1_c0      f1_c1       kappa  \
0   0.77027  0.513699  [[227, 65], [3, 1]]  0.869732  0.0285714  0.00316957   
3  0.986486       0.5   [[292, 0], [4, 0]]  0.993197          0           0   
6  0.986486       0.5   [[292, 0], [4, 0]]  0.993197          0           0   
7  0.986486       0.5   [[292, 0], [4, 0]]  0.993197          0           0   
4   0.97973  0.496575   [[290, 2], [4, 0]]  0.989761          0 -0.00909091   
5   0.97973  0.496575   [[290, 2], [4, 0]]  0.989761          0 -0.00909091   
8  0.969595  0.491438   [[287, 5], [4, 0]]  0.984563          0  -0.0152439   
2  0.945946  0.479452  [[280, 12], [4, 0]]  0.972222          0  -0.0206897   
1  0.939189  0.476027  [[278, 14], [4, 0]]  0.968641          0  -0.0214724   
9  0.925676  0.469178  [[274, 18], [4, 0]]  0.961404          0  -0.0226131   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
0  0.00759963  0.986957  0.0151515  0.777397   0.25  
3           0  0.986486          0         1      0  
6           0  0.986486          0         1      0  
7           0  0.986486          0         1      0  
4 -0.00965339  0.986395          0  0.993151      0  
5 -0.00965339  0.986395          0  0.993151      0  
8  -0.0153418  0.986254          0  0.982877      0  
2  -0.0240586  0.985915          0  0.958904      0  
1  -0.0260782  0.985816          0  0.952055      0  
9  -0.0297819  0.985612          0  0.938356      0  
Elapsed time 44.65 mins 

************************************************************

pre/post: 25/0  win/stride: 500/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-22 00:54:37.882000 
pca_target: 0 	 poly degree: 0 	 kselect: 80 
Imbalance: None 
Extended target (count):  25141 13
('Total : Processed (count): ', (986L, 222L), 13)
Final feature (count):  (986L, 222L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.652 	0.097 	0.030 	0.700 	0.699 	0.493
[[190 102]
 [  1   3]]
             precision    recall  f1-score   support

        0.0       0.99      0.65      0.79       292
        1.0       0.03      0.75      0.06         4

avg / total       0.98      0.65      0.78       296


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=10, class_weight={1: 15}, dual=False, fit_intercept=True,
          intercept_scaling=0.01, max_iter=100, multi_class='ovr',
          n_jobs=4, penalty='l2', random_state=None, solver='liblinear',
          tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.716 	0.118 	0.042 	0.733 	0.733 	0.539
[[209  83]
 [  1   3]]
             precision    recall  f1-score   support

        0.0       1.00      0.72      0.83       292
        1.0       0.03      0.75      0.07         4

avg / total       0.98      0.72      0.82       296


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=1, average=False, class_weight={1: 50}, epsilon=0.1,
       eta0=0.001, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='modified_huber', n_iter=5, n_jobs=4,
       penalty='none', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.807 	-0.055 	-0.026 	0.409 	0.000 	0.000
[[239  53]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.98      0.82      0.89       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.81      0.88       296


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 500}, criterion='gini',
           max_depth=32, max_features=0.75, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=30, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.970 	-0.015 	-0.015 	0.491 	0.000 	0.000
[[287   5]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.98      0.98       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.97      0.97       296


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 500},
            criterion='entropy', max_depth=None, max_features=0.75,
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=15, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.1, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.970 	-0.015 	-0.015 	0.491 	0.000 	0.000
[[287   5]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.98      0.98       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.97      0.97       296


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight='balanced', criterion='gini',
            max_depth=16, max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=0.5, n_estimators=15, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.5, cache_size=200, class_weight='balanced', coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.943 	-0.025 	-0.021 	0.478 	0.000 	0.000
[[279  13]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.96      0.97       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.94      0.96       296


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=10.0, class_weight={1: 500}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Ra...owski',
           metric_params=None, n_jobs=4, n_neighbors=4, p=2,
           weights='uniform'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=1,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


                estimator   min_score  mean_score  max_score    sd_score  \
1      LogisticRegression  -0.0620714   0.0260338   0.135839    0.035177   
0              GaussianNB   0.0473726   0.0473726  0.0473726           0   
4  RandomForestClassifier -0.00414424  0.00103331   0.141929   0.0128026   
6      AdaBoostClassifier  -0.0211649    0.024159   0.207951   0.0546422   
8        VotingClassifier  -0.0129676  0.00186473   0.141929   0.0280464   
9    KNeighborsClassifier  -0.0190759 -0.00439492          0  0.00733229   
3    ExtraTreesClassifier  -0.0100886   0.0114194   0.141929   0.0342107   
5           MLPClassifier  -0.0151853   0.0126589   0.134253   0.0430673   
7                     SVC   -0.024784   0.0114975  0.0755631   0.0226559   
2           SGDClassifier   -0.117754   0.0230427   0.128308   0.0346458   

        acc       auc           conf_matrix     f1_c0      f1_c1      kappa  \
1  0.716216  0.732877   [[209, 83], [1, 3]]  0.832669  0.0666667  0.0419236   
0  0.652027  0.700342  [[190, 102], [1, 3]]  0.786749  0.0550459  0.0297862   
4  0.986486       0.5    [[292, 0], [4, 0]]  0.993197          0          0   
6  0.986486       0.5    [[292, 0], [4, 0]]  0.993197          0          0   
8  0.986486       0.5    [[292, 0], [4, 0]]  0.993197          0          0   
9  0.986486       0.5    [[292, 0], [4, 0]]  0.993197          0          0   
3  0.969595  0.491438    [[287, 5], [4, 0]]  0.984563          0 -0.0152439   
5  0.969595  0.491438    [[287, 5], [4, 0]]  0.984563          0 -0.0152439   
7  0.942568   0.47774   [[279, 13], [4, 0]]  0.970435          0 -0.0211039   
2  0.807432  0.409247   [[239, 53], [4, 0]]  0.893458          0 -0.0257782   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
1    0.118446  0.995238  0.0348837  0.715753   0.75  
0    0.096697  0.994764  0.0285714  0.650685   0.75  
4           0  0.986486          0         1      0  
6           0  0.986486          0         1      0  
8           0  0.986486          0         1      0  
9           0  0.986486          0         1      0  
3  -0.0153418  0.986254          0  0.982877      0  
5  -0.0153418  0.986254          0  0.982877      0  
7  -0.0250852  0.985866          0  0.955479      0  
2  -0.0546605  0.983539          0  0.818493      0  
Elapsed time 23.02 mins 

************************************************************

pre/post: 25/0  win/stride: 500/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-22 01:17:39.004000 
pca_target: 0 	 poly degree: 0 	 kselect: 100 
Imbalance: ClusterCentroids(estimator=None, n_jobs=1, random_state=None, ratio='auto') 
Extended target (count):  25141 13
('Total : Processed (count): ', (986L, 222L), 13)
Final feature (count):  (986L, 222L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.530 	0.064 	0.016 	0.639 	0.629 	0.404
[[154 138]
 [  1   3]]
             precision    recall  f1-score   support

        0.0       0.99      0.53      0.69       292
        1.0       0.02      0.75      0.04         4

avg / total       0.98      0.53      0.68       296


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=10, class_weight={1: 500}, dual=False,
          fit_intercept=True, intercept_scaling=5, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='sag', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.446 	0.102 	0.021 	0.719 	0.662 	0.463
[[128 164]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.44      0.61       292
        1.0       0.02      1.00      0.05         4

avg / total       0.99      0.45      0.60       296


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.1, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='squared_hinge', n_iter=5, n_jobs=4,
       penalty='none', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.476 	-0.006 	-0.001 	0.488 	0.488 	0.239
[[139 153]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      0.48      0.64       292
        1.0       0.01      0.50      0.03         4

avg / total       0.97      0.48      0.63       296


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3},
           criterion='entropy', max_depth=8, max_features=0.75,
           max_leaf_nodes=None, min_impurity_split=1e-07,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=15, n_jobs=4,
           oob_score=False, random_state=None, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.510 	0.002 	0.001 	0.505 	0.505 	0.255
[[149 143]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      0.51      0.67       292
        1.0       0.01      0.50      0.03         4

avg / total       0.97      0.51      0.66       296


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3},
            criterion='entropy', max_depth=8, max_features=0.33,
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.517 	0.004 	0.001 	0.509 	0.508 	0.258
[[151 141]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      0.52      0.68       292
        1.0       0.01      0.50      0.03         4

avg / total       0.97      0.52      0.67       296


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.794 	0.015 	0.007 	0.526 	0.448 	0.189
[[234  58]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.80      0.88       292
        1.0       0.02      0.25      0.03         4

avg / total       0.97      0.79      0.87       296


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='entropy', max_depth=16,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=1.0, n_estimators=80, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.510 	0.059 	0.014 	0.628 	0.617 	0.389
[[148 144]
 [  1   3]]
             precision    recall  f1-score   support

        0.0       0.99      0.51      0.67       292
        1.0       0.02      0.75      0.04         4

avg / total       0.98      0.51      0.66       296


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.1, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='linear',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.733 	-0.068 	-0.026 	0.372 	0.000 	0.000
[[217  75]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.98      0.74      0.85       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.73      0.83       296


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...owski',
           metric_params=None, n_jobs=4, n_neighbors=4, p=2,
           weights='uniform'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.666 	-0.080 	-0.027 	0.337 	0.000 	0.000
[[197  95]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.98      0.67      0.80       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.67      0.79       296


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=6, p=1,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.868 	-0.043 	-0.025 	0.440 	0.000 	0.000
[[257  35]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.98      0.88      0.93       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.87      0.92       296


                estimator min_score mean_score  max_score  sd_score       acc  \
1      LogisticRegression -0.367711  0.0286297     0.3849  0.174385  0.445946   
0              GaussianNB  0.812156   0.812156   0.812156         0  0.530405   
6      AdaBoostClassifier -0.239411   0.476369          1  0.209049  0.510135   
5           MLPClassifier -0.367711  -0.126037  0.0171889  0.112163  0.793919   
4  RandomForestClassifier -0.111111   0.368843   0.812156  0.184846  0.516892   
3    ExtraTreesClassifier  0.111111   0.601935   0.906078  0.115189  0.510135   
2           SGDClassifier -0.589933   0.104809   0.555556  0.149834  0.476351   
9    KNeighborsClassifier -0.589933 -0.0769389     0.2566  0.186623  0.868243   
7                     SVC   -0.2566   0.107121     0.5132  0.164787  0.733108   
8        VotingClassifier -0.273789   0.116786   0.555556  0.158679  0.665541   

        auc           conf_matrix     f1_c0      f1_c1        kappa  \
1  0.719178  [[128, 164], [0, 4]]  0.609524  0.0465116    0.0206585   
0  0.638699  [[154, 138], [1, 3]]  0.689038  0.0413793    0.0155054   
6  0.628425  [[148, 144], [1, 3]]  0.671202  0.0397351    0.0137868   
5  0.525685   [[234, 58], [3, 1]]  0.884688   0.031746   0.00660211   
4  0.508562  [[151, 141], [2, 2]]  0.678652  0.0272109  0.000944109   
3  0.505137  [[149, 143], [2, 2]]  0.672686  0.0268456  0.000558867   
2  0.488014  [[139, 153], [2, 2]]  0.642032  0.0251572  -0.00122207   
9  0.440068   [[257, 35], [4, 0]]  0.929476          0    -0.024858   
7  0.371575   [[217, 75], [4, 0]]  0.846004          0   -0.0263343   
8  0.337329   [[197, 95], [4, 0]]  0.799189          0   -0.0266256   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
1    0.102162         1  0.0238095  0.438356      1  
0   0.0641281  0.993548  0.0212766  0.527397   0.75  
6   0.0593127  0.993289  0.0204082  0.506849   0.75  
5   0.0148467  0.987342  0.0169492   0.80137   0.25  
4  0.00395635  0.986928   0.013986  0.517123    0.5  
3  0.00237294  0.986755  0.0137931  0.510274    0.5  
2 -0.00554193  0.985816  0.0129032  0.476027    0.5  
9    -0.04286  0.984674          0  0.880137      0  
7  -0.0681825    0.9819          0  0.743151      0  
8  -0.0804641    0.9801          0  0.674658      0  
Elapsed time 15.78 mins 

************************************************************

pre/post: 25/0  win/stride: 500/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-22 01:33:25.605000 
pca_target: 0 	 poly degree: 0 	 kselect: 100 
Imbalance: SMOTE(k=None, k_neighbors=5, kind='regular', m=None, m_neighbors=10, n_jobs=1,
   out_step=0.5, random_state=None, ratio='auto', svm_estimator=None) 
Extended target (count):  25141 13
('Total : Processed (count): ', (986L, 222L), 13)
Final feature (count):  (986L, 222L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.780 	0.011 	0.005 	0.519 	0.444 	0.186
[[230  62]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.79      0.88       292
        1.0       0.02      0.25      0.03         4

avg / total       0.97      0.78      0.86       296


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=10, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=5, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.943 	-0.025 	-0.021 	0.478 	0.000 	0.000
[[279  13]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.96      0.97       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.94      0.96       296


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=1, average=False, class_weight='balanced', epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='invscaling', loss='perceptron', n_iter=5, n_jobs=4,
       penalty='none', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.939 	-0.026 	-0.021 	0.476 	0.000 	0.000
[[278  14]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.95      0.97       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.94      0.96       296


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 50},
           criterion='entropy', max_depth=32, max_features='auto',
           max_leaf_nodes=None, min_impurity_split=1e-07,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=4,
           oob_score=False, random_state=None, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.983 	-0.007 	-0.005 	0.498 	0.000 	0.000
[[291   1]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.98       296


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight='balanced',
            criterion='gini', max_depth=32, max_features='auto',
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.983 	-0.007 	-0.005 	0.498 	0.000 	0.000
[[291   1]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.98       296


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.983 	-0.007 	-0.005 	0.498 	0.000 	0.000
[[291   1]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.98       296


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='entropy', max_depth=8,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=1.0, n_estimators=80, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.1, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=10.0, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', ...owski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='uniform'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.973 	-0.014 	-0.014 	0.493 	0.000 	0.000
[[288   4]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.97      0.97       296


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=1,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.936 	-0.027 	-0.022 	0.474 	0.000 	0.000
[[277  15]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.95      0.97       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.94      0.95       296


                estimator  min_score mean_score max_score    sd_score  \
0              GaussianNB   0.753089   0.753089  0.753089           0   
6      AdaBoostClassifier   0.918447   0.973379  0.998537   0.0167116   
7                     SVC          0   0.793584         1    0.322739   
3    ExtraTreesClassifier   0.583661   0.967439         1   0.0585156   
4  RandomForestClassifier   0.952594   0.980294  0.997084  0.00959288   
5           MLPClassifier   0.962565   0.977278  0.992747  0.00753889   
8        VotingClassifier   0.900771   0.953489     0.984   0.0192366   
1      LogisticRegression  0.0795062   0.765231  0.947091    0.174171   
2           SGDClassifier -0.0227677   0.579712  0.951273     0.26333   
9    KNeighborsClassifier   0.839607   0.899812  0.954248   0.0342879   

        acc       auc          conf_matrix     f1_c0      f1_c1       kappa  \
0  0.780405  0.518836  [[230, 62], [3, 1]]   0.87619  0.0298507  0.00455298   
6  0.986486       0.5   [[292, 0], [4, 0]]  0.993197          0           0   
7  0.986486       0.5   [[292, 0], [4, 0]]  0.993197          0           0   
3  0.983108  0.498288   [[291, 1], [4, 0]]  0.991482          0 -0.00543478   
4  0.983108  0.498288   [[291, 1], [4, 0]]  0.991482          0 -0.00543478   
5  0.983108  0.498288   [[291, 1], [4, 0]]  0.991482          0 -0.00543478   
8  0.972973  0.493151   [[288, 4], [4, 0]]  0.986301          0  -0.0136986   
1  0.942568   0.47774  [[279, 13], [4, 0]]  0.970435          0  -0.0211039   
2  0.939189  0.476027  [[278, 14], [4, 0]]  0.968641          0  -0.0214724   
9  0.935811  0.474315  [[277, 15], [4, 0]]  0.966841          0  -0.0218023   

  model_score   prec_c0   prec_c1    rec_c0 rec_c1  
0   0.0106263  0.987124  0.015873  0.787671   0.25  
6           0  0.986486         0         1      0  
7           0  0.986486         0         1      0  
3  -0.0068144  0.986441         0  0.996575      0  
4  -0.0068144  0.986441         0  0.996575      0  
5  -0.0068144  0.986441         0  0.996575      0  
8  -0.0136986  0.986301         0  0.986301      0  
1  -0.0250852  0.985866         0  0.955479      0  
2  -0.0260782  0.985816         0  0.952055      0  
9  -0.0270415  0.985765         0   0.94863      0  
Elapsed time 48.87 mins 

************************************************************

pre/post: 25/0  win/stride: 500/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-22 02:22:17.566000 
pca_target: 0 	 poly degree: 0 	 kselect: 100 
Imbalance: None 
Extended target (count):  25141 13
('Total : Processed (count): ', (986L, 222L), 13)
Final feature (count):  (986L, 222L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.652 	0.097 	0.030 	0.700 	0.699 	0.493
[[190 102]
 [  1   3]]
             precision    recall  f1-score   support

        0.0       0.99      0.65      0.79       292
        1.0       0.03      0.75      0.06         4

avg / total       0.98      0.65      0.78       296


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=10, class_weight={1: 500}, dual=False,
          fit_intercept=True, intercept_scaling=0.01, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.635 	0.092 	0.027 	0.692 	0.689 	0.481
[[185 107]
 [  1   3]]
             precision    recall  f1-score   support

        0.0       0.99      0.63      0.77       292
        1.0       0.03      0.75      0.05         4

avg / total       0.98      0.64      0.76       296


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=1, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='modified_huber', n_iter=5, n_jobs=4,
       penalty='none', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.889 	0.056 	0.034 	0.574 	0.474 	0.210
[[262  30]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.90      0.94       292
        1.0       0.03      0.25      0.06         4

avg / total       0.98      0.89      0.93       296


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 500}, criterion='gini',
           max_depth=16, max_features=0.33, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=30, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.953 	-0.022 	-0.020 	0.483 	0.000 	0.000
[[282  10]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.97      0.98       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.95      0.96       296


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight='balanced',
            criterion='gini', max_depth=8, max_features=0.33,
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=15, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.983 	-0.007 	-0.005 	0.498 	0.000 	0.000
[[291   1]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.98       296


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=8,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=0.5, n_estimators=50, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.983 	-0.007 	-0.005 	0.498 	0.000 	0.000
[[291   1]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.98       296


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=10, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=10.0, class_weight={1: 500}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Ra...owski',
           metric_params=None, n_jobs=4, n_neighbors=4, p=2,
           weights='uniform'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.980 	-0.010 	-0.009 	0.497 	0.000 	0.000
[[290   2]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.98       296


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=1,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.983 	-0.007 	-0.005 	0.498 	0.000 	0.000
[[291   1]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.98       296


                estimator   min_score   mean_score  max_score    sd_score  \
0              GaussianNB   0.0539636    0.0539636  0.0539636           0   
1      LogisticRegression  -0.0345383    0.0210378   0.100248   0.0286381   
2           SGDClassifier  -0.0945915    0.0176864   0.118411   0.0333508   
4  RandomForestClassifier -0.00414424  0.000981504   0.141929   0.0128127   
7                     SVC  -0.0189874    0.0161283  0.0745289   0.0263217   
5           MLPClassifier  -0.0106172      0.03818   0.137785   0.0490075   
6      AdaBoostClassifier   -0.022474    0.0370213   0.194396   0.0602604   
9    KNeighborsClassifier  -0.0200118  -0.00491516          0  0.00798805   
8        VotingClassifier  -0.0129676   0.00439634   0.141929   0.0319321   
3    ExtraTreesClassifier  -0.0115695   0.00925833   0.159119   0.0312582   

        acc       auc           conf_matrix     f1_c0      f1_c1       kappa  \
0  0.652027  0.700342  [[190, 102], [1, 3]]  0.786749  0.0550459   0.0297862   
1  0.635135  0.691781  [[185, 107], [1, 3]]  0.774059  0.0526316   0.0272639   
2  0.888514   0.57363   [[262, 30], [3, 1]]  0.940754  0.0571429    0.034019   
4  0.986486       0.5    [[292, 0], [4, 0]]  0.993197          0           0   
7  0.986486       0.5    [[292, 0], [4, 0]]  0.993197          0           0   
5  0.983108  0.498288    [[291, 1], [4, 0]]  0.991482          0 -0.00543478   
6  0.983108  0.498288    [[291, 1], [4, 0]]  0.991482          0 -0.00543478   
9  0.983108  0.498288    [[291, 1], [4, 0]]  0.991482          0 -0.00543478   
8   0.97973  0.496575    [[290, 2], [4, 0]]  0.989761          0 -0.00909091   
3  0.952703  0.482877   [[282, 10], [4, 0]]  0.975779          0   -0.019685   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
0    0.096697  0.994764  0.0285714  0.650685   0.75  
1   0.0916439  0.994624  0.0272727  0.633562   0.75  
2   0.0555269  0.988679  0.0322581   0.89726   0.25  
4           0  0.986486          0         1      0  
7           0  0.986486          0         1      0  
5  -0.0068144  0.986441          0  0.996575      0  
6  -0.0068144  0.986441          0  0.996575      0  
9  -0.0068144  0.986441          0  0.996575      0  
8 -0.00965339  0.986395          0  0.993151      0  
3  -0.0218855  0.986014          0  0.965753      0  
Elapsed time 24.70 mins 

************************************************************

pre/post: 25/0  win/stride: 500/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-22 02:46:59.678000 
pca_target: 0 	 poly degree: 2 	 kselect: 40 
Imbalance: ClusterCentroids(estimator=None, n_jobs=1, random_state=None, ratio='auto') 
Extended target (count):  25141 13
('Total : Processed (count): ', (986L, 24976L), 13)
Final feature (count):  (986L, 24976L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.666 	-0.019 	-0.006 	0.461 	0.410 	0.161
[[196  96]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.98      0.67      0.80       292
        1.0       0.01      0.25      0.02         4

avg / total       0.97      0.67      0.79       296


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=5, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.642 	0.035 	0.011 	0.572 	0.567 	0.317
[[188 104]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      0.64      0.78       292
        1.0       0.02      0.50      0.04         4

avg / total       0.98      0.64      0.77       296


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.0001, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='constant', loss='perceptron', n_iter=5, n_jobs=4,
       penalty='none', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.625 	-0.029 	-0.009 	0.440 	0.397 	0.152
[[184 108]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.98      0.63      0.77       292
        1.0       0.01      0.25      0.02         4

avg / total       0.97      0.62      0.76       296


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=8, max_features=0.75, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.551 	0.069 	0.017 	0.649 	0.641 	0.419
[[160 132]
 [  1   3]]
             precision    recall  f1-score   support

        0.0       0.99      0.55      0.71       292
        1.0       0.02      0.75      0.04         4

avg / total       0.98      0.55      0.70       296


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3},
            criterion='entropy', max_depth=8, max_features=0.75,
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.595 	0.023 	0.006 	0.548 	0.546 	0.295
[[174 118]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      0.60      0.74       292
        1.0       0.02      0.50      0.03         4

avg / total       0.98      0.59      0.73       296


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.659 	-0.021 	-0.007 	0.457 	0.408 	0.159
[[194  98]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.98      0.66      0.79       292
        1.0       0.01      0.25      0.02         4

avg / total       0.97      0.66      0.78       296


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=2.0, n_estimators=50, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.470 	0.050 	0.011 	0.608 	0.591 	0.359
[[136 156]
 [  1   3]]
             precision    recall  f1-score   support

        0.0       0.99      0.47      0.63       292
        1.0       0.02      0.75      0.04         4

avg / total       0.98      0.47      0.63       296


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=1, cache_size=200, class_weight={1: 50}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='linear',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.591 	0.079 	0.022 	0.670 	0.665 	0.449
[[172 120]
 [  1   3]]
             precision    recall  f1-score   support

        0.0       0.99      0.59      0.74       292
        1.0       0.02      0.75      0.05         4

avg / total       0.98      0.59      0.73       296


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=1.0, class_weight={1: 500}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Ran...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.622 	0.029 	0.009 	0.562 	0.558 	0.308
[[182 110]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      0.62      0.76       292
        1.0       0.02      0.50      0.03         4

avg / total       0.98      0.62      0.75       296


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=4, p=4,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.824 	-0.051 	-0.026 	0.418 	0.000 	0.000
[[244  48]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.98      0.84      0.90       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.82      0.89       296


                estimator min_score mean_score max_score   sd_score       acc  \
7                     SVC         0   0.424329  0.906078   0.335144  0.591216   
3    ExtraTreesClassifier  0.444444   0.584313  0.649478  0.0597388  0.550676   
6      AdaBoostClassifier    0.2566   0.781769         1   0.119051  0.469595   
1      LogisticRegression         0   0.478659         1   0.338264  0.641892   
8        VotingClassifier  0.572745   0.756819  0.888889  0.0598912  0.621622   
4  RandomForestClassifier  0.478822    0.74044  0.906078  0.0639668  0.594595   
0              GaussianNB  0.812156   0.812156  0.812156          0  0.665541   
5           MLPClassifier  0.333333   0.744488  0.777778  0.0885052  0.658784   
2           SGDClassifier -0.222222   0.537152         1    0.26906     0.625   
9    KNeighborsClassifier  0.461633    0.67241  0.812156    0.13692  0.824324   

        auc           conf_matrix     f1_c0      f1_c1       kappa  \
7  0.669521  [[172, 120], [1, 3]]  0.739785  0.0472441   0.0216346   
3  0.648973  [[160, 132], [1, 3]]  0.706402  0.0431655   0.0173722   
6  0.607877  [[136, 156], [1, 3]]  0.634033  0.0368098   0.0107289   
1  0.571918  [[188, 104], [2, 2]]  0.780083  0.0363636   0.0105954   
8  0.561644  [[182, 110], [2, 2]]  0.764706  0.0344828  0.00861244   
4  0.547945  [[174, 118], [2, 2]]   0.74359  0.0322581  0.00626679   
0  0.460616   [[196, 96], [3, 1]]  0.798371   0.019802 -0.00631868   
5  0.457192   [[194, 98], [3, 1]]  0.793456  0.0194175 -0.00673491   
2  0.440068  [[184, 108], [3, 1]]  0.768267  0.0176991 -0.00859528   
9  0.417808   [[244, 48], [4, 0]]  0.903704          0  -0.0255864   

  model_score   prec_c0     prec_c1    rec_c0 rec_c1  
7   0.0794325   0.99422   0.0243902  0.589041   0.75  
3   0.0690682  0.993789   0.0222222  0.547945   0.75  
6   0.0499598  0.992701   0.0188679  0.465753   0.75  
1   0.0346384  0.989474   0.0188679  0.643836    0.5  
8    0.029351   0.98913   0.0178571  0.623288    0.5  
4   0.0225502  0.988636   0.0166667   0.59589    0.5  
0  -0.0193755  0.984925   0.0103093  0.671233   0.25  
5  -0.0209521  0.984772    0.010101  0.664384   0.25  
2  -0.0286928  0.983957  0.00917431  0.630137   0.25  
9  -0.0514912  0.983871           0  0.835616      0  
Elapsed time 19.32 mins 

************************************************************

pre/post: 25/0  win/stride: 500/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-22 03:06:18.729000 
pca_target: 0 	 poly degree: 2 	 kselect: 40 
Imbalance: SMOTE(k=None, k_neighbors=5, kind='regular', m=None, m_neighbors=10, n_jobs=1,
   out_step=0.5, random_state=None, ratio='auto', svm_estimator=None) 
Extended target (count):  25141 13
('Total : Processed (count): ', (986L, 24976L), 13)
Final feature (count):  (986L, 24976L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.524 	0.063 	0.015 	0.635 	0.625 	0.399
[[152 140]
 [  1   3]]
             precision    recall  f1-score   support

        0.0       0.99      0.52      0.68       292
        1.0       0.02      0.75      0.04         4

avg / total       0.98      0.52      0.67       296


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=1, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.787 	-0.058 	-0.026 	0.399 	0.000 	0.000
[[233  59]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.98      0.80      0.88       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.79      0.87       296


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.1, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='modified_huber', n_iter=5, n_jobs=4,
       penalty='none', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.736 	-0.068 	-0.026 	0.373 	0.000 	0.000
[[218  74]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.98      0.75      0.85       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.74      0.84       296


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 50}, criterion='gini',
           max_depth=32, max_features=0.75, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.963 	-0.018 	-0.018 	0.488 	0.000 	0.000
[[285   7]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.98      0.98       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.96      0.97       296


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 15},
            criterion='entropy', max_depth=None, max_features=0.33,
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.959 	-0.020 	-0.018 	0.486 	0.000 	0.000
[[284   8]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.97      0.98       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.96      0.97       296


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.1, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.929 	-0.029 	-0.022 	0.471 	0.000 	0.000
[[275  17]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.94      0.96       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.93      0.95       296


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight='balanced', criterion='entropy',
            max_depth=4, max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=0.5, n_estimators=50, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.970 	-0.015 	-0.015 	0.491 	0.000 	0.000
[[287   5]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.98      0.98       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.97      0.97       296


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.5, cache_size=200, class_weight='balanced', coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=10, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.966 	-0.017 	-0.016 	0.490 	0.000 	0.000
[[286   6]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.98      0.98       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.97      0.97       296


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=10.0, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', ...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.932 	-0.028 	-0.022 	0.473 	0.000 	0.000
[[276  16]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.95      0.97       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.93      0.95       296


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=4,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.943 	-0.025 	-0.021 	0.478 	0.000 	0.000
[[279  13]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.96      0.97       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.94      0.96       296


                estimator min_score mean_score max_score   sd_score       acc  \
0              GaussianNB  0.580209   0.580209  0.580209          0  0.523649   
6      AdaBoostClassifier  0.852569   0.914668  0.959419  0.0237845  0.969595   
7                     SVC         0   0.694479  0.971004   0.159179  0.966216   
3    ExtraTreesClassifier  0.615411   0.884809   0.96964   0.102043  0.962838   
4  RandomForestClassifier  0.803521   0.931133  0.965277  0.0396715  0.959459   
9    KNeighborsClassifier  0.871156   0.896025  0.916166  0.0149219  0.942568   
8        VotingClassifier   0.84066   0.869678  0.900052  0.0155216  0.932432   
5           MLPClassifier  0.899398    0.92745  0.951347  0.0136893  0.929054   
1      LogisticRegression  0.526712   0.652013  0.803242  0.0933387  0.787162   
2           SGDClassifier -0.183197   0.516387  0.741281   0.193203  0.736486   

        auc           conf_matrix     f1_c0      f1_c1      kappa model_score  \
0  0.635274  [[152, 140], [1, 3]]  0.683146  0.0408163  0.0149169   0.0625103   
6  0.491438    [[287, 5], [4, 0]]  0.984563          0 -0.0152439  -0.0153418   
7  0.489726    [[286, 6], [4, 0]]  0.982818          0 -0.0164835  -0.0168351   
3  0.488014    [[285, 7], [4, 0]]  0.981067          0    -0.0175  -0.0182154   
4  0.486301    [[284, 8], [4, 0]]   0.97931          0 -0.0183486  -0.0195069   
9   0.47774   [[279, 13], [4, 0]]  0.970435          0 -0.0211039  -0.0250852   
8  0.472603   [[276, 16], [4, 0]]  0.965035          0 -0.0220994  -0.0279782   
5   0.47089   [[275, 17], [4, 0]]  0.963222          0 -0.0223684  -0.0288909   
1  0.398973   [[233, 59], [4, 0]]  0.880907          0 -0.0259683   -0.058397   
2  0.373288   [[218, 74], [4, 0]]  0.848249          0 -0.0263158  -0.0675737   

    prec_c0   prec_c1    rec_c0 rec_c1  
0  0.993464  0.020979  0.520548   0.75  
6  0.986254         0  0.982877      0  
7  0.986207         0  0.979452      0  
3  0.986159         0  0.976027      0  
4  0.986111         0  0.972603      0  
9  0.985866         0  0.955479      0  
8  0.985714         0  0.945205      0  
5  0.985663         0  0.941781      0  
1  0.983122         0  0.797945      0  
2  0.981982         0  0.746575      0  
Elapsed time 36.96 mins 

************************************************************

pre/post: 25/0  win/stride: 500/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-22 03:43:16.210000 
pca_target: 0 	 poly degree: 2 	 kselect: 40 
Imbalance: None 
Extended target (count):  25141 13
('Total : Processed (count): ', (986L, 24976L), 13)
Final feature (count):  (986L, 24976L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.926 	-0.030 	-0.023 	0.469 	0.000 	0.000
[[274  18]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.94      0.96       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.93      0.95       296


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.001, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.922 	-0.031 	-0.023 	0.467 	0.000 	0.000
[[273  19]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.93      0.96       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.92      0.95       296


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.1, average=False, class_weight={1: 15}, epsilon=0.1,
       eta0=0.001, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='modified_huber', n_iter=5, n_jobs=4,
       penalty='l1', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.932 	-0.028 	-0.022 	0.473 	0.000 	0.000
[[276  16]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.95      0.97       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.93      0.95       296


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=8, max_features='auto', max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.5, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(500,), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight='balanced', criterion='entropy',
            max_depth=32, max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=0.5, n_estimators=15, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.959 	-0.020 	-0.018 	0.486 	0.000 	0.000
[[284   8]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.97      0.98       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.96      0.97       296


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='linear',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.926 	-0.030 	-0.023 	0.469 	0.000 	0.000
[[274  18]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.94      0.96       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.93      0.95       296


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=1,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


                estimator  min_score  mean_score  max_score    sd_score  \
3    ExtraTreesClassifier  -0.131634 -0.00772898          0   0.0248554   
4  RandomForestClassifier -0.0168582 -0.00042924          0  0.00178387   
5           MLPClassifier -0.0181875  0.00664797   0.138397   0.0338534   
8        VotingClassifier -0.0112757 -0.00292984          0  0.00350014   
9    KNeighborsClassifier -0.0129911 -0.00310954          0  0.00539297   
6      AdaBoostClassifier -0.0498599 -0.00727269   0.154243   0.0157828   
2           SGDClassifier  -0.138988   0.0276669   0.223773   0.0455924   
0              GaussianNB -0.0795979  -0.0795979 -0.0795979           0   
7                     SVC  -0.135438 -0.00859013  0.0729951   0.0325593   
1      LogisticRegression -0.0883801   0.0181559   0.211067   0.0506848   

        acc       auc          conf_matrix     f1_c0 f1_c1      kappa  \
3  0.986486       0.5   [[292, 0], [4, 0]]  0.993197     0          0   
4  0.986486       0.5   [[292, 0], [4, 0]]  0.993197     0          0   
5  0.986486       0.5   [[292, 0], [4, 0]]  0.993197     0          0   
8  0.986486       0.5   [[292, 0], [4, 0]]  0.993197     0          0   
9  0.986486       0.5   [[292, 0], [4, 0]]  0.993197     0          0   
6  0.959459  0.486301   [[284, 8], [4, 0]]   0.97931     0 -0.0183486   
2  0.932432  0.472603  [[276, 16], [4, 0]]  0.965035     0 -0.0220994   
0  0.925676  0.469178  [[274, 18], [4, 0]]  0.961404     0 -0.0226131   
7  0.925676  0.469178  [[274, 18], [4, 0]]  0.961404     0 -0.0226131   
1  0.922297  0.467466  [[273, 19], [4, 0]]  0.959578     0 -0.0228365   

  model_score   prec_c0 prec_c1    rec_c0 rec_c1  
3           0  0.986486       0         1      0  
4           0  0.986486       0         1      0  
5           0  0.986486       0         1      0  
8           0  0.986486       0         1      0  
9           0  0.986486       0         1      0  
6  -0.0195069  0.986111       0  0.972603      0  
2  -0.0279782  0.985714       0  0.945205      0  
0  -0.0297819  0.985612       0  0.938356      0  
7  -0.0297819  0.985612       0  0.938356      0  
1  -0.0306532   0.98556       0  0.934932      0  
Elapsed time 24.15 mins 

************************************************************

pre/post: 25/0  win/stride: 500/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-22 04:07:25.481000 
pca_target: 0 	 poly degree: 2 	 kselect: 80 
Imbalance: ClusterCentroids(estimator=None, n_jobs=1, random_state=None, ratio='auto') 
Extended target (count):  25141 13
('Total : Processed (count): ', (986L, 24976L), 13)
Final feature (count):  (986L, 24976L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.554 	0.070 	0.018 	0.651 	0.643 	0.422
[[161 131]
 [  1   3]]
             precision    recall  f1-score   support

        0.0       0.99      0.55      0.71       292
        1.0       0.02      0.75      0.04         4

avg / total       0.98      0.55      0.70       296


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=5, class_weight={1: 15}, dual=False, fit_intercept=True,
          intercept_scaling=0.1, max_iter=100, multi_class='ovr', n_jobs=4,
          penalty='l2', random_state=None, solver='lbfgs', tol=0.0001,
          verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.608 	0.026 	0.007 	0.555 	0.552 	0.301
[[178 114]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      0.61      0.75       292
        1.0       0.02      0.50      0.03         4

avg / total       0.98      0.61      0.74       296


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.0001, average=False, class_weight='balanced',
       epsilon=0.1, eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='modified_huber', n_iter=5, n_jobs=4,
       penalty='l2', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.534 	0.008 	0.002 	0.517 	0.517 	0.266
[[156 136]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      0.53      0.69       292
        1.0       0.01      0.50      0.03         4

avg / total       0.97      0.53      0.68       296


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=32, max_features=0.75, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.453 	-0.011 	-0.002 	0.476 	0.475 	0.227
[[132 160]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      0.45      0.62       292
        1.0       0.01      0.50      0.02         4

avg / total       0.97      0.45      0.61       296


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features=0.75, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.554 	0.013 	0.003 	0.527 	0.527 	0.276
[[162 130]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      0.55      0.71       292
        1.0       0.02      0.50      0.03         4

avg / total       0.97      0.55      0.70       296


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(500,), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.686 	-0.015 	-0.005 	0.471 	0.416 	0.165
[[202  90]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.69      0.81       292
        1.0       0.01      0.25      0.02         4

avg / total       0.97      0.69      0.80       296


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 500}, criterion='gini', max_depth=8,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=0.5, n_estimators=15, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.696 	-0.012 	-0.004 	0.476 	0.419 	0.168
[[205  87]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.70      0.82       292
        1.0       0.01      0.25      0.02         4

avg / total       0.97      0.70      0.81       296


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=10, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='linear',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.676 	0.044 	0.014 	0.589 	0.582 	0.333
[[198  94]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      0.68      0.80       292
        1.0       0.02      0.50      0.04         4

avg / total       0.98      0.68      0.79       296


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...owski',
           metric_params=None, n_jobs=4, n_neighbors=4, p=2,
           weights='uniform'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.625 	0.030 	0.009 	0.563 	0.560 	0.309
[[183 109]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      0.63      0.77       292
        1.0       0.02      0.50      0.03         4

avg / total       0.98      0.62      0.76       296


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=4,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.723 	-0.005 	-0.002 	0.490 	0.427 	0.174
[[213  79]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.73      0.84       292
        1.0       0.01      0.25      0.02         4

avg / total       0.97      0.72      0.83       296


                estimator min_score mean_score max_score   sd_score       acc  \
0              GaussianNB  0.812156   0.812156  0.812156          0  0.554054   
7                     SVC         0   0.441368  0.906078   0.327925  0.675676   
8        VotingClassifier  0.367711   0.546439  0.777778   0.100563     0.625   
1      LogisticRegression         0   0.465908  0.906078   0.311757  0.608108   
4  RandomForestClassifier  0.350522    0.67482  0.906078   0.128586  0.554054   
2           SGDClassifier   -0.1283   0.416999         1   0.236842  0.533784   
9    KNeighborsClassifier  0.589933   0.799507  0.906078  0.0714644  0.722973   
3    ExtraTreesClassifier    0.3849   0.654701  0.812156   0.134329  0.452703   
6      AdaBoostClassifier -0.333333    0.45815         1   0.205727  0.695946   
5           MLPClassifier  0.906078   0.990216         1   0.028691  0.685811   

        auc           conf_matrix     f1_c0      f1_c1       kappa  \
0  0.650685  [[161, 131], [1, 3]]  0.709251  0.0434783   0.0176991   
7  0.589041   [[198, 94], [2, 2]]  0.804878       0.04   0.0144284   
8  0.563356  [[183, 109], [2, 2]]  0.767296  0.0347826  0.00892857   
1  0.554795  [[178, 114], [2, 2]]  0.754237  0.0333333  0.00740056   
4  0.527397  [[162, 130], [2, 2]]  0.710526  0.0294118  0.00326531   
2  0.517123  [[156, 136], [2, 2]]  0.693333   0.028169  0.00195465   
9  0.489726   [[213, 79], [3, 1]]  0.838583  0.0238095 -0.00198151   
3  0.476027  [[132, 160], [2, 2]]  0.619718  0.0240964 -0.00234114   
6  0.476027   [[205, 87], [3, 1]]      0.82  0.0217391 -0.00422195   
5   0.47089   [[202, 90], [3, 1]]  0.812877  0.0210526 -0.00496495   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
0   0.0699055  0.993827  0.0223881   0.55137   0.75  
7   0.0439229      0.99  0.0208333  0.678082    0.5  
8   0.0302199  0.989189   0.018018  0.626712    0.5  
1   0.0259193  0.988889  0.0172414  0.609589    0.5  
4   0.0127277  0.987805  0.0151515  0.554795    0.5  
2   0.0079263  0.987342  0.0144928  0.534247    0.5  
9 -0.00534217  0.986111     0.0125  0.729452   0.25  
3  -0.0111213  0.985075  0.0123457  0.452055    0.5  
6  -0.0121114  0.985577  0.0113636  0.702055   0.25  
5  -0.0145677  0.985366   0.010989  0.691781   0.25  
Elapsed time 19.54 mins 

************************************************************

pre/post: 25/0  win/stride: 500/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-22 04:26:57.731000 
pca_target: 0 	 poly degree: 2 	 kselect: 80 
Imbalance: SMOTE(k=None, k_neighbors=5, kind='regular', m=None, m_neighbors=10, n_jobs=1,
   out_step=0.5, random_state=None, ratio='auto', svm_estimator=None) 
Extended target (count):  25141 13
('Total : Processed (count): ', (986L, 24976L), 13)
Final feature (count):  (986L, 24976L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.541 	0.067 	0.016 	0.644 	0.635 	0.412
[[157 135]
 [  1   3]]
             precision    recall  f1-score   support

        0.0       0.99      0.54      0.70       292
        1.0       0.02      0.75      0.04         4

avg / total       0.98      0.54      0.69       296


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=10, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=5, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.872 	-0.042 	-0.025 	0.442 	0.000 	0.000
[[258  34]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.98      0.88      0.93       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.87      0.92       296


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.001, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='perceptron', n_iter=5, n_jobs=4,
       penalty='l1', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.811 	-0.054 	-0.026 	0.411 	0.000 	0.000
[[240  52]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.98      0.82      0.90       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.81      0.88       296


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3},
           criterion='entropy', max_depth=None, max_features=0.75,
           max_leaf_nodes=None, min_impurity_split=1e-07,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=4,
           oob_score=False, random_state=None, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.966 	-0.017 	-0.016 	0.490 	0.000 	0.000
[[286   6]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.98      0.98       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.97      0.97       296


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight='balanced',
            criterion='entropy', max_depth=32, max_features=0.33,
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.956 	-0.021 	-0.019 	0.485 	0.000 	0.000
[[283   9]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.97      0.98       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.96      0.96       296


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.01, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.956 	-0.021 	-0.019 	0.485 	0.000 	0.000
[[283   9]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.97      0.98       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.96      0.96       296


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='entropy', max_depth=8,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=1.0, n_estimators=50, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.966 	-0.017 	-0.016 	0.490 	0.000 	0.000
[[286   6]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.98      0.98       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.97      0.97       296


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=1, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.980 	-0.010 	-0.009 	0.497 	0.000 	0.000
[[290   2]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.98       296


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=10.0, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', ...wski',
           metric_params=None, n_jobs=4, n_neighbors=4, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.922 	-0.031 	-0.023 	0.467 	0.000 	0.000
[[273  19]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.93      0.96       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.92      0.95       296


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=4,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.916 	-0.032 	-0.023 	0.464 	0.000 	0.000
[[271  21]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.93      0.96       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.92      0.94       296


                estimator  min_score mean_score max_score    sd_score  \
0              GaussianNB   0.604069   0.604069  0.604069           0   
7                     SVC          0   0.811129  0.986811    0.233994   
3    ExtraTreesClassifier   0.639348   0.907439  0.975446   0.0777286   
6      AdaBoostClassifier   0.861879   0.941803  0.981156   0.0233265   
4  RandomForestClassifier   0.821994    0.94343  0.976684   0.0330373   
5           MLPClassifier   0.956481   0.968411  0.978252  0.00513062   
8        VotingClassifier   0.882162   0.926464  0.955537   0.0170563   
9    KNeighborsClassifier   0.778628   0.869937  0.939868   0.0409881   
1      LogisticRegression   0.506119   0.709874  0.895406    0.115034   
2           SGDClassifier -0.0303398   0.575788  0.894295    0.225223   

        acc       auc           conf_matrix     f1_c0      f1_c1       kappa  \
0  0.540541  0.643836  [[157, 135], [1, 3]]  0.697778  0.0422535   0.0164191   
7   0.97973  0.496575    [[290, 2], [4, 0]]  0.989761          0 -0.00909091   
3  0.966216  0.489726    [[286, 6], [4, 0]]  0.982818          0  -0.0164835   
6  0.966216  0.489726    [[286, 6], [4, 0]]  0.982818          0  -0.0164835   
4  0.956081  0.484589    [[283, 9], [4, 0]]  0.977547          0  -0.0190678   
5  0.956081  0.484589    [[283, 9], [4, 0]]  0.977547          0  -0.0190678   
8  0.922297  0.467466   [[273, 19], [4, 0]]  0.959578          0  -0.0228365   
9  0.915541  0.464041   [[271, 21], [4, 0]]  0.955908          0  -0.0232301   
1  0.871622  0.441781   [[258, 34], [4, 0]]  0.931408          0  -0.0247813   
2  0.810811  0.410959   [[240, 52], [4, 0]]  0.895522          0  -0.0257426   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
0   0.0665809  0.993671  0.0217391  0.537671   0.75  
7 -0.00965339  0.986395          0  0.993151      0  
3  -0.0168351  0.986207          0  0.979452      0  
6  -0.0168351  0.986207          0  0.979452      0  
4  -0.0207262  0.986063          0  0.969178      0  
5  -0.0207262  0.986063          0  0.969178      0  
8  -0.0306532   0.98556          0  0.934932      0  
9  -0.0323431  0.985455          0  0.928082      0  
1  -0.0421626  0.984733          0  0.883562      0  
2  -0.0540313  0.983607          0  0.821918      0  
Elapsed time 53.24 mins 

************************************************************

pre/post: 25/0  win/stride: 500/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-22 05:20:12.309000 
pca_target: 0 	 poly degree: 2 	 kselect: 80 
Imbalance: None 
Extended target (count):  25141 13
('Total : Processed (count): ', (986L, 24976L), 13)
Final feature (count):  (986L, 24976L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.912 	-0.033 	-0.023 	0.462 	0.000 	0.000
[[270  22]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.92      0.95       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.91      0.94       296


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.01, class_weight={1: 3}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.0001, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.001, fit_intercept=True, l1_ratio=0.15,
       learning_rate='invscaling', loss='squared_hinge', n_iter=5,
       n_jobs=4, penalty='l1', power_t=0.5, random_state=None,
       shuffle=True, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.966 	-0.017 	-0.016 	0.490 	0.000 	0.000
[[286   6]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.98      0.98       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.97      0.97       296


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 500}, criterion='gini',
           max_depth=8, max_features=0.75, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=50, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.774 	-0.061 	-0.026 	0.392 	0.000 	0.000
[[229  63]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.98      0.78      0.87       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.77      0.86       296


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 50}, criterion='gini',
            max_depth=8, max_features=0.33, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.983 	-0.007 	-0.005 	0.498 	0.000 	0.000
[[291   1]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.98       296


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.5, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.973 	-0.014 	-0.014 	0.493 	0.000 	0.000
[[288   4]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.97      0.97       296


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight='balanced', criterion='gini',
            max_depth=32, max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=0.5, n_estimators=80, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.966 	-0.017 	-0.016 	0.490 	0.000 	0.000
[[286   6]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.98      0.98       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.97      0.97       296


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.01, cache_size=200, class_weight={1: 500}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.382 	0.089 	0.016 	0.687 	0.611 	0.397
[[109 183]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.37      0.54       292
        1.0       0.02      1.00      0.04         4

avg / total       0.99      0.38      0.54       296


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=1,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


                estimator   min_score   mean_score  max_score    sd_score  \
7                     SVC  -0.0382548   -0.0101425  0.0854332   0.0183606   
1      LogisticRegression  -0.0766268    0.0120785   0.133974   0.0402603   
8        VotingClassifier -0.00963273  -0.00149203          0  0.00212963   
9    KNeighborsClassifier  -0.0115979  -0.00216135          0  0.00384054   
4  RandomForestClassifier  -0.0106196  0.000352813   0.140904  0.00907123   
5           MLPClassifier  -0.0191255   -0.0109961 -0.0046196  0.00386106   
2           SGDClassifier   -0.195529    0.0322196   0.183053   0.0432628   
6      AdaBoostClassifier  -0.0224932  -0.00121642   0.169492   0.0262212   
0              GaussianNB  -0.0479997   -0.0479997 -0.0479997           0   
3    ExtraTreesClassifier  -0.0495514  0.000180705    0.11525   0.0132813   

        acc       auc           conf_matrix     f1_c0      f1_c1       kappa  \
7  0.381757  0.686644  [[109, 183], [0, 4]]  0.543641  0.0418848    0.015843   
1  0.986486       0.5    [[292, 0], [4, 0]]  0.993197          0           0   
8  0.986486       0.5    [[292, 0], [4, 0]]  0.993197          0           0   
9  0.986486       0.5    [[292, 0], [4, 0]]  0.993197          0           0   
4  0.983108  0.498288    [[291, 1], [4, 0]]  0.991482          0 -0.00543478   
5  0.972973  0.493151    [[288, 4], [4, 0]]  0.986301          0  -0.0136986   
2  0.966216  0.489726    [[286, 6], [4, 0]]  0.982818          0  -0.0164835   
6  0.966216  0.489726    [[286, 6], [4, 0]]  0.982818          0  -0.0164835   
0  0.912162  0.462329   [[270, 22], [4, 0]]  0.954064          0  -0.0234043   
3  0.773649  0.392123   [[229, 63], [4, 0]]  0.872381          0  -0.0260762   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
7   0.0893575         1  0.0213904  0.373288      1  
1           0  0.986486          0         1      0  
8           0  0.986486          0         1      0  
9           0  0.986486          0         1      0  
4  -0.0068144  0.986441          0  0.996575      0  
5  -0.0136986  0.986301          0  0.986301      0  
2  -0.0168351  0.986207          0  0.979452      0  
6  -0.0168351  0.986207          0  0.979452      0  
0  -0.0331646  0.985401          0  0.924658      0  
3  -0.0608599  0.982833          0  0.784247      0  
Elapsed time 23.37 mins 

************************************************************

pre/post: 25/0  win/stride: 500/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-22 05:43:34.295000 
pca_target: 0 	 poly degree: 2 	 kselect: 100 
Imbalance: ClusterCentroids(estimator=None, n_jobs=1, random_state=None, ratio='auto') 
Extended target (count):  25141 13
('Total : Processed (count): ', (986L, 24976L), 13)
Final feature (count):  (986L, 24976L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.797 	-0.057 	-0.026 	0.404 	0.000 	0.000
[[236  56]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.98      0.81      0.89       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.80      0.88       296


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.1, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=5, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.689 	-0.076 	-0.027 	0.349 	0.000 	0.000
[[204  88]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.98      0.70      0.82       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.69      0.80       296


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.1, average=False, class_weight='balanced', epsilon=0.1,
       eta0=0.001, fit_intercept=True, l1_ratio=0.15,
       learning_rate='invscaling', loss='perceptron', n_iter=5, n_jobs=4,
       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.561 	0.072 	0.018 	0.654 	0.647 	0.427
[[163 129]
 [  1   3]]
             precision    recall  f1-score   support

        0.0       0.99      0.56      0.71       292
        1.0       0.02      0.75      0.04         4

avg / total       0.98      0.56      0.71       296


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=8, max_features='auto', max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.412 	-0.079 	-0.015 	0.332 	0.322 	0.102
[[121 171]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.98      0.41      0.58       292
        1.0       0.01      0.25      0.01         4

avg / total       0.96      0.41      0.57       296


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 500},
            criterion='gini', max_depth=16, max_features=0.75,
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.480 	0.052 	0.011 	0.613 	0.598 	0.367
[[139 153]
 [  1   3]]
             precision    recall  f1-score   support

        0.0       0.99      0.48      0.64       292
        1.0       0.02      0.75      0.04         4

avg / total       0.98      0.48      0.64       296


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.652 	-0.023 	-0.007 	0.454 	0.405 	0.158
[[192 100]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.98      0.66      0.79       292
        1.0       0.01      0.25      0.02         4

avg / total       0.97      0.65      0.78       296


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=16,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=0.5, n_estimators=15, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.416 	-0.020 	-0.004 	0.457 	0.455 	0.209
[[121 171]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.98      0.41      0.58       292
        1.0       0.01      0.50      0.02         4

avg / total       0.97      0.42      0.58       296


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.5, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='linear',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.689 	-0.014 	-0.005 	0.473 	0.417 	0.166
[[203  89]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.70      0.82       292
        1.0       0.01      0.25      0.02         4

avg / total       0.97      0.69      0.80       296


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=1.0, class_weight={1: 500}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Ran...owski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='uniform'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.561 	0.014 	0.004 	0.531 	0.530 	0.279
[[164 128]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      0.56      0.72       292
        1.0       0.02      0.50      0.03         4

avg / total       0.97      0.56      0.71       296


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=1,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.770 	-0.061 	-0.026 	0.390 	0.000 	0.000
[[228  64]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.98      0.78      0.87       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.77      0.86       296


                estimator min_score mean_score max_score   sd_score       acc  \
2           SGDClassifier -0.478822   0.340149  0.906078   0.212765  0.560811   
4  RandomForestClassifier    0.3849   0.676138  0.906078  0.0808432   0.47973   
8        VotingClassifier  0.461633   0.679397  0.812156  0.0433943  0.560811   
7                     SVC         0   0.552989         1   0.412233  0.689189   
6      AdaBoostClassifier    0.2566   0.662924  0.906078   0.105539  0.415541   
5           MLPClassifier  0.589933   0.758007  0.812156   0.074249  0.652027   
0              GaussianNB  0.906078   0.906078  0.906078          0  0.797297   
9    KNeighborsClassifier  0.427255   0.619897  0.683856   0.100095   0.77027   
1      LogisticRegression         0   0.442288  0.906078    0.29511  0.689189   
3    ExtraTreesClassifier  0.572745   0.752559  0.812156   0.067263  0.412162   

        auc           conf_matrix     f1_c0      f1_c1       kappa  \
2   0.65411  [[163, 129], [1, 3]]  0.714912  0.0441176   0.0183673   
4  0.613014  [[139, 153], [1, 3]]  0.643519     0.0375   0.0114504   
8  0.530822  [[164, 128], [2, 2]]  0.716157  0.0298507  0.00372825   
7  0.472603   [[203, 89], [3, 1]]  0.815261  0.0212766 -0.00472255   
6  0.457192  [[121, 171], [2, 2]]  0.583133  0.0225989 -0.00392095   
5  0.453767  [[192, 100], [3, 1]]  0.788501  0.0190476 -0.00713531   
0   0.40411   [[236, 56], [4, 0]]  0.887218          0   -0.025878   
9  0.390411   [[228, 64], [4, 0]]  0.870229          0  -0.0261011   
1  0.349315   [[204, 88], [4, 0]]     0.816          0   -0.026538   
3  0.332192  [[121, 171], [3, 1]]  0.581731  0.0113636  -0.0154574   

  model_score   prec_c0     prec_c1    rec_c0 rec_c1  
2   0.0715933  0.993902   0.0227273  0.558219   0.75  
4   0.0522704  0.992857   0.0192308  0.476027   0.75  
8   0.0143412  0.987952   0.0153846  0.561644    0.5  
7  -0.0137532  0.985437   0.0111111  0.695205   0.25  
6  -0.0200587   0.98374   0.0115607  0.414384    0.5  
5  -0.0225177  0.984615  0.00990099  0.657534   0.25  
0  -0.0565362  0.983333           0  0.808219      0  
9   -0.061473  0.982759           0  0.780822      0  
1  -0.0761287  0.980769           0   0.69863      0  
3  -0.0785398  0.975806  0.00581395  0.414384   0.25  
Elapsed time 20.50 mins 

************************************************************

pre/post: 25/0  win/stride: 500/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-22 06:04:04.086000 
pca_target: 0 	 poly degree: 2 	 kselect: 100 
Imbalance: SMOTE(k=None, k_neighbors=5, kind='regular', m=None, m_neighbors=10, n_jobs=1,
   out_step=0.5, random_state=None, ratio='auto', svm_estimator=None) 
Extended target (count):  25141 13
('Total : Processed (count): ', (986L, 24976L), 13)
Final feature (count):  (986L, 24976L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.551 	0.012 	0.003 	0.526 	0.525 	0.274
[[161 131]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      0.55      0.71       292
        1.0       0.02      0.50      0.03         4

avg / total       0.97      0.55      0.70       296


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=10, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=5, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.895 	-0.037 	-0.024 	0.454 	0.000 	0.000
[[265  27]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.91      0.94       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.90      0.93       296


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.001, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='squared_hinge', n_iter=5, n_jobs=4,
       penalty='none', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.828 	-0.051 	-0.026 	0.420 	0.000 	0.000
[[245  47]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.98      0.84      0.91       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.83      0.89       296


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 15},
           criterion='entropy', max_depth=32, max_features=0.75,
           max_leaf_nodes=None, min_impurity_split=1e-07,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=4,
           oob_score=False, random_state=None, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.976 	-0.012 	-0.012 	0.495 	0.000 	0.000
[[289   3]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.97       296


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight='balanced',
            criterion='gini', max_depth=None, max_features=0.33,
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.966 	-0.017 	-0.016 	0.490 	0.000 	0.000
[[286   6]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.98      0.98       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.97      0.97       296


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.1, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.956 	-0.021 	-0.019 	0.485 	0.000 	0.000
[[283   9]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.97      0.98       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.96      0.96       296


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight='balanced', criterion='gini', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=1.0, n_estimators=50, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.976 	-0.012 	-0.012 	0.495 	0.000 	0.000
[[289   3]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.97       296


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=10, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.976 	-0.012 	-0.012 	0.495 	0.000 	0.000
[[289   3]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.97       296


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=10.0, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', ...owski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='uniform'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.936 	-0.027 	-0.022 	0.474 	0.000 	0.000
[[277  15]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.95      0.97       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.94      0.95       296


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=3,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.912 	-0.033 	-0.023 	0.462 	0.000 	0.000
[[270  22]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.92      0.95       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.91      0.94       296


                estimator min_score mean_score max_score    sd_score  \
0              GaussianNB  0.606358   0.606358  0.606358           0   
3    ExtraTreesClassifier  0.654158    0.92599  0.985452   0.0714683   
6      AdaBoostClassifier  0.897703   0.956345  0.988368   0.0187167   
7                     SVC         0   0.784311  0.988263    0.233712   
4  RandomForestClassifier  0.842101   0.949694   0.97961   0.0293754   
5           MLPClassifier  0.953454   0.965182  0.973808  0.00474433   
8        VotingClassifier  0.869137   0.920958  0.954126   0.0194563   
9    KNeighborsClassifier  0.822587   0.891651  0.944195   0.0336181   
1      LogisticRegression  0.509593   0.754886  0.931865    0.129704   
2           SGDClassifier -0.168783   0.582548  0.914224    0.233363   

        acc       auc           conf_matrix     f1_c0      f1_c1      kappa  \
0  0.550676  0.525685  [[161, 131], [2, 2]]  0.707692  0.0291971  0.0030389   
3  0.976351  0.494863    [[289, 3], [4, 0]]  0.988034          0 -0.0117188   
6  0.976351  0.494863    [[289, 3], [4, 0]]  0.988034          0 -0.0117188   
7  0.976351  0.494863    [[289, 3], [4, 0]]  0.988034          0 -0.0117188   
4  0.966216  0.489726    [[286, 6], [4, 0]]  0.982818          0 -0.0164835   
5  0.956081  0.484589    [[283, 9], [4, 0]]  0.977547          0 -0.0190678   
8  0.935811  0.474315   [[277, 15], [4, 0]]  0.966841          0 -0.0218023   
9  0.912162  0.462329   [[270, 22], [4, 0]]  0.954064          0 -0.0234043   
1   0.89527  0.453767   [[265, 27], [4, 0]]  0.944742          0 -0.0241071   
2  0.827703  0.419521   [[245, 47], [4, 0]]   0.90573          0 -0.0255435   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
0   0.0119237   0.98773  0.0150376   0.55137    0.5  
3  -0.0118431  0.986348          0  0.989726      0  
6  -0.0118431  0.986348          0  0.989726      0  
7  -0.0118431  0.986348          0  0.989726      0  
4  -0.0168351  0.986207          0  0.979452      0  
5  -0.0207262  0.986063          0  0.969178      0  
8  -0.0270415  0.985765          0   0.94863      0  
9  -0.0331646  0.985401          0  0.924658      0  
1  -0.0370804   0.98513          0  0.907534      0  
2  -0.0508496  0.983936          0  0.839041      0  
Elapsed time 62.21 mins 

************************************************************

pre/post: 25/0  win/stride: 500/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-22 07:06:16.725000 
pca_target: 0 	 poly degree: 2 	 kselect: 100 
Imbalance: None 
Extended target (count):  25141 13
('Total : Processed (count): ', (986L, 24976L), 13)
Final feature (count):  (986L, 24976L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.895 	-0.037 	-0.024 	0.454 	0.000 	0.000
[[265  27]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.91      0.94       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.90      0.93       296


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.001, class_weight={1: 3}, dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.642 	-0.025 	-0.008 	0.449 	0.402 	0.155
[[189 103]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.98      0.65      0.78       292
        1.0       0.01      0.25      0.02         4

avg / total       0.97      0.64      0.77       296


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=1, average=False, class_weight={1: 15}, epsilon=0.1,
       eta0=0.001, fit_intercept=True, l1_ratio=0.15,
       learning_rate='constant', loss='squared_hinge', n_iter=5, n_jobs=4,
       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.970 	-0.015 	-0.015 	0.491 	0.000 	0.000
[[287   5]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.98      0.98       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.97      0.97       296


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 500},
           criterion='entropy', max_depth=8, max_features=0.75,
           max_leaf_nodes=None, min_impurity_split=1e-07,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=4,
           oob_score=False, random_state=None, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.902 	-0.036 	-0.024 	0.457 	0.000 	0.000
[[267  25]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.91      0.95       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.90      0.94       296


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.5, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(500,), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.976 	-0.012 	-0.012 	0.495 	0.000 	0.000
[[289   3]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.97       296


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 50}, criterion='gini', max_depth=32,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=2.0, n_estimators=50, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.973 	-0.014 	-0.014 	0.493 	0.000 	0.000
[[288   4]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.97      0.97       296


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.01, cache_size=200, class_weight={1: 500}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.372 	0.087 	0.015 	0.682 	0.603 	0.386
[[106 186]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.36      0.53       292
        1.0       0.02      1.00      0.04         4

avg / total       0.99      0.37      0.53       296


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=1,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


                estimator   min_score   mean_score  max_score    sd_score  \
7                     SVC  -0.0331853  0.000467061  0.0827741    0.016549   
4  RandomForestClassifier  -0.0109191 -0.000320469          0  0.00108883   
8        VotingClassifier -0.00669156  -0.00166746          0  0.00178443   
9    KNeighborsClassifier  -0.0103989  -0.00235963          0  0.00411199   
5           MLPClassifier  -0.0170636   -0.0106012 -0.0033136  0.00352392   
6      AdaBoostClassifier  -0.0196508   0.00637755   0.173782   0.0341137   
2           SGDClassifier   -0.125025    0.0365873   0.210468   0.0434714   
3    ExtraTreesClassifier   -0.036358   0.00438403   0.163189   0.0228932   
0              GaussianNB  -0.0494879   -0.0494879 -0.0494879           0   
1      LogisticRegression  -0.0968045    0.0180285   0.146101   0.0412285   

        acc       auc           conf_matrix     f1_c0      f1_c1       kappa  \
7  0.371622  0.681507  [[106, 186], [0, 4]]  0.532663  0.0412371   0.0151689   
4  0.986486       0.5    [[292, 0], [4, 0]]  0.993197          0           0   
8  0.986486       0.5    [[292, 0], [4, 0]]  0.993197          0           0   
9  0.986486       0.5    [[292, 0], [4, 0]]  0.993197          0           0   
5  0.976351  0.494863    [[289, 3], [4, 0]]  0.988034          0  -0.0117188   
6  0.972973  0.493151    [[288, 4], [4, 0]]  0.986301          0  -0.0136986   
2  0.969595  0.491438    [[287, 5], [4, 0]]  0.984563          0  -0.0152439   
3  0.902027  0.457192   [[267, 25], [4, 0]]   0.94849          0   -0.023855   
0   0.89527  0.453767   [[265, 27], [4, 0]]  0.944742          0  -0.0241071   
1  0.641892   0.44863  [[189, 103], [3, 1]]  0.780992  0.0185185 -0.00770812   

  model_score   prec_c0     prec_c1    rec_c0 rec_c1  
7   0.0874208         1   0.0210526  0.363014      1  
4           0  0.986486           0         1      0  
8           0  0.986486           0         1      0  
9           0  0.986486           0         1      0  
5  -0.0118431  0.986348           0  0.989726      0  
6  -0.0136986  0.986301           0  0.986301      0  
2  -0.0153418  0.986254           0  0.982877      0  
3  -0.0355487   0.98524           0  0.914384      0  
0  -0.0370804   0.98513           0  0.907534      0  
1  -0.0248481  0.984375  0.00961538   0.64726   0.25  
Elapsed time 25.00 mins 

************************************************************

pre/post: 25/0  win/stride: 500/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-22 07:31:16.961000 
pca_target: 100 	 poly degree: 0 	 kselect: 40 
Imbalance: ClusterCentroids(estimator=None, n_jobs=1, random_state=None, ratio='auto') 
Extended target (count):  25141 13
('Total : Processed (count): ', (986L, 222L), 13)
Final feature (count):  (986L, 222L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.014 	0.000 	0.000 	0.500 	0.000 	0.000
[[  0 292]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       0.00      0.00      0.00       292
        1.0       0.01      1.00      0.03         4

avg / total       0.00      0.01      0.00       296


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=5, class_weight={1: 50}, dual=False, fit_intercept=True,
          intercept_scaling=0.1, max_iter=100, multi_class='ovr', n_jobs=4,
          penalty='l2', random_state=None, solver='sag', tol=0.0001,
          verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.490 	0.112 	0.025 	0.741 	0.695 	0.508
[[141 151]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.48      0.65       292
        1.0       0.03      1.00      0.05         4

avg / total       0.99      0.49      0.64       296


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.1, average=False, class_weight='balanced', epsilon=0.1,
       eta0=0.001, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='modified_huber', n_iter=5, n_jobs=4,
       penalty='l2', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.497 	-0.058 	-0.013 	0.375 	0.354 	0.122
[[146 146]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.98      0.50      0.66       292
        1.0       0.01      0.25      0.01         4

avg / total       0.97      0.50      0.65       296


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3},
           criterion='entropy', max_depth=16, max_features=0.33,
           max_leaf_nodes=None, min_impurity_split=1e-07,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=15, n_jobs=4,
           oob_score=False, random_state=None, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.561 	0.014 	0.004 	0.531 	0.530 	0.279
[[164 128]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      0.56      0.72       292
        1.0       0.02      0.50      0.03         4

avg / total       0.97      0.56      0.71       296


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=16, max_features=0.33, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=50, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.544 	0.010 	0.003 	0.522 	0.522 	0.271
[[159 133]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      0.54      0.70       292
        1.0       0.01      0.50      0.03         4

avg / total       0.97      0.54      0.69       296


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.514 	0.003 	0.001 	0.507 	0.507 	0.256
[[150 142]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      0.51      0.68       292
        1.0       0.01      0.50      0.03         4

avg / total       0.97      0.51      0.67       296


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 500}, criterion='entropy',
            max_depth=4, max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=0.5, n_estimators=15, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.774 	-0.061 	-0.026 	0.392 	0.000 	0.000
[[229  63]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.98      0.78      0.87       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.77      0.86       296


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='linear',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.429 	-0.074 	-0.015 	0.341 	0.328 	0.106
[[126 166]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.98      0.43      0.60       292
        1.0       0.01      0.25      0.01         4

avg / total       0.96      0.43      0.59       296


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', R...wski',
           metric_params=None, n_jobs=4, n_neighbors=4, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.490 	-0.116 	-0.027 	0.248 	0.000 	0.000
[[145 147]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.97      0.50      0.66       292
        1.0       0.00      0.00      0.00         4

avg / total       0.96      0.49      0.65       296


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=5, p=1,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.851 	0.036 	0.019 	0.555 	0.464 	0.202
[[251  41]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.86      0.92       292
        1.0       0.02      0.25      0.04         4

avg / total       0.98      0.85      0.91       296


                estimator  min_score mean_score max_score   sd_score  \
1      LogisticRegression  -0.367711  0.0451675  0.367711   0.133277   
9    KNeighborsClassifier  -0.367711  0.0799699  0.589933   0.244845   
3    ExtraTreesClassifier   0.333333    0.71987         1   0.113948   
4  RandomForestClassifier     0.2566   0.728074         1   0.127211   
5           MLPClassifier   0.111111     0.2627  0.555556  0.0915502   
0              GaussianNB   0.812156   0.812156  0.812156          0   
6      AdaBoostClassifier -0.0939222   0.669411         1   0.139857   
2           SGDClassifier  -0.794967  0.0972499  0.683856   0.152513   
7                     SVC  -0.239411  0.0659419  0.350522   0.124799   
8        VotingClassifier    -0.1283   0.265927  0.718234   0.151942   

         acc       auc           conf_matrix     f1_c0      f1_c1  \
1   0.489865  0.741438  [[141, 151], [0, 4]]   0.65127  0.0503145   
9   0.851351  0.554795   [[251, 41], [3, 1]]  0.919414  0.0434783   
3   0.560811  0.530822  [[164, 128], [2, 2]]  0.716157  0.0298507   
4   0.543919   0.52226  [[159, 133], [2, 2]]  0.701987   0.028777   
5   0.513514  0.506849  [[150, 142], [2, 2]]  0.675676   0.027027   
0  0.0135135       0.5    [[0, 292], [0, 4]]         0  0.0266667   
6   0.773649  0.392123   [[229, 63], [4, 0]]  0.872381          0   
2   0.496622     0.375  [[146, 146], [3, 1]]  0.662132   0.013245   
7   0.429054  0.340753  [[126, 166], [3, 1]]  0.598575  0.0116959   
8   0.489865  0.248288  [[145, 147], [4, 0]]  0.657596          0   

         kappa model_score   prec_c0     prec_c1    rec_c0 rec_c1  
1    0.0246159     0.11163         1   0.0258065  0.482877      1  
9    0.0192771   0.0362616  0.988189   0.0238095  0.859589   0.25  
3   0.00372825   0.0143412  0.987952   0.0153846  0.561644    0.5  
4   0.00259585   0.0103205  0.987578   0.0148148  0.544521    0.5  
5  0.000750188  0.00316443  0.986842   0.0138889  0.513699    0.5  
0            0           0         0   0.0135135         0      1  
6   -0.0260762  -0.0608599  0.982833           0  0.784247      0  
2   -0.0134191  -0.0577311  0.979866  0.00680272       0.5   0.25  
7   -0.0150974  -0.0741598  0.976744  0.00598802  0.431507   0.25  
8   -0.0270221   -0.116253  0.973154           0  0.496575      0  
Elapsed time 14.11 mins 

************************************************************

pre/post: 25/0  win/stride: 500/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-22 07:45:23.857000 
pca_target: 100 	 poly degree: 0 	 kselect: 40 
Imbalance: SMOTE(k=None, k_neighbors=5, kind='regular', m=None, m_neighbors=10, n_jobs=1,
   out_step=0.5, random_state=None, ratio='auto', svm_estimator=None) 
Extended target (count):  25141 13
('Total : Processed (count): ', (986L, 222L), 13)
Final feature (count):  (986L, 222L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=5, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=5, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.949 	-0.023 	-0.020 	0.481 	0.000 	0.000
[[281  11]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.96      0.97       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.95      0.96       296


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.001, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.001, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='modified_huber', n_iter=5, n_jobs=4,
       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.973 	-0.014 	-0.014 	0.493 	0.000 	0.000
[[288   4]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.97      0.97       296


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=8, max_features='auto', max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.1, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(500,), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=0.5, n_estimators=15, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.01, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=10.0, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', ...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.973 	-0.014 	-0.014 	0.493 	0.000 	0.000
[[288   4]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.97      0.97       296


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=1,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.936 	-0.027 	-0.022 	0.474 	0.000 	0.000
[[277  15]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.95      0.97       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.94      0.95       296


                estimator min_score mean_score max_score     sd_score  \
0              GaussianNB         1          1         1            0   
3    ExtraTreesClassifier  0.998537   0.999927         1  0.000318869   
4  RandomForestClassifier  0.995611   0.999902         1  0.000452082   
5           MLPClassifier  0.959777   0.982572         1    0.0115591   
6      AdaBoostClassifier  0.938833   0.984171         1    0.0136066   
7                     SVC         0   0.836766         1     0.321833   
2           SGDClassifier         0   0.674935  0.992685     0.295352   
8        VotingClassifier  0.895524   0.952334  0.976908    0.0189612   
1      LogisticRegression  0.182164   0.850103  0.969754     0.166617   
9    KNeighborsClassifier  0.461138   0.662127   0.84998     0.127835   

        acc       auc          conf_matrix     f1_c0 f1_c1      kappa  \
0  0.986486       0.5   [[292, 0], [4, 0]]  0.993197     0          0   
3  0.986486       0.5   [[292, 0], [4, 0]]  0.993197     0          0   
4  0.986486       0.5   [[292, 0], [4, 0]]  0.993197     0          0   
5  0.986486       0.5   [[292, 0], [4, 0]]  0.993197     0          0   
6  0.986486       0.5   [[292, 0], [4, 0]]  0.993197     0          0   
7  0.986486       0.5   [[292, 0], [4, 0]]  0.993197     0          0   
2  0.972973  0.493151   [[288, 4], [4, 0]]  0.986301     0 -0.0136986   
8  0.972973  0.493151   [[288, 4], [4, 0]]  0.986301     0 -0.0136986   
1  0.949324  0.481164  [[281, 11], [4, 0]]  0.974003     0 -0.0202206   
9  0.935811  0.474315  [[277, 15], [4, 0]]  0.966841     0 -0.0218023   

  model_score   prec_c0 prec_c1    rec_c0 rec_c1  
0           0  0.986486       0         1      0  
3           0  0.986486       0         1      0  
4           0  0.986486       0         1      0  
5           0  0.986486       0         1      0  
6           0  0.986486       0         1      0  
7           0  0.986486       0         1      0  
2  -0.0136986  0.986301       0  0.986301      0  
8  -0.0136986  0.986301       0  0.986301      0  
1  -0.0229939  0.985965       0  0.962329      0  
9  -0.0270415  0.985765       0   0.94863      0  
Elapsed time 45.14 mins 

************************************************************

pre/post: 25/0  win/stride: 500/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-22 08:30:32.058000 
pca_target: 100 	 poly degree: 0 	 kselect: 40 
Imbalance: None 
Extended target (count):  25141 13
('Total : Processed (count): ', (986L, 222L), 13)
Final feature (count):  (986L, 222L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.885 	0.053 	0.032 	0.572 	0.473 	0.209
[[261  31]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.89      0.94       292
        1.0       0.03      0.25      0.06         4

avg / total       0.98      0.89      0.93       296


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=5, class_weight={1: 500}, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=4,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.926 	-0.030 	-0.023 	0.469 	0.000 	0.000
[[274  18]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.94      0.96       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.93      0.95       296


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.0001, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='perceptron', n_iter=5, n_jobs=4,
       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.943 	-0.025 	-0.021 	0.478 	0.000 	0.000
[[279  13]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.96      0.97       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.94      0.96       296


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=8, max_features='auto', max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.973 	-0.014 	-0.014 	0.493 	0.000 	0.000
[[288   4]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.97      0.97       296


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight='balanced', criterion='gini', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=2.0, n_estimators=50, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='linear',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.949 	-0.023 	-0.020 	0.481 	0.000 	0.000
[[281  11]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.96      0.97       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.95      0.96       296


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...owski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='uniform'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=1,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


                estimator   min_score   mean_score   max_score     sd_score  \
0              GaussianNB  0.00725214   0.00725214  0.00725214            0   
3    ExtraTreesClassifier  -0.0215403 -0.000471109           0   0.00202963   
4  RandomForestClassifier -0.00207196 -2.30218e-05           0  0.000217187   
6      AdaBoostClassifier  -0.0226578  -0.00708842    0.176723    0.0191761   
8        VotingClassifier  -0.0114862  -0.00210137           0   0.00258885   
9    KNeighborsClassifier  -0.0174841  -0.00423982           0   0.00734574   
5           MLPClassifier  -0.0173225  -0.00310989    0.134348    0.0203507   
7                     SVC  -0.0129676  -0.00105901   0.0701063    0.0121444   
2           SGDClassifier   -0.133904    0.0161447     0.21283    0.0348103   
1      LogisticRegression  -0.0476381    0.0128784    0.103717    0.0303934   

        acc       auc          conf_matrix     f1_c0      f1_c1      kappa  \
0  0.885135  0.571918  [[261, 31], [3, 1]]  0.938849  0.0555556  0.0323077   
3  0.986486       0.5   [[292, 0], [4, 0]]  0.993197          0          0   
4  0.986486       0.5   [[292, 0], [4, 0]]  0.993197          0          0   
6  0.986486       0.5   [[292, 0], [4, 0]]  0.993197          0          0   
8  0.986486       0.5   [[292, 0], [4, 0]]  0.993197          0          0   
9  0.986486       0.5   [[292, 0], [4, 0]]  0.993197          0          0   
5  0.972973  0.493151   [[288, 4], [4, 0]]  0.986301          0 -0.0136986   
7  0.949324  0.481164  [[281, 11], [4, 0]]  0.974003          0 -0.0202206   
2  0.942568   0.47774  [[279, 13], [4, 0]]  0.970435          0 -0.0211039   
1  0.925676  0.469178  [[274, 18], [4, 0]]  0.961404          0 -0.0226131   

  model_score   prec_c0  prec_c1    rec_c0 rec_c1  
0   0.0534824  0.988636  0.03125  0.893836   0.25  
3           0  0.986486        0         1      0  
4           0  0.986486        0         1      0  
6           0  0.986486        0         1      0  
8           0  0.986486        0         1      0  
9           0  0.986486        0         1      0  
5  -0.0136986  0.986301        0  0.986301      0  
7  -0.0229939  0.985965        0  0.962329      0  
2  -0.0250852  0.985866        0  0.955479      0  
1  -0.0297819  0.985612        0  0.938356      0  
Elapsed time 28.46 mins 

************************************************************

pre/post: 25/0  win/stride: 500/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-22 08:58:59.555000 
pca_target: 100 	 poly degree: 0 	 kselect: 80 
Imbalance: ClusterCentroids(estimator=None, n_jobs=1, random_state=None, ratio='auto') 
Extended target (count):  25141 13
('Total : Processed (count): ', (986L, 222L), 13)
Final feature (count):  (986L, 222L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=1, class_weight={1: 500}, dual=False, fit_intercept=True,
          intercept_scaling=0.1, max_iter=100, multi_class='ovr', n_jobs=4,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.483 	-0.061 	-0.014 	0.368 	0.349 	0.119
[[142 150]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.98      0.49      0.65       292
        1.0       0.01      0.25      0.01         4

avg / total       0.97      0.48      0.64       296


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.5, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='squared_hinge', n_iter=5, n_jobs=4,
       penalty='l2', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.500 	0.057 	0.013 	0.623 	0.610 	0.382
[[145 147]
 [  1   3]]
             precision    recall  f1-score   support

        0.0       0.99      0.50      0.66       292
        1.0       0.02      0.75      0.04         4

avg / total       0.98      0.50      0.65       296


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=8, max_features=0.75, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.483 	-0.004 	-0.001 	0.491 	0.491 	0.242
[[141 151]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      0.48      0.65       292
        1.0       0.01      0.50      0.03         4

avg / total       0.97      0.48      0.64       296


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 15}, criterion='gini',
            max_depth=16, max_features=0.75, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.598 	-0.035 	-0.010 	0.426 	0.388 	0.145
[[176 116]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.98      0.60      0.75       292
        1.0       0.01      0.25      0.02         4

avg / total       0.97      0.60      0.74       296


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.500 	-0.000 	0.000 	0.500 	0.500 	0.250
[[146 146]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      0.50      0.66       292
        1.0       0.01      0.50      0.03         4

avg / total       0.97      0.50      0.66       296


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='entropy', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=0.5, n_estimators=80, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.443 	-0.071 	-0.015 	0.348 	0.334 	0.109
[[130 162]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.98      0.45      0.61       292
        1.0       0.01      0.25      0.01         4

avg / total       0.96      0.44      0.60       296


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='linear',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.524 	0.006 	0.001 	0.512 	0.512 	0.261
[[153 139]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      0.52      0.68       292
        1.0       0.01      0.50      0.03         4

avg / total       0.97      0.52      0.68       296


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=1.0, class_weight={1: 500}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Ran...wski',
           metric_params=None, n_jobs=4, n_neighbors=4, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.497 	0.113 	0.025 	0.745 	0.700 	0.515
[[143 149]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.49      0.66       292
        1.0       0.03      1.00      0.05         4

avg / total       0.99      0.50      0.65       296


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=1,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.885 	-0.039 	-0.024 	0.449 	0.000 	0.000
[[262  30]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.98      0.90      0.94       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.89      0.93       296


                estimator min_score  mean_score max_score  sd_score       acc  \
8        VotingClassifier -0.367711   0.0969013  0.496011  0.166237  0.496622   
2           SGDClassifier -0.701045    0.136775  0.589933  0.163678       0.5   
7                     SVC   -0.3849   0.0676104  0.239411    0.1676  0.523649   
0              GaussianNB  0.906078    0.906078  0.906078         0  0.986486   
5           MLPClassifier         0    0.321747  0.589933  0.125062       0.5   
3    ExtraTreesClassifier  0.205033    0.634512  0.906078  0.122334  0.483108   
9    KNeighborsClassifier -0.478822 -0.00234053    0.2566  0.212216  0.885135   
4  RandomForestClassifier         0    0.502136  0.906078  0.159517  0.597973   
1      LogisticRegression   -0.1283    0.180523  0.589933  0.163957  0.483108   
6      AdaBoostClassifier -0.145489    0.433905  0.906078  0.204756  0.442568   

        auc           conf_matrix     f1_c0      f1_c1        kappa  \
8  0.744863  [[143, 149], [0, 4]]  0.657471  0.0509554    0.0252829   
2  0.623288  [[145, 147], [1, 3]]    0.6621   0.038961    0.0129776   
7  0.511986  [[153, 139], [2, 2]]  0.684564  0.0275862   0.00133997   
0       0.5    [[292, 0], [4, 0]]  0.993197          0            0   
5       0.5  [[146, 146], [2, 2]]  0.663636  0.0263158            0   
3  0.491438  [[141, 151], [2, 2]]  0.648276  0.0254777 -0.000884017   
9   0.44863   [[262, 30], [4, 0]]  0.939068          0     -0.02443   
4   0.42637  [[176, 116], [3, 1]]  0.747346  0.0165289  -0.00986239   
1  0.368151  [[142, 150], [3, 1]]  0.649886  0.0129032   -0.0137894   
6  0.347603  [[130, 162], [3, 1]]  0.611765   0.011976   -0.0147939   

   model_score   prec_c0     prec_c1    rec_c0 rec_c1  
8     0.113152         1   0.0261438  0.489726      1  
2    0.0569441  0.993151        0.02  0.496575   0.75  
7   0.00554193  0.987097   0.0141844  0.523973    0.5  
0            0  0.986486           0         1      0  
5 -3.24854e-18  0.986486   0.0135135       0.5    0.5  
3  -0.00395635  0.986014   0.0130719  0.482877    0.5  
9    -0.039306  0.984962           0   0.89726      0  
4   -0.0347766   0.98324  0.00854701   0.60274   0.25  
1   -0.0609055   0.97931  0.00662252  0.486301   0.25  
6   -0.0707472  0.977444  0.00613497  0.445205   0.25  
Elapsed time 28.73 mins 

************************************************************

pre/post: 25/0  win/stride: 500/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-22 09:27:43.508000 
pca_target: 100 	 poly degree: 0 	 kselect: 80 
Imbalance: SMOTE(k=None, k_neighbors=5, kind='regular', m=None, m_neighbors=10, n_jobs=1,
   out_step=0.5, random_state=None, ratio='auto', svm_estimator=None) 
Extended target (count):  25141 13
('Total : Processed (count): ', (986L, 222L), 13)
Final feature (count):  (986L, 222L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=5, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=5, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.949 	-0.023 	-0.020 	0.481 	0.000 	0.000
[[281  11]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.96      0.97       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.95      0.96       296


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.0001, average=False, class_weight='balanced',
       epsilon=0.1, eta0=0.001, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='squared_hinge', n_iter=5, n_jobs=4,
       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.970 	-0.015 	-0.015 	0.491 	0.000 	0.000
[[287   5]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.98      0.98       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.97      0.97       296


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=8, max_features='auto', max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=30, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=0.5, n_estimators=50, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.1, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=10.0, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', ...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.973 	-0.014 	-0.014 	0.493 	0.000 	0.000
[[288   4]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.97      0.97       296


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=1,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.932 	-0.028 	-0.022 	0.473 	0.000 	0.000
[[276  16]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.95      0.97       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.93      0.95       296


                estimator min_score mean_score max_score     sd_score  \
0              GaussianNB  0.998537   0.998537  0.998537            0   
3    ExtraTreesClassifier  0.997074   0.999955         1  0.000274408   
4  RandomForestClassifier  0.997074   0.999374         1  0.000779006   
5           MLPClassifier  0.962613   0.981828  0.997074     0.010001   
6      AdaBoostClassifier  0.936499   0.985473         1     0.011068   
7                     SVC         0   0.831233         1     0.322083   
8        VotingClassifier  0.900796   0.952743   0.97836    0.0181297   
2           SGDClassifier  -0.15268   0.665098  0.994148     0.294095   
1      LogisticRegression  0.204513   0.855897  0.969754     0.152064   
9    KNeighborsClassifier  0.466966   0.681369  0.890302     0.129242   

        acc       auc          conf_matrix     f1_c0 f1_c1      kappa  \
0  0.986486       0.5   [[292, 0], [4, 0]]  0.993197     0          0   
3  0.986486       0.5   [[292, 0], [4, 0]]  0.993197     0          0   
4  0.986486       0.5   [[292, 0], [4, 0]]  0.993197     0          0   
5  0.986486       0.5   [[292, 0], [4, 0]]  0.993197     0          0   
6  0.986486       0.5   [[292, 0], [4, 0]]  0.993197     0          0   
7  0.986486       0.5   [[292, 0], [4, 0]]  0.993197     0          0   
8  0.972973  0.493151   [[288, 4], [4, 0]]  0.986301     0 -0.0136986   
2  0.969595  0.491438   [[287, 5], [4, 0]]  0.984563     0 -0.0152439   
1  0.949324  0.481164  [[281, 11], [4, 0]]  0.974003     0 -0.0202206   
9  0.932432  0.472603  [[276, 16], [4, 0]]  0.965035     0 -0.0220994   

  model_score   prec_c0 prec_c1    rec_c0 rec_c1  
0           0  0.986486       0         1      0  
3           0  0.986486       0         1      0  
4           0  0.986486       0         1      0  
5           0  0.986486       0         1      0  
6           0  0.986486       0         1      0  
7           0  0.986486       0         1      0  
8  -0.0136986  0.986301       0  0.986301      0  
2  -0.0153418  0.986254       0  0.982877      0  
1  -0.0229939  0.985965       0  0.962329      0  
9  -0.0279782  0.985714       0  0.945205      0  
Elapsed time 99.45 mins 

************************************************************

pre/post: 25/0  win/stride: 500/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-22 11:07:10.455000 
pca_target: 100 	 poly degree: 0 	 kselect: 80 
Imbalance: None 
Extended target (count):  25141 13
('Total : Processed (count): ', (986L, 222L), 13)
Final feature (count):  (986L, 222L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.801 	0.017 	0.008 	0.529 	0.450 	0.191
[[236  56]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.81      0.89       292
        1.0       0.02      0.25      0.03         4

avg / total       0.97      0.80      0.88       296


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.1, class_weight={1: 500}, dual=False,
          fit_intercept=True, intercept_scaling=10, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.939 	-0.026 	-0.021 	0.476 	0.000 	0.000
[[278  14]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.95      0.97       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.94      0.96       296


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.001, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='modified_huber', n_iter=5, n_jobs=4,
       penalty='l1', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.973 	-0.014 	-0.014 	0.493 	0.000 	0.000
[[288   4]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.97      0.97       296


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 500}, criterion='gini',
           max_depth=8, max_features='auto', max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=30, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.966 	-0.017 	-0.016 	0.490 	0.000 	0.000
[[286   6]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.98      0.98       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.97      0.97       296


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.01, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight='balanced', criterion='entropy',
            max_depth=4, max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=2.0, n_estimators=80, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.959 	-0.020 	-0.018 	0.486 	0.000 	0.000
[[284   8]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.97      0.98       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.96      0.97       296


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='linear',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.953 	-0.022 	-0.020 	0.483 	0.000 	0.000
[[282  10]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.97      0.98       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.95      0.96       296


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=1,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


                estimator   min_score   mean_score  max_score     sd_score  \
0              GaussianNB   0.0781352    0.0781352  0.0781352            0   
4  RandomForestClassifier -0.00207196 -1.72663e-05          0  0.000188353   
5           MLPClassifier  -0.0151553   0.00123861  0.0911871    0.0212413   
8        VotingClassifier -0.00854504  -0.00167258          0   0.00209147   
9    KNeighborsClassifier  -0.0174219  -0.00403534          0   0.00700183   
2           SGDClassifier  -0.0805552    0.0145928   0.197018    0.0326482   
3    ExtraTreesClassifier  -0.0183339 -0.000225495  0.0605332   0.00362816   
6      AdaBoostClassifier  -0.0207258  -0.00709634   0.189053    0.0216068   
7                     SVC  -0.0130296  -0.00106456  0.0700444    0.0121364   
1      LogisticRegression  -0.0413447    0.0146371  0.0992138    0.0301915   

        acc       auc          conf_matrix     f1_c0      f1_c1       kappa  \
0  0.800676   0.52911  [[236, 56], [3, 1]]  0.888889  0.0327869  0.00772727   
4  0.986486       0.5   [[292, 0], [4, 0]]  0.993197          0           0   
5  0.986486       0.5   [[292, 0], [4, 0]]  0.993197          0           0   
8  0.986486       0.5   [[292, 0], [4, 0]]  0.993197          0           0   
9  0.986486       0.5   [[292, 0], [4, 0]]  0.993197          0           0   
2  0.972973  0.493151   [[288, 4], [4, 0]]  0.986301          0  -0.0136986   
3  0.966216  0.489726   [[286, 6], [4, 0]]  0.982818          0  -0.0164835   
6  0.959459  0.486301   [[284, 8], [4, 0]]   0.97931          0  -0.0183486   
7  0.952703  0.482877  [[282, 10], [4, 0]]  0.975779          0   -0.019685   
1  0.939189  0.476027  [[278, 14], [4, 0]]  0.968641          0  -0.0214724   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
0   0.0170471  0.987448  0.0175439  0.808219   0.25  
4           0  0.986486          0         1      0  
5           0  0.986486          0         1      0  
8           0  0.986486          0         1      0  
9           0  0.986486          0         1      0  
2  -0.0136986  0.986301          0  0.986301      0  
3  -0.0168351  0.986207          0  0.979452      0  
6  -0.0195069  0.986111          0  0.972603      0  
7  -0.0218855  0.986014          0  0.965753      0  
1  -0.0260782  0.985816          0  0.952055      0  
Elapsed time 54.75 mins 

************************************************************

pre/post: 25/0  win/stride: 500/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-22 12:01:55.313000 
pca_target: 100 	 poly degree: 0 	 kselect: 100 
Imbalance: ClusterCentroids(estimator=None, n_jobs=1, random_state=None, ratio='auto') 
Extended target (count):  25141 13
('Total : Processed (count): ', (986L, 222L), 13)
Final feature (count):  (986L, 222L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=10, class_weight={1: 500}, dual=False,
          fit_intercept=True, intercept_scaling=5, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='sag', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.483 	-0.118 	-0.027 	0.245 	0.000 	0.000
[[143 149]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.97      0.49      0.65       292
        1.0       0.00      0.00      0.00         4

avg / total       0.96      0.48      0.64       296


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.0001, average=False, class_weight={1: 15}, epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='constant', loss='squared_hinge', n_iter=5, n_jobs=4,
       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.466 	-0.008 	-0.002 	0.483 	0.483 	0.234
[[136 156]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      0.47      0.63       292
        1.0       0.01      0.50      0.02         4

avg / total       0.97      0.47      0.62       296


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=8, max_features=0.75, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=50, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.510 	0.059 	0.014 	0.628 	0.617 	0.389
[[148 144]
 [  1   3]]
             precision    recall  f1-score   support

        0.0       0.99      0.51      0.67       292
        1.0       0.02      0.75      0.04         4

avg / total       0.98      0.51      0.66       296


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 50},
            criterion='entropy', max_depth=16, max_features=0.33,
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.689 	-0.014 	-0.005 	0.473 	0.417 	0.166
[[203  89]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.70      0.82       292
        1.0       0.01      0.25      0.02         4

avg / total       0.97      0.69      0.80       296


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.01, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.534 	0.122 	0.029 	0.764 	0.726 	0.552
[[154 138]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.53      0.69       292
        1.0       0.03      1.00      0.05         4

avg / total       0.99      0.53      0.68       296


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=0.5, n_estimators=15, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.507 	0.115 	0.026 	0.750 	0.707 	0.525
[[146 146]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.50      0.67       292
        1.0       0.03      1.00      0.05         4

avg / total       0.99      0.51      0.66       296


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.1, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='linear',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.557 	-0.044 	-0.011 	0.406 	0.375 	0.136
[[164 128]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.98      0.56      0.71       292
        1.0       0.01      0.25      0.02         4

avg / total       0.97      0.56      0.71       296


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', R...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.568 	0.130 	0.033 	0.781 	0.749 	0.586
[[164 128]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.56      0.72       292
        1.0       0.03      1.00      0.06         4

avg / total       0.99      0.57      0.71       296


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=3, p=1,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.821 	0.024 	0.012 	0.539 	0.455 	0.195
[[242  50]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.83      0.90       292
        1.0       0.02      0.25      0.04         4

avg / total       0.97      0.82      0.89       296


                estimator  min_score   mean_score max_score  sd_score  \
8        VotingClassifier  -0.350522    0.0356416  0.350522    0.1363   
5           MLPClassifier  0.0171889     0.406424  0.718234  0.145151   
6      AdaBoostClassifier  -0.239411     0.531174  0.906078   0.22419   
3    ExtraTreesClassifier   0.145489      0.80431         1  0.148445   
9    KNeighborsClassifier  -0.496011    -0.106533  0.367711  0.237908   
0              GaussianNB   0.906078     0.906078  0.906078         0   
2           SGDClassifier  -0.496011     0.114624  0.589933  0.153962   
4  RandomForestClassifier    -0.1283     0.562142         1   0.18438   
7                     SVC  -0.478822 -0.000921153  0.205033  0.204647   
1      LogisticRegression    -0.1283     0.200986  0.607122   0.18758   

        acc       auc           conf_matrix     f1_c0      f1_c1       kappa  \
8  0.567568  0.780822  [[164, 128], [0, 4]]  0.719298  0.0588235   0.0334694   
5  0.533784  0.763699  [[154, 138], [0, 4]]  0.690583  0.0547945   0.0292776   
6  0.506757      0.75  [[146, 146], [0, 4]]  0.666667  0.0519481   0.0263158   
3  0.510135  0.628425  [[148, 144], [1, 3]]  0.671202  0.0397351   0.0137868   
9  0.820946  0.539384   [[242, 50], [3, 1]]  0.901304  0.0363636   0.0115927   
0  0.986486       0.5    [[292, 0], [4, 0]]  0.993197          0           0   
2  0.466216  0.482877  [[136, 156], [2, 2]]  0.632558  0.0246914  -0.0017135   
4  0.689189  0.472603   [[203, 89], [3, 1]]  0.815261  0.0212766 -0.00472255   
7  0.557432  0.405822  [[164, 128], [3, 1]]  0.714597  0.0150376  -0.0114775   
1  0.483108  0.244863  [[143, 149], [4, 0]]  0.651481          0  -0.0270319   

  model_score   prec_c0     prec_c1    rec_c0 rec_c1  
8    0.130459         1    0.030303  0.561644      1  
5    0.121886         1    0.028169  0.527397      1  
6     0.11547         1   0.0266667       0.5      1  
3   0.0593127  0.993289   0.0204082  0.506849   0.75  
9   0.0240823  0.987755   0.0196078  0.828767   0.25  
0           0  0.986486           0         1      0  
2  -0.0079263  0.985507   0.0126582  0.465753    0.5  
4  -0.0137532  0.985437   0.0111111  0.695205   0.25  
7  -0.0438579  0.982036  0.00775194  0.561644   0.25  
1   -0.117835  0.972789           0  0.489726      0  
Elapsed time 29.23 mins 

************************************************************

pre/post: 25/0  win/stride: 500/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-22 12:31:09.112000 
pca_target: 100 	 poly degree: 0 	 kselect: 100 
Imbalance: SMOTE(k=None, k_neighbors=5, kind='regular', m=None, m_neighbors=10, n_jobs=1,
   out_step=0.5, random_state=None, ratio='auto', svm_estimator=None) 
Extended target (count):  25141 13
('Total : Processed (count): ', (986L, 222L), 13)
Final feature (count):  (986L, 222L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=10, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.956 	-0.021 	-0.019 	0.485 	0.000 	0.000
[[283   9]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.97      0.98       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.96      0.96       296


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.0001, average=False, class_weight='balanced',
       epsilon=0.1, eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='squared_hinge', n_iter=5, n_jobs=4,
       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.976 	-0.012 	-0.012 	0.495 	0.000 	0.000
[[289   3]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.97       296


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=8, max_features='auto', max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.980 	-0.010 	-0.009 	0.497 	0.000 	0.000
[[290   2]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.98       296


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=0.5, n_estimators=15, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.1, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=10.0, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', ...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.973 	-0.014 	-0.014 	0.493 	0.000 	0.000
[[288   4]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.97      0.97       296


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=1,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.946 	-0.024 	-0.021 	0.479 	0.000 	0.000
[[280  12]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.96      0.97       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.95      0.96       296


                estimator  min_score mean_score max_score    sd_score  \
0              GaussianNB   0.998537   0.998537  0.998537           0   
3    ExtraTreesClassifier   0.998537   0.999939         1  0.00029236   
4  RandomForestClassifier   0.989821   0.998845         1  0.00181519   
6      AdaBoostClassifier   0.876019   0.984782         1    0.014416   
7                     SVC          0   0.822979         1    0.326518   
5           MLPClassifier   0.965429   0.983844         1  0.00985244   
2           SGDClassifier -0.0777366   0.660891  0.991253    0.295319   
8        VotingClassifier   0.904918   0.955524  0.979792   0.0183443   
1      LogisticRegression    0.23026   0.861471  0.971148    0.143268   
9    KNeighborsClassifier   0.487833   0.698125  0.895589    0.124465   

        acc       auc          conf_matrix     f1_c0 f1_c1       kappa  \
0  0.986486       0.5   [[292, 0], [4, 0]]  0.993197     0           0   
3  0.986486       0.5   [[292, 0], [4, 0]]  0.993197     0           0   
4  0.986486       0.5   [[292, 0], [4, 0]]  0.993197     0           0   
6  0.986486       0.5   [[292, 0], [4, 0]]  0.993197     0           0   
7  0.986486       0.5   [[292, 0], [4, 0]]  0.993197     0           0   
5   0.97973  0.496575   [[290, 2], [4, 0]]  0.989761     0 -0.00909091   
2  0.976351  0.494863   [[289, 3], [4, 0]]  0.988034     0  -0.0117188   
8  0.972973  0.493151   [[288, 4], [4, 0]]  0.986301     0  -0.0136986   
1  0.956081  0.484589   [[283, 9], [4, 0]]  0.977547     0  -0.0190678   
9  0.945946  0.479452  [[280, 12], [4, 0]]  0.972222     0  -0.0206897   

  model_score   prec_c0 prec_c1    rec_c0 rec_c1  
0           0  0.986486       0         1      0  
3           0  0.986486       0         1      0  
4           0  0.986486       0         1      0  
6           0  0.986486       0         1      0  
7           0  0.986486       0         1      0  
5 -0.00965339  0.986395       0  0.993151      0  
2  -0.0118431  0.986348       0  0.989726      0  
8  -0.0136986  0.986301       0  0.986301      0  
1  -0.0207262  0.986063       0  0.969178      0  
9  -0.0240586  0.985915       0  0.958904      0  
Elapsed time 109.40 mins 

************************************************************

pre/post: 25/0  win/stride: 500/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-22 14:20:33.190000 
pca_target: 100 	 poly degree: 0 	 kselect: 100 
Imbalance: None 
Extended target (count):  25141 13
('Total : Processed (count): ', (986L, 222L), 13)
Final feature (count):  (986L, 222L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.818 	0.023 	0.011 	0.538 	0.454 	0.194
[[241  51]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.83      0.90       292
        1.0       0.02      0.25      0.04         4

avg / total       0.97      0.82      0.89       296


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=10, class_weight={1: 50}, dual=False, fit_intercept=True,
          intercept_scaling=5, max_iter=100, multi_class='ovr', n_jobs=4,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.953 	-0.022 	-0.020 	0.483 	0.000 	0.000
[[282  10]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.97      0.98       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.95      0.96       296


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.001, average=False, class_weight={1: 15}, epsilon=0.1,
       eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='squared_hinge', n_iter=5, n_jobs=4,
       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.956 	-0.021 	-0.019 	0.485 	0.000 	0.000
[[283   9]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.97      0.98       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.96      0.96       296


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 500}, criterion='gini',
           max_depth=8, max_features='auto', max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.899 	-0.036 	-0.024 	0.455 	0.000 	0.000
[[266  26]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.91      0.95       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.90      0.93       296


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.01, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.983 	-0.007 	-0.005 	0.498 	0.000 	0.000
[[291   1]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.98       296


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight='balanced', criterion='gini', max_depth=8,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=1.0, n_estimators=15, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='linear',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.953 	-0.022 	-0.020 	0.483 	0.000 	0.000
[[282  10]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.97      0.98       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.95      0.96       296


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.983 	-0.007 	-0.005 	0.498 	0.000 	0.000
[[291   1]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.98       296


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=1,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


                estimator   min_score   mean_score  max_score     sd_score  \
0              GaussianNB   0.0529304    0.0529304  0.0529304            0   
4  RandomForestClassifier -0.00294087 -1.96809e-05          0  0.000217923   
6      AdaBoostClassifier  -0.0206141  -0.00508684   0.140904    0.0251663   
9    KNeighborsClassifier  -0.0181588  -0.00429099          0   0.00744847   
5           MLPClassifier  -0.0136421    0.0023739   0.134844     0.025761   
8        VotingClassifier -0.00854519  -0.00161705          0   0.00214836   
2           SGDClassifier  -0.0981073     0.011464   0.168922     0.032145   
1      LogisticRegression  -0.0304924    0.0129559   0.131685    0.0300951   
7                     SVC  -0.0130296   -0.0010305  0.0727908    0.0124724   
3    ExtraTreesClassifier  -0.0181503 -0.000166333  0.0766298   0.00441088   

        acc       auc          conf_matrix     f1_c0      f1_c1       kappa  \
0  0.817568  0.537671  [[241, 51], [3, 1]]  0.899254  0.0357143   0.0108911   
4  0.986486       0.5   [[292, 0], [4, 0]]  0.993197          0           0   
6  0.986486       0.5   [[292, 0], [4, 0]]  0.993197          0           0   
9  0.986486       0.5   [[292, 0], [4, 0]]  0.993197          0           0   
5  0.983108  0.498288   [[291, 1], [4, 0]]  0.991482          0 -0.00543478   
8  0.983108  0.498288   [[291, 1], [4, 0]]  0.991482          0 -0.00543478   
2  0.956081  0.484589   [[283, 9], [4, 0]]  0.977547          0  -0.0190678   
1  0.952703  0.482877  [[282, 10], [4, 0]]  0.975779          0   -0.019685   
7  0.952703  0.482877  [[282, 10], [4, 0]]  0.975779          0   -0.019685   
3  0.898649  0.455479  [[266, 26], [4, 0]]  0.946619          0  -0.0239852   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
0   0.0228594  0.987705  0.0192308  0.825342   0.25  
4           0  0.986486          0         1      0  
6           0  0.986486          0         1      0  
9           0  0.986486          0         1      0  
5  -0.0068144  0.986441          0  0.996575      0  
8  -0.0068144  0.986441          0  0.996575      0  
2  -0.0207262  0.986063          0  0.969178      0  
1  -0.0218855  0.986014          0  0.965753      0  
7  -0.0218855  0.986014          0  0.965753      0  
3  -0.0363198  0.985185          0  0.910959      0  
Elapsed time 59.34 mins 

************************************************************

pre/post: 25/0  win/stride: 500/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-22 15:19:53.328000 
pca_target: 100 	 poly degree: 2 	 kselect: 40 
Imbalance: ClusterCentroids(estimator=None, n_jobs=1, random_state=None, ratio='auto') 
Extended target (count):  25141 13
('Total : Processed (count): ', (986L, 24976L), 13)
Final feature (count):  (986L, 24976L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.01, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.470 	-0.064 	-0.014 	0.361 	0.344 	0.116
[[138 154]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.98      0.47      0.64       292
        1.0       0.01      0.25      0.01         4

avg / total       0.97      0.47      0.63       296


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.0001, average=False, class_weight={1: 500}, epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='invscaling', loss='modified_huber', n_iter=5,
       n_jobs=4, penalty='l2', power_t=0.5, random_state=None,
       shuffle=True, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.486 	-0.060 	-0.014 	0.370 	0.350 	0.119
[[143 149]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.98      0.49      0.65       292
        1.0       0.01      0.25      0.01         4

avg / total       0.97      0.49      0.64       296


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 15},
           criterion='entropy', max_depth=8, max_features=0.33,
           max_leaf_nodes=None, min_impurity_split=1e-07,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=15, n_jobs=4,
           oob_score=False, random_state=None, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.608 	0.026 	0.007 	0.555 	0.552 	0.301
[[178 114]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      0.61      0.75       292
        1.0       0.02      0.50      0.03         4

avg / total       0.98      0.61      0.74       296


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 15},
            criterion='entropy', max_depth=32, max_features='auto',
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=15, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.747 	0.001 	0.000 	0.502 	0.434 	0.179
[[220  72]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.75      0.85       292
        1.0       0.01      0.25      0.03         4

avg / total       0.97      0.75      0.84       296


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.1, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.446 	-0.127 	-0.027 	0.226 	0.000 	0.000
[[132 160]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.97      0.45      0.62       292
        1.0       0.00      0.00      0.00         4

avg / total       0.96      0.45      0.61       296


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=0.5, n_estimators=80, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.679 	0.045 	0.015 	0.591 	0.584 	0.335
[[199  93]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      0.68      0.81       292
        1.0       0.02      0.50      0.04         4

avg / total       0.98      0.68      0.80       296


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='linear',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.500 	0.000 	0.000 	0.500 	0.500 	0.250
[[146 146]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      0.50      0.66       292
        1.0       0.01      0.50      0.03         4

avg / total       0.97      0.50      0.66       296


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.490 	0.112 	0.025 	0.741 	0.695 	0.508
[[141 151]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.48      0.65       292
        1.0       0.03      1.00      0.05         4

avg / total       0.99      0.49      0.64       296


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=1,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.726 	0.059 	0.022 	0.615 	0.604 	0.356
[[213  79]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      0.73      0.84       292
        1.0       0.02      0.50      0.05         4

avg / total       0.98      0.73      0.83       296


                estimator  min_score mean_score max_score   sd_score  \
8        VotingClassifier   0.461633    0.65628  0.683856  0.0506657   
9    KNeighborsClassifier          0   0.540056  0.906078   0.228864   
6      AdaBoostClassifier -0.0171889   0.614885  0.906078   0.176535   
3    ExtraTreesClassifier   0.461633   0.713297  0.906078  0.0701866   
4  RandomForestClassifier  0.0171889   0.502586  0.812156   0.126373   
0              GaussianNB   0.718234   0.718234  0.718234          0   
7                     SVC          0   0.494422  0.812156   0.289011   
2           SGDClassifier    -0.2566   0.504304  0.906078    0.18178   
1      LogisticRegression          0   0.542976         1   0.352227   
5           MLPClassifier -0.0171889   0.602825  0.718234   0.172942   

        acc       auc           conf_matrix     f1_c0      f1_c1        kappa  \
8  0.489865  0.741438  [[141, 151], [0, 4]]   0.65127  0.0503145    0.0246159   
9  0.726351  0.614726   [[213, 79], [2, 2]]  0.840237  0.0470588    0.0218668   
6  0.679054  0.590753   [[199, 93], [2, 2]]  0.807302   0.040404    0.0148543   
3  0.608108  0.554795  [[178, 114], [2, 2]]  0.754237  0.0333333   0.00740056   
4  0.746622  0.501712   [[220, 72], [3, 1]]  0.854369   0.025974  0.000360231   
0  0.986486       0.5    [[292, 0], [4, 0]]  0.993197          0            0   
7       0.5       0.5  [[146, 146], [2, 2]]  0.663636  0.0263158            0   
2  0.486486  0.369863  [[143, 149], [3, 1]]  0.652968   0.012987   -0.0136986   
1  0.469595  0.361301  [[138, 154], [3, 1]]  0.637413  0.0125786   -0.0141411   
5  0.445946  0.226027  [[132, 160], [4, 0]]  0.616822          0   -0.0270819   

   model_score   prec_c0     prec_c1    rec_c0 rec_c1  
8      0.11163         1   0.0258065  0.482877      1  
9    0.0594226  0.990698   0.0246914  0.729452    0.5  
6    0.0448905   0.99005   0.0210526  0.681507    0.5  
3    0.0259193  0.988889   0.0172414  0.609589    0.5  
4  0.000917328  0.986547   0.0136986  0.753425   0.25  
0            0  0.986486           0         1      0  
7            0  0.986486   0.0135135       0.5    0.5  
2   -0.0601077  0.979452  0.00666667  0.489726   0.25  
1   -0.0641281  0.978723  0.00645161  0.472603   0.25  
5    -0.126949  0.970588           0  0.452055      0  
Elapsed time 26.93 mins 

************************************************************

pre/post: 25/0  win/stride: 500/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-22 15:46:48.953000 
pca_target: 100 	 poly degree: 2 	 kselect: 40 
Imbalance: SMOTE(k=None, k_neighbors=5, kind='regular', m=None, m_neighbors=10, n_jobs=1,
   out_step=0.5, random_state=None, ratio='auto', svm_estimator=None) 
Extended target (count):  25141 13
('Total : Processed (count): ', (986L, 24976L), 13)
Final feature (count):  (986L, 24976L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=5, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.966 	-0.017 	-0.016 	0.490 	0.000 	0.000
[[286   6]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.98      0.98       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.97      0.97       296


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.001, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='squared_hinge', n_iter=5, n_jobs=4,
       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.980 	-0.010 	-0.009 	0.497 	0.000 	0.000
[[290   2]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.98       296


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=8, max_features='auto', max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.983 	-0.007 	-0.005 	0.498 	0.000 	0.000
[[291   1]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.98       296


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=0.5, n_estimators=15, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.1, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=10.0, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', ...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.983 	-0.007 	-0.005 	0.498 	0.000 	0.000
[[291   1]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.98       296


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=1,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.956 	-0.021 	-0.019 	0.485 	0.000 	0.000
[[283   9]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.97      0.98       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.96      0.96       296


                estimator min_score mean_score max_score     sd_score  \
0              GaussianNB  0.997074   0.997074  0.997074            0   
4  RandomForestClassifier  0.997084   0.999931         1  0.000328691   
5           MLPClassifier  0.969638    0.98536         1    0.0102901   
6      AdaBoostClassifier  0.950946   0.989159         1   0.00756745   
7                     SVC         0   0.861747         1     0.298488   
3    ExtraTreesClassifier  0.988358   0.999785         1   0.00113326   
8        VotingClassifier  0.958317   0.980033  0.991232   0.00683229   
2           SGDClassifier -0.103588   0.696223  0.995621     0.304628   
1      LogisticRegression  0.515294   0.871774   0.97682     0.143771   
9    KNeighborsClassifier  0.773751   0.860167  0.941773    0.0611799   

        acc       auc         conf_matrix     f1_c0 f1_c1       kappa  \
0  0.986486       0.5  [[292, 0], [4, 0]]  0.993197     0           0   
4  0.986486       0.5  [[292, 0], [4, 0]]  0.993197     0           0   
5  0.986486       0.5  [[292, 0], [4, 0]]  0.993197     0           0   
6  0.986486       0.5  [[292, 0], [4, 0]]  0.993197     0           0   
7  0.986486       0.5  [[292, 0], [4, 0]]  0.993197     0           0   
3  0.983108  0.498288  [[291, 1], [4, 0]]  0.991482     0 -0.00543478   
8  0.983108  0.498288  [[291, 1], [4, 0]]  0.991482     0 -0.00543478   
2   0.97973  0.496575  [[290, 2], [4, 0]]  0.989761     0 -0.00909091   
1  0.966216  0.489726  [[286, 6], [4, 0]]  0.982818     0  -0.0164835   
9  0.956081  0.484589  [[283, 9], [4, 0]]  0.977547     0  -0.0190678   

  model_score   prec_c0 prec_c1    rec_c0 rec_c1  
0           0  0.986486       0         1      0  
4           0  0.986486       0         1      0  
5           0  0.986486       0         1      0  
6           0  0.986486       0         1      0  
7           0  0.986486       0         1      0  
3  -0.0068144  0.986441       0  0.996575      0  
8  -0.0068144  0.986441       0  0.996575      0  
2 -0.00965339  0.986395       0  0.993151      0  
1  -0.0168351  0.986207       0  0.979452      0  
9  -0.0207262  0.986063       0  0.969178      0  
Elapsed time 78.58 mins 

************************************************************

pre/post: 25/0  win/stride: 500/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-22 17:05:23.842000 
pca_target: 100 	 poly degree: 2 	 kselect: 40 
Imbalance: None 
Extended target (count):  25141 13
('Total : Processed (count): ', (986L, 24976L), 13)
Final feature (count):  (986L, 24976L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.946 	-0.024 	-0.021 	0.479 	0.000 	0.000
[[280  12]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.96      0.97       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.95      0.96       296


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=1, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=0.01, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.584 	0.020 	0.005 	0.543 	0.541 	0.290
[[171 121]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      0.59      0.74       292
        1.0       0.02      0.50      0.03         4

avg / total       0.98      0.58      0.73       296


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.5, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.001, fit_intercept=True, l1_ratio=0.15,
       learning_rate='invscaling', loss='squared_hinge', n_iter=5,
       n_jobs=4, penalty='none', power_t=0.5, random_state=None,
       shuffle=True, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.973 	-0.014 	-0.014 	0.493 	0.000 	0.000
[[288   4]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.97      0.97       296


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=8, max_features='auto', max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(500,), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.980 	-0.010 	-0.009 	0.497 	0.000 	0.000
[[290   2]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.98       296


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 50}, criterion='gini', max_depth=32,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=0.5, n_estimators=50, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.973 	-0.014 	-0.014 	0.493 	0.000 	0.000
[[288   4]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.97      0.97       296


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.01, cache_size=200, class_weight={1: 500}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.014 	0.000 	0.000 	0.500 	0.000 	0.000
[[  0 292]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       0.00      0.00      0.00       292
        1.0       0.01      1.00      0.03         4

avg / total       0.00      0.01      0.00       296


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=1,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


                estimator   min_score   mean_score   max_score     sd_score  \
1      LogisticRegression  -0.0759756  -0.00228279    0.106214    0.0330082   
3    ExtraTreesClassifier  -0.0188452 -0.000235757           0   0.00137139   
4  RandomForestClassifier -0.00414408  -2.5378e-05           0  0.000266135   
7                     SVC    -0.02139   -0.0087301  0.00207212   0.00867094   
8        VotingClassifier -0.00921952  -0.00186472           0   0.00222046   
9    KNeighborsClassifier   -0.012378  -0.00273167           0   0.00475264   
5           MLPClassifier  -0.0194293   -0.0101103           0   0.00533875   
2           SGDClassifier   -0.140336     0.010407     0.15413    0.0325304   
6      AdaBoostClassifier  -0.0217045  -0.00330296    0.259559    0.0259782   
0              GaussianNB  -0.0647648   -0.0647648  -0.0647648            0   

         acc       auc           conf_matrix     f1_c0      f1_c1       kappa  \
1   0.584459  0.542808  [[171, 121], [2, 2]]  0.735484  0.0314961  0.00546329   
3   0.986486       0.5    [[292, 0], [4, 0]]  0.993197          0           0   
4   0.986486       0.5    [[292, 0], [4, 0]]  0.993197          0           0   
7  0.0135135       0.5    [[0, 292], [0, 4]]         0  0.0266667           0   
8   0.986486       0.5    [[292, 0], [4, 0]]  0.993197          0           0   
9   0.986486       0.5    [[292, 0], [4, 0]]  0.993197          0           0   
5    0.97973  0.496575    [[290, 2], [4, 0]]  0.989761          0 -0.00909091   
2   0.972973  0.493151    [[288, 4], [4, 0]]  0.986301          0  -0.0136986   
6   0.972973  0.493151    [[288, 4], [4, 0]]  0.986301          0  -0.0136986   
0   0.945946  0.479452   [[280, 12], [4, 0]]  0.972222          0  -0.0206897   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
1   0.0200587  0.988439  0.0162602  0.585616    0.5  
3           0  0.986486          0         1      0  
4           0  0.986486          0         1      0  
7           0         0  0.0135135         0      1  
8           0  0.986486          0         1      0  
9           0  0.986486          0         1      0  
5 -0.00965339  0.986395          0  0.993151      0  
2  -0.0136986  0.986301          0  0.986301      0  
6  -0.0136986  0.986301          0  0.986301      0  
0  -0.0240586  0.985915          0  0.958904      0  
Elapsed time 50.77 mins 

************************************************************

pre/post: 25/0  win/stride: 500/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-22 17:56:09.846000 
pca_target: 100 	 poly degree: 2 	 kselect: 80 
Imbalance: ClusterCentroids(estimator=None, n_jobs=1, random_state=None, ratio='auto') 
Extended target (count):  25141 13
('Total : Processed (count): ', (986L, 24976L), 13)
Final feature (count):  (986L, 24976L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.014 	0.000 	0.000 	0.500 	0.000 	0.000
[[  0 292]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       0.00      0.00      0.00       292
        1.0       0.01      1.00      0.03         4

avg / total       0.00      0.01      0.00       296


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=1, class_weight={1: 3}, dual=False, fit_intercept=True,
          intercept_scaling=0.1, max_iter=100, multi_class='ovr', n_jobs=4,
          penalty='l2', random_state=None, solver='sag', tol=0.0001,
          verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.436 	-0.072 	-0.015 	0.344 	0.331 	0.108
[[128 164]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.98      0.44      0.61       292
        1.0       0.01      0.25      0.01         4

avg / total       0.96      0.44      0.60       296


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.1, average=False, class_weight='balanced', epsilon=0.1,
       eta0=0.001, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='modified_huber', n_iter=5, n_jobs=4,
       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.750 	0.068 	0.026 	0.627 	0.614 	0.367
[[220  72]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      0.75      0.86       292
        1.0       0.03      0.50      0.05         4

avg / total       0.98      0.75      0.85       296


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 15}, criterion='gini',
           max_depth=None, max_features=0.33, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=30, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.757 	0.004 	0.001 	0.507 	0.437 	0.181
[[223  69]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.76      0.86       292
        1.0       0.01      0.25      0.03         4

avg / total       0.97      0.76      0.85       296


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features=0.75, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=50, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.639 	-0.026 	-0.008 	0.447 	0.401 	0.155
[[188 104]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.98      0.64      0.78       292
        1.0       0.01      0.25      0.02         4

avg / total       0.97      0.64      0.77       296


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.01, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.517 	-0.053 	-0.013 	0.385 	0.361 	0.127
[[152 140]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.98      0.52      0.68       292
        1.0       0.01      0.25      0.01         4

avg / total       0.97      0.52      0.67       296


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='entropy', max_depth=32,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=1.0, n_estimators=50, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.601 	-0.034 	-0.010 	0.428 	0.389 	0.146
[[177 115]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.98      0.61      0.75       292
        1.0       0.01      0.25      0.02         4

avg / total       0.97      0.60      0.74       296


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='linear',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.530 	0.064 	0.016 	0.639 	0.629 	0.404
[[154 138]
 [  1   3]]
             precision    recall  f1-score   support

        0.0       0.99      0.53      0.69       292
        1.0       0.02      0.75      0.04         4

avg / total       0.98      0.53      0.68       296


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 500}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Ran...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.875 	-0.041 	-0.025 	0.443 	0.000 	0.000
[[259  33]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.98      0.89      0.93       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.88      0.92       296


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=5, p=1,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.818 	0.023 	0.011 	0.538 	0.454 	0.194
[[241  51]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.83      0.90       292
        1.0       0.02      0.25      0.04         4

avg / total       0.97      0.82      0.89       296


                estimator  min_score mean_score max_score   sd_score  \
7                     SVC          0   0.440317  0.701045   0.294261   
2           SGDClassifier  -0.496011   0.381084  0.906078   0.171545   
9    KNeighborsClassifier   0.111111   0.470062  0.683856   0.145175   
3    ExtraTreesClassifier   0.478822   0.714023  0.906078  0.0839387   
0              GaussianNB   0.718234   0.718234  0.718234          0   
4  RandomForestClassifier   0.239411   0.648668  0.906078   0.132105   
8        VotingClassifier   0.333333   0.592397  0.777778  0.0867481   
6      AdaBoostClassifier  0.0939222   0.579216  0.906078   0.148095   
5           MLPClassifier   0.111111   0.730779  0.812156   0.187528   
1      LogisticRegression    -0.1283   0.388667  0.812156   0.297466   

         acc       auc           conf_matrix     f1_c0      f1_c1       kappa  \
7   0.530405  0.638699  [[154, 138], [1, 3]]  0.689038  0.0413793   0.0155054   
2       0.75  0.626712   [[220, 72], [2, 2]]  0.856031  0.0512821   0.0263158   
9   0.817568  0.537671   [[241, 51], [3, 1]]  0.899254  0.0357143   0.0108911   
3   0.756757  0.506849   [[223, 69], [3, 1]]  0.861004   0.027027  0.00149925   
0  0.0135135       0.5    [[0, 292], [0, 4]]         0  0.0266667           0   
4   0.638514  0.446918  [[188, 104], [3, 1]]  0.778468  0.0183486 -0.00789206   
8      0.875  0.443493   [[259, 33], [4, 0]]  0.933333          0  -0.0247006   
6   0.601351  0.428082  [[177, 115], [3, 1]]      0.75  0.0166667 -0.00971323   
5   0.516892  0.385274  [[152, 140], [3, 1]]  0.680089  0.0137931  -0.0128254   
1   0.435811  0.344178  [[128, 164], [3, 1]]  0.605201  0.0118343  -0.0149474   

  model_score   prec_c0     prec_c1    rec_c0 rec_c1  
7   0.0641281  0.993548   0.0212766  0.527397   0.75  
2   0.0675737  0.990991    0.027027  0.753425    0.5  
9   0.0228594  0.987705   0.0192308  0.825342   0.25  
3  0.00372216  0.986726   0.0142857  0.763699   0.25  
0           0         0   0.0135135         0      1  
4  -0.0256206  0.984293  0.00952381  0.643836   0.25  
8  -0.0414589  0.984791           0  0.886986      0  
6  -0.0340191  0.983333  0.00862069  0.606164   0.25  
5  -0.0530442  0.980645   0.0070922  0.520548   0.25  
1   -0.072444  0.977099  0.00606061  0.438356   0.25  
Elapsed time 29.15 mins 

************************************************************

pre/post: 25/0  win/stride: 500/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-22 18:25:18.740000 
pca_target: 100 	 poly degree: 2 	 kselect: 80 
Imbalance: SMOTE(k=None, k_neighbors=5, kind='regular', m=None, m_neighbors=10, n_jobs=1,
   out_step=0.5, random_state=None, ratio='auto', svm_estimator=None) 
Extended target (count):  25141 13
('Total : Processed (count): ', (986L, 24976L), 13)
Final feature (count):  (986L, 24976L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=5, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=5, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.966 	-0.017 	-0.016 	0.490 	0.000 	0.000
[[286   6]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.98      0.98       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.97      0.97       296


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.001, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='modified_huber', n_iter=5, n_jobs=4,
       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=8, max_features='auto', max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.983 	-0.007 	-0.005 	0.498 	0.000 	0.000
[[291   1]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.98       296


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.01, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.983 	-0.007 	-0.005 	0.498 	0.000 	0.000
[[291   1]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.98       296


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=0.5, n_estimators=15, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.1, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=10.0, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', ...owski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='uniform'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.983 	-0.007 	-0.005 	0.498 	0.000 	0.000
[[291   1]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.98       296


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=4,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.919 	-0.032 	-0.023 	0.466 	0.000 	0.000
[[272  20]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.93      0.96       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.92      0.94       296


                estimator min_score mean_score max_score     sd_score  \
0              GaussianNB  0.997074   0.997074  0.997074            0   
2           SGDClassifier -0.156116   0.706882  0.992727     0.285357   
4  RandomForestClassifier  0.997074   0.999854         1  0.000489794   
6      AdaBoostClassifier  0.943247   0.986501         1    0.0107632   
7                     SVC         0   0.838356         1       0.3233   
3    ExtraTreesClassifier  0.988327   0.999753         1   0.00130124   
5           MLPClassifier  0.972522   0.986299         1   0.00834743   
8        VotingClassifier  0.937405   0.970517  0.988369    0.0110517   
1      LogisticRegression  0.517601   0.880797  0.975367     0.128161   
9    KNeighborsClassifier  0.723834   0.823023   0.92392    0.0646266   

        acc       auc          conf_matrix     f1_c0 f1_c1       kappa  \
0  0.986486       0.5   [[292, 0], [4, 0]]  0.993197     0           0   
2  0.986486       0.5   [[292, 0], [4, 0]]  0.993197     0           0   
4  0.986486       0.5   [[292, 0], [4, 0]]  0.993197     0           0   
6  0.986486       0.5   [[292, 0], [4, 0]]  0.993197     0           0   
7  0.986486       0.5   [[292, 0], [4, 0]]  0.993197     0           0   
3  0.983108  0.498288   [[291, 1], [4, 0]]  0.991482     0 -0.00543478   
5  0.983108  0.498288   [[291, 1], [4, 0]]  0.991482     0 -0.00543478   
8  0.983108  0.498288   [[291, 1], [4, 0]]  0.991482     0 -0.00543478   
1  0.966216  0.489726   [[286, 6], [4, 0]]  0.982818     0  -0.0164835   
9  0.918919  0.465753  [[272, 20], [4, 0]]  0.957746     0  -0.0230415   

  model_score   prec_c0 prec_c1    rec_c0 rec_c1  
0           0  0.986486       0         1      0  
2           0  0.986486       0         1      0  
4           0  0.986486       0         1      0  
6           0  0.986486       0         1      0  
7           0  0.986486       0         1      0  
3  -0.0068144  0.986441       0  0.996575      0  
5  -0.0068144  0.986441       0  0.996575      0  
8  -0.0068144  0.986441       0  0.996575      0  
1  -0.0168351  0.986207       0  0.979452      0  
9  -0.0315064  0.985507       0  0.931507      0  
Elapsed time 100.76 mins 

************************************************************

pre/post: 25/0  win/stride: 500/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-22 20:06:04.510000 
pca_target: 100 	 poly degree: 2 	 kselect: 80 
Imbalance: None 
Extended target (count):  25141 13
('Total : Processed (count): ', (986L, 24976L), 13)
Final feature (count):  (986L, 24976L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.953 	-0.022 	-0.020 	0.483 	0.000 	0.000
[[282  10]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.97      0.98       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.95      0.96       296


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.001, class_weight={1: 50}, dual=False,
          fit_intercept=True, intercept_scaling=5, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='sag', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.848 	-0.047 	-0.025 	0.430 	0.000 	0.000
[[251  41]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.98      0.86      0.92       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.85      0.91       296


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.1, average=False, class_weight='balanced', epsilon=0.1,
       eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='constant', loss='squared_hinge', n_iter=5, n_jobs=4,
       penalty='l2', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.274 	0.004 	0.001 	0.509 	0.448 	0.210
[[ 78 214]
 [  1   3]]
             precision    recall  f1-score   support

        0.0       0.99      0.27      0.42       292
        1.0       0.01      0.75      0.03         4

avg / total       0.97      0.27      0.42       296


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 500}, criterion='gini',
           max_depth=8, max_features='auto', max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=50, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.943 	-0.025 	-0.021 	0.478 	0.000 	0.000
[[279  13]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.96      0.97       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.94      0.96       296


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(500,), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.980 	-0.010 	-0.009 	0.497 	0.000 	0.000
[[290   2]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.98       296


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight='balanced', criterion='gini',
            max_depth=32, max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=1.0, n_estimators=80, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.949 	-0.023 	-0.020 	0.481 	0.000 	0.000
[[281  11]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.96      0.97       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.95      0.96       296


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.01, cache_size=200, class_weight={1: 500}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.338 	0.081 	0.013 	0.664 	0.573 	0.351
[[ 96 196]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.33      0.49       292
        1.0       0.02      1.00      0.04         4

avg / total       0.99      0.34      0.49       296


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=1,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


                estimator   min_score   mean_score   max_score     sd_score  \
7                     SVC  -0.0211824  -0.00763065   0.0612407   0.00985153   
2           SGDClassifier    -0.12533    0.0201654    0.250007     0.042107   
4  RandomForestClassifier -0.00294118 -3.93042e-05           0  0.000286414   
8        VotingClassifier  -0.0104062  -0.00168109           0   0.00239384   
9    KNeighborsClassifier  -0.0165408  -0.00370027           0   0.00643114   
5           MLPClassifier  -0.0169578  -0.00990233 -0.00145993   0.00422536   
0              GaussianNB  -0.0428824   -0.0428824  -0.0428824            0   
6      AdaBoostClassifier  -0.0204999   0.00900694    0.196479    0.0382816   
3    ExtraTreesClassifier  -0.0124502  0.000175076    0.125874   0.00742974   
1      LogisticRegression  -0.0555944   0.00448411    0.158489    0.0454013   

        acc       auc          conf_matrix     f1_c0      f1_c1        kappa  \
7  0.337838  0.664384  [[96, 196], [0, 4]]  0.494845  0.0392157    0.0130648   
2  0.273649  0.508562  [[78, 214], [1, 3]]  0.420485  0.0271493  0.000628141   
4  0.986486       0.5   [[292, 0], [4, 0]]  0.993197          0            0   
8  0.986486       0.5   [[292, 0], [4, 0]]  0.993197          0            0   
9  0.986486       0.5   [[292, 0], [4, 0]]  0.993197          0            0   
5   0.97973  0.496575   [[290, 2], [4, 0]]  0.989761          0  -0.00909091   
0  0.952703  0.482877  [[282, 10], [4, 0]]  0.975779          0    -0.019685   
6  0.949324  0.481164  [[281, 11], [4, 0]]  0.974003          0   -0.0202206   
3  0.942568   0.47774  [[279, 13], [4, 0]]  0.970435          0   -0.0211039   
1  0.847973  0.429795  [[251, 41], [4, 0]]  0.917733          0   -0.0252463   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
7   0.0810885         1       0.02  0.328767      1  
2  0.00446956  0.987342  0.0138249  0.267123   0.75  
4           0  0.986486          0         1      0  
8           0  0.986486          0         1      0  
9           0  0.986486          0         1      0  
5 -0.00965339  0.986395          0  0.993151      0  
0  -0.0218855  0.986014          0  0.965753      0  
6  -0.0229939  0.985965          0  0.962329      0  
3  -0.0250852  0.985866          0  0.955479      0  
1  -0.0469311  0.984314          0  0.859589      0  
Elapsed time 56.55 mins 

************************************************************

pre/post: 25/0  win/stride: 500/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-22 21:02:37.330000 
pca_target: 100 	 poly degree: 2 	 kselect: 100 
Imbalance: ClusterCentroids(estimator=None, n_jobs=1, random_state=None, ratio='auto') 
Extended target (count):  25141 13
('Total : Processed (count): ', (986L, 24976L), 13)
Final feature (count):  (986L, 24976L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.014 	0.000 	0.000 	0.500 	0.000 	0.000
[[  0 292]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       0.00      0.00      0.00       292
        1.0       0.01      1.00      0.03         4

avg / total       0.00      0.01      0.00       296


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.01, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=10, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.527 	-0.051 	-0.013 	0.390 	0.364 	0.129
[[155 137]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.98      0.53      0.69       292
        1.0       0.01      0.25      0.01         4

avg / total       0.97      0.53      0.68       296


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=1, average=False, class_weight='balanced', epsilon=0.1,
       eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='invscaling', loss='squared_hinge', n_iter=5,
       n_jobs=4, penalty='elasticnet', power_t=0.5, random_state=None,
       shuffle=True, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.456 	-0.067 	-0.014 	0.354 	0.339 	0.112
[[134 158]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.98      0.46      0.62       292
        1.0       0.01      0.25      0.01         4

avg / total       0.96      0.46      0.62       296


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=8, max_features=0.75, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.591 	0.022 	0.006 	0.546 	0.544 	0.293
[[173 119]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      0.59      0.74       292
        1.0       0.02      0.50      0.03         4

avg / total       0.98      0.59      0.73       296


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 15},
            criterion='entropy', max_depth=16, max_features=0.75,
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.365 	-0.033 	-0.006 	0.432 	0.426 	0.184
[[106 186]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.98      0.36      0.53       292
        1.0       0.01      0.50      0.02         4

avg / total       0.97      0.36      0.52       296


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.01, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.510 	-0.055 	-0.013 	0.382 	0.358 	0.125
[[150 142]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.98      0.51      0.67       292
        1.0       0.01      0.25      0.01         4

avg / total       0.97      0.51      0.67       296


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=8,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=2.0, n_estimators=15, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.176 	-0.025 	-0.003 	0.459 	0.355 	0.133
[[ 49 243]
 [  1   3]]
             precision    recall  f1-score   support

        0.0       0.98      0.17      0.29       292
        1.0       0.01      0.75      0.02         4

avg / total       0.97      0.18      0.28       296


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.1, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='linear',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.378 	0.029 	0.005 	0.562 	0.529 	0.291
[[109 183]
 [  1   3]]
             precision    recall  f1-score   support

        0.0       0.99      0.37      0.54       292
        1.0       0.02      0.75      0.03         4

avg / total       0.98      0.38      0.54       296


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 500}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Ran...owski',
           metric_params=None, n_jobs=4, n_neighbors=4, p=2,
           weights='uniform'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.422 	0.097 	0.019 	0.707 	0.644 	0.439
[[121 171]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.41      0.59       292
        1.0       0.02      1.00      0.04         4

avg / total       0.99      0.42      0.58       296


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=4, p=1,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.618 	0.028 	0.008 	0.560 	0.557 	0.306
[[181 111]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      0.62      0.76       292
        1.0       0.02      0.50      0.03         4

avg / total       0.98      0.62      0.75       296


                estimator min_score mean_score max_score   sd_score  \
8        VotingClassifier    0.5132   0.668172  0.812156  0.0675967   
7                     SVC         0   0.593371  0.906078    0.36586   
9    KNeighborsClassifier  0.239411   0.687296         1   0.215512   
3    ExtraTreesClassifier  0.572745    0.82204  0.906078  0.0932948   
0              GaussianNB  0.624311   0.624311  0.624311          0   
6      AdaBoostClassifier         0   0.471106  0.906078   0.175505   
4  RandomForestClassifier    0.2566   0.600828  0.906078   0.118574   
1      LogisticRegression   -0.1283   0.391183  0.718234   0.260078   
5           MLPClassifier  0.444444   0.664429  0.683856   0.050618   
2           SGDClassifier   -0.2566   0.451996  0.906078   0.208238   

         acc       auc           conf_matrix     f1_c0      f1_c1       kappa  \
8   0.422297  0.707192  [[121, 171], [0, 4]]  0.585956  0.0446927   0.0187655   
7   0.378378  0.561644  [[109, 183], [1, 3]]  0.542289  0.0315789  0.00526008   
9   0.618243  0.559932  [[181, 111], [2, 2]]  0.762105   0.034188  0.00830171   
3   0.591216  0.546233  [[173, 119], [2, 2]]  0.740899      0.032  0.00599467   
0  0.0135135       0.5    [[0, 292], [0, 4]]         0  0.0266667           0   
6   0.175676  0.458904   [[49, 243], [1, 3]]   0.28655      0.024 -0.00266548   
4   0.364865  0.431507  [[106, 186], [2, 2]]      0.53  0.0208333 -0.00578369   
1   0.527027  0.390411  [[155, 137], [3, 1]]  0.688889  0.0140845  -0.0125098   
5   0.510135  0.381849  [[150, 142], [3, 1]]  0.674157  0.0136054  -0.0130287   
2   0.456081  0.354452  [[134, 158], [3, 1]]  0.624709  0.0122699  -0.0144755   

  model_score   prec_c0     prec_c1    rec_c0 rec_c1  
8   0.0973223         1   0.0228571  0.414384      1  
7    0.029457  0.990909    0.016129  0.373288   0.75  
9   0.0284867  0.989071   0.0176991  0.619863    0.5  
3   0.0217165  0.988571   0.0165289  0.592466    0.5  
0           0         0   0.0135135         0      1  
6  -0.0253278      0.98   0.0121951  0.167808   0.75  
4  -0.0328555  0.981481   0.0106383  0.363014    0.5  
1  -0.0507283  0.981013  0.00724638  0.530822   0.25  
5  -0.0545976  0.980392  0.00699301  0.513699   0.25  
2   -0.067406  0.978102  0.00628931  0.458904   0.25  
Elapsed time 29.99 mins 

************************************************************

pre/post: 25/0  win/stride: 500/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-22 21:32:36.468000 
pca_target: 100 	 poly degree: 2 	 kselect: 100 
Imbalance: SMOTE(k=None, k_neighbors=5, kind='regular', m=None, m_neighbors=10, n_jobs=1,
   out_step=0.5, random_state=None, ratio='auto', svm_estimator=None) 
Extended target (count):  25141 13
('Total : Processed (count): ', (986L, 24976L), 13)
Final feature (count):  (986L, 24976L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=10, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.973 	-0.014 	-0.014 	0.493 	0.000 	0.000
[[288   4]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.97      0.97       296


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.001, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='squared_hinge', n_iter=5, n_jobs=4,
       penalty='l2', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.980 	-0.010 	-0.009 	0.497 	0.000 	0.000
[[290   2]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.98       296


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=8, max_features='auto', max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=50, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.983 	-0.007 	-0.005 	0.498 	0.000 	0.000
[[291   1]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.98       296


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=0.5, n_estimators=15, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.1, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=10.0, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', ...owski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='uniform'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.983 	-0.007 	-0.005 	0.498 	0.000 	0.000
[[291   1]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.98       296


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=4,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.919 	-0.032 	-0.023 	0.466 	0.000 	0.000
[[272  20]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.93      0.96       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.92      0.94       296


                estimator  min_score mean_score max_score    sd_score  \
0              GaussianNB   0.997074   0.997074  0.997074           0   
3    ExtraTreesClassifier   0.986926   0.999809         1  0.00104963   
4  RandomForestClassifier   0.992706    0.99882         1  0.00159173   
6      AdaBoostClassifier   0.918148   0.986311         1  0.00983765   
7                     SVC          0   0.835122         1    0.325559   
5           MLPClassifier   0.973945   0.986027  0.997084  0.00743612   
8        VotingClassifier   0.940139   0.968806  0.985432   0.0103796   
2           SGDClassifier -0.0553715   0.703973  0.992716    0.284542   
1      LogisticRegression   0.523304   0.880594   0.97682    0.126349   
9    KNeighborsClassifier   0.720288   0.814459  0.922499   0.0655643   

        acc       auc          conf_matrix     f1_c0 f1_c1       kappa  \
0  0.986486       0.5   [[292, 0], [4, 0]]  0.993197     0           0   
3  0.986486       0.5   [[292, 0], [4, 0]]  0.993197     0           0   
4  0.986486       0.5   [[292, 0], [4, 0]]  0.993197     0           0   
6  0.986486       0.5   [[292, 0], [4, 0]]  0.993197     0           0   
7  0.986486       0.5   [[292, 0], [4, 0]]  0.993197     0           0   
5  0.983108  0.498288   [[291, 1], [4, 0]]  0.991482     0 -0.00543478   
8  0.983108  0.498288   [[291, 1], [4, 0]]  0.991482     0 -0.00543478   
2   0.97973  0.496575   [[290, 2], [4, 0]]  0.989761     0 -0.00909091   
1  0.972973  0.493151   [[288, 4], [4, 0]]  0.986301     0  -0.0136986   
9  0.918919  0.465753  [[272, 20], [4, 0]]  0.957746     0  -0.0230415   

  model_score   prec_c0 prec_c1    rec_c0 rec_c1  
0           0  0.986486       0         1      0  
3           0  0.986486       0         1      0  
4           0  0.986486       0         1      0  
6           0  0.986486       0         1      0  
7           0  0.986486       0         1      0  
5  -0.0068144  0.986441       0  0.996575      0  
8  -0.0068144  0.986441       0  0.996575      0  
2 -0.00965339  0.986395       0  0.993151      0  
1  -0.0136986  0.986301       0  0.986301      0  
9  -0.0315064  0.985507       0  0.931507      0  
Elapsed time 103.91 mins 

************************************************************

pre/post: 25/0  win/stride: 500/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-22 23:16:31.087000 
pca_target: 100 	 poly degree: 2 	 kselect: 100 
Imbalance: None 
Extended target (count):  25141 13
('Total : Processed (count): ', (986L, 24976L), 13)
Final feature (count):  (986L, 24976L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.926 	-0.030 	-0.023 	0.469 	0.000 	0.000
[[274  18]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.94      0.96       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.93      0.95       296


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=1, class_weight={1: 500}, dual=False, fit_intercept=True,
          intercept_scaling=0.1, max_iter=100, multi_class='ovr', n_jobs=4,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.818 	-0.053 	-0.026 	0.414 	0.000 	0.000
[[242  50]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.98      0.83      0.90       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.82      0.89       296


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.001, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.001, fit_intercept=True, l1_ratio=0.15,
       learning_rate='invscaling', loss='modified_huber', n_iter=5,
       n_jobs=4, penalty='l1', power_t=0.5, random_state=None,
       shuffle=True, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.963 	-0.018 	-0.018 	0.488 	0.000 	0.000
[[285   7]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.98      0.98       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.96      0.97       296


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 500}, criterion='gini',
           max_depth=8, max_features=0.75, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=50, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.932 	-0.028 	-0.022 	0.473 	0.000 	0.000
[[276  16]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.95      0.97       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.93      0.95       296


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.01, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.980 	-0.010 	-0.009 	0.497 	0.000 	0.000
[[290   2]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.98       296


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 50}, criterion='entropy',
            max_depth=16, max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=1.0, n_estimators=50, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.966 	-0.017 	-0.016 	0.490 	0.000 	0.000
[[286   6]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.98      0.98       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.97      0.97       296


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.01, cache_size=200, class_weight={1: 500}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.355 	0.084 	0.014 	0.673 	0.588 	0.369
[[101 191]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.35      0.51       292
        1.0       0.02      1.00      0.04         4

avg / total       0.99      0.35      0.51       296


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=1.0, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=1,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


                estimator   min_score   mean_score  max_score     sd_score  \
7                     SVC  -0.0189646  -0.00835513   0.070048    0.0108712   
4  RandomForestClassifier -0.00207212 -2.36774e-05          0  0.000202615   
8        VotingClassifier  -0.0100883  -0.00193121          0   0.00244259   
9    KNeighborsClassifier  -0.0164778  -0.00368303          0   0.00640998   
5           MLPClassifier   -0.016707  -0.00673511  0.0884917    0.0144345   
6      AdaBoostClassifier  -0.0231011    0.0155765   0.190687    0.0476489   
2           SGDClassifier    -0.18241    0.0234336   0.190954    0.0429827   
3    ExtraTreesClassifier  -0.0221129   0.00097294  0.0715754   0.00864792   
0              GaussianNB     -0.0449      -0.0449    -0.0449            0   
1      LogisticRegression  -0.0379035   0.00524106   0.133592    0.0443949   

        acc       auc           conf_matrix     f1_c0     f1_c1       kappa  \
7   0.35473  0.672945  [[101, 191], [0, 4]]  0.513995  0.040201   0.0140904   
4  0.986486       0.5    [[292, 0], [4, 0]]  0.993197         0           0   
8  0.986486       0.5    [[292, 0], [4, 0]]  0.993197         0           0   
9  0.986486       0.5    [[292, 0], [4, 0]]  0.993197         0           0   
5   0.97973  0.496575    [[290, 2], [4, 0]]  0.989761         0 -0.00909091   
6  0.966216  0.489726    [[286, 6], [4, 0]]  0.982818         0  -0.0164835   
2  0.962838  0.488014    [[285, 7], [4, 0]]  0.981067         0     -0.0175   
3  0.932432  0.472603   [[276, 16], [4, 0]]  0.965035         0  -0.0220994   
0  0.925676  0.469178   [[274, 18], [4, 0]]  0.961404         0  -0.0226131   
1  0.817568  0.414384   [[242, 50], [4, 0]]  0.899628         0  -0.0256674   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
7   0.0842329         1  0.0205128   0.34589      1  
4           0  0.986486          0         1      0  
8           0  0.986486          0         1      0  
9           0  0.986486          0         1      0  
5 -0.00965339  0.986395          0  0.993151      0  
6  -0.0168351  0.986207          0  0.979452      0  
2  -0.0182154  0.986159          0  0.976027      0  
3  -0.0279782  0.985714          0  0.945205      0  
0  -0.0297819  0.985612          0  0.938356      0  
1  -0.0527662   0.98374          0  0.828767      0  
Elapsed time 61.35 mins 

************************************************************

[4;33mReloaded modules[24m: migraine_processing, classifiers[0m
Finished.





lagged allx1, StandardScaler

    pca = [0]
    poly = [0]
    ksel = [40, 100]
    imb = [ClusterCentroids(), SMOTE(), None
	
	

	
pre/post: 25/0  win/stride: 500/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-23 09:48:25.534000 
pca_target: 0 	 poly degree: 0 	 kselect: 40 
Imbalance: ClusterCentroids(estimator=None, n_jobs=1, random_state=None, ratio='auto') 
Extended target (count):  25141 13
('Total : Processed (count): ', (986L, 438L), 13)
Final feature (count):  (986L, 438L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.527 	0.063 	0.015 	0.637 	0.627 	0.402
[[153 139]
 [  1   3]]
             precision    recall  f1-score   support

        0.0       0.99      0.52      0.69       292
        1.0       0.02      0.75      0.04         4

avg / total       0.98      0.53      0.68       296


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=1, class_weight={1: 3}, dual=False, fit_intercept=True,
          intercept_scaling=0.1, max_iter=100, multi_class='ovr', n_jobs=4,
          penalty='l2', random_state=None, solver='lbfgs', tol=0.0001,
          verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.720 	-0.071 	-0.026 	0.365 	0.000 	0.000
[[213  79]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.98      0.73      0.84       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.72      0.83       296


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.1, average=False, class_weight='balanced', epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='modified_huber', n_iter=5, n_jobs=4,
       penalty='l1', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.720 	-0.006 	-0.002 	0.488 	0.426 	0.173
[[212  80]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.73      0.84       292
        1.0       0.01      0.25      0.02         4

avg / total       0.97      0.72      0.83       296


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 15},
           criterion='entropy', max_depth=8, max_features=0.75,
           max_leaf_nodes=None, min_impurity_split=1e-07,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=15, n_jobs=4,
           oob_score=False, random_state=None, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.530 	0.064 	0.016 	0.639 	0.629 	0.404
[[154 138]
 [  1   3]]
             precision    recall  f1-score   support

        0.0       0.99      0.53      0.69       292
        1.0       0.02      0.75      0.04         4

avg / total       0.98      0.53      0.68       296


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=50, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.682 	-0.077 	-0.027 	0.346 	0.000 	0.000
[[202  90]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.98      0.69      0.81       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.68      0.80       296


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.01, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.794 	-0.057 	-0.026 	0.402 	0.000 	0.000
[[235  57]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.98      0.80      0.89       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.79      0.87       296


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='entropy', max_depth=16,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=2.0, n_estimators=15, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.524 	0.063 	0.015 	0.635 	0.625 	0.399
[[152 140]
 [  1   3]]
             precision    recall  f1-score   support

        0.0       0.99      0.52      0.68       292
        1.0       0.02      0.75      0.04         4

avg / total       0.98      0.52      0.67       296


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.1, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='linear',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.743 	0.000 	0.000 	0.500 	0.433 	0.178
[[219  73]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.75      0.85       292
        1.0       0.01      0.25      0.03         4

avg / total       0.97      0.74      0.84       296


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...owski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='uniform'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.693 	-0.013 	-0.004 	0.474 	0.418 	0.167
[[204  88]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.70      0.82       292
        1.0       0.01      0.25      0.02         4

avg / total       0.97      0.69      0.81       296


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=3, p=1,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.814 	-0.053 	-0.026 	0.413 	0.000 	0.000
[[241  51]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.98      0.83      0.90       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.81      0.89       296


                estimator min_score mean_score max_score   sd_score       acc  \
3    ExtraTreesClassifier  0.478822   0.800634         1  0.0846722  0.530405   
0              GaussianNB  0.906078   0.906078  0.906078          0  0.527027   
6      AdaBoostClassifier         0   0.563226         1   0.200463  0.523649   
7                     SVC         0   0.371045  0.649478   0.235122  0.743243   
2           SGDClassifier -0.444444   0.288022  0.812156   0.172739  0.719595   
8        VotingClassifier -0.111111   0.324208  0.812156   0.165559  0.692568   
9    KNeighborsClassifier   -0.2566  0.0751741  0.461633   0.192072  0.814189   
5           MLPClassifier  0.367711    0.58859  0.683856   0.104294  0.793919   
1      LogisticRegression         0   0.347193  0.701045   0.213592  0.719595   
4  RandomForestClassifier  0.333333   0.740037         1   0.150155  0.682432   

        auc           conf_matrix     f1_c0      f1_c1       kappa  \
3  0.638699  [[154, 138], [1, 3]]  0.689038  0.0413793   0.0155054   
0  0.636986  [[153, 139], [1, 3]]  0.686099  0.0410959   0.0152091   
6  0.635274  [[152, 140], [1, 3]]  0.683146  0.0408163   0.0149169   
7       0.5   [[219, 73], [3, 1]]   0.85214   0.025641           0   
2  0.488014   [[212, 80], [3, 1]]  0.836292  0.0235294  -0.0022846   
8  0.474315   [[204, 88], [3, 1]]  0.817635  0.0215054 -0.00447494   
9  0.412671   [[241, 51], [4, 0]]  0.897579          0  -0.0257056   
5  0.402397   [[235, 57], [4, 0]]  0.885122          0  -0.0259091   
1  0.364726   [[213, 79], [4, 0]]  0.836935          0  -0.0264037   
4   0.34589   [[202, 90], [4, 0]]  0.811245          0  -0.0265643   

   model_score   prec_c0    prec_c1    rec_c0 rec_c1  
3    0.0641281  0.993548  0.0212766  0.527397   0.75  
0    0.0633175  0.993506  0.0211268  0.523973   0.75  
6    0.0625103  0.993464   0.020979  0.520548   0.75  
7  1.87555e-18  0.986486  0.0135135      0.75   0.25  
2  -0.00620833  0.986047  0.0123457  0.726027   0.25  
8   -0.0129345  0.985507   0.011236   0.69863   0.25  
9   -0.0533999  0.983673          0  0.825342      0  
5    -0.057158  0.983264          0  0.804795      0  
1   -0.0706191  0.981567          0  0.729452      0  
4   -0.0773617  0.980583          0  0.691781      0  
Elapsed time 13.96 mins 

************************************************************

pre/post: 25/0  win/stride: 500/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-23 10:02:23.198000 
pca_target: 0 	 poly degree: 0 	 kselect: 40 
Imbalance: SMOTE(k=None, k_neighbors=5, kind='regular', m=None, m_neighbors=10, n_jobs=1,
   out_step=0.5, random_state=None, ratio='auto', svm_estimator=None) 
Extended target (count):  25141 13
('Total : Processed (count): ', (986L, 438L), 13)
Final feature (count):  (986L, 438L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.720 	0.057 	0.021 	0.611 	0.601 	0.353
[[211  81]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      0.72      0.84       292
        1.0       0.02      0.50      0.05         4

avg / total       0.98      0.72      0.82       296


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=10, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=10, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.899 	-0.036 	-0.024 	0.455 	0.000 	0.000
[[266  26]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.91      0.95       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.90      0.93       296


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.001, average=False, class_weight={1: 15}, epsilon=0.1,
       eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='modified_huber', n_iter=5, n_jobs=4,
       penalty='none', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.807 	0.019 	0.009 	0.533 	0.451 	0.192
[[238  54]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.82      0.89       292
        1.0       0.02      0.25      0.03         4

avg / total       0.97      0.81      0.88       296


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3},
           criterion='entropy', max_depth=32, max_features=0.33,
           max_leaf_nodes=None, min_impurity_split=1e-07,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=4,
           oob_score=False, random_state=None, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.976 	-0.012 	-0.012 	0.495 	0.000 	0.000
[[289   3]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.97       296


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight='balanced',
            criterion='gini', max_depth=None, max_features='auto',
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=15, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.980 	0.240 	0.240 	0.620 	0.497 	0.229
[[289   3]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       292
        1.0       0.25      0.25      0.25         4

avg / total       0.98      0.98      0.98       296


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(500,), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.976 	-0.012 	-0.012 	0.495 	0.000 	0.000
[[289   3]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.97       296


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight='balanced', criterion='gini', max_depth=8,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=1.0, n_estimators=80, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.976 	-0.012 	-0.012 	0.495 	0.000 	0.000
[[289   3]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.97       296


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.1, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=10.0, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', ...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.936 	-0.027 	-0.022 	0.474 	0.000 	0.000
[[277  15]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.95      0.97       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.94      0.95       296


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=1,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.936 	-0.027 	-0.022 	0.474 	0.000 	0.000
[[277  15]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.95      0.97       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.94      0.95       296


                estimator  min_score mean_score max_score    sd_score  \
4  RandomForestClassifier   0.935681   0.973598    0.9912   0.0102035   
0              GaussianNB   0.673586   0.673586  0.673586           0   
2           SGDClassifier -0.0644833   0.557954  0.858865    0.230674   
7                     SVC          0   0.803309  0.998537     0.25327   
3    ExtraTreesClassifier   0.641688   0.953315  0.997074   0.0659739   
5           MLPClassifier   0.961132   0.973481  0.984021  0.00623877   
6      AdaBoostClassifier   0.894539    0.96195  0.995611   0.0204963   
8        VotingClassifier   0.860119   0.925315  0.966823    0.024685   
9    KNeighborsClassifier   0.843716    0.89486  0.940353    0.030874   
1      LogisticRegression  0.0487488   0.703461  0.923813    0.188635   

        acc       auc          conf_matrix     f1_c0      f1_c1       kappa  \
4   0.97973  0.619863   [[289, 3], [3, 1]]  0.989726       0.25    0.239726   
0  0.719595  0.611301  [[211, 81], [2, 2]]  0.835644   0.045977    0.020727   
2  0.807432  0.532534  [[238, 54], [3, 1]]  0.893058  0.0338983  0.00892857   
7  0.986486       0.5   [[292, 0], [4, 0]]  0.993197          0           0   
3  0.976351  0.494863   [[289, 3], [4, 0]]  0.988034          0  -0.0117188   
5  0.976351  0.494863   [[289, 3], [4, 0]]  0.988034          0  -0.0117188   
6  0.976351  0.494863   [[289, 3], [4, 0]]  0.988034          0  -0.0117188   
8  0.935811  0.474315  [[277, 15], [4, 0]]  0.966841          0  -0.0218023   
9  0.935811  0.474315  [[277, 15], [4, 0]]  0.966841          0  -0.0218023   
1  0.898649  0.455479  [[266, 26], [4, 0]]  0.946619          0  -0.0239852   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
4    0.239726  0.989726       0.25  0.989726   0.25  
0   0.0572167   0.99061  0.0240964  0.722603    0.5  
2   0.0193153  0.987552  0.0181818  0.815068   0.25  
7           0  0.986486          0         1      0  
3  -0.0118431  0.986348          0  0.989726      0  
5  -0.0118431  0.986348          0  0.989726      0  
6  -0.0118431  0.986348          0  0.989726      0  
8  -0.0270415  0.985765          0   0.94863      0  
9  -0.0270415  0.985765          0   0.94863      0  
1  -0.0363198  0.985185          0  0.910959      0  
Elapsed time 35.01 mins 

************************************************************

pre/post: 25/0  win/stride: 500/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-23 10:37:23.684000 
pca_target: 0 	 poly degree: 0 	 kselect: 40 
Imbalance: None 
Extended target (count):  25141 13
('Total : Processed (count): ', (986L, 438L), 13)
Final feature (count):  (986L, 438L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.571 	0.017 	0.004 	0.536 	0.535 	0.284
[[167 125]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      0.57      0.72       292
        1.0       0.02      0.50      0.03         4

avg / total       0.98      0.57      0.72       296


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=1, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=5, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='sag', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.774 	-0.061 	-0.026 	0.392 	0.000 	0.000
[[229  63]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.98      0.78      0.87       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.77      0.86       296


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.1, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.001, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='modified_huber', n_iter=5, n_jobs=4,
       penalty='l2', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.983 	-0.007 	-0.005 	0.498 	0.000 	0.000
[[291   1]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.98       296


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 500}, criterion='gini',
           max_depth=8, max_features='auto', max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.855 	0.038 	0.020 	0.557 	0.464 	0.203
[[252  40]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.86      0.92       292
        1.0       0.02      0.25      0.04         4

avg / total       0.98      0.85      0.91       296


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 500},
            criterion='gini', max_depth=8, max_features=0.75,
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=15, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.949 	-0.023 	-0.020 	0.481 	0.000 	0.000
[[281  11]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.96      0.97       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.95      0.96       296


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.1, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.983 	-0.007 	-0.005 	0.498 	0.000 	0.000
[[291   1]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.98       296


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 500}, criterion='gini', max_depth=8,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=2.0, n_estimators=50, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.976 	-0.012 	-0.012 	0.495 	0.000 	0.000
[[289   3]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.97       296


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.1, cache_size=200, class_weight={1: 500}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.645 	-0.024 	-0.008 	0.450 	0.403 	0.156
[[190 102]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.98      0.65      0.78       292
        1.0       0.01      0.25      0.02         4

avg / total       0.97      0.65      0.77       296


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=1,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


                estimator   min_score   mean_score   max_score    sd_score  \
3    ExtraTreesClassifier  -0.0275221  5.65571e-05    0.112406    0.011392   
0              GaussianNB    0.109504     0.109504    0.109504           0   
8        VotingClassifier  -0.0157602  -0.00535696           0  0.00482882   
9    KNeighborsClassifier   -0.014217  -0.00316669           0  0.00514288   
2           SGDClassifier   -0.130789    0.0251123    0.234943   0.0356801   
5           MLPClassifier  -0.0190622   -0.0116364 -0.00713155  0.00327597   
6      AdaBoostClassifier  -0.0215265    0.0205972     0.29911     0.05497   
4  RandomForestClassifier -0.00811174 -0.000221829   0.0759261  0.00417414   
7                     SVC  -0.0287568 -0.000492401   0.0669433   0.0171375   
1      LogisticRegression   -0.125474    0.0119116    0.100798   0.0372406   

        acc       auc           conf_matrix     f1_c0      f1_c1       kappa  \
3   0.85473  0.556507   [[252, 40], [3, 1]]  0.921389  0.0444444   0.0203202   
0  0.570946  0.535959  [[167, 125], [2, 2]]  0.724512  0.0305344  0.00444915   
8  0.986486       0.5    [[292, 0], [4, 0]]  0.993197          0           0   
9  0.986486       0.5    [[292, 0], [4, 0]]  0.993197          0           0   
2  0.983108  0.498288    [[291, 1], [4, 0]]  0.991482          0 -0.00543478   
5  0.983108  0.498288    [[291, 1], [4, 0]]  0.991482          0 -0.00543478   
6  0.976351  0.494863    [[289, 3], [4, 0]]  0.988034          0  -0.0117188   
4  0.949324  0.481164   [[281, 11], [4, 0]]  0.974003          0  -0.0202206   
7   0.64527  0.450342  [[190, 102], [3, 1]]  0.783505  0.0186916 -0.00752075   
1  0.773649  0.392123   [[229, 63], [4, 0]]  0.872381          0  -0.0260762   

  model_score   prec_c0     prec_c1    rec_c0 rec_c1  
3   0.0377738  0.988235   0.0243902  0.863014   0.25  
0   0.0167769  0.988166    0.015748  0.571918    0.5  
8           0  0.986486           0         1      0  
9           0  0.986486           0         1      0  
2  -0.0068144  0.986441           0  0.996575      0  
5  -0.0068144  0.986441           0  0.996575      0  
6  -0.0118431  0.986348           0  0.989726      0  
4  -0.0229939  0.985965           0  0.962329      0  
7  -0.0240735  0.984456  0.00970874  0.650685   0.25  
1  -0.0608599  0.982833           0  0.784247      0  
Elapsed time 21.41 mins 

************************************************************

pre/post: 25/0  win/stride: 500/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-23 10:58:48.175000 
pca_target: 0 	 poly degree: 0 	 kselect: 100 
Imbalance: ClusterCentroids(estimator=None, n_jobs=1, random_state=None, ratio='auto') 
Extended target (count):  25141 13
('Total : Processed (count): ', (986L, 438L), 13)
Final feature (count):  (986L, 438L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.541 	0.067 	0.016 	0.644 	0.635 	0.412
[[157 135]
 [  1   3]]
             precision    recall  f1-score   support

        0.0       0.99      0.54      0.70       292
        1.0       0.02      0.75      0.04         4

avg / total       0.98      0.54      0.69       296


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.1, class_weight={1: 3}, dual=False, fit_intercept=True,
          intercept_scaling=0.1, max_iter=100, multi_class='ovr', n_jobs=4,
          penalty='l2', random_state=None, solver='lbfgs', tol=0.0001,
          verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.672 	-0.079 	-0.027 	0.341 	0.000 	0.000
[[199  93]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.98      0.68      0.80       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.67      0.79       296


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.0001, average=False, class_weight={1: 50}, epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='invscaling', loss='squared_hinge', n_iter=5,
       n_jobs=4, penalty='none', power_t=0.5, random_state=None,
       shuffle=True, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.581 	0.019 	0.005 	0.541 	0.540 	0.289
[[170 122]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      0.58      0.73       292
        1.0       0.02      0.50      0.03         4

avg / total       0.98      0.58      0.72       296


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=8, max_features=0.75, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.480 	0.052 	0.011 	0.613 	0.598 	0.367
[[139 153]
 [  1   3]]
             precision    recall  f1-score   support

        0.0       0.99      0.48      0.64       292
        1.0       0.02      0.75      0.04         4

avg / total       0.98      0.48      0.64       296


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 15}, criterion='gini',
            max_depth=8, max_features=0.33, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=50, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.571 	0.017 	0.004 	0.536 	0.535 	0.284
[[167 125]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      0.57      0.72       292
        1.0       0.02      0.50      0.03         4

avg / total       0.98      0.57      0.72       296


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.01, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(500,), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.824 	-0.051 	-0.026 	0.418 	0.000 	0.000
[[244  48]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.98      0.84      0.90       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.82      0.89       296


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 500}, criterion='entropy',
            max_depth=8, max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=2.0, n_estimators=15, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.409 	0.036 	0.007 	0.577 	0.551 	0.314
[[118 174]
 [  1   3]]
             precision    recall  f1-score   support

        0.0       0.99      0.40      0.57       292
        1.0       0.02      0.75      0.03         4

avg / total       0.98      0.41      0.57       296


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='linear',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.720 	-0.071 	-0.026 	0.365 	0.000 	0.000
[[213  79]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.98      0.73      0.84       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.72      0.83       296


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...wski',
           metric_params=None, n_jobs=4, n_neighbors=4, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.628 	-0.087 	-0.027 	0.318 	0.000 	0.000
[[186 106]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.98      0.64      0.77       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.63      0.76       296


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=4, p=1,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.824 	-0.051 	-0.026 	0.418 	0.000 	0.000
[[244  48]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.98      0.84      0.90       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.82      0.89       296


                estimator min_score mean_score max_score  sd_score       acc  \
0              GaussianNB  0.906078   0.906078  0.906078         0  0.540541   
3    ExtraTreesClassifier  0.478822   0.847683         1  0.114869   0.47973   
6      AdaBoostClassifier  0.111111   0.684918         1   0.14742  0.408784   
2           SGDClassifier   -0.3849   0.332867  0.794967  0.190244  0.581081   
4  RandomForestClassifier         0   0.609606         1  0.180812  0.570946   
5           MLPClassifier -0.145489  0.0705445  0.350522  0.119435  0.824324   
9    KNeighborsClassifier   -0.1283  0.0443396    0.3849  0.134932  0.824324   
7                     SVC         0   0.183813  0.461633  0.138137  0.719595   
1      LogisticRegression   -0.1283   0.324853  0.718234  0.218578  0.672297   
8        VotingClassifier   -0.1283   0.341385  0.683856  0.146225  0.628378   

        auc           conf_matrix     f1_c0      f1_c1       kappa  \
0  0.643836  [[157, 135], [1, 3]]  0.697778  0.0422535   0.0164191   
3  0.613014  [[139, 153], [1, 3]]  0.643519     0.0375   0.0114504   
6  0.577055  [[118, 174], [1, 3]]  0.574209  0.0331492  0.00690184   
2  0.541096  [[170, 122], [2, 2]]  0.732759    0.03125  0.00520382   
4  0.535959  [[167, 125], [2, 2]]  0.724512  0.0305344  0.00444915   
5  0.417808   [[244, 48], [4, 0]]  0.903704          0  -0.0255864   
9  0.417808   [[244, 48], [4, 0]]  0.903704          0  -0.0255864   
7  0.364726   [[213, 79], [4, 0]]  0.836935          0  -0.0264037   
1  0.340753   [[199, 93], [4, 0]]   0.80404          0  -0.0266018   
8  0.318493  [[186, 106], [4, 0]]  0.771784          0  -0.0267407   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
0   0.0665809  0.993671  0.0217391  0.537671   0.75  
3   0.0522704  0.992857  0.0192308  0.476027   0.75  
6   0.0362903  0.991597  0.0169492   0.40411   0.75  
2   0.0192342  0.988372   0.016129  0.582192    0.5  
4   0.0167769  0.988166   0.015748  0.571918    0.5  
5  -0.0514912  0.983871          0  0.835616      0  
9  -0.0514912  0.983871          0  0.835616      0  
7  -0.0706191  0.981567          0  0.729452      0  
1  -0.0792195  0.980296          0  0.681507      0  
8  -0.0874208  0.978947          0  0.636986      0  
Elapsed time 15.08 mins 

************************************************************

pre/post: 25/0  win/stride: 500/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-23 11:13:53.098000 
pca_target: 0 	 poly degree: 0 	 kselect: 100 
Imbalance: SMOTE(k=None, k_neighbors=5, kind='regular', m=None, m_neighbors=10, n_jobs=1,
   out_step=0.5, random_state=None, ratio='auto', svm_estimator=None) 
Extended target (count):  25141 13
('Total : Processed (count): ', (986L, 438L), 13)
Final feature (count):  (986L, 438L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.797 	0.016 	0.007 	0.527 	0.449 	0.190
[[235  57]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.80      0.89       292
        1.0       0.02      0.25      0.03         4

avg / total       0.97      0.80      0.88       296


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=10, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.956 	-0.021 	-0.019 	0.485 	0.000 	0.000
[[283   9]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.97      0.98       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.96      0.96       296


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.001, average=False, class_weight='balanced',
       epsilon=0.1, eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='invscaling', loss='modified_huber', n_iter=5,
       n_jobs=4, penalty='l1', power_t=0.5, random_state=None,
       shuffle=True, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.926 	-0.030 	-0.023 	0.469 	0.000 	0.000
[[274  18]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.94      0.96       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.93      0.95       296


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 500},
           criterion='entropy', max_depth=None, max_features='auto',
           max_leaf_nodes=None, min_impurity_split=1e-07,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=4,
           oob_score=False, random_state=None, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.983 	-0.007 	-0.005 	0.498 	0.000 	0.000
[[291   1]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.98       296


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight='balanced',
            criterion='gini', max_depth=None, max_features='auto',
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(500,), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.973 	-0.014 	-0.014 	0.493 	0.000 	0.000
[[288   4]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.97      0.97       296


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='entropy', max_depth=8,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=1.0, n_estimators=50, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.983 	-0.007 	-0.005 	0.498 	0.000 	0.000
[[291   1]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.98       296


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.1, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=10.0, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', ...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.970 	-0.015 	-0.015 	0.491 	0.000 	0.000
[[287   5]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.98      0.98       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.97      0.97       296


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=1,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.936 	-0.027 	-0.022 	0.474 	0.000 	0.000
[[277  15]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.95      0.97       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.94      0.95       296


                estimator min_score mean_score max_score    sd_score  \
0              GaussianNB  0.703617   0.703617  0.703617           0   
4  RandomForestClassifier  0.953802   0.978061  0.992674  0.00833687   
7                     SVC         0   0.798577         1    0.311484   
3    ExtraTreesClassifier  0.647758   0.966781         1    0.055703   
6      AdaBoostClassifier  0.888849   0.972655  0.997084   0.0192057   
5           MLPClassifier  0.958432   0.971291  0.984032  0.00757947   
8        VotingClassifier  0.874571   0.934893  0.969776   0.0223321   
1      LogisticRegression  0.136642   0.774574   0.94323     0.15315   
9    KNeighborsClassifier  0.830906   0.871907  0.925066   0.0313999   
2           SGDClassifier  -0.07244   0.591139  0.945716      0.2598   

        acc       auc          conf_matrix     f1_c0      f1_c1       kappa  \
0  0.797297  0.527397  [[235, 57], [3, 1]]  0.886792  0.0322581  0.00715564   
4  0.986486       0.5   [[292, 0], [4, 0]]  0.993197          0           0   
7  0.986486       0.5   [[292, 0], [4, 0]]  0.993197          0           0   
3  0.983108  0.498288   [[291, 1], [4, 0]]  0.991482          0 -0.00543478   
6  0.983108  0.498288   [[291, 1], [4, 0]]  0.991482          0 -0.00543478   
5  0.972973  0.493151   [[288, 4], [4, 0]]  0.986301          0  -0.0136986   
8  0.969595  0.491438   [[287, 5], [4, 0]]  0.984563          0  -0.0152439   
1  0.956081  0.484589   [[283, 9], [4, 0]]  0.977547          0  -0.0190678   
9  0.935811  0.474315  [[277, 15], [4, 0]]  0.966841          0  -0.0218023   
2  0.925676  0.469178  [[274, 18], [4, 0]]  0.961404          0  -0.0226131   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
0   0.0159388  0.987395  0.0172414  0.804795   0.25  
4           0  0.986486          0         1      0  
7           0  0.986486          0         1      0  
3  -0.0068144  0.986441          0  0.996575      0  
6  -0.0068144  0.986441          0  0.996575      0  
5  -0.0136986  0.986301          0  0.986301      0  
8  -0.0153418  0.986254          0  0.982877      0  
1  -0.0207262  0.986063          0  0.969178      0  
9  -0.0270415  0.985765          0   0.94863      0  
2  -0.0297819  0.985612          0  0.938356      0  
Elapsed time 51.80 mins 

************************************************************

pre/post: 25/0  win/stride: 500/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-04-23 12:05:41.191000 
pca_target: 0 	 poly degree: 0 	 kselect: 100 
Imbalance: None 
Extended target (count):  25141 13
('Total : Processed (count): ', (986L, 438L), 13)
Final feature (count):  (986L, 438L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.632 	0.032 	0.010 	0.567 	0.563 	0.313
[[185 107]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      0.63      0.77       292
        1.0       0.02      0.50      0.04         4

avg / total       0.98      0.63      0.76       296


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=10, class_weight={1: 500}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='sag', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.716 	-0.007 	-0.003 	0.486 	0.425 	0.172
[[211  81]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.72      0.83       292
        1.0       0.01      0.25      0.02         4

avg / total       0.97      0.72      0.82       296


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.001, average=False, class_weight={1: 50}, epsilon=0.1,
       eta0=0.001, fit_intercept=True, l1_ratio=0.15,
       learning_rate='invscaling', loss='modified_huber', n_iter=5,
       n_jobs=4, penalty='elasticnet', power_t=0.5, random_state=None,
       shuffle=True, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.649 	-0.084 	-0.027 	0.329 	0.000 	0.000
[[192 100]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.98      0.66      0.79       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.65      0.78       296


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 500},
           criterion='entropy', max_depth=8, max_features='auto',
           max_leaf_nodes=None, min_impurity_split=1e-07,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=15, n_jobs=4,
           oob_score=False, random_state=None, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.959 	-0.020 	-0.018 	0.486 	0.000 	0.000
[[284   8]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.97      0.98       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.96      0.97       296


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight='balanced',
            criterion='entropy', max_depth=8, max_features=0.75,
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=15, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.1, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.986 	0.000 	0.000 	0.500 	0.000 	0.000
[[292   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       296


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 50}, criterion='entropy', max_depth=8,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=2.0, n_estimators=80, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.973 	-0.014 	-0.014 	0.493 	0.000 	0.000
[[288   4]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.97      0.97       296


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=10, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.983 	-0.007 	-0.005 	0.498 	0.000 	0.000
[[291   1]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.98       296


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 500}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Ran...wski',
           metric_params=None, n_jobs=4, n_neighbors=4, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.983 	-0.007 	-0.005 	0.498 	0.000 	0.000
[[291   1]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.98       296


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=1,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.983 	-0.007 	-0.005 	0.498 	0.000 	0.000
[[291   1]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       292
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.98       296


                estimator   min_score   mean_score  max_score    sd_score  \
0              GaussianNB   0.0782007    0.0782007  0.0782007           0   
4  RandomForestClassifier -0.00414424  0.000177878  0.0985294  0.00784481   
5           MLPClassifier  -0.0152473   0.00479956   0.136916   0.0406067   
7                     SVC  -0.0260556   0.00406309  0.0942409   0.0287541   
8        VotingClassifier  -0.0114864   0.00565505   0.139857   0.0323652   
9    KNeighborsClassifier  -0.0169657    0.0189604   0.140904    0.050683   
6      AdaBoostClassifier  -0.0194447    0.0259367   0.271598   0.0505119   
1      LogisticRegression  -0.0640393     0.011751   0.127617   0.0375259   
3    ExtraTreesClassifier  -0.0206565   0.00475374   0.231609   0.0244868   
2           SGDClassifier   -0.085025     0.028344   0.149581   0.0384965   

        acc       auc           conf_matrix     f1_c0      f1_c1       kappa  \
0  0.631757  0.566781  [[185, 107], [2, 2]]  0.772443  0.0353982   0.0095776   
4  0.986486       0.5    [[292, 0], [4, 0]]  0.993197          0           0   
5  0.986486       0.5    [[292, 0], [4, 0]]  0.993197          0           0   
7  0.983108  0.498288    [[291, 1], [4, 0]]  0.991482          0 -0.00543478   
8  0.983108  0.498288    [[291, 1], [4, 0]]  0.991482          0 -0.00543478   
9  0.983108  0.498288    [[291, 1], [4, 0]]  0.991482          0 -0.00543478   
6  0.972973  0.493151    [[288, 4], [4, 0]]  0.986301          0  -0.0136986   
1  0.716216  0.486301   [[211, 81], [3, 1]]  0.833992  0.0232558 -0.00258065   
3  0.959459  0.486301    [[284, 8], [4, 0]]   0.97931          0  -0.0183486   
2  0.648649  0.328767  [[192, 100], [4, 0]]  0.786885          0  -0.0266809   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
0   0.0319719  0.989305  0.0183486  0.633562    0.5  
4           0  0.986486          0         1      0  
5           0  0.986486          0         1      0  
7  -0.0068144  0.986441          0  0.996575      0  
8  -0.0068144  0.986441          0  0.996575      0  
9  -0.0068144  0.986441          0  0.996575      0  
6  -0.0136986  0.986301          0  0.986301      0  
1  -0.0070683  0.985981  0.0121951  0.722603   0.25  
3  -0.0195069  0.986111          0  0.972603      0  
2  -0.0836008  0.979592          0  0.657534      0  
Elapsed time 25.11 mins 

************************************************************






