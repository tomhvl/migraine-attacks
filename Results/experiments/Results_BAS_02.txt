
******************************************************************************

TS features, MCC

pre/post: 50/0  win/stride: 300/50  label:start
filename: stm_sb_modified.csv 
Extended target (count):  31485 650
Feature Extraction: 100%|██████████| 1/1 [06:25<00:00, 385.50s/it]
('Total : Processed (count): ', (624L, 218L), 13)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
         ACC     MCC     KAP     AUC     GEOM    IBA
        0.718   -0.097  -0.051  0.369   0.000   0.000
[[135  48]
 [  5   0]]
             precision    recall  f1-score   support

          0       0.96      0.74      0.84       183
          1       0.00      0.00      0.00         5

avg / total       0.94      0.72      0.81       188


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.01, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
         ACC     MCC     KAP     AUC     GEOM    IBA
        0.681   0.031   0.014   0.544   0.525   0.267
[[126  57]
 [  3   2]]
             precision    recall  f1-score   support

          0       0.98      0.69      0.81       183
          1       0.03      0.40      0.06         5

avg / total       0.95      0.68      0.79       188


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.001, average=False, class_weight={1: 15}, epsilon=0.1,
       eta0=0.001, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='modified_huber', n_iter=5, n_jobs=4,
       penalty='l2', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
         ACC     MCC     KAP     AUC     GEOM    IBA
        0.899   -0.047  -0.041  0.462   0.000   0.000
[[169  14]
 [  5   0]]
             precision    recall  f1-score   support

          0       0.97      0.92      0.95       183
          1       0.00      0.00      0.00         5

avg / total       0.95      0.90      0.92       188


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 50}, criterion='gini',
           max_depth=8, max_features=0.75, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
         ACC     MCC     KAP     AUC     GEOM    IBA
        0.947   -0.027  -0.027  0.486   0.000   0.000
[[178   5]
 [  5   0]]
             precision    recall  f1-score   support

          0       0.97      0.97      0.97       183
          1       0.00      0.00      0.00         5

avg / total       0.95      0.95      0.95       188


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
         ACC     MCC     KAP     AUC     GEOM    IBA
        0.973   0.000   0.000   0.500   0.000   0.000
[[183   0]
 [  5   0]]
             precision    recall  f1-score   support

          0       0.97      1.00      0.99       183
          1       0.00      0.00      0.00         5

avg / total       0.95      0.97      0.96       188


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 32 candidates, totalling 160 fits
BEST: MLPClassifier(activation='relu', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
         ACC     MCC     KAP     AUC     GEOM    IBA
        0.963   -0.017  -0.015  0.495   0.000   0.000
[[181   2]
 [  5   0]]
             precision    recall  f1-score   support

          0       0.97      0.99      0.98       183
          1       0.00      0.00      0.00         5

avg / total       0.95      0.96      0.95       188


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 768 candidates, totalling 3840 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='entropy', max_depth=32,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=2.0, n_estimators=15, random_state=None)
         ACC     MCC     KAP     AUC     GEOM    IBA
        0.947   -0.027  -0.027  0.486   0.000   0.000
[[178   5]
 [  5   0]]
             precision    recall  f1-score   support

          0       0.97      0.97      0.97       183
          1       0.00      0.00      0.00         5

avg / total       0.95      0.95      0.95       188


Running GridSearchCV for SVC.
Fitting 5 folds for each of 200 candidates, totalling 1000 fits
BEST: SVC(C=0.5, cache_size=200, class_weight='balanced', coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
         ACC     MCC     KAP     AUC     GEOM    IBA
        0.968   -0.012  -0.009  0.497   0.000   0.000
[[182   1]
 [  5   0]]
             precision    recall  f1-score   support

          0       0.97      0.99      0.98       183
          1       0.00      0.00      0.00         5

avg / total       0.95      0.97      0.96       188


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 432 candidates, totalling 2160 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', R...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='hard', weights=[1, 1, 1])
         ACC     MCC     KAP     AUC     GEOM    IBA
        0.968   -0.012  -0.009  0.497   0.000   0.000
[[182   1]
 [  5   0]]
             precision    recall  f1-score   support

          0       0.97      0.99      0.98       183
          1       0.00      0.00      0.00         5

avg / total       0.95      0.97      0.96       188


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=3,
           weights='distance')
         ACC     MCC     KAP     AUC     GEOM    IBA
        0.968   0.243   0.235   0.595   0.445   0.182
[[181   2]
 [  4   1]]
             precision    recall  f1-score   support

          0       0.98      0.99      0.98       183
          1       0.33      0.20      0.25         5

avg / total       0.96      0.97      0.96       188


                estimator   min_score   mean_score  max_score    sd_score  \
9    KNeighborsClassifier  -0.0217261 -0.000945064   0.039334   0.0139401   
1      LogisticRegression  -0.0341036    0.0618904   0.175463   0.0539809   
4  RandomForestClassifier -0.00562047 -0.000311953          0  0.00097676   
7                     SVC  -0.0286663    0.0217753  0.0938767   0.0315265   
8        VotingClassifier  -0.0207919  -0.00783038  0.0510683   0.0107987   
5           MLPClassifier  -0.0255675    0.0209297  0.0687127   0.0370967   
3    ExtraTreesClassifier  -0.0160981    0.0359554   0.149179   0.0583031   
6      AdaBoostClassifier  -0.0274475    0.0205261   0.329243   0.0567704   
2           SGDClassifier    -0.11534    0.0702809   0.275984   0.0531301   
0              GaussianNB   0.0939981    0.0939981  0.0939981           0   

        acc       auc          conf_matrix     f1_c0   f1_c1       kappa  \
9  0.968085  0.594536   [[181, 2], [4, 1]]  0.983696    0.25    0.234735   
1  0.680851  0.544262  [[126, 57], [3, 2]]  0.807692  0.0625   0.0141584   
4  0.973404       0.5   [[183, 0], [5, 0]]  0.986523       0           0   
7  0.968085  0.497268   [[182, 1], [5, 0]]  0.983784       0 -0.00894454   
8  0.968085  0.497268   [[182, 1], [5, 0]]  0.983784       0 -0.00894454   
5  0.962766  0.494536   [[181, 2], [5, 0]]   0.98103       0  -0.0154321   
3  0.946809  0.486339   [[178, 5], [5, 0]]  0.972678       0  -0.0273224   
6  0.946809  0.486339   [[178, 5], [5, 0]]  0.972678       0  -0.0273224   
2  0.898936  0.461749  [[169, 14], [5, 0]]  0.946779       0  -0.0407925   
0  0.718085  0.368852  [[135, 48], [5, 0]]  0.835913       0  -0.0506116   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
9    0.242767  0.978378   0.333333  0.989071    0.2  
1    0.030694  0.976744  0.0338983  0.688525    0.4  
4           0  0.973404          0         1      0  
7  -0.0120876  0.973262          0  0.994536      0  
8  -0.0120876  0.973262          0  0.994536      0  
5  -0.0171403  0.973118          0  0.989071      0  
3  -0.0273224  0.972678          0  0.972678      0  
6  -0.0273224  0.972678          0  0.972678      0  
2  -0.0468866  0.971264          0  0.923497      0  
0  -0.0967868  0.964286          0  0.737705      0  
Elapsed time 39.56 mins


*******************************************************************************



pre/post: 50/0  win/stride: 200/50  label:start
filename: stm_sb_modified.csv 
Extended target (count):  31485 650
('Total : Processed (count): ', (626L, 22L), 13)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
         ACC     MCC     KAP     AUC     GEOM    IBA
        0.676   0.091   0.032   0.671   0.671   0.450
[[125  60]
 [  1   2]]
             precision    recall  f1-score   support

          0       0.99      0.68      0.80       185
          1       0.03      0.67      0.06         3

avg / total       0.98      0.68      0.79       188


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
C:\Users\Tomba\Anaconda2\lib\site-packages\sklearn\linear_model\sag.py:286: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  "the coef_ did not converge", ConvergenceWarning)
BEST: LogisticRegression(C=0.1, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=5, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='sag', tol=0.0001, verbose=0, warm_start=False)
         ACC     MCC     KAP     AUC     GEOM    IBA
        0.564   0.058   0.016   0.614   0.612   0.379
[[104  81]
 [  1   2]]
             precision    recall  f1-score   support

          0       0.99      0.56      0.72       185
          1       0.02      0.67      0.05         3

avg / total       0.98      0.56      0.71       188


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.001, average=False, class_weight='balanced',
       epsilon=0.1, eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='squared_hinge', n_iter=5, n_jobs=4,
       penalty='none', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
         ACC     MCC     KAP     AUC     GEOM    IBA
        0.809   -0.059  -0.030  0.411   0.000   0.000
[[152  33]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.98      0.82      0.89       185
          1       0.00      0.00      0.00         3

avg / total       0.96      0.81      0.88       188


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 500},
           criterion='entropy', max_depth=8, max_features=0.33,
           max_leaf_nodes=None, min_impurity_split=1e-07,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=4,
           oob_score=False, random_state=None, verbose=0, warm_start=False)
         ACC     MCC     KAP     AUC     GEOM    IBA
        0.824   -0.055  -0.030  0.419   0.000   0.000
[[155  30]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.98      0.84      0.90       185
          1       0.00      0.00      0.00         3

avg / total       0.97      0.82      0.89       188


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
C:\Users\Tomba\Anaconda2\lib\site-packages\sklearn\metrics\classification.py:516: RuntimeWarning: invalid value encountered in double_scalars
  mcc = cov_ytyp / np.sqrt(var_yt * var_yp)
C:\Users\Tomba\Anaconda2\lib\site-packages\sklearn\metrics\classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.
  'precision', 'predicted', average, warn_for)
C:\Users\Tomba\Anaconda2\lib\site-packages\sklearn\metrics\classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.
  'precision', 'predicted', average, warn_for)
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
         ACC     MCC     KAP     AUC     GEOM    IBA
        0.984   0.000   0.000   0.500   0.000   0.000
[[185   0]
 [  3   0]]
C:\Users\Tomba\Anaconda2\lib\site-packages\sklearn\metrics\classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
             precision    recall  f1-score   support

          0       0.98      1.00      0.99       185
          1       0.00      0.00      0.00         3

avg / total       0.97      0.98      0.98       188


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 32 candidates, totalling 160 fits
BEST: MLPClassifier(activation='relu', alpha=0.5, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
         ACC     MCC     KAP     AUC     GEOM    IBA
        0.979   -0.009  -0.008  0.497   0.000   0.000
[[184   1]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.98      0.99      0.99       185
          1       0.00      0.00      0.00         3

avg / total       0.97      0.98      0.97       188


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 768 candidates, totalling 3840 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 500}, criterion='entropy',
            max_depth=32, max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=0.5, n_estimators=30, random_state=None)
         ACC     MCC     KAP     AUC     GEOM    IBA
        0.947   -0.025  -0.023  0.481   0.000   0.000
[[178   7]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.98      0.96      0.97       185
          1       0.00      0.00      0.00         3

avg / total       0.97      0.95      0.96       188


Running GridSearchCV for SVC.
Fitting 5 folds for each of 200 candidates, totalling 1000 fits
BEST: SVC(C=10, cache_size=200, class_weight='balanced', coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
         ACC     MCC     KAP     AUC     GEOM    IBA
        0.963   -0.019  -0.019  0.489   0.000   0.000
[[181   4]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.98      0.98      0.98       185
          1       0.00      0.00      0.00         3

avg / total       0.97      0.96      0.97       188


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 432 candidates, totalling 2160 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 500}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Ran...wski',
           metric_params=None, n_jobs=4, n_neighbors=4, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
         ACC     MCC     KAP     AUC     GEOM    IBA
        0.984   0.000   0.000   0.500   0.000   0.000
[[185   0]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.98      1.00      0.99       185
          1       0.00      0.00      0.00         3

avg / total       0.97      0.98      0.98       188


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=3,
           weights='distance')
         ACC     MCC     KAP     AUC     GEOM    IBA
        0.968   -0.016  -0.016  0.492   0.000   0.000
[[182   3]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.98      0.98      0.98       185
          1       0.00      0.00      0.00         3

avg / total       0.97      0.97      0.97       188


                estimator  min_score  mean_score max_score   sd_score  \
0              GaussianNB   0.158324    0.158324  0.158324          0   
1      LogisticRegression -0.0320929   0.0669555  0.190154  0.0546984   
4  RandomForestClassifier -0.0161884 -0.00145259         0   0.002735   
8        VotingClassifier -0.0230607   0.0257537  0.231411   0.054914   
5           MLPClassifier -0.0283802   0.0456537  0.130006  0.0570845   
9    KNeighborsClassifier -0.0126309   0.0546366  0.282789  0.0864283   
7                     SVC -0.0183368   0.0643625  0.313885  0.0744662   
6      AdaBoostClassifier -0.0315747   0.0207923  0.367852  0.0523639   
3    ExtraTreesClassifier -0.0186921   0.0218825  0.257898  0.0587038   
2           SGDClassifier -0.0810987   0.0596812  0.203284  0.0538641   

        acc       auc          conf_matrix     f1_c0      f1_c1      kappa  \
0  0.675532  0.671171  [[125, 60], [1, 2]]  0.803859  0.0615385  0.0320729   
1   0.56383  0.614414  [[104, 81], [1, 2]]  0.717241  0.0465116  0.0162093   
4  0.984043       0.5   [[185, 0], [3, 0]]  0.991957          0          0   
8  0.984043       0.5   [[185, 0], [3, 0]]  0.991957          0          0   
5  0.978723  0.497297   [[184, 1], [3, 0]]  0.989247          0 -0.0080429   
9  0.968085  0.491892   [[182, 3], [3, 0]]  0.983784          0 -0.0162162   
7  0.962766  0.489189   [[181, 4], [3, 0]]   0.98103          0 -0.0185759   
6  0.946809  0.481081   [[178, 7], [3, 0]]  0.972678          0 -0.0228509   
3  0.824468  0.418919  [[155, 30], [3, 0]]   0.90379          0 -0.0298805   
2  0.808511  0.410811  [[152, 33], [3, 0]]  0.894118          0  -0.030137   

  model_score   prec_c0    prec_c1    rec_c0    rec_c1  
0   0.0912486  0.992063  0.0322581  0.675676  0.666667  
1   0.0577462  0.990476  0.0240964  0.562162  0.666667  
4           0  0.984043          0         1         0  
8           0  0.984043          0         1         0  
5 -0.00931224  0.983957          0  0.994595         0  
9  -0.0162162  0.983784          0  0.983784         0  
7  -0.0187757  0.983696          0  0.978378         0  
6  -0.0250429  0.983425          0  0.962162         0  
3   -0.055489  0.981013          0  0.837838         0  
2  -0.0587578  0.980645          0  0.821622         0  
Elapsed time 28.45 mins


*******************************************************************************

pre/post: 50/0  win/stride: 200/50  label:start
filename: stm_sb_modified.csv 
Extended target (count):  31485 650
('Total : Processed (count): ', (626L, 19L), 13)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
         ACC     MCC     KAP     AUC     GEOM    IBA
        0.686   0.095   0.034   0.677   0.677   0.457
[[127  58]
 [  1   2]]
             precision    recall  f1-score   support

          0       0.99      0.69      0.81       185
          1       0.03      0.67      0.06         3

avg / total       0.98      0.69      0.80       188


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=1, class_weight={1: 500}, dual=False, fit_intercept=True,
          intercept_scaling=0.1, max_iter=100, multi_class='ovr', n_jobs=4,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
         ACC     MCC     KAP     AUC     GEOM    IBA
        0.617   -0.012  -0.004  0.477   0.455   0.201
[[115  70]
 [  2   1]]
             precision    recall  f1-score   support

          0       0.98      0.62      0.76       185
          1       0.01      0.33      0.03         3

avg / total       0.97      0.62      0.75       188


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.1, average=False, class_weight='balanced', epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='modified_huber', n_iter=5, n_jobs=4,
       penalty='l1', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
         ACC     MCC     KAP     AUC     GEOM    IBA
        0.654   0.084   0.028   0.660   0.660   0.437
[[121  64]
 [  1   2]]
             precision    recall  f1-score   support

          0       0.99      0.65      0.79       185
          1       0.03      0.67      0.06         3

avg / total       0.98      0.65      0.78       188


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 50},
           criterion='entropy', max_depth=8, max_features=0.75,
           max_leaf_nodes=None, min_impurity_split=1e-07,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=4,
           oob_score=False, random_state=None, verbose=0, warm_start=False)
         ACC     MCC     KAP     AUC     GEOM    IBA
        0.931   -0.030  -0.025  0.473   0.000   0.000
[[175  10]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.98      0.95      0.96       185
          1       0.00      0.00      0.00         3

avg / total       0.97      0.93      0.95       188


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 500},
            criterion='entropy', max_depth=8, max_features='auto',
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=15, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
         ACC     MCC     KAP     AUC     GEOM    IBA
        0.984   0.000   0.000   0.500   0.000   0.000
[[185   0]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.98      1.00      0.99       185
          1       0.00      0.00      0.00         3

avg / total       0.97      0.98      0.98       188


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 32 candidates, totalling 160 fits
BEST: MLPClassifier(activation='tanh', alpha=0.1, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
         ACC     MCC     KAP     AUC     GEOM    IBA
        0.979   -0.009  -0.008  0.497   0.000   0.000
[[184   1]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.98      0.99      0.99       185
          1       0.00      0.00      0.00         3

avg / total       0.97      0.98      0.97       188


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 768 candidates, totalling 3840 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='entropy', max_depth=8,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=2.0, n_estimators=15, random_state=None)
         ACC     MCC     KAP     AUC     GEOM    IBA
        0.947   -0.025  -0.023  0.481   0.000   0.000
[[178   7]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.98      0.96      0.97       185
          1       0.00      0.00      0.00         3

avg / total       0.97      0.95      0.96       188


Running GridSearchCV for SVC.
Fitting 5 folds for each of 200 candidates, totalling 1000 fits
BEST: SVC(C=10, cache_size=200, class_weight={1: 15}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
         ACC     MCC     KAP     AUC     GEOM    IBA
        0.947   -0.025  -0.023  0.481   0.000   0.000
[[178   7]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.98      0.96      0.97       185
          1       0.00      0.00      0.00         3

avg / total       0.97      0.95      0.96       188


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 432 candidates, totalling 2160 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 500}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Ran...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='hard', weights=[1, 1, 1])
         ACC     MCC     KAP     AUC     GEOM    IBA
        0.968   -0.016  -0.016  0.492   0.000   0.000
[[182   3]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.98      0.98      0.98       185
          1       0.00      0.00      0.00         3

avg / total       0.97      0.97      0.97       188


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=2,
           weights='distance')
         ACC     MCC     KAP     AUC     GEOM    IBA
        0.968   -0.016  -0.016  0.492   0.000   0.000
[[182   3]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.98      0.98      0.98       185
          1       0.00      0.00      0.00         3

avg / total       0.97      0.97      0.97       188


                estimator  min_score  mean_score max_score   sd_score  \
0              GaussianNB   0.124409    0.124409  0.124409          0   
2           SGDClassifier -0.0753813   0.0506637  0.235617  0.0540948   
4  RandomForestClassifier -0.0145288  0.00174482  0.274537  0.0203531   
5           MLPClassifier -0.0246174   0.0623346  0.197405  0.0625425   
8        VotingClassifier -0.0324088 -0.00270167  0.128406  0.0227866   
9    KNeighborsClassifier -0.0208594  0.00729089  0.128406  0.0357544   
6      AdaBoostClassifier -0.0363482   0.0138422  0.271027   0.052069   
7                     SVC -0.0159164   0.0473453   0.23431  0.0624994   
1      LogisticRegression -0.0312286   0.0564395  0.151283  0.0508157   
3    ExtraTreesClassifier -0.0230606   0.0309452  0.268604  0.0733873   

        acc       auc          conf_matrix     f1_c0      f1_c1       kappa  \
0   0.68617  0.676577  [[127, 58], [1, 2]]  0.811502  0.0634921   0.0341344   
2  0.654255   0.66036  [[121, 64], [1, 2]]  0.788274   0.057971   0.0283079   
4  0.984043       0.5   [[185, 0], [3, 0]]  0.991957          0           0   
5  0.978723  0.497297   [[184, 1], [3, 0]]  0.989247          0  -0.0080429   
8  0.968085  0.491892   [[182, 3], [3, 0]]  0.983784          0  -0.0162162   
9  0.968085  0.491892   [[182, 3], [3, 0]]  0.983784          0  -0.0162162   
6  0.946809  0.481081   [[178, 7], [3, 0]]  0.972678          0  -0.0228509   
7  0.946809  0.481081   [[178, 7], [3, 0]]  0.972678          0  -0.0228509   
1  0.617021  0.477477  [[115, 70], [2, 1]]  0.761589   0.027027 -0.00370755   
3  0.930851  0.472973  [[175, 10], [3, 0]]  0.964187          0  -0.0251678   

  model_score   prec_c0    prec_c1    rec_c0    rec_c1  
0   0.0949356  0.992188  0.0333333  0.686486  0.666667  
2   0.0842018  0.991803   0.030303  0.654054  0.666667  
4           0  0.984043          0         1         0  
5 -0.00931224  0.983957          0  0.994595         0  
8  -0.0162162  0.983784          0  0.983784         0  
9  -0.0162162  0.983784          0  0.983784         0  
6  -0.0250429  0.983425          0  0.962162         0  
7  -0.0250429  0.983425          0  0.962162         0  
1  -0.0116432  0.982906  0.0140845  0.621622  0.333333  
3  -0.0301832  0.983146          0  0.945946         0  
Elapsed time 28.23 mins


*****************************************************************************



pre/post: 30/0  win/stride: 300/30  label:start
filename: stm_sb_modified.csv 
Extended target (count):  31485 390
('Total : Processed (count): ', (1040L, 22L), 13)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
         ACC     MCC     KAP     AUC     GEOM    IBA
        0.577   0.130   0.033   0.786   0.756   0.596
[[176 132]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.57      0.73       308
          1       0.03      1.00      0.06         4

avg / total       0.99      0.58      0.72       312


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=10, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=10, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='sag', tol=0.0001, verbose=0, warm_start=False)
         ACC     MCC     KAP     AUC     GEOM    IBA
        0.795   0.015   0.006   0.526   0.448   0.189
[[247  61]
 [  3   1]]
             precision    recall  f1-score   support

          0       0.99      0.80      0.89       308
          1       0.02      0.25      0.03         4

avg / total       0.98      0.79      0.87       312


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.1, average=False, class_weight={1: 50}, epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='perceptron', n_iter=5, n_jobs=4,
       penalty='l2', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
         ACC     MCC     KAP     AUC     GEOM    IBA
        0.670   0.158   0.049   0.833   0.816   0.688
[[205 103]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.67      0.80       308
          1       0.04      1.00      0.07         4

avg / total       0.99      0.67      0.79       312


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 50}, criterion='gini',
           max_depth=64, max_features=0.75, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
         ACC     MCC     KAP     AUC     GEOM    IBA
        0.987   0.000   0.000   0.500   0.000   0.000
[[308   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       308
          1       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       312


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 500},
            criterion='gini', max_depth=8, max_features=0.33,
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=15, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
         ACC     MCC     KAP     AUC     GEOM    IBA
        0.913   -0.032  -0.022  0.463   0.000   0.000
[[285  23]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.93      0.95       308
          1       0.00      0.00      0.00         4

avg / total       0.97      0.91      0.94       312


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 32 candidates, totalling 160 fits
BEST: MLPClassifier(activation='tanh', alpha=0.1, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(1000, 50), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
         ACC     MCC     KAP     AUC     GEOM    IBA
        0.978   -0.011  -0.011  0.495   0.000   0.000
[[305   3]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       308
          1       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.98       312


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 768 candidates, totalling 3840 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 50}, criterion='gini', max_depth=8,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=2.0, n_estimators=50, random_state=None)
         ACC     MCC     KAP     AUC     GEOM    IBA
        0.971   -0.015  -0.014  0.492   0.000   0.000
[[303   5]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.98      0.99       308
          1       0.00      0.00      0.00         4

avg / total       0.97      0.97      0.97       312


Running GridSearchCV for SVC.
Fitting 5 folds for each of 200 candidates, totalling 1000 fits
BEST: SVC(C=0.5, cache_size=200, class_weight={1: 500}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='linear',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
         ACC     MCC     KAP     AUC     GEOM    IBA
        0.731   0.121   0.043   0.740   0.740   0.549
[[225  83]
 [  1   3]]
             precision    recall  f1-score   support

          0       1.00      0.73      0.84       308
          1       0.03      0.75      0.07         4

avg / total       0.98      0.73      0.83       312


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 432 candidates, totalling 2160 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=1.0, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', R...owski',
           metric_params=None, n_jobs=4, n_neighbors=4, p=2,
           weights='uniform'))],
         n_jobs=4, voting='hard', weights=[1, 1, 1])
         ACC     MCC     KAP     AUC     GEOM    IBA
        0.987   0.000   0.000   0.500   0.000   0.000
[[308   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       308
          1       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       312


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='uniform')
         ACC     MCC     KAP     AUC     GEOM    IBA
        0.987   0.000   0.000   0.500   0.000   0.000
[[308   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       308
          1       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       312


                estimator   min_score   mean_score  max_score    sd_score  \
2           SGDClassifier  -0.0882226    0.0383718   0.181883   0.0417985   
0              GaussianNB   0.0116288    0.0116288  0.0116288           0   
7                     SVC  -0.0480931    0.0249772   0.115192   0.0449003   
1      LogisticRegression  -0.0365159    0.0461222   0.148091   0.0451063   
3    ExtraTreesClassifier  -0.0250825   0.00815266    0.14132   0.0352699   
8        VotingClassifier  -0.0107361  -0.00293676   0.139357  0.00752532   
9    KNeighborsClassifier -0.00935291  -0.00388565          0  0.00341006   
5           MLPClassifier  -0.0180516  -0.00053643  0.0551798   0.0237289   
6      AdaBoostClassifier  -0.0192544    0.0172802   0.213533   0.0417767   
4  RandomForestClassifier  -0.0144167 -0.000724544  0.0622187  0.00390719   

        acc       auc           conf_matrix     f1_c0      f1_c1       kappa  \
2  0.669872  0.832792  [[205, 103], [0, 4]]   0.79922  0.0720721   0.0485552   
0  0.576923  0.785714  [[176, 132], [0, 4]]  0.727273  0.0571429   0.0330579   
7  0.730769   0.74026   [[225, 83], [1, 3]]  0.842697  0.0666667   0.0432243   
1  0.794872  0.525974   [[247, 61], [3, 1]]  0.885305   0.030303  0.00636943   
3  0.987179       0.5    [[308, 0], [4, 0]]  0.993548          0           0   
8  0.987179       0.5    [[308, 0], [4, 0]]  0.993548          0           0   
9  0.987179       0.5    [[308, 0], [4, 0]]  0.993548          0           0   
5  0.977564   0.49513    [[305, 3], [4, 0]]  0.988655          0  -0.0111111   
6  0.971154  0.491883    [[303, 5], [4, 0]]  0.985366          0  -0.0144509   
4  0.913462  0.462662   [[285, 23], [4, 0]]  0.954774          0  -0.0223301   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
2    0.157739         1  0.0373832  0.665584      1  
0    0.129641         1  0.0294118  0.571429      1  
7     0.12098  0.995575  0.0348837  0.730519   0.75  
1   0.0146457     0.988   0.016129  0.801948   0.25  
3           0  0.987179          0         1      0  
8           0  0.987179          0         1      0  
9           0  0.987179          0         1      0  
5  -0.0112289  0.987055          0   0.99026      0  
6  -0.0145436  0.986971          0  0.983766      0  
4  -0.0321492  0.986159          0  0.925325      0  
Elapsed time 33.99 mins


****************************************************************************


pre/post: 30/0  win/stride: 300/30  label:start
filename: stm_sb_modified.csv 
Extended target (count):  31485 390
('Total : Processed (count): ', (1040L, 19L), 13)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
         ACC     MCC     KAP     AUC     GEOM    IBA
        0.593   0.134   0.035   0.794   0.767   0.612
[[181 127]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.59      0.74       308
          1       0.03      1.00      0.06         4

avg / total       0.99      0.59      0.73       312


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=5, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='sag', tol=0.0001, verbose=0, warm_start=False)
         ACC     MCC     KAP     AUC     GEOM    IBA
        0.936   0.094   0.071   0.597   0.486   0.220
[[291  17]
 [  3   1]]
             precision    recall  f1-score   support

          0       0.99      0.94      0.97       308
          1       0.06      0.25      0.09         4

avg / total       0.98      0.94      0.96       312


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.1, average=False, class_weight={1: 15}, epsilon=0.1,
       eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='constant', loss='perceptron', n_iter=5, n_jobs=4,
       penalty='none', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
         ACC     MCC     KAP     AUC     GEOM    IBA
        0.686   0.105   0.034   0.718   0.717   0.517
[[211  97]
 [  1   3]]
             precision    recall  f1-score   support

          0       1.00      0.69      0.81       308
          1       0.03      0.75      0.06         4

avg / total       0.98      0.69      0.80       312


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 15}, criterion='gini',
           max_depth=64, max_features=0.75, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
         ACC     MCC     KAP     AUC     GEOM    IBA
        0.984   -0.006  -0.005  0.498   0.000   0.000
[[307   1]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       308
          1       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.98       312


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 500},
            criterion='gini', max_depth=8, max_features=0.33,
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
         ACC     MCC     KAP     AUC     GEOM    IBA
        0.881   0.215   0.119   0.817   0.814   0.654
[[272  36]
 [  1   3]]
             precision    recall  f1-score   support

          0       1.00      0.88      0.94       308
          1       0.08      0.75      0.14         4

avg / total       0.98      0.88      0.93       312


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 32 candidates, totalling 160 fits
BEST: MLPClassifier(activation='relu', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
         ACC     MCC     KAP     AUC     GEOM    IBA
        0.974   -0.013  -0.013  0.494   0.000   0.000
[[304   4]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       308
          1       0.00      0.00      0.00         4

avg / total       0.97      0.97      0.97       312


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 768 candidates, totalling 3840 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight='balanced', criterion='entropy',
            max_depth=16, max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=1.5, n_estimators=30, random_state=None)
         ACC     MCC     KAP     AUC     GEOM    IBA
        0.984   -0.006  -0.005  0.498   0.000   0.000
[[307   1]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       308
          1       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.98       312


Running GridSearchCV for SVC.
Fitting 5 folds for each of 200 candidates, totalling 1000 fits
BEST: SVC(C=0.1, cache_size=200, class_weight='balanced', coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='linear',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
         ACC     MCC     KAP     AUC     GEOM    IBA
        0.689   0.165   0.053   0.843   0.828   0.707
[[211  97]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.69      0.81       308
          1       0.04      1.00      0.08         4

avg / total       0.99      0.69      0.80       312


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 432 candidates, totalling 2160 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=1.0, class_weight={1: 500}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Ran...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='hard', weights=[1, 1, 1])
         ACC     MCC     KAP     AUC     GEOM    IBA
        0.965   -0.017  -0.017  0.489   0.000   0.000
[[301   7]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.98      0.98       308
          1       0.00      0.00      0.00         4

avg / total       0.97      0.96      0.97       312


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='uniform')
         ACC     MCC     KAP     AUC     GEOM    IBA
        0.987   0.000   0.000   0.500   0.000   0.000
[[308   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       308
          1       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       312


                estimator   min_score   mean_score  max_score    sd_score  \
7                     SVC  -0.0452415    0.0172797    0.10727   0.0363035   
4  RandomForestClassifier  -0.0153151  0.000206282  0.0854266  0.00808735   
0              GaussianNB   0.0218747    0.0218747  0.0218747           0   
2           SGDClassifier  -0.0640058    0.0381165   0.179558   0.0411286   
1      LogisticRegression  -0.0324346    0.0437852   0.176835    0.044056   
9    KNeighborsClassifier -0.00871499  -0.00331426          0  0.00331479   
3    ExtraTreesClassifier  -0.0275933   0.00129018   0.139357    0.024802   
6      AdaBoostClassifier  -0.0192335    0.0138437   0.206962    0.038276   
5           MLPClassifier  -0.0175914  -0.00443099  0.0523581   0.0203826   
8        VotingClassifier -0.00935291  -0.00272307  0.0636792  0.00439144   

        acc       auc           conf_matrix     f1_c0      f1_c1       kappa  \
7  0.689103  0.842532   [[211, 97], [0, 4]]  0.813102  0.0761905   0.0528292   
4   0.88141  0.816558   [[272, 36], [1, 3]]  0.936317   0.139535    0.119048   
0  0.592949  0.793831  [[181, 127], [0, 4]]  0.740286  0.0592593   0.0352552   
2  0.685897  0.717532   [[211, 97], [1, 3]]  0.811538  0.0576923   0.0338726   
1  0.935897  0.597403   [[291, 17], [3, 1]]  0.966777  0.0909091   0.0714286   
9  0.987179       0.5    [[308, 0], [4, 0]]  0.993548          0           0   
3  0.983974  0.498377    [[307, 1], [4, 0]]  0.991922          0 -0.00515464   
6  0.983974  0.498377    [[307, 1], [4, 0]]  0.991922          0 -0.00515464   
5  0.974359  0.493506    [[304, 4], [4, 0]]  0.987013          0   -0.012987   
8  0.964744  0.488636    [[301, 7], [4, 0]]  0.982055          0  -0.0165877   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
7    0.164716         1   0.039604  0.685065      1  
4    0.215365  0.996337  0.0769231  0.883117   0.75  
0    0.133955         1  0.0305344  0.587662      1  
2     0.10488  0.995283       0.03  0.685065   0.75  
1   0.0939931  0.989796  0.0555556  0.944805   0.25  
9           0  0.987179          0         1      0  
3 -0.00646211  0.987138          0  0.996753      0  
6 -0.00646211  0.987138          0  0.996753      0  
5   -0.012987  0.987013          0  0.987013      0  
8  -0.0172645  0.986885          0  0.977273      0  
Elapsed time 33.69 mins


*****************************************************************************

