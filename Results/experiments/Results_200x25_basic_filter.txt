






Standard, lagged allx1, filter(tukey & hp), NT+, truncated





    pca = [0, 20]
    poly = [2, 0]
    ksel = [0, 20]
    imb = [None, SMOTE(), ClusterCentroids ]
	
	

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-05-03 20:04:18.339000 
pca_target: 0 	 poly degree: 2 	 kselect: 0 
Imbalance: None 
Extended target (count):  25141 325
('Total : Processed (count): ', (998L, 780L), 13)
Final feature (count):  (998L, 780L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.610 	0.141 	0.039 	0.802 	0.778 	0.629
[[179 117]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.60      0.75       296
          1       0.03      1.00      0.06         4

avg / total       0.99      0.61      0.74       300


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.001, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='sag', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.657 	0.097 	0.030 	0.703 	0.701 	0.496
[[194 102]
 [  1   3]]
             precision    recall  f1-score   support

          0       0.99      0.66      0.79       296
          1       0.03      0.75      0.06         4

avg / total       0.98      0.66      0.78       300


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.1, average=False, class_weight={1: 15}, epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='constant', loss='squared_hinge', n_iter=5, n_jobs=4,
       penalty='l2', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.750 	0.002 	0.001 	0.503 	0.435 	0.180
[[224  72]
 [  3   1]]
             precision    recall  f1-score   support

          0       0.99      0.76      0.86       296
          1       0.01      0.25      0.03         4

avg / total       0.97      0.75      0.85       300


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 500},
           criterion='entropy', max_depth=8, max_features='auto',
           max_leaf_nodes=None, min_impurity_split=1e-07,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=15, n_jobs=4,
           oob_score=False, random_state=None, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.930 	0.089 	0.066 	0.595 	0.485 	0.219
[[278  18]
 [  3   1]]
             precision    recall  f1-score   support

          0       0.99      0.94      0.96       296
          1       0.05      0.25      0.09         4

avg / total       0.98      0.93      0.95       300


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	0.000 	0.000 	0.500 	0.000 	0.000
[[296   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       296
          1       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       300


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.01, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.970 	-0.015 	-0.015 	0.492 	0.000 	0.000
[[291   5]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.98      0.98       296
          1       0.00      0.00      0.00         4

avg / total       0.97      0.97      0.97       300


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 50}, criterion='gini', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=1.0, n_estimators=15, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.983 	-0.007 	-0.005 	0.498 	0.000 	0.000
[[295   1]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       296
          1       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.98       300


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.01, cache_size=200, class_weight={1: 500}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.283 	0.071 	0.010 	0.637 	0.523 	0.294
[[ 81 215]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.27      0.43       296
          1       0.02      1.00      0.04         4

avg / total       0.99      0.28      0.42       300


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	0.000 	0.000 	0.500 	0.000 	0.000
[[296   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       296
          1       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       300


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=1,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	0.000 	0.000 	0.500 	0.000 	0.000
[[296   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       296
          1       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       300


                estimator   min_score   mean_score  max_score     sd_score  \
0              GaussianNB   0.0640833    0.0640833  0.0640833            0   
1      LogisticRegression  -0.0743317    0.0015557  0.0667332    0.0219012   
7                     SVC  -0.0236381   0.00176098  0.0622315     0.016587   
3    ExtraTreesClassifier  -0.0510135  -0.00360754  0.0325714    0.0075624   
2           SGDClassifier    -0.12138   0.00529294   0.122852     0.034435   
4  RandomForestClassifier -0.00614415 -0.000217185          0  0.000698319   
8        VotingClassifier  -0.0104941  -0.00210539          0   0.00239244   
9    KNeighborsClassifier  -0.0150083  -0.00333653          0   0.00581887   
6      AdaBoostClassifier  -0.0219649  -0.00537617   0.141315    0.0162444   
5           MLPClassifier  -0.0162052  -0.00136735  0.0923531    0.0244417   

        acc       auc           conf_matrix     f1_c0      f1_c1        kappa  \
0      0.61  0.802365  [[179, 117], [0, 4]]  0.753684      0.064    0.0391985   
1  0.656667  0.702703  [[194, 102], [1, 3]]  0.790224  0.0550459    0.0301318   
7  0.283333  0.636824   [[81, 215], [0, 4]]  0.429708  0.0358744   0.00994658   
3      0.93  0.594595   [[278, 18], [3, 1]]  0.963605  0.0869565      0.06639   
2      0.75  0.503378   [[224, 72], [3, 1]]  0.856597   0.025974  0.000710606   
4  0.986667       0.5    [[296, 0], [4, 0]]  0.993289          0            0   
8  0.986667       0.5    [[296, 0], [4, 0]]  0.993289          0            0   
9  0.986667       0.5    [[296, 0], [4, 0]]  0.993289          0            0   
6  0.983333  0.498311    [[295, 1], [4, 0]]  0.991597          0  -0.00536193   
5      0.97  0.491554    [[291, 5], [4, 0]]  0.984772          0   -0.0150376   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
0     0.14139         1  0.0330579   0.60473      1  
1   0.0974885  0.994872  0.0285714  0.655405   0.75  
7   0.0706976         1  0.0182648  0.273649      1  
3   0.0890927  0.989324  0.0526316  0.939189   0.25  
2  0.00180609  0.986784  0.0136986  0.756757   0.25  
4           0  0.986667          0         1      0  
8           0  0.986667          0         1      0  
9           0  0.986667          0         1      0  
6 -0.00672277  0.986622          0  0.996622      0  
5  -0.0151342  0.986441          0  0.983108      0  
Elapsed time 105.74 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-05-03 21:50:02.613000 
pca_target: 0 	 poly degree: 2 	 kselect: 0 
Imbalance: SMOTE(k=None, k_neighbors=5, kind='regular', m=None, m_neighbors=10, n_jobs=1,
   out_step=0.5, random_state=None, ratio='auto', svm_estimator=None) 
Extended target (count):  25141 325
('Total : Processed (count): ', (998L, 780L), 13)
Final feature (count):  (998L, 780L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.607 	0.140 	0.039 	0.801 	0.775 	0.625
[[178 118]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.60      0.75       296
          1       0.03      1.00      0.06         4

avg / total       0.99      0.61      0.74       300


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=10, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.933 	-0.028 	-0.022 	0.473 	0.000 	0.000
[[280  16]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.95      0.97       296
          1       0.00      0.00      0.00         4

avg / total       0.97      0.93      0.95       300


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.1, average=False, class_weight='balanced', epsilon=0.1,
       eta0=0.001, fit_intercept=True, l1_ratio=0.15,
       learning_rate='invscaling', loss='perceptron', n_iter=5, n_jobs=4,
       penalty='none', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.740 	0.190 	0.069 	0.868 	0.858 	0.756
[[218  78]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.74      0.85       296
          1       0.05      1.00      0.09         4

avg / total       0.99      0.74      0.84       300


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 50},
           criterion='entropy', max_depth=32, max_features=0.33,
           max_leaf_nodes=None, min_impurity_split=1e-07,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=4,
           oob_score=False, random_state=None, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.963 	-0.018 	-0.017 	0.488 	0.000 	0.000
[[289   7]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.98      0.98       296
          1       0.00      0.00      0.00         4

avg / total       0.97      0.96      0.97       300


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight='balanced',
            criterion='entropy', max_depth=16, max_features=0.33,
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.970 	-0.015 	-0.015 	0.492 	0.000 	0.000
[[291   5]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.98      0.98       296
          1       0.00      0.00      0.00         4

avg / total       0.97      0.97      0.97       300


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(500,), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.983 	-0.007 	-0.005 	0.498 	0.000 	0.000
[[295   1]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       296
          1       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.98       300


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 500}, criterion='entropy',
            max_depth=8, max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=1.0, n_estimators=80, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.983 	-0.007 	-0.005 	0.498 	0.000 	0.000
[[295   1]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       296
          1       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.98       300


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=10, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.977 	0.212 	0.211 	0.618 	0.497 	0.228
[[292   4]
 [  3   1]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       296
          1       0.20      0.25      0.22         4

avg / total       0.98      0.98      0.98       300


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=10.0, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', ...owski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='uniform'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.980 	0.240 	0.240 	0.620 	0.497 	0.229
[[293   3]
 [  3   1]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       296
          1       0.25      0.25      0.25         4

avg / total       0.98      0.98      0.98       300


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=4,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.920 	0.274 	0.181 	0.836 	0.832 	0.680
[[273  23]
 [  1   3]]
             precision    recall  f1-score   support

          0       1.00      0.92      0.96       296
          1       0.12      0.75      0.20         4

avg / total       0.98      0.92      0.95       300


                estimator min_score mean_score max_score   sd_score       acc  \
2           SGDClassifier -0.163957   0.500027  0.867751   0.220791      0.74   
9    KNeighborsClassifier  0.829224   0.888016  0.932325   0.031567      0.92   
0              GaussianNB  0.569898   0.569898  0.569898          0  0.606667   
8        VotingClassifier  0.861495   0.931141  0.968772  0.0235942      0.98   
7                     SVC         0   0.743072  0.988451   0.337899  0.976667   
5           MLPClassifier   0.94014   0.969855  0.989948  0.0111491  0.983333   
6      AdaBoostClassifier  0.882156   0.951784  0.994226  0.0248921  0.983333   
4  RandomForestClassifier  0.817967   0.942127  0.975628  0.0332588      0.97   
3    ExtraTreesClassifier  0.622792   0.918029  0.985538   0.087999  0.963333   
1      LogisticRegression   0.43861   0.725871  0.953314    0.14423  0.933333   

        auc           conf_matrix     f1_c0      f1_c1       kappa  \
2  0.868243   [[218, 78], [0, 4]]  0.848249  0.0930233   0.0693605   
9  0.836149   [[273, 23], [1, 3]]  0.957895        0.2    0.181074   
0  0.800676  [[178, 118], [0, 4]]  0.751055  0.0634921   0.0386704   
8  0.619932    [[293, 3], [3, 1]]  0.989865       0.25    0.239865   
7  0.618243    [[292, 4], [3, 1]]  0.988156   0.222222    0.210526   
5  0.498311    [[295, 1], [4, 0]]  0.991597          0 -0.00536193   
6  0.498311    [[295, 1], [4, 0]]  0.991597          0 -0.00536193   
4  0.491554    [[291, 5], [4, 0]]  0.984772          0  -0.0150376   
3  0.488176    [[289, 7], [4, 0]]  0.981324          0  -0.0172626   
1  0.472973   [[280, 16], [4, 0]]  0.965517          0  -0.0217984   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
2    0.189542         1  0.0487805  0.736486      1  
9    0.274079   0.99635   0.115385  0.922297   0.75  
0    0.140415         1  0.0327869  0.601351      1  
8    0.239865  0.989865       0.25  0.989865   0.25  
7    0.211878  0.989831        0.2  0.986486   0.25  
5 -0.00672277  0.986622          0  0.996622      0  
6 -0.00672277  0.986622          0  0.996622      0  
4  -0.0151342  0.986441          0  0.983108      0  
3   -0.017968  0.986348          0  0.976351      0  
1  -0.0275921  0.985915          0  0.945946      0  
Elapsed time 355.87 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-05-04 07:16:47.283000 
pca_target: 0 	 poly degree: 2 	 kselect: 0 
Imbalance: ClusterCentroids(estimator=None, n_jobs=1, random_state=None, ratio='auto') 
Extended target (count):  25141 325
('Total : Processed (count): ', (998L, 780L), 13)
Final feature (count):  (998L, 780L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.497 	0.112 	0.025 	0.745 	0.700 	0.515
[[145 151]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.49      0.66       296
          1       0.03      1.00      0.05         4

avg / total       0.99      0.50      0.65       300


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.001, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.483 	0.109 	0.024 	0.738 	0.690 	0.501
[[141 155]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.48      0.65       296
          1       0.03      1.00      0.05         4

avg / total       0.99      0.48      0.64       300


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=1, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.001, fit_intercept=True, l1_ratio=0.15,
       learning_rate='constant', loss='modified_huber', n_iter=5, n_jobs=4,
       penalty='l1', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.347 	0.082 	0.013 	0.669 	0.581 	0.360
[[100 196]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.34      0.51       296
          1       0.02      1.00      0.04         4

avg / total       0.99      0.35      0.50       300


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=8, max_features=0.75, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=30, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.347 	0.082 	0.013 	0.669 	0.581 	0.360
[[100 196]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.34      0.51       296
          1       0.02      1.00      0.04         4

avg / total       0.99      0.35      0.50       300


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features=0.75, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.350 	0.083 	0.014 	0.671 	0.584 	0.364
[[101 195]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.34      0.51       296
          1       0.02      1.00      0.04         4

avg / total       0.99      0.35      0.50       300


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.5, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.720 	0.057 	0.021 	0.611 	0.601 	0.353
[[214  82]
 [  2   2]]
             precision    recall  f1-score   support

          0       0.99      0.72      0.84       296
          1       0.02      0.50      0.05         4

avg / total       0.98      0.72      0.83       300


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 500}, criterion='entropy',
            max_depth=32, max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=2.0, n_estimators=15, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.463 	0.105 	0.022 	0.728 	0.675 	0.481
[[135 161]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.46      0.63       296
          1       0.02      1.00      0.05         4

avg / total       0.99      0.46      0.62       300


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.5, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='linear',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.607 	0.025 	0.007 	0.554 	0.551 	0.301
[[180 116]
 [  2   2]]
             precision    recall  f1-score   support

          0       0.99      0.61      0.75       296
          1       0.02      0.50      0.03         4

avg / total       0.98      0.61      0.74       300


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=1.0, class_weight={1: 500}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Ran...owski',
           metric_params=None, n_jobs=4, n_neighbors=4, p=2,
           weights='uniform'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.563 	0.129 	0.032 	0.779 	0.747 	0.582
[[165 131]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.56      0.72       296
          1       0.03      1.00      0.06         4

avg / total       0.99      0.56      0.71       300


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=5, p=1,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.617 	0.143 	0.040 	0.806 	0.782 	0.635
[[181 115]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.61      0.76       296
          1       0.03      1.00      0.07         4

avg / total       0.99      0.62      0.75       300


                estimator min_score mean_score  max_score  sd_score       acc  \
9    KNeighborsClassifier -0.589933  -0.237096  0.0171889  0.124355  0.616667   
8        VotingClassifier -0.496011  -0.255332     0.2566    0.1405  0.563333   
0              GaussianNB  0.794967   0.794967   0.794967         0  0.496667   
1      LogisticRegression -0.683856  -0.112803   0.273789  0.211958  0.483333   
6      AdaBoostClassifier  0.205033   0.778161          1  0.110936  0.463333   
4  RandomForestClassifier -0.111111   0.483216   0.794967  0.168357      0.35   
2           SGDClassifier -0.624311   0.011585     0.5132  0.191004  0.346667   
3    ExtraTreesClassifier -0.367711   0.659562   0.794967  0.208596  0.346667   
5           MLPClassifier -0.812156  -0.442808    -0.1283  0.164119      0.72   
7                     SVC -0.589933  0.0086099   0.273789  0.242128  0.606667   

        auc           conf_matrix     f1_c0      f1_c1       kappa  \
9  0.805743  [[181, 115], [0, 4]]   0.75891  0.0650407   0.0402804   
8  0.778716  [[165, 131], [0, 4]]  0.715835   0.057554   0.0324963   
0  0.744932  [[145, 151], [0, 4]]  0.657596  0.0503145   0.0249677   
1  0.738176  [[141, 155], [0, 4]]  0.645309  0.0490798   0.0236835   
6  0.728041  [[135, 161], [0, 4]]   0.62645  0.0473373   0.0218712   
4  0.670608  [[101, 195], [0, 4]]  0.508816  0.0394089   0.0136238   
2  0.668919  [[100, 196], [0, 4]]  0.505051  0.0392157   0.0134228   
3  0.668919  [[100, 196], [0, 4]]  0.505051  0.0392157   0.0134228   
5  0.611486   [[214, 82], [2, 2]]  0.835938  0.0454545   0.0205224   
7  0.554054  [[180, 116], [2, 2]]  0.753138  0.0327869  0.00717972   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
9    0.143367         1  0.0336134  0.611486      1  
8    0.128517         1  0.0296296  0.557432      1  
0    0.112435         1  0.0258065  0.489865      1  
1     0.10947         1  0.0251572  0.476351      1  
6     0.10515         1  0.0242424  0.456081      1  
4   0.0828168         1  0.0201005  0.341216      1  
2   0.0821995         1       0.02  0.337838      1  
3   0.0821995         1       0.02  0.337838      1  
5   0.0569589  0.990741  0.0238095  0.722973    0.5  
7   0.0253838  0.989011  0.0169492  0.608108    0.5  
Elapsed time 37.75 mins 

************************************************************



Standard, lagged allx1, filter(tukey & hp), NT+, truncated


    pca = [0, 20]
    poly = [0]
    ksel = [0]
    imb = [None, SMOTE(), ClusterCentroids() ]





	
pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-05-04 08:37:41.387000 
pca_target: 0 	 poly degree: 0 	 kselect: 0 
Imbalance: None 
Extended target (count):  25141 325
('Total : Processed (count): ', (998L, 38L), 13)
Final feature (count):  (998L, 38L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.507 	0.115 	0.026 	0.750 	0.707 	0.525
[[148 148]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.50      0.67       296
          1       0.03      1.00      0.05         4

avg / total       0.99      0.51      0.66       300


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.01, class_weight={1: 50}, dual=False,
          fit_intercept=True, intercept_scaling=5, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='sag', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.790 	0.013 	0.006 	0.524 	0.446 	0.188
[[236  60]
 [  3   1]]
             precision    recall  f1-score   support

          0       0.99      0.80      0.88       296
          1       0.02      0.25      0.03         4

avg / total       0.97      0.79      0.87       300


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.001, average=False, class_weight='balanced',
       epsilon=0.1, eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='constant', loss='perceptron', n_iter=5, n_jobs=4,
       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.540 	0.123 	0.030 	0.767 	0.731 	0.559
[[158 138]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.53      0.70       296
          1       0.03      1.00      0.05         4

avg / total       0.99      0.54      0.69       300


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 500}, criterion='gini',
           max_depth=8, max_features='auto', max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=50, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.807 	0.160 	0.071 	0.779 	0.778 	0.602
[[239  57]
 [  1   3]]
             precision    recall  f1-score   support

          0       1.00      0.81      0.89       296
          1       0.05      0.75      0.09         4

avg / total       0.98      0.81      0.88       300


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 500},
            criterion='gini', max_depth=8, max_features=0.75,
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.917 	0.175 	0.118 	0.711 	0.679 	0.442
[[273  23]
 [  2   2]]
             precision    recall  f1-score   support

          0       0.99      0.92      0.96       296
          1       0.08      0.50      0.14         4

avg / total       0.98      0.92      0.95       300


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.01, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.980 	-0.010 	-0.009 	0.497 	0.000 	0.000
[[294   2]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       296
          1       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.98       300


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 500}, criterion='entropy',
            max_depth=16, max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=0.5, n_estimators=80, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.980 	-0.010 	-0.009 	0.497 	0.000 	0.000
[[294   2]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       296
          1       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.98       300


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=1, cache_size=200, class_weight={1: 50}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.970 	-0.015 	-0.015 	0.492 	0.000 	0.000
[[291   5]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.98      0.98       296
          1       0.00      0.00      0.00         4

avg / total       0.97      0.97      0.97       300


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	0.000 	0.000 	0.500 	0.000 	0.000
[[296   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       296
          1       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       300


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=1,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	0.000 	0.000 	0.500 	0.000 	0.000
[[296   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       296
          1       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       300


                estimator  min_score   mean_score  max_score    sd_score  \
3    ExtraTreesClassifier -0.0469563  -0.00207726  0.0836598  0.00833979   
2           SGDClassifier  -0.153766      0.01873   0.146488   0.0351578   
0              GaussianNB  0.0574514    0.0574514  0.0574514           0   
4  RandomForestClassifier -0.0207016 -0.000222976  0.0435658  0.00288244   
1      LogisticRegression -0.0473292    0.0111274   0.103497   0.0273283   
8        VotingClassifier -0.0126245  -0.00239959          0  0.00358026   
9    KNeighborsClassifier -0.0165446  -0.00382419          0  0.00663878   
5           MLPClassifier -0.0169521  -0.00856577  0.0513588  0.00933295   
6      AdaBoostClassifier -0.0237221  -0.00600462   0.134836   0.0149973   
7                     SVC -0.0449648   0.00664654  0.0540121   0.0187833   

        acc       auc           conf_matrix     f1_c0      f1_c1       kappa  \
3  0.806667  0.778716   [[239, 57], [1, 3]]  0.891791    0.09375   0.0705128   
2      0.54  0.766892  [[158, 138], [0, 4]]  0.696035  0.0547945   0.0296269   
0  0.506667      0.75  [[148, 148], [0, 4]]  0.666667  0.0512821    0.025974   
4  0.916667  0.711149   [[273, 23], [2, 2]]  0.956217   0.137931    0.117647   
1      0.79  0.523649   [[236, 60], [3, 1]]  0.882243  0.0307692  0.00589102   
8  0.986667       0.5    [[296, 0], [4, 0]]  0.993289          0           0   
9  0.986667       0.5    [[296, 0], [4, 0]]  0.993289          0           0   
5      0.98  0.496622    [[294, 2], [4, 0]]  0.989899          0 -0.00896861   
6      0.98  0.496622    [[294, 2], [4, 0]]  0.989899          0 -0.00896861   
7      0.97  0.491554    [[291, 5], [4, 0]]  0.984772          0  -0.0150376   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
3    0.159841  0.995833       0.05  0.807432   0.75  
2    0.122622         1   0.028169  0.533784      1  
0    0.114708         1  0.0263158       0.5      1  
4     0.17525  0.992727       0.08  0.922297    0.5  
1   0.0134787  0.987448  0.0163934  0.797297   0.25  
8           0  0.986667          0         1      0  
9           0  0.986667          0         1      0  
5 -0.00952338  0.986577          0  0.993243      0  
6 -0.00952338  0.986577          0  0.993243      0  
7  -0.0151342  0.986441          0  0.983108      0  
Elapsed time 22.76 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-05-04 09:00:26.912000 
pca_target: 0 	 poly degree: 0 	 kselect: 0 
Imbalance: SMOTE(k=None, k_neighbors=5, kind='regular', m=None, m_neighbors=10, n_jobs=1,
   out_step=0.5, random_state=None, ratio='auto', svm_estimator=None) 
Extended target (count):  25141 325
('Total : Processed (count): ', (998L, 38L), 13)
Final feature (count):  (998L, 38L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.527 	0.119 	0.028 	0.760 	0.721 	0.545
[[154 142]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.52      0.68       296
          1       0.03      1.00      0.05         4

avg / total       0.99      0.53      0.68       300


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=10, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=5, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.810 	0.020 	0.009 	0.534 	0.452 	0.193
[[242  54]
 [  3   1]]
             precision    recall  f1-score   support

          0       0.99      0.82      0.89       296
          1       0.02      0.25      0.03         4

avg / total       0.97      0.81      0.88       300


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.001, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.001, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='perceptron', n_iter=5, n_jobs=4,
       penalty='l1', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.807 	0.160 	0.071 	0.779 	0.778 	0.602
[[239  57]
 [  1   3]]
             precision    recall  f1-score   support

          0       1.00      0.81      0.89       296
          1       0.05      0.75      0.09         4

avg / total       0.98      0.81      0.88       300


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 500},
           criterion='entropy', max_depth=None, max_features=0.33,
           max_leaf_nodes=None, min_impurity_split=1e-07,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=4,
           oob_score=False, random_state=None, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.980 	-0.010 	-0.009 	0.497 	0.000 	0.000
[[294   2]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       296
          1       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.98       300


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 500},
            criterion='entropy', max_depth=32, max_features='auto',
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.967 	0.161 	0.152 	0.613 	0.494 	0.226
[[289   7]
 [  3   1]]
             precision    recall  f1-score   support

          0       0.99      0.98      0.98       296
          1       0.12      0.25      0.17         4

avg / total       0.98      0.97      0.97       300


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.5, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(500,), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.977 	0.212 	0.211 	0.618 	0.497 	0.228
[[292   4]
 [  3   1]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       296
          1       0.20      0.25      0.22         4

avg / total       0.98      0.98      0.98       300


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 500}, criterion='entropy',
            max_depth=8, max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=1.0, n_estimators=80, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.963 	0.150 	0.138 	0.611 	0.493 	0.226
[[288   8]
 [  3   1]]
             precision    recall  f1-score   support

          0       0.99      0.97      0.98       296
          1       0.11      0.25      0.15         4

avg / total       0.98      0.96      0.97       300


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.5, cache_size=200, class_weight={1: 50}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.977 	-0.012 	-0.012 	0.495 	0.000 	0.000
[[293   3]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       296
          1       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.98       300


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=10.0, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', ...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.930 	0.196 	0.141 	0.718 	0.684 	0.448
[[277  19]
 [  2   2]]
             precision    recall  f1-score   support

          0       0.99      0.94      0.96       296
          1       0.10      0.50      0.16         4

avg / total       0.98      0.93      0.95       300


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=3,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.923 	0.370 	0.240 	0.961 	0.960 	0.929
[[273  23]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.92      0.96       296
          1       0.15      1.00      0.26         4

avg / total       0.99      0.92      0.95       300


                estimator  min_score mean_score max_score   sd_score  \
9    KNeighborsClassifier   0.816847   0.864375   0.91221  0.0314781   
2           SGDClassifier -0.0931434   0.452822   0.77571   0.206419   
0              GaussianNB    0.54748    0.54748   0.54748          0   
8        VotingClassifier   0.820084   0.880211  0.929739   0.023533   
5           MLPClassifier   0.936265   0.965827  0.981373  0.0101103   
4  RandomForestClassifier   0.706335   0.897322  0.966927  0.0732731   
6      AdaBoostClassifier   0.788114   0.917704  0.975567  0.0374688   
1      LogisticRegression          0   0.572366  0.822771   0.173035   
3    ExtraTreesClassifier   0.605923   0.894714  0.982676   0.112642   
7                     SVC          0   0.700293  0.985589   0.248928   

        acc       auc           conf_matrix     f1_c0      f1_c1       kappa  \
9  0.923333  0.961149   [[273, 23], [0, 4]]  0.959578   0.258065    0.240423   
2  0.806667  0.778716   [[239, 57], [1, 3]]  0.891791    0.09375   0.0705128   
0  0.526667  0.760135  [[154, 142], [0, 4]]  0.684444  0.0533333   0.0281073   
8      0.93  0.717905   [[277, 19], [2, 2]]  0.963478       0.16    0.140753   
5  0.976667  0.618243    [[292, 4], [3, 1]]  0.988156   0.222222    0.210526   
4  0.966667  0.613176    [[289, 7], [3, 1]]  0.982993   0.166667    0.151584   
6  0.963333  0.611486    [[288, 8], [3, 1]]  0.981261   0.153846    0.137931   
1      0.81  0.533784   [[242, 54], [3, 1]]   0.89464  0.0338983  0.00926999   
3      0.98  0.496622    [[294, 2], [4, 0]]  0.989899          0 -0.00896861   
7  0.976667  0.494932    [[293, 3], [4, 0]]  0.988196          0  -0.0115607   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
9    0.369644         1   0.148148  0.922297      1  
2    0.159841  0.995833       0.05  0.807432   0.75  
0     0.11939         1  0.0273973   0.52027      1  
8    0.195912  0.992832  0.0952381  0.935811    0.5  
5    0.211878  0.989831        0.2  0.986486   0.25  
4    0.161147  0.989726      0.125  0.976351   0.25  
6     0.14992  0.989691   0.111111  0.972973   0.25  
1   0.0200286  0.987755  0.0181818  0.817568   0.25  
3 -0.00952338  0.986577          0  0.993243      0  
7  -0.0116833  0.986532          0  0.989865      0  
Elapsed time 43.14 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-05-04 09:43:35.038000 
pca_target: 0 	 poly degree: 0 	 kselect: 0 
Imbalance: ClusterCentroids(estimator=None, n_jobs=1, random_state=None, ratio='auto') 
Extended target (count):  25141 325
('Total : Processed (count): ', (998L, 38L), 13)
Final feature (count):  (998L, 38L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.393 	0.091 	0.016 	0.693 	0.621 	0.409
[[114 182]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.39      0.56       296
          1       0.02      1.00      0.04         4

avg / total       0.99      0.39      0.55       300


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.001, class_weight={1: 3}, dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.507 	0.115 	0.026 	0.750 	0.707 	0.525
[[148 148]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.50      0.67       296
          1       0.03      1.00      0.05         4

avg / total       0.99      0.51      0.66       300


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.5, average=False, class_weight={1: 15}, epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='constant', loss='squared_hinge', n_iter=5, n_jobs=4,
       penalty='none', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.487 	0.110 	0.024 	0.740 	0.693 	0.505
[[142 154]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.48      0.65       296
          1       0.03      1.00      0.05         4

avg / total       0.99      0.49      0.64       300


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3},
           criterion='entropy', max_depth=16, max_features=0.75,
           max_leaf_nodes=None, min_impurity_split=1e-07,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=15, n_jobs=4,
           oob_score=False, random_state=None, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.500 	0.113 	0.025 	0.747 	0.702 	0.518
[[146 150]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.49      0.66       296
          1       0.03      1.00      0.05         4

avg / total       0.99      0.50      0.65       300


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3},
            criterion='entropy', max_depth=16, max_features=0.75,
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=15, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.430 	0.098 	0.019 	0.711 	0.650 	0.447
[[125 171]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.42      0.59       296
          1       0.02      1.00      0.04         4

avg / total       0.99      0.43      0.59       300


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.01, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.657 	0.038 	0.012 	0.579 	0.574 	0.324
[[195 101]
 [  2   2]]
             precision    recall  f1-score   support

          0       0.99      0.66      0.79       296
          1       0.02      0.50      0.04         4

avg / total       0.98      0.66      0.78       300


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=8,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=2.0, n_estimators=50, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.503 	0.114 	0.026 	0.748 	0.705 	0.522
[[147 149]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.50      0.66       296
          1       0.03      1.00      0.05         4

avg / total       0.99      0.50      0.66       300


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=1, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='linear',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.453 	0.103 	0.021 	0.723 	0.668 	0.471
[[132 164]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.45      0.62       296
          1       0.02      1.00      0.05         4

avg / total       0.99      0.45      0.61       300


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=10.0, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', ...wski',
           metric_params=None, n_jobs=4, n_neighbors=4, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.597 	0.138 	0.037 	0.796 	0.769 	0.615
[[175 121]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.59      0.74       296
          1       0.03      1.00      0.06         4

avg / total       0.99      0.60      0.73       300


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=5, p=1,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.570 	0.130 	0.033 	0.782 	0.751 	0.589
[[167 129]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.56      0.72       296
          1       0.03      1.00      0.06         4

avg / total       0.99      0.57      0.71       300


                estimator min_score mean_score max_score  sd_score       acc  \
8        VotingClassifier -0.205033   0.193587  0.461633  0.124611  0.596667   
9    KNeighborsClassifier   -0.3849 -0.0362061  0.589933  0.225272      0.57   
1      LogisticRegression   -0.1283    0.15725  0.496011  0.154144  0.506667   
6      AdaBoostClassifier  0.111111   0.731662         1  0.121404  0.503333   
3    ExtraTreesClassifier         0   0.460908  0.812156  0.183049       0.5   
2           SGDClassifier -0.812156  0.0764376  0.607122  0.226375  0.486667   
7                     SVC -0.461633  0.0596302  0.444444  0.199199  0.453333   
4  RandomForestClassifier -0.222222   0.404446  0.812156    0.2304      0.43   
0              GaussianNB         1          1         1         0  0.393333   
5           MLPClassifier -0.367711  0.0256292  0.239411  0.186385  0.656667   

        auc           conf_matrix     f1_c0      f1_c1      kappa model_score  \
8  0.795608  [[175, 121], [0, 4]]    0.7431  0.0620155  0.0371353    0.137546   
9  0.782095  [[167, 129], [0, 4]]  0.721382  0.0583942    0.03337    0.130262   
1      0.75  [[148, 148], [0, 4]]  0.666667  0.0512821   0.025974    0.114708   
6  0.748311  [[147, 149], [0, 4]]  0.663657  0.0509554  0.0256343    0.113945   
3  0.746622  [[146, 150], [0, 4]]  0.660633  0.0506329  0.0252989    0.113188   
2  0.739865  [[142, 154], [0, 4]]  0.648402  0.0493827  0.0239986    0.110205   
7  0.722973  [[132, 164], [0, 4]]  0.616822  0.0465116  0.0210124    0.103043   
4  0.711149  [[125, 171], [0, 4]]  0.593824  0.0446927  0.0191205   0.0982472   
0  0.692568  [[114, 182], [0, 4]]  0.556098  0.0421053  0.0164289   0.0910081   
5  0.579392  [[195, 101], [2, 2]]  0.791075  0.0373832   0.012022   0.0383557   

    prec_c0    prec_c1    rec_c0 rec_c1  
8         1      0.032  0.591216      1  
9         1  0.0300752  0.564189      1  
1         1  0.0263158       0.5      1  
6         1  0.0261438  0.496622      1  
3         1   0.025974  0.493243      1  
2         1  0.0253165   0.47973      1  
7         1  0.0238095  0.445946      1  
4         1  0.0228571  0.422297      1  
0         1  0.0215054  0.385135      1  
5  0.989848  0.0194175  0.658784    0.5  
Elapsed time 15.14 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-05-04 09:58:43.556000 
pca_target: 20 	 poly degree: 0 	 kselect: 0 
Imbalance: None 
Extended target (count):  25141 325
('Total : Processed (count): ', (998L, 38L), 13)
Final feature (count):  (998L, 38L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.960 	-0.019 	-0.018 	0.486 	0.000 	0.000
[[288   8]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.97      0.98       296
          1       0.00      0.00      0.00         4

avg / total       0.97      0.96      0.97       300


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.01, class_weight={1: 3}, dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.683 	-0.015 	-0.005 	0.470 	0.415 	0.165
[[204  92]
 [  3   1]]
             precision    recall  f1-score   support

          0       0.99      0.69      0.81       296
          1       0.01      0.25      0.02         4

avg / total       0.97      0.68      0.80       300


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=1, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='constant', loss='modified_huber', n_iter=5, n_jobs=4,
       penalty='none', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.913 	0.073 	0.050 	0.586 	0.480 	0.215
[[273  23]
 [  3   1]]
             precision    recall  f1-score   support

          0       0.99      0.92      0.95       296
          1       0.04      0.25      0.07         4

avg / total       0.98      0.91      0.94       300


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 500}, criterion='gini',
           max_depth=8, max_features=0.33, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=50, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.897 	0.060 	0.038 	0.578 	0.476 	0.212
[[268  28]
 [  3   1]]
             precision    recall  f1-score   support

          0       0.99      0.91      0.95       296
          1       0.03      0.25      0.06         4

avg / total       0.98      0.90      0.93       300


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight='balanced',
            criterion='gini', max_depth=8, max_features=0.75,
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=15, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	0.000 	0.000 	0.500 	0.000 	0.000
[[296   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       296
          1       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       300


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.1, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	0.000 	0.000 	0.500 	0.000 	0.000
[[296   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       296
          1       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       300


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight='balanced', criterion='entropy',
            max_depth=32, max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=2.0, n_estimators=50, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.977 	-0.012 	-0.012 	0.495 	0.000 	0.000
[[293   3]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       296
          1       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.98       300


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.5, cache_size=200, class_weight='balanced', coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	0.000 	0.000 	0.500 	0.000 	0.000
[[296   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       296
          1       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       300


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=1.0, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	0.000 	0.000 	0.500 	0.000 	0.000
[[296   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       296
          1       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       300


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=2,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.983 	-0.007 	-0.005 	0.498 	0.000 	0.000
[[295   1]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       296
          1       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.98       300


                estimator   min_score   mean_score  max_score    sd_score  \
2           SGDClassifier   -0.170701   0.00369726   0.135687   0.0260394   
3    ExtraTreesClassifier   -0.030061   0.00209839   0.171439   0.0167022   
4  RandomForestClassifier -0.00409642  0.000317937   0.141315  0.00745253   
5           MLPClassifier -0.00700296    0.0892961   0.236052   0.0723724   
7                     SVC  -0.0307416    0.0218982   0.277615   0.0607738   
8        VotingClassifier -0.00581371    0.0253406   0.141315   0.0542944   
9    KNeighborsClassifier -0.00495491    0.0404339   0.176585   0.0724821   
6      AdaBoostClassifier  -0.0209865     0.027732   0.260409   0.0514818   
0              GaussianNB  -0.0146132   -0.0146132 -0.0146132           0   
1      LogisticRegression  -0.0606473   0.00541691  0.0971959   0.0243254   

        acc       auc          conf_matrix     f1_c0      f1_c1       kappa  \
2  0.913333  0.586149  [[273, 23], [3, 1]]  0.954545  0.0714286   0.0497076   
3  0.896667  0.577703  [[268, 28], [3, 1]]  0.945326  0.0606061   0.0380637   
4  0.986667       0.5   [[296, 0], [4, 0]]  0.993289          0           0   
5  0.986667       0.5   [[296, 0], [4, 0]]  0.993289          0           0   
7  0.986667       0.5   [[296, 0], [4, 0]]  0.993289          0           0   
8  0.986667       0.5   [[296, 0], [4, 0]]  0.993289          0           0   
9  0.983333  0.498311   [[295, 1], [4, 0]]  0.991597          0 -0.00536193   
6  0.976667  0.494932   [[293, 3], [4, 0]]  0.988196          0  -0.0115607   
0      0.96  0.486486   [[288, 8], [4, 0]]  0.979592          0  -0.0180995   
1  0.683333  0.469595  [[204, 92], [3, 1]]  0.811133  0.0206186 -0.00507829   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
2   0.0728441   0.98913  0.0416667  0.922297   0.25  
3   0.0603196   0.98893  0.0344828  0.905405   0.25  
4           0  0.986667          0         1      0  
5           0  0.986667          0         1      0  
7           0  0.986667          0         1      0  
8           0  0.986667          0         1      0  
9 -0.00672277  0.986622          0  0.996622      0  
6  -0.0116833  0.986532          0  0.989865      0  
0  -0.0192414  0.986301          0  0.972973      0  
1   -0.015081  0.985507  0.0107527  0.689189   0.25  
Elapsed time 19.10 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-05-04 10:17:49.469000 
pca_target: 20 	 poly degree: 0 	 kselect: 0 
Imbalance: SMOTE(k=None, k_neighbors=5, kind='regular', m=None, m_neighbors=10, n_jobs=1,
   out_step=0.5, random_state=None, ratio='auto', svm_estimator=None) 
Extended target (count):  25141 325
('Total : Processed (count): ', (998L, 38L), 13)
Final feature (count):  (998L, 38L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.937 	-0.027 	-0.022 	0.475 	0.000 	0.000
[[281  15]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.95      0.97       296
          1       0.00      0.00      0.00         4

avg / total       0.97      0.94      0.95       300


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=5, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.803 	0.089 	0.040 	0.654 	0.635 	0.391
[[239  57]
 [  2   2]]
             precision    recall  f1-score   support

          0       0.99      0.81      0.89       296
          1       0.03      0.50      0.06         4

avg / total       0.98      0.80      0.88       300


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.1, average=False, class_weight='balanced', epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='modified_huber', n_iter=5, n_jobs=4,
       penalty='none', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.873 	0.130 	0.073 	0.689 	0.663 	0.423
[[260  36]
 [  2   2]]
             precision    recall  f1-score   support

          0       0.99      0.88      0.93       296
          1       0.05      0.50      0.10         4

avg / total       0.98      0.87      0.92       300


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 15},
           criterion='entropy', max_depth=32, max_features='auto',
           max_leaf_nodes=None, min_impurity_split=1e-07,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=4,
           oob_score=False, random_state=None, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.983 	-0.007 	-0.005 	0.498 	0.000 	0.000
[[295   1]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       296
          1       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.98       300


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight='balanced',
            criterion='gini', max_depth=32, max_features='auto',
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	0.000 	0.000 	0.500 	0.000 	0.000
[[296   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       296
          1       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       300


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.01, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.983 	-0.007 	-0.005 	0.498 	0.000 	0.000
[[295   1]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       296
          1       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.98       300


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='entropy', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=1.0, n_estimators=50, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	0.000 	0.000 	0.500 	0.000 	0.000
[[296   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       296
          1       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       300


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.5, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	0.000 	0.000 	0.500 	0.000 	0.000
[[296   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       296
          1       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       300


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=1.0, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', R...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.963 	-0.018 	-0.017 	0.488 	0.000 	0.000
[[289   7]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.98      0.98       296
          1       0.00      0.00      0.00         4

avg / total       0.97      0.96      0.97       300


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=4,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.953 	-0.022 	-0.019 	0.483 	0.000 	0.000
[[286  10]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.97      0.98       296
          1       0.00      0.00      0.00         4

avg / total       0.97      0.95      0.96       300


                estimator min_score mean_score max_score    sd_score  \
2           SGDClassifier -0.192448   0.519591  0.852879    0.245908   
1      LogisticRegression         0   0.631553  0.796103    0.227007   
4  RandomForestClassifier  0.934967   0.979422  0.994246   0.0117016   
6      AdaBoostClassifier  0.873954   0.974295  0.997108   0.0198293   
7                     SVC         0   0.763659         1    0.270221   
3    ExtraTreesClassifier  0.479456   0.954649  0.998554   0.0826252   
5           MLPClassifier  0.968721   0.984077  0.995672  0.00692348   
8        VotingClassifier  0.931415   0.958736   0.97439  0.00895526   
9    KNeighborsClassifier  0.906044   0.940725    0.9701   0.0221269   
0              GaussianNB  0.894183   0.894183  0.894183           0   

        acc       auc          conf_matrix     f1_c0      f1_c1       kappa  \
2  0.873333  0.689189  [[260, 36], [2, 2]]    0.9319  0.0952381   0.0728692   
1  0.803333  0.653716  [[239, 57], [2, 2]]   0.89013  0.0634921   0.0395051   
4  0.986667       0.5   [[296, 0], [4, 0]]  0.993289          0           0   
6  0.986667       0.5   [[296, 0], [4, 0]]  0.993289          0           0   
7  0.986667       0.5   [[296, 0], [4, 0]]  0.993289          0           0   
3  0.983333  0.498311   [[295, 1], [4, 0]]  0.991597          0 -0.00536193   
5  0.983333  0.498311   [[295, 1], [4, 0]]  0.991597          0 -0.00536193   
8  0.963333  0.488176   [[289, 7], [4, 0]]  0.981324          0  -0.0172626   
9  0.953333  0.483108  [[286, 10], [4, 0]]  0.976109          0  -0.0194175   
0  0.936667  0.474662  [[281, 15], [4, 0]]  0.967298          0  -0.0215054   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
2    0.130485  0.992366  0.0526316  0.878378    0.5  
1   0.0887138  0.991701  0.0338983  0.807432    0.5  
4           0  0.986667          0         1      0  
6           0  0.986667          0         1      0  
7           0  0.986667          0         1      0  
3 -0.00672277  0.986622          0  0.996622      0  
5 -0.00672277  0.986622          0  0.996622      0  
8   -0.017968  0.986348          0  0.976351      0  
9  -0.0215866  0.986207          0  0.966216      0  
0   -0.026669  0.985965          0  0.949324      0  
Elapsed time 26.03 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-05-04 10:43:51.332000 
pca_target: 20 	 poly degree: 0 	 kselect: 0 
Imbalance: ClusterCentroids(estimator=None, n_jobs=1, random_state=None, ratio='auto') 
Extended target (count):  25141 325
('Total : Processed (count): ', (998L, 38L), 13)
Final feature (count):  (998L, 38L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	0.000 	0.000 	0.500 	0.000 	0.000
[[296   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       296
          1       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       300


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.001, class_weight={1: 3}, dual=False,
          fit_intercept=True, intercept_scaling=0.01, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.480 	-0.005 	-0.001 	0.490 	0.490 	0.240
[[142 154]
 [  2   2]]
             precision    recall  f1-score   support

          0       0.99      0.48      0.65       296
          1       0.01      0.50      0.03         4

avg / total       0.97      0.48      0.64       300


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.1, average=False, class_weight='balanced', epsilon=0.1,
       eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='invscaling', loss='squared_hinge', n_iter=5,
       n_jobs=4, penalty='l1', power_t=0.5, random_state=None,
       shuffle=True, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.543 	0.010 	0.003 	0.522 	0.521 	0.271
[[161 135]
 [  2   2]]
             precision    recall  f1-score   support

          0       0.99      0.54      0.70       296
          1       0.01      0.50      0.03         4

avg / total       0.97      0.54      0.69       300


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=16, max_features='auto', max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=30, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.973 	-0.014 	-0.014 	0.493 	0.000 	0.000
[[292   4]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       296
          1       0.00      0.00      0.00         4

avg / total       0.97      0.97      0.97       300


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight='balanced',
            criterion='gini', max_depth=8, max_features=0.75,
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=15, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.487 	-0.003 	-0.001 	0.493 	0.493 	0.244
[[144 152]
 [  2   2]]
             precision    recall  f1-score   support

          0       0.99      0.49      0.65       296
          1       0.01      0.50      0.03         4

avg / total       0.97      0.49      0.64       300


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(500,), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.537 	0.009 	0.002 	0.519 	0.518 	0.268
[[159 137]
 [  2   2]]
             precision    recall  f1-score   support

          0       0.99      0.54      0.70       296
          1       0.01      0.50      0.03         4

avg / total       0.97      0.54      0.69       300


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 50}, criterion='gini', max_depth=8,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=1.0, n_estimators=15, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.930 	0.089 	0.066 	0.595 	0.485 	0.219
[[278  18]
 [  3   1]]
             precision    recall  f1-score   support

          0       0.99      0.94      0.96       296
          1       0.05      0.25      0.09         4

avg / total       0.98      0.93      0.95       300


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.5, cache_size=200, class_weight='balanced', coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	0.000 	0.000 	0.500 	0.000 	0.000
[[296   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       296
          1       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       300


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=10.0, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Ran...wski',
           metric_params=None, n_jobs=4, n_neighbors=4, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.543 	0.010 	0.003 	0.522 	0.521 	0.271
[[161 135]
 [  2   2]]
             precision    recall  f1-score   support

          0       0.99      0.54      0.70       296
          1       0.01      0.50      0.03         4

avg / total       0.97      0.54      0.69       300


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=4,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.530 	0.007 	0.002 	0.515 	0.515 	0.264
[[157 139]
 [  2   2]]
             precision    recall  f1-score   support

          0       0.99      0.53      0.69       296
          1       0.01      0.50      0.03         4

avg / total       0.97      0.53      0.68       300


                estimator min_score  mean_score max_score   sd_score  \
6      AdaBoostClassifier -0.718234  -0.0511734  0.624311   0.220149   
2           SGDClassifier -0.589933   0.0901127  0.461633  0.0973746   
8        VotingClassifier -0.333333    0.203076  0.538367   0.164243   
5           MLPClassifier -0.367711   0.0937955  0.478822   0.158564   
9    KNeighborsClassifier -0.589933    0.015897    0.3849   0.227568   
0              GaussianNB         0           0         0          0   
7                     SVC -0.222222   0.0502724  0.222222  0.0898298   
4  RandomForestClassifier -0.607122     0.04403  0.589933   0.220744   
3    ExtraTreesClassifier -0.461633   0.0547169    0.5132   0.177919   
1      LogisticRegression   -0.3849  0.00714002  0.239411  0.0677164   

        acc       auc           conf_matrix     f1_c0      f1_c1        kappa  \
6      0.93  0.594595   [[278, 18], [3, 1]]  0.963605  0.0869565      0.06639   
2  0.543333  0.521959  [[161, 135], [2, 2]]  0.701525  0.0283688   0.00252403   
8  0.543333  0.521959  [[161, 135], [2, 2]]  0.701525  0.0283688   0.00252403   
5  0.536667  0.518581  [[159, 137], [2, 2]]  0.695842   0.027972   0.00210587   
9      0.53  0.515203  [[157, 139], [2, 2]]   0.69011  0.0275862   0.00169924   
0  0.986667       0.5    [[296, 0], [4, 0]]  0.993289          0            0   
7  0.986667       0.5    [[296, 0], [4, 0]]  0.993289          0            0   
4  0.486667  0.493243  [[144, 152], [2, 2]]  0.651584  0.0253165 -0.000693121   
3  0.973333  0.493243    [[292, 4], [4, 0]]  0.986486          0   -0.0135135   
1      0.48  0.489865  [[142, 154], [2, 2]]  0.645455      0.025  -0.00102669   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
6   0.0890927  0.989324  0.0526316  0.939189   0.25  
2   0.0101128   0.98773  0.0145985  0.543919    0.5  
8   0.0101128   0.98773  0.0145985  0.543919    0.5  
5  0.00854784  0.987578  0.0143885  0.537162    0.5  
9  0.00698745  0.987421  0.0141844  0.530405    0.5  
0           0  0.986667          0         1      0  
7           0  0.986667          0         1      0  
4 -0.00310104  0.986301   0.012987  0.486486    0.5  
3  -0.0135135  0.986486          0  0.986486      0  
1 -0.00465363  0.986111  0.0128205   0.47973    0.5  
Elapsed time 13.68 mins 

************************************************************




Standard, lagged allx1, filter(tukey & hp), NT+, truncated



    pca = [0, 60]
    poly = [2]
    ksel = [60]
    imb = [None, SMOTE(), ClusterCentroids() ]
	
	
	
	

	
pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-05-04 12:03:43.790000 
pca_target: 0 	 poly degree: 2 	 kselect: 60 
Imbalance: None 
Extended target (count):  25141 325
('Total : Processed (count): ', (998L, 780L), 13)
Final feature (count):  (998L, 780L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.767 	0.006 	0.003 	0.512 	0.440 	0.183
[[229  67]
 [  3   1]]
             precision    recall  f1-score   support

          0       0.99      0.77      0.87       296
          1       0.01      0.25      0.03         4

avg / total       0.97      0.77      0.86       300


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.001, class_weight={1: 3}, dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.580 	0.133 	0.035 	0.787 	0.758 	0.599
[[170 126]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.57      0.73       296
          1       0.03      1.00      0.06         4

avg / total       0.99      0.58      0.72       300


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=1, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='perceptron', n_iter=5, n_jobs=4,
       penalty='none', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.973 	-0.014 	-0.014 	0.493 	0.000 	0.000
[[292   4]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       296
          1       0.00      0.00      0.00         4

avg / total       0.97      0.97      0.97       300


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 500}, criterion='gini',
           max_depth=16, max_features=0.33, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=30, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.973 	0.191 	0.187 	0.617 	0.496 	0.228
[[291   5]
 [  3   1]]
             precision    recall  f1-score   support

          0       0.99      0.98      0.99       296
          1       0.17      0.25      0.20         4

avg / total       0.98      0.97      0.98       300


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=30, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	0.000 	0.000 	0.500 	0.000 	0.000
[[296   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       296
          1       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       300


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.973 	-0.014 	-0.014 	0.493 	0.000 	0.000
[[292   4]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       296
          1       0.00      0.00      0.00         4

avg / total       0.97      0.97      0.97       300


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight='balanced', criterion='entropy',
            max_depth=32, max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=2.0, n_estimators=80, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.980 	-0.010 	-0.009 	0.497 	0.000 	0.000
[[294   2]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       296
          1       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.98       300


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.560 	0.128 	0.032 	0.777 	0.744 	0.579
[[164 132]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.55      0.71       296
          1       0.03      1.00      0.06         4

avg / total       0.99      0.56      0.70       300


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.983 	-0.007 	-0.005 	0.498 	0.000 	0.000
[[295   1]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       296
          1       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.98       300


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=1,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	0.000 	0.000 	0.500 	0.000 	0.000
[[296   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       296
          1       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       300


                estimator  min_score   mean_score  max_score     sd_score  \
1      LogisticRegression  -0.202637   0.00896395   0.103353    0.0384123   
7                     SVC -0.0660793   0.00541715  0.0899252    0.0203945   
3    ExtraTreesClassifier -0.0137368   0.00740466   0.216765    0.0318488   
0              GaussianNB  0.0532332    0.0532332  0.0532332            0   
4  RandomForestClassifier -0.0094165 -0.000289553          0  0.000942053   
9    KNeighborsClassifier -0.0139529  -0.00345718          0   0.00564567   
8        VotingClassifier -0.0134833  -0.00315005          0   0.00371107   
6      AdaBoostClassifier -0.0202511  -0.00280871   0.124734    0.0218986   
2           SGDClassifier  -0.197708   0.00768918   0.126132     0.035074   
5           MLPClassifier -0.0153762  -0.00849861  0.0697352     0.011994   

        acc       auc           conf_matrix     f1_c0      f1_c1       kappa  \
1      0.58  0.787162  [[170, 126], [0, 4]]  0.729614  0.0597015   0.0347293   
7      0.56  0.777027  [[164, 132], [0, 4]]  0.713043  0.0571429   0.0320688   
3  0.973333  0.616554    [[291, 5], [3, 1]]  0.986441        0.2    0.186992   
0  0.766667  0.511824   [[229, 67], [3, 1]]  0.867424  0.0277778  0.00265957   
4  0.986667       0.5    [[296, 0], [4, 0]]  0.993289          0           0   
9  0.986667       0.5    [[296, 0], [4, 0]]  0.993289          0           0   
8  0.983333  0.498311    [[295, 1], [4, 0]]  0.991597          0 -0.00536193   
6      0.98  0.496622    [[294, 2], [4, 0]]  0.989899          0 -0.00896861   
2  0.973333  0.493243    [[292, 4], [4, 0]]  0.986486          0  -0.0135135   
5  0.973333  0.493243    [[292, 4], [4, 0]]  0.986486          0  -0.0135135   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
1    0.132934         1  0.0307692  0.574324      1  
7    0.127655         1  0.0294118  0.554054      1  
3    0.190978  0.989796   0.166667  0.983108   0.25  
0  0.00647864  0.987069  0.0147059  0.773649   0.25  
4           0  0.986667          0         1      0  
9           0  0.986667          0         1      0  
8 -0.00672277  0.986622          0  0.996622      0  
6 -0.00952338  0.986577          0  0.993243      0  
2  -0.0135135  0.986486          0  0.986486      0  
5  -0.0135135  0.986486          0  0.986486      0  
Elapsed time 27.54 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-05-04 12:31:16.142000 
pca_target: 0 	 poly degree: 2 	 kselect: 60 
Imbalance: SMOTE(k=None, k_neighbors=5, kind='regular', m=None, m_neighbors=10, n_jobs=1,
   out_step=0.5, random_state=None, ratio='auto', svm_estimator=None) 
Extended target (count):  25141 325
('Total : Processed (count): ', (998L, 780L), 13)
Final feature (count):  (998L, 780L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.543 	0.123 	0.030 	0.769 	0.733 	0.562
[[159 137]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.54      0.70       296
          1       0.03      1.00      0.06         4

avg / total       0.99      0.54      0.69       300


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=10, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.823 	-0.051 	-0.025 	0.417 	0.000 	0.000
[[247  49]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.98      0.83      0.90       296
          1       0.00      0.00      0.00         4

avg / total       0.97      0.82      0.89       300


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.1, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.001, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='perceptron', n_iter=5, n_jobs=4,
       penalty='none', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.630 	0.031 	0.009 	0.566 	0.562 	0.312
[[187 109]
 [  2   2]]
             precision    recall  f1-score   support

          0       0.99      0.63      0.77       296
          1       0.02      0.50      0.03         4

avg / total       0.98      0.63      0.76       300


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 50}, criterion='gini',
           max_depth=None, max_features=0.33, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=30, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.940 	0.102 	0.080 	0.600 	0.487 	0.221
[[281  15]
 [  3   1]]
             precision    recall  f1-score   support

          0       0.99      0.95      0.97       296
          1       0.06      0.25      0.10         4

avg / total       0.98      0.94      0.96       300


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 500},
            criterion='gini', max_depth=None, max_features=0.33,
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.917 	0.076 	0.053 	0.588 	0.481 	0.216
[[274  22]
 [  3   1]]
             precision    recall  f1-score   support

          0       0.99      0.93      0.96       296
          1       0.04      0.25      0.07         4

avg / total       0.98      0.92      0.94       300


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(500,), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.973 	-0.014 	-0.014 	0.493 	0.000 	0.000
[[292   4]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       296
          1       0.00      0.00      0.00         4

avg / total       0.97      0.97      0.97       300


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 500}, criterion='entropy',
            max_depth=8, max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=1.0, n_estimators=80, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.907 	0.067 	0.045 	0.583 	0.478 	0.214
[[271  25]
 [  3   1]]
             precision    recall  f1-score   support

          0       0.99      0.92      0.95       296
          1       0.04      0.25      0.07         4

avg / total       0.98      0.91      0.94       300


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=10, cache_size=200, class_weight='balanced', coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.957 	0.132 	0.116 	0.608 	0.491 	0.224
[[286  10]
 [  3   1]]
             precision    recall  f1-score   support

          0       0.99      0.97      0.98       296
          1       0.09      0.25      0.13         4

avg / total       0.98      0.96      0.97       300


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=10.0, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', ...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.900 	0.155 	0.096 	0.703 	0.673 	0.434
[[268  28]
 [  2   2]]
             precision    recall  f1-score   support

          0       0.99      0.91      0.95       296
          1       0.07      0.50      0.12         4

avg / total       0.98      0.90      0.94       300


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=4,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.880 	0.050 	0.029 	0.569 	0.471 	0.208
[[263  33]
 [  3   1]]
             precision    recall  f1-score   support

          0       0.99      0.89      0.94       296
          1       0.03      0.25      0.05         4

avg / total       0.98      0.88      0.92       300


                estimator  min_score mean_score max_score   sd_score  \
0              GaussianNB   0.541778   0.541778  0.541778          0   
8        VotingClassifier   0.789575   0.851333  0.905909  0.0298261   
7                     SVC          0    0.66318  0.940197   0.204634   
3    ExtraTreesClassifier   0.621649   0.859711  0.954025   0.101132   
4  RandomForestClassifier   0.702839   0.872654  0.931606  0.0586405   
6      AdaBoostClassifier   0.626991   0.872282  0.941325  0.0440227   
9    KNeighborsClassifier   0.801359   0.849084  0.890969  0.0281587   
2           SGDClassifier  -0.103048   0.417413  0.689281   0.182409   
5           MLPClassifier   0.912428   0.945422  0.971623  0.0137657   
1      LogisticRegression  0.0848548   0.569403  0.814564   0.101592   

        acc       auc           conf_matrix     f1_c0      f1_c1      kappa  \
0  0.543333  0.768581  [[159, 137], [0, 4]]  0.698901  0.0551724  0.0300198   
8       0.9  0.702703   [[268, 28], [2, 2]]  0.946996   0.117647  0.0963855   
7  0.956667  0.608108   [[286, 10], [3, 1]]  0.977778   0.133333   0.116047   
3      0.94  0.599662   [[281, 15], [3, 1]]  0.968966        0.1  0.0803815   
4  0.916667  0.587838   [[274, 22], [3, 1]]   0.95637  0.0740741  0.0525518   
6  0.906667   0.58277   [[271, 25], [3, 1]]  0.950877  0.0666667   0.044586   
9      0.88  0.569257   [[263, 33], [3, 1]]  0.935943  0.0526316  0.0294752   
2      0.63  0.565878  [[187, 109], [2, 2]]  0.771134  0.0347826  0.0092824   
5  0.973333  0.493243    [[292, 4], [4, 0]]  0.986486          0 -0.0135135   
1  0.823333   0.41723   [[247, 49], [4, 0]]  0.903108          0 -0.0252773   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
0    0.123445         1  0.0283688  0.537162      1  
8    0.154997  0.992593  0.0666667  0.905405    0.5  
7    0.131953  0.989619  0.0909091  0.966216   0.25  
3    0.101746  0.989437     0.0625  0.949324   0.25  
4   0.0757327   0.98917  0.0434783  0.925676   0.25  
6   0.0674867  0.989051  0.0384615  0.915541   0.25  
9   0.0501173  0.988722  0.0294118  0.888514   0.25  
2   0.0313009  0.989418   0.018018  0.631757    0.5  
5  -0.0135135  0.986486          0  0.986486      0  
1  -0.0513624  0.984064          0  0.834459      0  
Elapsed time 61.04 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-05-04 13:32:18.508000 
pca_target: 0 	 poly degree: 2 	 kselect: 60 
Imbalance: ClusterCentroids(estimator=None, n_jobs=1, random_state=None, ratio='auto') 
Extended target (count):  25141 325
('Total : Processed (count): ', (998L, 780L), 13)
Final feature (count):  (998L, 780L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.437 	0.100 	0.020 	0.715 	0.655 	0.454
[[127 169]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.43      0.60       296
          1       0.02      1.00      0.05         4

avg / total       0.99      0.44      0.59       300


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.1, class_weight={1: 3}, dual=False, fit_intercept=True,
          intercept_scaling=0.1, max_iter=100, multi_class='ovr', n_jobs=4,
          penalty='l2', random_state=None, solver='lbfgs', tol=0.0001,
          verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.347 	0.082 	0.013 	0.669 	0.581 	0.360
[[100 196]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.34      0.51       296
          1       0.02      1.00      0.04         4

avg / total       0.99      0.35      0.50       300


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.1, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='squared_hinge', n_iter=5, n_jobs=4,
       penalty='none', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.360 	0.085 	0.014 	0.676 	0.593 	0.374
[[104 192]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.35      0.52       296
          1       0.02      1.00      0.04         4

avg / total       0.99      0.36      0.51       300


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3},
           criterion='entropy', max_depth=32, max_features='auto',
           max_leaf_nodes=None, min_impurity_split=1e-07,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=15, n_jobs=4,
           oob_score=False, random_state=None, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.350 	0.083 	0.014 	0.671 	0.584 	0.364
[[101 195]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.34      0.51       296
          1       0.02      1.00      0.04         4

avg / total       0.99      0.35      0.50       300


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=16, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.387 	0.090 	0.016 	0.689 	0.615 	0.402
[[112 184]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.38      0.55       296
          1       0.02      1.00      0.04         4

avg / total       0.99      0.39      0.54       300


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.01, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.560 	0.014 	0.004 	0.530 	0.530 	0.279
[[166 130]
 [  2   2]]
             precision    recall  f1-score   support

          0       0.99      0.56      0.72       296
          1       0.02      0.50      0.03         4

avg / total       0.98      0.56      0.71       300


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='entropy', max_depth=8,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=1.0, n_estimators=80, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.347 	0.082 	0.013 	0.669 	0.581 	0.360
[[100 196]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.34      0.51       296
          1       0.02      1.00      0.04         4

avg / total       0.99      0.35      0.50       300


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.5, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='linear',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.347 	0.082 	0.013 	0.669 	0.581 	0.360
[[100 196]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.34      0.51       296
          1       0.02      1.00      0.04         4

avg / total       0.99      0.35      0.50       300


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.347 	0.082 	0.013 	0.669 	0.581 	0.360
[[100 196]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.34      0.51       296
          1       0.02      1.00      0.04         4

avg / total       0.99      0.35      0.50       300


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=3, p=1,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.480 	0.052 	0.011 	0.613 	0.598 	0.367
[[141 155]
 [  1   3]]
             precision    recall  f1-score   support

          0       0.99      0.48      0.64       296
          1       0.02      0.75      0.04         4

avg / total       0.98      0.48      0.64       300


                estimator min_score mean_score max_score   sd_score       acc  \
0              GaussianNB  0.906078   0.906078  0.906078          0  0.436667   
4  RandomForestClassifier  0.444444   0.644164  0.812156  0.0843464  0.386667   
2           SGDClassifier -0.572745   0.228646  0.607122   0.200699      0.36   
3    ExtraTreesClassifier  0.718234   0.900338         1  0.0282876      0.35   
1      LogisticRegression   -0.1283   0.365754  0.624311   0.195898  0.346667   
6      AdaBoostClassifier  0.333333   0.834619         1  0.0805573  0.346667   
7                     SVC         0   0.293624  0.812156   0.281631  0.346667   
8        VotingClassifier  0.273789   0.514919  0.701045   0.119725  0.346667   
9    KNeighborsClassifier   -0.2566   0.103476  0.812156    0.30665      0.48   
5           MLPClassifier    0.2566   0.519389  0.794967   0.144283      0.56   

        auc           conf_matrix     f1_c0      f1_c1       kappa  \
0  0.714527  [[127, 169], [0, 4]]  0.600473  0.0451977   0.0196458   
4  0.689189  [[112, 184], [0, 4]]   0.54902  0.0416667   0.0159726   
2  0.675676  [[104, 192], [0, 4]]      0.52       0.04   0.0142388   
3  0.670608  [[101, 195], [0, 4]]  0.508816  0.0394089   0.0136238   
1  0.668919  [[100, 196], [0, 4]]  0.505051  0.0392157   0.0134228   
6  0.668919  [[100, 196], [0, 4]]  0.505051  0.0392157   0.0134228   
7  0.668919  [[100, 196], [0, 4]]  0.505051  0.0392157   0.0134228   
8  0.668919  [[100, 196], [0, 4]]  0.505051  0.0392157   0.0134228   
9  0.613176  [[141, 155], [1, 3]]  0.643836   0.037037   0.0113233   
5  0.530405  [[166, 130], [2, 2]]  0.715517  0.0294118  0.00362319   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
0   0.0996008         1  0.0231214  0.429054      1  
4   0.0897252         1  0.0212766  0.378378      1  
2   0.0846784         1  0.0204082  0.351351      1  
3   0.0828168         1  0.0201005  0.341216      1  
1   0.0821995         1       0.02  0.337838      1  
6   0.0821995         1       0.02  0.337838      1  
7   0.0821995         1       0.02  0.337838      1  
8   0.0821995         1       0.02  0.337838      1  
9    0.051998  0.992958  0.0189873  0.476351   0.75  
5   0.0140513  0.988095  0.0151515  0.560811    0.5  
Elapsed time 16.45 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-05-04 13:48:45.654000 
pca_target: 60 	 poly degree: 2 	 kselect: 60 
Imbalance: None 
Extended target (count):  25141 325
('Total : Processed (count): ', (998L, 780L), 13)
Final feature (count):  (998L, 780L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.833 	-0.049 	-0.025 	0.422 	0.000 	0.000
[[250  46]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.98      0.84      0.91       296
          1       0.00      0.00      0.00         4

avg / total       0.97      0.83      0.90       300


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=5, class_weight={1: 500}, dual=False, fit_intercept=True,
          intercept_scaling=0.1, max_iter=100, multi_class='ovr', n_jobs=4,
          penalty='l2', random_state=None, solver='lbfgs', tol=0.0001,
          verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.947 	0.112 	0.092 	0.603 	0.489 	0.222
[[283  13]
 [  3   1]]
             precision    recall  f1-score   support

          0       0.99      0.96      0.97       296
          1       0.07      0.25      0.11         4

avg / total       0.98      0.95      0.96       300


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.5, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='constant', loss='squared_hinge', n_iter=5, n_jobs=4,
       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	0.000 	0.000 	0.500 	0.000 	0.000
[[296   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       296
          1       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       300


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 50}, criterion='gini',
           max_depth=8, max_features=0.33, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	0.000 	0.000 	0.500 	0.000 	0.000
[[296   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       296
          1       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       300


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight='balanced',
            criterion='entropy', max_depth=16, max_features=0.33,
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=15, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	0.000 	0.000 	0.500 	0.000 	0.000
[[296   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       296
          1       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       300


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.5, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.983 	-0.007 	-0.005 	0.498 	0.000 	0.000
[[295   1]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       296
          1       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.98       300


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=8,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=2.0, n_estimators=15, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.970 	-0.015 	-0.015 	0.492 	0.000 	0.000
[[291   5]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.98      0.98       296
          1       0.00      0.00      0.00         4

avg / total       0.97      0.97      0.97       300


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=10, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	0.000 	0.000 	0.500 	0.000 	0.000
[[296   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       296
          1       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       300


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=10.0, class_weight={1: 500}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Ra...owski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='uniform'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.983 	-0.007 	-0.005 	0.498 	0.000 	0.000
[[295   1]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       296
          1       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.98       300


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=4,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.983 	-0.007 	-0.005 	0.498 	0.000 	0.000
[[295   1]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       296
          1       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.98       300


                estimator   min_score   mean_score   max_score   sd_score  \
1      LogisticRegression   -0.140728    0.0159546   0.0984516  0.0297244   
2           SGDClassifier   -0.182402  0.000354888    0.230103  0.0342954   
3    ExtraTreesClassifier  -0.0325506  0.000800336    0.141315  0.0125006   
4  RandomForestClassifier -0.00290686  0.000378779    0.141315  0.0074407   
7                     SVC  -0.0225918    0.0125788    0.136299  0.0309257   
5           MLPClassifier   -0.018001    0.0119451    0.133078  0.0443852   
8        VotingClassifier  -0.0117123  -0.00127491   0.0757034  0.0118903   
9    KNeighborsClassifier  -0.0120031   0.00944816    0.118731  0.0321067   
6      AdaBoostClassifier  -0.0237031 -0.000277581     0.18494  0.0300293   
0              GaussianNB  0.00455127   0.00455127  0.00455127          0   

        acc       auc          conf_matrix     f1_c0     f1_c1       kappa  \
1  0.946667  0.603041  [[283, 13], [3, 1]]  0.972509  0.111111   0.0922844   
2  0.986667       0.5   [[296, 0], [4, 0]]  0.993289         0           0   
3  0.986667       0.5   [[296, 0], [4, 0]]  0.993289         0           0   
4  0.986667       0.5   [[296, 0], [4, 0]]  0.993289         0           0   
7  0.986667       0.5   [[296, 0], [4, 0]]  0.993289         0           0   
5  0.983333  0.498311   [[295, 1], [4, 0]]  0.991597         0 -0.00536193   
8  0.983333  0.498311   [[295, 1], [4, 0]]  0.991597         0 -0.00536193   
9  0.983333  0.498311   [[295, 1], [4, 0]]  0.991597         0 -0.00536193   
6      0.97  0.491554   [[291, 5], [4, 0]]  0.984772         0  -0.0150376   
0  0.833333  0.422297  [[250, 46], [4, 0]]  0.909091         0  -0.0251504   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
1    0.112064   0.98951  0.0714286  0.956081   0.25  
2           0  0.986667          0         1      0  
3           0  0.986667          0         1      0  
4           0  0.986667          0         1      0  
7           0  0.986667          0         1      0  
5 -0.00672277  0.986622          0  0.996622      0  
8 -0.00672277  0.986622          0  0.996622      0  
9 -0.00672277  0.986622          0  0.996622      0  
6  -0.0151342  0.986441          0  0.983108      0  
0  -0.0494705  0.984252          0  0.844595      0  
Elapsed time 27.61 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-05-04 14:16:22.259000 
pca_target: 60 	 poly degree: 2 	 kselect: 60 
Imbalance: SMOTE(k=None, k_neighbors=5, kind='regular', m=None, m_neighbors=10, n_jobs=1,
   out_step=0.5, random_state=None, ratio='auto', svm_estimator=None) 
Extended target (count):  25141 325
('Total : Processed (count): ', (998L, 780L), 13)
Final feature (count):  (998L, 780L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.957 	-0.020 	-0.019 	0.485 	0.000 	0.000
[[287   9]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.97      0.98       296
          1       0.00      0.00      0.00         4

avg / total       0.97      0.96      0.96       300


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=5, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.943 	-0.025 	-0.021 	0.478 	0.000 	0.000
[[283  13]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.96      0.97       296
          1       0.00      0.00      0.00         4

avg / total       0.97      0.94      0.96       300


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.0001, average=False, class_weight='balanced',
       epsilon=0.1, eta0=0.001, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='modified_huber', n_iter=5, n_jobs=4,
       penalty='none', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.967 	-0.017 	-0.016 	0.490 	0.000 	0.000
[[290   6]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.98      0.98       296
          1       0.00      0.00      0.00         4

avg / total       0.97      0.97      0.97       300


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=16, max_features=0.75, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=30, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	0.000 	0.000 	0.500 	0.000 	0.000
[[296   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       296
          1       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       300


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=30, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	0.000 	0.000 	0.500 	0.000 	0.000
[[296   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       296
          1       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       300


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.983 	-0.007 	-0.005 	0.498 	0.000 	0.000
[[295   1]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       296
          1       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.98       300


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=0.5, n_estimators=15, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	0.000 	0.000 	0.500 	0.000 	0.000
[[296   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       296
          1       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       300


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.1, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	0.000 	0.000 	0.500 	0.000 	0.000
[[296   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       296
          1       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       300


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=10.0, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', ...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.977 	-0.012 	-0.012 	0.495 	0.000 	0.000
[[293   3]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       296
          1       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.98       300


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=3,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.977 	0.491 	0.451 	0.865 	0.857 	0.718
[[290   6]
 [  1   3]]
             precision    recall  f1-score   support

          0       1.00      0.98      0.99       296
          1       0.33      0.75      0.46         4

avg / total       0.99      0.98      0.98       300


                estimator min_score mean_score max_score    sd_score  \
9    KNeighborsClassifier  0.804166   0.910259   0.96873   0.0449594   
3    ExtraTreesClassifier  0.861624    0.99364         1   0.0210606   
4  RandomForestClassifier  0.984112   0.997982         1  0.00189901   
6      AdaBoostClassifier  0.902981   0.985669         1    0.014167   
7                     SVC         0   0.834617         1    0.293456   
5           MLPClassifier  0.951937   0.973606   0.99281   0.0121391   
8        VotingClassifier   0.93673   0.968751  0.984255   0.0106052   
2           SGDClassifier -0.212123   0.631526   0.96436    0.280743   
0              GaussianNB  0.971054   0.971054  0.971054           0   
1      LogisticRegression  0.379467   0.811889  0.947743    0.152232   

        acc       auc          conf_matrix     f1_c0     f1_c1       kappa  \
9  0.976667  0.864865   [[290, 6], [1, 3]]  0.988075  0.461538    0.451411   
3  0.986667       0.5   [[296, 0], [4, 0]]  0.993289         0           0   
4  0.986667       0.5   [[296, 0], [4, 0]]  0.993289         0           0   
6  0.986667       0.5   [[296, 0], [4, 0]]  0.993289         0           0   
7  0.986667       0.5   [[296, 0], [4, 0]]  0.993289         0           0   
5  0.983333  0.498311   [[295, 1], [4, 0]]  0.991597         0 -0.00536193   
8  0.976667  0.494932   [[293, 3], [4, 0]]  0.988196         0  -0.0115607   
2  0.966667  0.489865   [[290, 6], [4, 0]]  0.983051         0  -0.0162602   
0  0.956667  0.484797   [[287, 9], [4, 0]]  0.977853         0  -0.0188088   
1  0.943333  0.478041  [[283, 13], [4, 0]]   0.97084         0  -0.0208167   

  model_score   prec_c0   prec_c1    rec_c0 rec_c1  
9    0.490648  0.996564  0.333333   0.97973   0.75  
3           0  0.986667         0         1      0  
4           0  0.986667         0         1      0  
6           0  0.986667         0         1      0  
7           0  0.986667         0         1      0  
5 -0.00672277  0.986622         0  0.996622      0  
8  -0.0116833  0.986532         0  0.989865      0  
2  -0.0166068  0.986395         0   0.97973      0  
0  -0.0204437  0.986254         0  0.969595      0  
1  -0.0247409  0.986063         0  0.956081      0  
Elapsed time 44.00 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-05-04 15:00:22.442000 
pca_target: 60 	 poly degree: 2 	 kselect: 60 
Imbalance: ClusterCentroids(estimator=None, n_jobs=1, random_state=None, ratio='auto') 
Extended target (count):  25141 325
('Total : Processed (count): ', (998L, 780L), 13)
Final feature (count):  (998L, 780L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	0.000 	0.000 	0.500 	0.000 	0.000
[[296   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       296
          1       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       300


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.1, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.477 	-0.119 	-0.027 	0.242 	0.000 	0.000
[[143 153]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.97      0.48      0.65       296
          1       0.00      0.00      0.00         4

avg / total       0.96      0.48      0.64       300


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.0001, average=False, class_weight={1: 500}, epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='constant', loss='squared_hinge', n_iter=5, n_jobs=4,
       penalty='l2', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.493 	-0.002 	-0.000 	0.497 	0.497 	0.247
[[146 150]
 [  2   2]]
             precision    recall  f1-score   support

          0       0.99      0.49      0.66       296
          1       0.01      0.50      0.03         4

avg / total       0.97      0.49      0.65       300


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=8, max_features='auto', max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.347 	0.082 	0.013 	0.669 	0.581 	0.360
[[100 196]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.34      0.51       296
          1       0.02      1.00      0.04         4

avg / total       0.99      0.35      0.50       300


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.360 	0.085 	0.014 	0.676 	0.593 	0.374
[[104 192]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.35      0.52       296
          1       0.02      1.00      0.04         4

avg / total       0.99      0.36      0.51       300


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.01, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.530 	0.007 	0.002 	0.515 	0.515 	0.264
[[157 139]
 [  2   2]]
             precision    recall  f1-score   support

          0       0.99      0.53      0.69       296
          1       0.01      0.50      0.03         4

avg / total       0.97      0.53      0.68       300


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 500}, criterion='gini', max_depth=32,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=0.5, n_estimators=80, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.503 	0.114 	0.026 	0.748 	0.705 	0.522
[[147 149]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.50      0.66       296
          1       0.03      1.00      0.05         4

avg / total       0.99      0.50      0.66       300


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	0.000 	0.000 	0.500 	0.000 	0.000
[[296   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       296
          1       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       300


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', R...owski',
           metric_params=None, n_jobs=4, n_neighbors=4, p=2,
           weights='uniform'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.673 	0.043 	0.014 	0.588 	0.581 	0.332
[[200  96]
 [  2   2]]
             precision    recall  f1-score   support

          0       0.99      0.68      0.80       296
          1       0.02      0.50      0.04         4

avg / total       0.98      0.67      0.79       300


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=5, p=1,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.387 	0.090 	0.016 	0.689 	0.615 	0.402
[[112 184]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.38      0.55       296
          1       0.02      1.00      0.04         4

avg / total       0.99      0.39      0.54       300


                estimator  min_score mean_score max_score   sd_score  \
6      AdaBoostClassifier  0.0939222   0.587013  0.906078   0.135608   
9    KNeighborsClassifier  -0.478822 -0.0479206  0.444444   0.250992   
4  RandomForestClassifier   0.683856   0.860334  0.906078  0.0594436   
3    ExtraTreesClassifier   0.701045    0.87767  0.888889  0.0320285   
8        VotingClassifier     0.2566   0.578227  0.812156  0.0805711   
5           MLPClassifier     0.1283   0.539288  0.701045  0.0930336   
0              GaussianNB          1          1         1          0   
7                     SVC    -0.1283   0.293129  0.589933   0.228076   
2           SGDClassifier    -0.3849   0.303854  0.718234   0.166806   
1      LogisticRegression          0   0.397321  0.718234   0.187358   

        acc       auc           conf_matrix     f1_c0      f1_c1       kappa  \
6  0.503333  0.748311  [[147, 149], [0, 4]]  0.663657  0.0509554   0.0256343   
9  0.386667  0.689189  [[112, 184], [0, 4]]   0.54902  0.0416667   0.0159726   
4      0.36  0.675676  [[104, 192], [0, 4]]      0.52       0.04   0.0142388   
3  0.346667  0.668919  [[100, 196], [0, 4]]  0.505051  0.0392157   0.0134228   
8  0.673333  0.587838   [[200, 96], [2, 2]]  0.803213  0.0392157   0.0139522   
5      0.53  0.515203  [[157, 139], [2, 2]]   0.69011  0.0275862  0.00169924   
0  0.986667       0.5    [[296, 0], [4, 0]]  0.993289          0           0   
7  0.986667       0.5    [[296, 0], [4, 0]]  0.993289          0           0   
2  0.493333  0.496622  [[146, 150], [2, 2]]  0.657658   0.025641   -0.000351   
1  0.476667  0.241554  [[143, 153], [4, 0]]  0.645598          0  -0.0266806   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
6    0.113945         1  0.0261438  0.496622      1  
9   0.0897252         1  0.0212766  0.378378      1  
4   0.0846784         1  0.0204082  0.351351      1  
3   0.0821995         1       0.02  0.337838      1  
8   0.0429634  0.990099  0.0204082  0.675676    0.5  
5  0.00698745  0.987421  0.0141844  0.530405    0.5  
0           0  0.986667          0         1      0  
7           0  0.986667          0         1      0  
2 -0.00155011  0.986486  0.0131579  0.493243    0.5  
1   -0.118596  0.972789          0  0.483108      0  
Elapsed time 14.66 mins 

************************************************************

[4;33mReloaded modules[24m: migraine_processing, classifiers[0m
Finished.














Standard, lagged(3,4)x1, filter(tukey & hp), NT+, UN-truncated



    pca = [0]
    poly = [2]
    ksel = [60, 40]
    imb = [None, SMOTE(), ClusterCentroids() ]
	
	
	


pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-05-04 17:05:08.452000 
pca_target: 0 	 poly degree: 2 	 kselect: 60 
Imbalance: None 
Extended target (count):  31485 325
('Total : Processed (count): ', (1252L, 276L), 13)
Final feature (count):  (1252L, 276L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.787 	0.011 	0.004 	0.522 	0.445 	0.187
[[295  77]
 [  3   1]]
             precision    recall  f1-score   support

          0       0.99      0.79      0.88       372
          1       0.01      0.25      0.02         4

avg / total       0.98      0.79      0.87       376


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.001, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=5, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='sag', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.673 	0.145 	0.041 	0.835 	0.818 	0.691
[[249 123]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.67      0.80       372
          1       0.03      1.00      0.06         4

avg / total       0.99      0.67      0.79       376


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=1, average=False, class_weight={1: 50}, epsilon=0.1,
       eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='invscaling', loss='modified_huber', n_iter=5,
       n_jobs=4, penalty='l2', power_t=0.5, random_state=None,
       shuffle=True, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.662 	0.142 	0.039 	0.829 	0.812 	0.681
[[245 127]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.66      0.79       372
          1       0.03      1.00      0.06         4

avg / total       0.99      0.66      0.79       376


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 500}, criterion='gini',
           max_depth=16, max_features=0.33, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.971 	0.290 	0.255 	0.738 	0.699 	0.465
[[363   9]
 [  2   2]]
             precision    recall  f1-score   support

          0       0.99      0.98      0.99       372
          1       0.18      0.50      0.27         4

avg / total       0.99      0.97      0.98       376


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       372
          1       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.5, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	-0.005 	-0.004 	0.499 	0.000 	0.000
[[371   1]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       372
          1       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight='balanced', criterion='entropy',
            max_depth=32, max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=0.5, n_estimators=80, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.979 	-0.011 	-0.011 	0.495 	0.000 	0.000
[[368   4]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       372
          1       0.00      0.00      0.00         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.497 	0.101 	0.020 	0.746 	0.701 	0.517
[[183 189]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.49      0.66       372
          1       0.02      1.00      0.04         4

avg / total       0.99      0.50      0.65       376


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       372
          1       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=1,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       372
          1       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


                estimator   min_score   mean_score   max_score     sd_score  \
1      LogisticRegression  -0.0990299   0.00317087    0.117114    0.0308866   
2           SGDClassifier   -0.197277   0.00580689    0.196632    0.0335172   
7                     SVC   -0.118423  -0.00467439   0.0714837    0.0310922   
3    ExtraTreesClassifier  -0.0196817 -0.000842747    0.047631   0.00867475   
0              GaussianNB  0.00509244   0.00509244  0.00509244            0   
4  RandomForestClassifier  -0.0072414 -0.000341137           0  0.000909928   
8        VotingClassifier   -0.011559  -0.00260668           0   0.00302685   
9    KNeighborsClassifier  -0.0119223  -0.00212626           0   0.00382708   
5           MLPClassifier  -0.0136665  -0.00724875 -0.00114815   0.00336694   
6      AdaBoostClassifier  -0.0161442  -0.00657225   0.0726996    0.0101397   

        acc       auc           conf_matrix     f1_c0      f1_c1       kappa  \
1  0.672872  0.834677  [[249, 123], [0, 4]]  0.801932  0.0610687   0.0412935   
2  0.662234  0.829301  [[245, 127], [0, 4]]  0.794165  0.0592593   0.0394271   
7   0.49734  0.745968  [[183, 189], [0, 4]]  0.659459  0.0406091   0.0201853   
3  0.970745  0.737903    [[363, 9], [2, 2]]  0.985075   0.266667    0.255043   
0  0.787234  0.521505   [[295, 77], [3, 1]]  0.880597  0.0243902  0.00423729   
4  0.989362       0.5    [[372, 0], [4, 0]]  0.994652          0           0   
8  0.989362       0.5    [[372, 0], [4, 0]]  0.994652          0           0   
9  0.989362       0.5    [[372, 0], [4, 0]]  0.994652          0           0   
5  0.986702  0.498656    [[371, 1], [4, 0]]  0.993307          0  -0.0042735   
6  0.978723  0.494624    [[368, 4], [4, 0]]  0.989247          0  -0.0107527   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
1    0.145197         1  0.0314961  0.669355      1  
2     0.14181         1  0.0305344  0.658602      1  
7    0.100973         1  0.0207254  0.491935      1  
3     0.28966  0.994521   0.181818  0.975806    0.5  
0   0.0108824  0.989933  0.0128205  0.793011   0.25  
4           0  0.989362          0         1      0  
8           0  0.989362          0         1      0  
9           0  0.989362          0         1      0  
5  -0.0053548  0.989333          0  0.997312      0  
6  -0.0107527  0.989247          0  0.989247      0  
Elapsed time 31.45 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-05-04 17:36:35.640000 
pca_target: 0 	 poly degree: 2 	 kselect: 60 
Imbalance: SMOTE(k=None, k_neighbors=5, kind='regular', m=None, m_neighbors=10, n_jobs=1,
   out_step=0.5, random_state=None, ratio='auto', svm_estimator=None) 
Extended target (count):  31485 325
('Total : Processed (count): ', (1252L, 276L), 13)
Final feature (count):  (1252L, 276L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.668 	0.143 	0.040 	0.832 	0.815 	0.686
[[247 125]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.66      0.80       372
          1       0.03      1.00      0.06         4

avg / total       0.99      0.67      0.79       376


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=10, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.763 	0.181 	0.063 	0.880 	0.872 	0.779
[[283  89]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.76      0.86       372
          1       0.04      1.00      0.08         4

avg / total       0.99      0.76      0.86       376


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.001, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.001, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='perceptron', n_iter=5, n_jobs=4,
       penalty='l1', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.609 	0.127 	0.032 	0.802 	0.778 	0.629
[[225 147]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.60      0.75       372
          1       0.03      1.00      0.05         4

avg / total       0.99      0.61      0.75       376


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 15},
           criterion='entropy', max_depth=None, max_features=0.75,
           max_leaf_nodes=None, min_impurity_split=1e-07,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=4,
           oob_score=False, random_state=None, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.947 	0.098 	0.075 	0.602 	0.488 	0.222
[[355  17]
 [  3   1]]
             precision    recall  f1-score   support

          0       0.99      0.95      0.97       372
          1       0.06      0.25      0.09         4

avg / total       0.98      0.95      0.96       376


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 500},
            criterion='entropy', max_depth=None, max_features=0.33,
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.926 	-0.027 	-0.019 	0.468 	0.000 	0.000
[[348  24]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.94      0.96       372
          1       0.00      0.00      0.00         4

avg / total       0.98      0.93      0.95       376


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.01, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.955 	0.227 	0.176 	0.730 	0.693 	0.458
[[357  15]
 [  2   2]]
             precision    recall  f1-score   support

          0       0.99      0.96      0.98       372
          1       0.12      0.50      0.19         4

avg / total       0.99      0.95      0.97       376


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 50}, criterion='gini', max_depth=16,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=1.0, n_estimators=80, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.939 	0.088 	0.063 	0.598 	0.486 	0.220
[[352  20]
 [  3   1]]
             precision    recall  f1-score   support

          0       0.99      0.95      0.97       372
          1       0.05      0.25      0.08         4

avg / total       0.98      0.94      0.96       376


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.5, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=10, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.984 	0.242 	0.242 	0.621 	0.498 	0.230
[[369   3]
 [  3   1]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       372
          1       0.25      0.25      0.25         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=10.0, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', ...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.888 	0.204 	0.108 	0.820 	0.817 	0.658
[[331  41]
 [  1   3]]
             precision    recall  f1-score   support

          0       1.00      0.89      0.94       372
          1       0.07      0.75      0.12         4

avg / total       0.99      0.89      0.93       376


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=3,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.910 	0.148 	0.088 	0.707 	0.676 	0.438
[[340  32]
 [  2   2]]
             precision    recall  f1-score   support

          0       0.99      0.91      0.95       372
          1       0.06      0.50      0.11         4

avg / total       0.98      0.91      0.94       376


                estimator  min_score mean_score max_score   sd_score  \
1      LogisticRegression  0.0800828   0.569477  0.732854  0.0927904   
0              GaussianNB   0.581603   0.581603  0.581603          0   
8        VotingClassifier   0.777334   0.832951  0.895905  0.0298366   
2           SGDClassifier -0.0378715   0.408551  0.654801   0.186975   
5           MLPClassifier   0.884913   0.929937  0.947199  0.0115508   
9    KNeighborsClassifier   0.798756    0.84936  0.898138  0.0290676   
7                     SVC          0    0.66169  0.923213   0.183049   
3    ExtraTreesClassifier   0.662816   0.853181  0.932761  0.0829294   
6      AdaBoostClassifier   0.604231   0.871655  0.937926  0.0431608   
4  RandomForestClassifier   0.703634   0.861668  0.917874   0.053905   

        acc       auc           conf_matrix     f1_c0      f1_c1      kappa  \
1  0.763298  0.880376   [[283, 89], [0, 4]]  0.864122  0.0824742  0.0633677   
0  0.667553  0.831989  [[247, 125], [0, 4]]  0.798061  0.0601504  0.0403463   
8  0.888298  0.819892   [[331, 41], [1, 3]]  0.940341      0.125   0.107595   
2  0.609043  0.802419  [[225, 147], [0, 4]]  0.753769  0.0516129  0.0315391   
5  0.954787  0.729839   [[357, 15], [2, 2]]  0.976744   0.190476   0.176289   
9  0.909574  0.706989   [[340, 32], [2, 2]]  0.952381   0.105263  0.0878995   
7  0.984043  0.620968    [[369, 3], [3, 1]]  0.991935       0.25   0.241935   
3  0.946809  0.602151   [[355, 17], [3, 1]]  0.972603  0.0909091  0.0748031   
6   0.93883  0.598118   [[352, 20], [3, 1]]  0.968363       0.08  0.0632582   
4  0.925532  0.467742   [[348, 24], [4, 0]]  0.961326          0 -0.0185759   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
1    0.180888         1  0.0430108  0.760753      1  
0    0.143487         1  0.0310078  0.663978      1  
8    0.204193  0.996988  0.0681818  0.889785   0.75  
2    0.126579         1  0.0264901  0.604839      1  
5    0.226978  0.994429   0.117647  0.959677    0.5  
9     0.14809  0.994152  0.0588235  0.913978    0.5  
7    0.241935  0.991935       0.25  0.991935   0.25  
3   0.0981735   0.99162  0.0555556  0.954301   0.25  
6   0.0876713  0.991549   0.047619  0.946237   0.25  
4  -0.0270765  0.988636          0  0.935484      0  
Elapsed time 71.88 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-05-04 18:48:28.319000 
pca_target: 0 	 poly degree: 2 	 kselect: 60 
Imbalance: ClusterCentroids(estimator=None, n_jobs=1, random_state=None, ratio='auto') 
Extended target (count):  31485 325
('Total : Processed (count): ', (1252L, 276L), 13)
Final feature (count):  (1252L, 276L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.561 	0.115 	0.026 	0.778 	0.746 	0.581
[[207 165]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.56      0.72       372
          1       0.02      1.00      0.05         4

avg / total       0.99      0.56      0.71       376


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=5, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.354 	0.075 	0.011 	0.673 	0.589 	0.369
[[129 243]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.35      0.51       372
          1       0.02      1.00      0.03         4

avg / total       0.99      0.35      0.51       376


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.0001, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='constant', loss='modified_huber', n_iter=5, n_jobs=4,
       penalty='none', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.434 	0.037 	0.007 	0.590 	0.568 	0.333
[[160 212]
 [  1   3]]
             precision    recall  f1-score   support

          0       0.99      0.43      0.60       372
          1       0.01      0.75      0.03         4

avg / total       0.98      0.43      0.59       376


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=8, max_features=0.75, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=30, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.343 	0.073 	0.011 	0.668 	0.580 	0.358
[[125 247]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.34      0.50       372
          1       0.02      1.00      0.03         4

avg / total       0.99      0.34      0.50       376


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features=0.75, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=30, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.343 	0.073 	0.011 	0.668 	0.580 	0.358
[[125 247]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.34      0.50       372
          1       0.02      1.00      0.03         4

avg / total       0.99      0.34      0.50       376


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.01, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.492 	0.100 	0.020 	0.743 	0.698 	0.512
[[181 191]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.49      0.65       372
          1       0.02      1.00      0.04         4

avg / total       0.99      0.49      0.65       376


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=0.5, n_estimators=15, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.343 	0.073 	0.011 	0.668 	0.580 	0.358
[[125 247]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.34      0.50       372
          1       0.02      1.00      0.03         4

avg / total       0.99      0.34      0.50       376


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.1, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='linear',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.399 	0.083 	0.014 	0.696 	0.626 	0.416
[[146 226]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.39      0.56       372
          1       0.02      1.00      0.03         4

avg / total       0.99      0.40      0.56       376


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=10.0, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', ...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.348 	0.074 	0.011 	0.671 	0.584 	0.364
[[127 245]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.34      0.51       372
          1       0.02      1.00      0.03         4

avg / total       0.99      0.35      0.50       376


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=4, p=3,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.888 	0.204 	0.108 	0.820 	0.817 	0.658
[[331  41]
 [  1   3]]
             precision    recall  f1-score   support

          0       1.00      0.89      0.94       372
          1       0.07      0.75      0.12         4

avg / total       0.99      0.89      0.93       376


                estimator  min_score mean_score max_score   sd_score  \
9    KNeighborsClassifier    -0.3849 -0.0443139    0.3849   0.238701   
0              GaussianNB   0.794967   0.794967  0.794967          0   
5           MLPClassifier -0.0939222    0.37096  0.607122   0.102585   
7                     SVC  -0.239411   0.200035  0.607122    0.30624   
1      LogisticRegression  -0.111111   0.321482  0.701045   0.227796   
8        VotingClassifier   0.273789   0.574877  0.794967   0.136733   
3    ExtraTreesClassifier   0.478822   0.827946         1   0.118126   
4  RandomForestClassifier     0.5132   0.938616         1  0.0736699   
6      AdaBoostClassifier   0.555556   0.958143         1  0.0612235   
2           SGDClassifier  -0.367711   0.229829  0.607122   0.158181   

        acc       auc           conf_matrix     f1_c0      f1_c1       kappa  \
9  0.888298  0.819892   [[331, 41], [1, 3]]  0.940341      0.125    0.107595   
0   0.56117  0.778226  [[207, 165], [0, 4]]  0.715026  0.0462428   0.0259985   
5  0.492021   0.74328  [[181, 191], [0, 4]]  0.654611   0.040201   0.0197641   
7  0.398936  0.696237  [[146, 226], [0, 4]]  0.563707   0.034188   0.0135587   
1  0.353723  0.673387  [[129, 243], [0, 4]]   0.51497  0.0318725   0.0111688   
8  0.348404  0.670699  [[127, 245], [0, 4]]  0.509018  0.0316206   0.0109088   
3  0.343085  0.668011  [[125, 247], [0, 4]]  0.503018  0.0313725   0.0106528   
4  0.343085  0.668011  [[125, 247], [0, 4]]  0.503018  0.0313725   0.0106528   
6  0.343085  0.668011  [[125, 247], [0, 4]]  0.503018  0.0313725   0.0106528   
2  0.433511  0.590054  [[160, 212], [1, 3]]  0.600375  0.0273973  0.00664814   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
9    0.204193  0.996988  0.0681818  0.889785   0.75  
0    0.114763         1  0.0236686  0.556452      1  
5   0.0999035         1  0.0205128  0.486559      1  
7   0.0826173         1  0.0173913  0.392473      1  
1   0.0749385         1  0.0161943  0.346774      1  
8   0.0740561         1  0.0160643  0.341398      1  
3   0.0731773         1  0.0159363  0.336022      1  
4   0.0731773         1  0.0159363  0.336022      1  
6   0.0731773         1  0.0159363  0.336022      1  
2   0.0373423  0.993789  0.0139535  0.430108   0.75  
Elapsed time 16.12 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-05-04 19:04:35.794000 
pca_target: 0 	 poly degree: 2 	 kselect: 40 
Imbalance: None 
Extended target (count):  31485 325
('Total : Processed (count): ', (1252L, 276L), 13)
Final feature (count):  (1252L, 276L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.787 	0.011 	0.004 	0.522 	0.445 	0.187
[[295  77]
 [  3   1]]
             precision    recall  f1-score   support

          0       0.99      0.79      0.88       372
          1       0.01      0.25      0.02         4

avg / total       0.98      0.79      0.87       376


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.001, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.652 	0.139 	0.038 	0.824 	0.805 	0.671
[[241 131]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.65      0.79       372
          1       0.03      1.00      0.06         4

avg / total       0.99      0.65      0.78       376


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.1, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='modified_huber', n_iter=5, n_jobs=4,
       penalty='l1', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       372
          1       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 50},
           criterion='entropy', max_depth=8, max_features='auto',
           max_leaf_nodes=None, min_impurity_split=1e-07,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=15, n_jobs=4,
           oob_score=False, random_state=None, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.957 	0.117 	0.096 	0.608 	0.491 	0.224
[[359  13]
 [  3   1]]
             precision    recall  f1-score   support

          0       0.99      0.97      0.98       372
          1       0.07      0.25      0.11         4

avg / total       0.98      0.96      0.97       376


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=30, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       372
          1       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.981 	-0.009 	-0.009 	0.496 	0.000 	0.000
[[369   3]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       372
          1       0.00      0.00      0.00         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=16,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=1.0, n_estimators=80, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.976 	-0.012 	-0.012 	0.493 	0.000 	0.000
[[367   5]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       372
          1       0.00      0.00      0.00         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.505 	0.103 	0.021 	0.750 	0.707 	0.525
[[186 186]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.50      0.67       372
          1       0.02      1.00      0.04         4

avg / total       0.99      0.51      0.66       376


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=1.0, class_weight={1: 500}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Ran...owski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='uniform'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.979 	-0.011 	-0.011 	0.495 	0.000 	0.000
[[368   4]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       372
          1       0.00      0.00      0.00         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=3,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.981 	-0.009 	-0.009 	0.496 	0.000 	0.000
[[369   3]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       372
          1       0.00      0.00      0.00         4

avg / total       0.98      0.98      0.98       376


                estimator   min_score   mean_score  max_score    sd_score  \
1      LogisticRegression   -0.134471   0.00498666   0.101987   0.0330352   
7                     SVC    -0.12248  -0.00268837  0.0732648   0.0285596   
3    ExtraTreesClassifier   -0.030946  -0.00378694  0.0328549  0.00601037   
0              GaussianNB   0.0331668    0.0331668  0.0331668           0   
2           SGDClassifier   -0.207144    0.0113135   0.197002   0.0368067   
4  RandomForestClassifier -0.00719459 -0.000639473          0  0.00109827   
5           MLPClassifier  -0.0135426 -0.000128736  0.0906633   0.0210822   
9    KNeighborsClassifier  -0.0044048    0.0322097   0.156617   0.0601721   
8        VotingClassifier  -0.0097983  -0.00120353   0.135768   0.0118459   
6      AdaBoostClassifier  -0.0178189   0.00376904   0.177152   0.0304411   

        acc       auc           conf_matrix     f1_c0      f1_c1       kappa  \
1  0.651596  0.823925  [[241, 131], [0, 4]]  0.786297   0.057554    0.037668   
7  0.505319      0.75  [[186, 186], [0, 4]]  0.666667  0.0412371   0.0208333   
3  0.957447  0.607527   [[359, 13], [3, 1]]  0.978202   0.111111   0.0961538   
0  0.787234  0.521505   [[295, 77], [3, 1]]  0.880597  0.0243902  0.00423729   
2  0.989362       0.5    [[372, 0], [4, 0]]  0.994652          0           0   
4  0.989362       0.5    [[372, 0], [4, 0]]  0.994652          0           0   
5  0.981383  0.495968    [[369, 3], [4, 0]]  0.990604          0 -0.00920245   
9  0.981383  0.495968    [[369, 3], [4, 0]]  0.990604          0 -0.00920245   
8  0.978723  0.494624    [[368, 4], [4, 0]]  0.989247          0  -0.0107527   
6  0.976064   0.49328    [[367, 5], [4, 0]]  0.987887          0  -0.0119617   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
1    0.138548         1  0.0296296  0.647849      1  
7    0.102598         1  0.0210526       0.5      1  
3    0.116528  0.991713  0.0714286  0.965054   0.25  
0   0.0108824  0.989933  0.0128205  0.793011   0.25  
2           0  0.989362          0         1      0  
4           0  0.989362          0         1      0  
5 -0.00929961  0.989276          0  0.991935      0  
9 -0.00929961  0.989276          0  0.991935      0  
8  -0.0107527  0.989247          0  0.989247      0  
6  -0.0120381  0.989218          0  0.986559      0  
Elapsed time 28.05 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-05-04 19:32:39.004000 
pca_target: 0 	 poly degree: 2 	 kselect: 40 
Imbalance: SMOTE(k=None, k_neighbors=5, kind='regular', m=None, m_neighbors=10, n_jobs=1,
   out_step=0.5, random_state=None, ratio='auto', svm_estimator=None) 
Extended target (count):  31485 325
('Total : Processed (count): ', (1252L, 276L), 13)
Final feature (count):  (1252L, 276L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.654 	0.139 	0.038 	0.825 	0.807 	0.673
[[242 130]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.65      0.79       372
          1       0.03      1.00      0.06         4

avg / total       0.99      0.65      0.78       376


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=10, class_weight={1: 3}, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=4,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.723 	0.163 	0.052 	0.860 	0.849 	0.741
[[268 104]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.72      0.84       372
          1       0.04      1.00      0.07         4

avg / total       0.99      0.72      0.83       376


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.0001, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.001, fit_intercept=True, l1_ratio=0.15,
       learning_rate='invscaling', loss='perceptron', n_iter=5, n_jobs=4,
       penalty='l1', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.636 	0.134 	0.035 	0.816 	0.795 	0.655
[[235 137]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.63      0.77       372
          1       0.03      1.00      0.06         4

avg / total       0.99      0.64      0.77       376


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 500},
           criterion='entropy', max_depth=None, max_features=0.75,
           max_leaf_nodes=None, min_impurity_split=1e-07,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=15, n_jobs=4,
           oob_score=False, random_state=None, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.979 	0.194 	0.190 	0.618 	0.497 	0.228
[[367   5]
 [  3   1]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       372
          1       0.17      0.25      0.20         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 500},
            criterion='entropy', max_depth=32, max_features=0.75,
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.944 	0.094 	0.071 	0.601 	0.488 	0.221
[[354  18]
 [  3   1]]
             precision    recall  f1-score   support

          0       0.99      0.95      0.97       372
          1       0.05      0.25      0.09         4

avg / total       0.98      0.94      0.96       376


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.01, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.965 	0.264 	0.223 	0.735 	0.697 	0.462
[[361  11]
 [  2   2]]
             precision    recall  f1-score   support

          0       0.99      0.97      0.98       372
          1       0.15      0.50      0.24         4

avg / total       0.99      0.97      0.97       376


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='entropy', max_depth=16,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=1.0, n_estimators=50, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.963 	0.129 	0.111 	0.610 	0.493 	0.225
[[361  11]
 [  3   1]]
             precision    recall  f1-score   support

          0       0.99      0.97      0.98       372
          1       0.08      0.25      0.12         4

avg / total       0.98      0.96      0.97       376


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.5, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=10, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.979 	0.194 	0.190 	0.618 	0.497 	0.228
[[367   5]
 [  3   1]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       372
          1       0.17      0.25      0.20         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=10.0, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', ...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.926 	0.168 	0.108 	0.715 	0.682 	0.445
[[346  26]
 [  2   2]]
             precision    recall  f1-score   support

          0       0.99      0.93      0.96       372
          1       0.07      0.50      0.12         4

avg / total       0.98      0.93      0.95       376


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=3,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.918 	0.157 	0.097 	0.711 	0.679 	0.442
[[343  29]
 [  2   2]]
             precision    recall  f1-score   support

          0       0.99      0.92      0.96       372
          1       0.06      0.50      0.11         4

avg / total       0.98      0.92      0.95       376


                estimator  min_score mean_score max_score    sd_score  \
1      LogisticRegression  0.0791116   0.525873  0.711807    0.103426   
0              GaussianNB   0.588461   0.588461  0.588461           0   
2           SGDClassifier -0.0891711   0.425575  0.678098    0.192409   
5           MLPClassifier   0.940055    0.95588  0.967069  0.00694223   
8        VotingClassifier    0.80486    0.84682  0.891167   0.0220831   
9    KNeighborsClassifier   0.772868   0.842151  0.892636   0.0331428   
3    ExtraTreesClassifier   0.671622    0.86799  0.940735   0.0773416   
7                     SVC          0   0.652956  0.928914    0.170226   
6      AdaBoostClassifier   0.674954   0.885479  0.939057   0.0392385   
4  RandomForestClassifier   0.726428   0.866195  0.910727   0.0455009   

        acc       auc           conf_matrix     f1_c0      f1_c1      kappa  \
1  0.723404  0.860215  [[268, 104], [0, 4]]    0.8375  0.0714286  0.0519783   
0  0.654255  0.825269  [[242, 130], [0, 4]]  0.788274   0.057971  0.0380982   
2  0.635638   0.81586  [[235, 137], [0, 4]]    0.7743  0.0551724  0.0352113   
5  0.965426  0.735215   [[361, 11], [2, 2]]  0.982313   0.235294   0.222646   
8  0.925532  0.715054   [[346, 26], [2, 2]]  0.961111      0.125   0.108401   
9  0.917553  0.711022   [[343, 29], [2, 2]]  0.956764   0.114286  0.0972739   
3  0.978723   0.61828    [[367, 5], [3, 1]]  0.989218        0.2   0.189655   
7  0.978723   0.61828    [[367, 5], [3, 1]]  0.989218        0.2   0.189655   
6  0.962766  0.610215   [[361, 11], [3, 1]]  0.980978      0.125   0.110811   
4  0.944149  0.600806   [[354, 18], [3, 1]]  0.971193  0.0869565  0.0706215   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
1    0.163348         1   0.037037   0.72043      1  
0    0.139352         1  0.0298507  0.650538      1  
2     0.13387         1  0.0283688   0.63172      1  
5    0.264163   0.99449   0.153846   0.97043    0.5  
8    0.168078  0.994253  0.0714286  0.930108    0.5  
9    0.157423  0.994203  0.0645161  0.922043    0.5  
3    0.193671  0.991892   0.166667  0.986559   0.25  
7    0.193671  0.991892   0.166667  0.986559   0.25  
6    0.128656  0.991758  0.0833333   0.97043   0.25  
4   0.0944298  0.991597  0.0526316  0.951613   0.25  
Elapsed time 59.46 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-05-04 20:32:06.480000 
pca_target: 0 	 poly degree: 2 	 kselect: 40 
Imbalance: ClusterCentroids(estimator=None, n_jobs=1, random_state=None, ratio='auto') 
Extended target (count):  31485 325
('Total : Processed (count): ', (1252L, 276L), 13)
Final feature (count):  (1252L, 276L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.556 	0.114 	0.025 	0.776 	0.742 	0.576
[[205 167]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.55      0.71       372
          1       0.02      1.00      0.05         4

avg / total       0.99      0.56      0.70       376


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.1, class_weight={1: 3}, dual=False, fit_intercept=True,
          intercept_scaling=0.1, max_iter=100, multi_class='ovr', n_jobs=4,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.410 	0.084 	0.014 	0.702 	0.635 	0.427
[[150 222]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.40      0.57       372
          1       0.02      1.00      0.03         4

avg / total       0.99      0.41      0.57       376


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.0001, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='invscaling', loss='squared_hinge', n_iter=5,
       n_jobs=4, penalty='l1', power_t=0.5, random_state=None,
       shuffle=True, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.388 	0.081 	0.013 	0.691 	0.618 	0.405
[[142 230]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.38      0.55       372
          1       0.02      1.00      0.03         4

avg / total       0.99      0.39      0.55       376


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=8, max_features=0.75, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.343 	0.073 	0.011 	0.668 	0.580 	0.358
[[125 247]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.34      0.50       372
          1       0.02      1.00      0.03         4

avg / total       0.99      0.34      0.50       376


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=16, max_features=0.33, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.343 	0.073 	0.011 	0.668 	0.580 	0.358
[[125 247]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.34      0.50       372
          1       0.02      1.00      0.03         4

avg / total       0.99      0.34      0.50       376


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.01, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.489 	0.099 	0.020 	0.742 	0.696 	0.509
[[180 192]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.48      0.65       372
          1       0.02      1.00      0.04         4

avg / total       0.99      0.49      0.65       376


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=2.0, n_estimators=80, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.346 	0.074 	0.011 	0.669 	0.582 	0.361
[[126 246]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.34      0.51       372
          1       0.02      1.00      0.03         4

avg / total       0.99      0.35      0.50       376


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.1, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='linear',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.386 	0.080 	0.013 	0.690 	0.616 	0.403
[[141 231]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.38      0.55       372
          1       0.02      1.00      0.03         4

avg / total       0.99      0.39      0.54       376


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=1.0, class_weight={1: 500}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Ran...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.383 	0.080 	0.013 	0.688 	0.613 	0.400
[[140 232]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.38      0.55       372
          1       0.02      1.00      0.03         4

avg / total       0.99      0.38      0.54       376


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=1,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.590 	0.122 	0.029 	0.793 	0.766 	0.610
[[218 154]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.59      0.74       372
          1       0.03      1.00      0.05         4

avg / total       0.99      0.59      0.73       376


                estimator  min_score mean_score max_score   sd_score  \
9    KNeighborsClassifier    -0.1283   0.240205  0.478822   0.159171   
0              GaussianNB   0.906078   0.906078  0.906078          0   
5           MLPClassifier  0.0343779   0.293649  0.444444   0.108209   
1      LogisticRegression  -0.333333   0.149065  0.478822   0.162801   
2           SGDClassifier  -0.461633   0.329567  0.718234   0.207844   
7                     SVC  -0.496011  0.0772483  0.478822   0.279633   
8        VotingClassifier   0.222222    0.49671  0.701045  0.0882496   
6      AdaBoostClassifier   0.444444   0.869836         1    0.06696   
3    ExtraTreesClassifier   0.701045    0.94217         1  0.0579321   
4  RandomForestClassifier   0.649478   0.845736         1   0.100434   

        acc       auc           conf_matrix     f1_c0      f1_c1      kappa  \
9  0.590426  0.793011  [[218, 154], [0, 4]]  0.738983  0.0493827  0.0292382   
0  0.555851  0.775538  [[205, 167], [0, 4]]  0.710572  0.0457143  0.0254532   
5  0.489362  0.741935  [[180, 192], [0, 4]]  0.652174       0.04  0.0195567   
1  0.409574  0.701613  [[150, 222], [0, 4]]  0.574713  0.0347826  0.0141723   
2  0.388298   0.69086  [[142, 230], [0, 4]]  0.552529  0.0336134  0.0129657   
7  0.385638  0.689516  [[141, 231], [0, 4]]  0.549708  0.0334728  0.0128205   
8  0.382979  0.688172  [[140, 232], [0, 4]]  0.546875  0.0333333  0.0126766   
6  0.345745  0.669355  [[126, 246], [0, 4]]  0.506024  0.0314961  0.0107803   
3  0.343085  0.668011  [[125, 247], [0, 4]]  0.503018  0.0313725  0.0106528   
4  0.343085  0.668011  [[125, 247], [0, 4]]  0.503018  0.0313725  0.0106528   

  model_score prec_c0    prec_c1    rec_c0 rec_c1  
9    0.121803       1  0.0253165  0.586022      1  
0    0.113537       1  0.0233918  0.551075      1  
5   0.0993726       1  0.0204082  0.483871      1  
1   0.0844792       1  0.0176991  0.403226      1  
2   0.0807783       1   0.017094   0.38172      1  
7   0.0803219       1  0.0170213  0.379032      1  
8   0.0798668       1  0.0169492  0.376344      1  
6   0.0736163       1      0.016   0.33871      1  
3   0.0731773       1  0.0159363  0.336022      1  
4   0.0731773       1  0.0159363  0.336022      1  
Elapsed time 15.52 mins 

************************************************************








Standard, lagged(3,4)x1, filter(tukey), None, UN-truncated







 
    pca = [0]
    poly = [0]
    ksel = [20, 0]
    imb = [None, SMOTE(), ClusterCentroids() ]
	
	
	
	

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv 
datetime: 2017-05-09 15:35:52.044000 
pca_target: 0 	 poly degree: 0 	 kselect: 20 
Imbalance: None 
Extended target (count):  31485 325
('Total : Processed (count): ', (1252L, 20L), 13)
Final feature (count):  (1252L, 20L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.636 	0.134 	0.035 	0.816 	0.795 	0.655
[[235 137]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.63      0.77       372
          1       0.03      1.00      0.06         4

avg / total       0.99      0.64      0.77       376


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.01, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.641 	0.135 	0.036 	0.819 	0.798 	0.660
[[237 135]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.64      0.78       372
          1       0.03      1.00      0.06         4

avg / total       0.99      0.64      0.77       376


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.5, average=False, class_weight={1: 15}, epsilon=0.1,
       eta0=0.001, fit_intercept=True, l1_ratio=0.15,
       learning_rate='invscaling', loss='modified_huber', n_iter=5,
       n_jobs=4, penalty='elasticnet', power_t=0.5, random_state=None,
       shuffle=True, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.902 	-0.032 	-0.019 	0.456 	0.000 	0.000
[[339  33]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.91      0.95       372
          1       0.00      0.00      0.00         4

avg / total       0.98      0.90      0.94       376


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight='balanced',
           criterion='entropy', max_depth=8, max_features='auto',
           max_leaf_nodes=None, min_impurity_split=1e-07,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=4,
           oob_score=False, random_state=None, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.944 	0.094 	0.071 	0.601 	0.488 	0.221
[[354  18]
 [  3   1]]
             precision    recall  f1-score   support

          0       0.99      0.95      0.97       372
          1       0.05      0.25      0.09         4

avg / total       0.98      0.94      0.96       376


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 500},
            criterion='gini', max_depth=8, max_features=0.75,
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=15, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       372
          1       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.976 	-0.012 	-0.012 	0.493 	0.000 	0.000
[[367   5]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       372
          1       0.00      0.00      0.00         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight='balanced', criterion='entropy',
            max_depth=8, max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=0.5, n_estimators=15, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	-0.005 	-0.004 	0.499 	0.000 	0.000
[[371   1]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       372
          1       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.5, cache_size=200, class_weight='balanced', coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	-0.005 	-0.004 	0.499 	0.000 	0.000
[[371   1]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       372
          1       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       372
          1       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=1,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       372
          1       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


                estimator  min_score   mean_score  max_score    sd_score  \
1      LogisticRegression -0.0683018    0.0135861   0.091956   0.0277871   
0              GaussianNB  0.0103047    0.0103047  0.0103047           0   
3    ExtraTreesClassifier -0.0193835   0.00119524  0.0869853   0.0117768   
4  RandomForestClassifier -0.0110503 -0.000329302  0.0429483  0.00264525   
8        VotingClassifier -0.0113127   -0.0028456          0  0.00341143   
9    KNeighborsClassifier -0.0112699   -0.0029565          0   0.0042875   
6      AdaBoostClassifier -0.0188364 -0.000368076   0.137042   0.0225953   
7                     SVC -0.0219763    0.0155917  0.0964652   0.0238788   
5           MLPClassifier   -0.01245   -0.0049355  0.0735937   0.0120405   
2           SGDClassifier  -0.183588    0.0131818   0.179673   0.0309432   

        acc       auc           conf_matrix     f1_c0      f1_c1      kappa  \
1  0.640957  0.818548  [[237, 135], [0, 4]]  0.778325  0.0559441  0.0360073   
0  0.635638   0.81586  [[235, 137], [0, 4]]    0.7743  0.0551724  0.0352113   
3  0.944149  0.600806   [[354, 18], [3, 1]]  0.971193  0.0869565  0.0706215   
4  0.989362       0.5    [[372, 0], [4, 0]]  0.994652          0          0   
8  0.989362       0.5    [[372, 0], [4, 0]]  0.994652          0          0   
9  0.989362       0.5    [[372, 0], [4, 0]]  0.994652          0          0   
6  0.986702  0.498656    [[371, 1], [4, 0]]  0.993307          0 -0.0042735   
7  0.986702  0.498656    [[371, 1], [4, 0]]  0.993307          0 -0.0042735   
5  0.976064   0.49328    [[367, 5], [4, 0]]  0.987887          0 -0.0119617   
2  0.901596  0.455645   [[339, 33], [4, 0]]  0.948252          0 -0.0193435   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
1    0.135402         1   0.028777  0.637097      1  
0     0.13387         1  0.0283688   0.63172      1  
3   0.0944298  0.991597  0.0526316  0.951613   0.25  
4           0  0.989362          0         1      0  
8           0  0.989362          0         1      0  
9           0  0.989362          0         1      0  
6  -0.0053548  0.989333          0  0.997312      0  
7  -0.0053548  0.989333          0  0.997312      0  
5  -0.0120381  0.989218          0  0.986559      0  
2  -0.0321639  0.988338          0   0.91129      0  
Elapsed time 23.52 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv 
datetime: 2017-05-09 15:59:23.463000 
pca_target: 0 	 poly degree: 0 	 kselect: 20 
Imbalance: SMOTE(k=None, k_neighbors=5, kind='regular', m=None, m_neighbors=10, n_jobs=1,
   out_step=0.5, random_state=None, ratio='auto', svm_estimator=None) 
Extended target (count):  31485 325
('Total : Processed (count): ', (1252L, 20L), 13)
Final feature (count):  (1252L, 20L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.641 	0.135 	0.036 	0.819 	0.798 	0.660
[[237 135]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.64      0.78       372
          1       0.03      1.00      0.06         4

avg / total       0.99      0.64      0.77       376


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=10, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.843 	0.098 	0.044 	0.673 	0.651 	0.409
[[315  57]
 [  2   2]]
             precision    recall  f1-score   support

          0       0.99      0.85      0.91       372
          1       0.03      0.50      0.06         4

avg / total       0.98      0.84      0.91       376


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.001, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='modified_huber', n_iter=5, n_jobs=4,
       penalty='l1', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.859 	0.107 	0.051 	0.681 	0.657 	0.416
[[321  51]
 [  2   2]]
             precision    recall  f1-score   support

          0       0.99      0.86      0.92       372
          1       0.04      0.50      0.07         4

avg / total       0.98      0.86      0.91       376


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 50}, criterion='gini',
           max_depth=None, max_features=0.33, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=50, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.979 	-0.011 	-0.011 	0.495 	0.000 	0.000
[[368   4]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       372
          1       0.00      0.00      0.00         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight='balanced',
            criterion='entropy', max_depth=16, max_features='auto',
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.976 	-0.012 	-0.012 	0.493 	0.000 	0.000
[[367   5]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       372
          1       0.00      0.00      0.00         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.973 	-0.013 	-0.013 	0.492 	0.000 	0.000
[[366   6]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.98      0.99       372
          1       0.00      0.00      0.00         4

avg / total       0.98      0.97      0.98       376


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 500}, criterion='entropy',
            max_depth=8, max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=1.0, n_estimators=50, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.963 	-0.017 	-0.015 	0.487 	0.000 	0.000
[[362  10]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.97      0.98       372
          1       0.00      0.00      0.00         4

avg / total       0.98      0.96      0.97       376


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=10, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.981 	-0.009 	-0.009 	0.496 	0.000 	0.000
[[369   3]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       372
          1       0.00      0.00      0.00         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=10.0, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', ...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.949 	-0.021 	-0.017 	0.480 	0.000 	0.000
[[357  15]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.96      0.97       372
          1       0.00      0.00      0.00         4

avg / total       0.98      0.95      0.96       376


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=3,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.955 	-0.020 	-0.017 	0.483 	0.000 	0.000
[[359  13]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.97      0.98       372
          1       0.00      0.00      0.00         4

avg / total       0.98      0.95      0.97       376


                estimator min_score mean_score max_score   sd_score       acc  \
0              GaussianNB  0.574799   0.574799  0.574799          0  0.640957   
2           SGDClassifier -0.109368   0.430435  0.819539   0.205454  0.859043   
1      LogisticRegression         0   0.580482  0.803019   0.170369  0.843085   
7                     SVC         0   0.717596  0.982819   0.232714  0.981383   
3    ExtraTreesClassifier  0.630301   0.906242  0.988582    0.10773  0.978723   
4  RandomForestClassifier  0.771691   0.921856  0.973762   0.059182  0.976064   
5           MLPClassifier  0.966101   0.980582  0.989669  0.0047495  0.973404   
6      AdaBoostClassifier  0.823402   0.945984  0.984064  0.0274042  0.962766   
9    KNeighborsClassifier  0.859091   0.896785  0.935748   0.026104  0.954787   
8        VotingClassifier  0.857078    0.90472  0.932254  0.0187777  0.949468   

        auc           conf_matrix     f1_c0      f1_c1       kappa  \
0  0.818548  [[237, 135], [0, 4]]  0.778325  0.0559441   0.0360073   
2  0.681452   [[321, 51], [2, 2]]  0.923741  0.0701754    0.051409   
1  0.673387   [[315, 57], [2, 2]]  0.914369  0.0634921   0.0444521   
7  0.495968    [[369, 3], [4, 0]]  0.990604          0 -0.00920245   
3  0.494624    [[368, 4], [4, 0]]  0.989247          0  -0.0107527   
4   0.49328    [[367, 5], [4, 0]]  0.987887          0  -0.0119617   
5  0.491935    [[366, 6], [4, 0]]  0.986523          0   -0.012931   
6  0.486559   [[362, 10], [4, 0]]   0.98103          0  -0.0154321   
9  0.482527   [[359, 13], [4, 0]]  0.976871          0  -0.0165394   
8  0.479839   [[357, 15], [4, 0]]  0.974079          0  -0.0170843   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
0    0.135402         1   0.028777  0.637097      1  
2    0.106992  0.993808  0.0377358  0.862903    0.5  
1   0.0978121  0.993691  0.0338983  0.846774    0.5  
7 -0.00929961  0.989276          0  0.991935      0  
3  -0.0107527  0.989247          0  0.989247      0  
4  -0.0120381  0.989218          0  0.986559      0  
5  -0.0132048  0.989189          0  0.983871      0  
6  -0.0171403  0.989071          0  0.973118      0  
9  -0.0196235  0.988981          0  0.965054      0  
8  -0.0211374   0.98892          0  0.959677      0  
Elapsed time 41.38 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv 
datetime: 2017-05-09 16:40:46.054000 
pca_target: 0 	 poly degree: 0 	 kselect: 20 
Imbalance: ClusterCentroids(estimator=None, n_jobs=1, random_state=None, ratio='auto') 
Extended target (count):  31485 325
('Total : Processed (count): ', (1252L, 20L), 13)
Final feature (count):  (1252L, 20L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.622 	0.130 	0.033 	0.809 	0.786 	0.642
[[230 142]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.62      0.76       372
          1       0.03      1.00      0.05         4

avg / total       0.99      0.62      0.76       376


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.01, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.545 	0.111 	0.024 	0.770 	0.735 	0.565
[[201 171]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.54      0.70       372
          1       0.02      1.00      0.04         4

avg / total       0.99      0.55      0.69       376


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.5, average=False, class_weight={1: 500}, epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='invscaling', loss='squared_hinge', n_iter=5,
       n_jobs=4, penalty='none', power_t=0.5, random_state=None,
       shuffle=True, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.524 	0.106 	0.022 	0.759 	0.720 	0.544
[[193 179]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.52      0.68       372
          1       0.02      1.00      0.04         4

avg / total       0.99      0.52      0.68       376


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 15}, criterion='gini',
           max_depth=8, max_features=0.75, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=50, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.577 	0.067 	0.016 	0.663 	0.657 	0.439
[[214 158]
 [  1   3]]
             precision    recall  f1-score   support

          0       1.00      0.58      0.73       372
          1       0.02      0.75      0.04         4

avg / total       0.98      0.58      0.72       376


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight='balanced',
            criterion='gini', max_depth=8, max_features=0.33,
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=15, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.569 	0.117 	0.027 	0.782 	0.751 	0.589
[[210 162]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.56      0.72       372
          1       0.02      1.00      0.05         4

avg / total       0.99      0.57      0.71       376


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.5, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.806 	0.016 	0.007 	0.531 	0.451 	0.192
[[302  70]
 [  3   1]]
             precision    recall  f1-score   support

          0       0.99      0.81      0.89       372
          1       0.01      0.25      0.03         4

avg / total       0.98      0.81      0.88       376


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='entropy', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=1.0, n_estimators=80, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.622 	0.078 	0.020 	0.685 	0.682 	0.472
[[231 141]
 [  1   3]]
             precision    recall  f1-score   support

          0       1.00      0.62      0.76       372
          1       0.02      0.75      0.04         4

avg / total       0.99      0.62      0.76       376


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.1, cache_size=200, class_weight='balanced', coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='linear',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.606 	0.126 	0.031 	0.801 	0.776 	0.626
[[224 148]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.60      0.75       372
          1       0.03      1.00      0.05         4

avg / total       0.99      0.61      0.74       376


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=10.0, class_weight={1: 500}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Ra...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.527 	0.107 	0.023 	0.761 	0.722 	0.546
[[194 178]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.52      0.69       372
          1       0.02      1.00      0.04         4

avg / total       0.99      0.53      0.68       376


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=5, p=1,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.588 	0.121 	0.029 	0.792 	0.764 	0.608
[[217 155]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.58      0.74       372
          1       0.03      1.00      0.05         4

avg / total       0.99      0.59      0.73       376


                estimator min_score mean_score  max_score  sd_score       acc  \
0              GaussianNB    0.1283     0.1283     0.1283         0   0.62234   
7                     SVC -0.367711 -0.0462553     0.3849  0.163485  0.606383   
9    KNeighborsClassifier -0.624311  -0.308715  0.0171889  0.187937  0.587766   
4  RandomForestClassifier -0.222222   0.218841   0.683856  0.154968  0.569149   
1      LogisticRegression -0.478822  0.0246601   0.367711  0.128478  0.545213   
8        VotingClassifier -0.367711 -0.0034839   0.273789  0.116114  0.526596   
2           SGDClassifier   -0.5132  0.0443598   0.496011   0.15831  0.523936   
6      AdaBoostClassifier -0.572745   0.183685   0.701045  0.204148   0.62234   
3    ExtraTreesClassifier -0.624311  -0.130331   0.350522  0.182503  0.577128   
5           MLPClassifier   -0.1283 -0.0213062     0.2566  0.100063  0.805851   

        auc           conf_matrix     f1_c0      f1_c1       kappa  \
0   0.80914  [[230, 142], [0, 4]]   0.76412  0.0533333    0.033314   
7  0.801075  [[224, 148], [0, 4]]  0.751678  0.0512821   0.0311978   
9  0.791667  [[217, 155], [0, 4]]  0.736842  0.0490798   0.0289256   
4  0.782258  [[210, 162], [0, 4]]  0.721649  0.0470588   0.0268405   
1  0.770161  [[201, 171], [0, 4]]  0.701571  0.0446927   0.0243991   
8  0.760753  [[194, 178], [0, 4]]  0.685512  0.0430108   0.0226636   
2  0.759409  [[193, 179], [0, 4]]  0.683186  0.0427807   0.0224262   
6  0.685484  [[231, 141], [1, 3]]  0.764901  0.0405405   0.0202584   
3  0.662634  [[214, 158], [1, 3]]  0.729131  0.0363636   0.0159336   
5  0.530914   [[302, 70], [3, 1]]  0.892171  0.0266667  0.00665895   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
0    0.130151         1  0.0273973   0.61828      1  
7    0.125881         1  0.0263158  0.602151      1  
9    0.121141         1  0.0251572  0.583333      1  
4    0.116631         1  0.0240964  0.564516      1  
1    0.111132         1  0.0228571  0.540323      1  
8    0.107059         1   0.021978  0.521505      1  
2    0.106491         1  0.0218579  0.518817      1  
6   0.0782911   0.99569  0.0208333  0.620968   0.75  
3   0.0674391  0.995349  0.0186335  0.575269   0.75  
5   0.0162072  0.990164  0.0140845  0.811828   0.25  
Elapsed time 14.63 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv 
datetime: 2017-05-09 16:55:23.558000 
pca_target: 0 	 poly degree: 0 	 kselect: 0 
Imbalance: None 
Extended target (count):  31485 325
('Total : Processed (count): ', (1252L, 20L), 13)
Final feature (count):  (1252L, 20L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.636 	0.134 	0.035 	0.816 	0.795 	0.655
[[235 137]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.63      0.77       372
          1       0.03      1.00      0.06         4

avg / total       0.99      0.64      0.77       376


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.01, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.641 	0.135 	0.036 	0.819 	0.798 	0.660
[[237 135]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.64      0.78       372
          1       0.03      1.00      0.06         4

avg / total       0.99      0.64      0.77       376


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=1, average=False, class_weight={1: 15}, epsilon=0.1,
       eta0=0.001, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='modified_huber', n_iter=5, n_jobs=4,
       penalty='l2', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.957 	-0.019 	-0.016 	0.484 	0.000 	0.000
[[360  12]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.97      0.98       372
          1       0.00      0.00      0.00         4

avg / total       0.98      0.96      0.97       376


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight='balanced',
           criterion='gini', max_depth=8, max_features='auto',
           max_leaf_nodes=None, min_impurity_split=1e-07,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=4,
           oob_score=False, random_state=None, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.965 	-0.016 	-0.015 	0.488 	0.000 	0.000
[[363   9]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.98      0.98       372
          1       0.00      0.00      0.00         4

avg / total       0.98      0.97      0.97       376


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       372
          1       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.5, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(500,), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       372
          1       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 50}, criterion='entropy',
            max_depth=32, max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=1.0, n_estimators=15, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	-0.005 	-0.004 	0.499 	0.000 	0.000
[[371   1]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       372
          1       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.5, cache_size=200, class_weight='balanced', coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	-0.005 	-0.004 	0.499 	0.000 	0.000
[[371   1]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       372
          1       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       372
          1       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=1,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       372
          1       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


                estimator  min_score   mean_score  max_score    sd_score  \
1      LogisticRegression -0.0448778    0.0143668   0.091956   0.0281027   
0              GaussianNB  0.0103047    0.0103047  0.0103047           0   
4  RandomForestClassifier -0.0206961 -0.000555479          0  0.00186373   
5           MLPClassifier -0.0125348  -0.00636662          0  0.00365135   
8        VotingClassifier -0.0111587  -0.00279889          0  0.00343567   
9    KNeighborsClassifier -0.0112699   -0.0029565          0   0.0042875   
6      AdaBoostClassifier -0.0195581  -0.00144225   0.184727   0.0226489   
7                     SVC -0.0219763    0.0155917  0.0964652   0.0238788   
3    ExtraTreesClassifier -0.0198184   0.00210225   0.164446   0.0157799   
2           SGDClassifier  -0.195276    0.0129524   0.140057   0.0308845   

        acc       auc           conf_matrix     f1_c0      f1_c1      kappa  \
1  0.640957  0.818548  [[237, 135], [0, 4]]  0.778325  0.0559441  0.0360073   
0  0.635638   0.81586  [[235, 137], [0, 4]]    0.7743  0.0551724  0.0352113   
4  0.989362       0.5    [[372, 0], [4, 0]]  0.994652          0          0   
5  0.989362       0.5    [[372, 0], [4, 0]]  0.994652          0          0   
8  0.989362       0.5    [[372, 0], [4, 0]]  0.994652          0          0   
9  0.989362       0.5    [[372, 0], [4, 0]]  0.994652          0          0   
6  0.986702  0.498656    [[371, 1], [4, 0]]  0.993307          0 -0.0042735   
7  0.986702  0.498656    [[371, 1], [4, 0]]  0.993307          0 -0.0042735   
3  0.965426  0.487903    [[363, 9], [4, 0]]  0.982409          0 -0.0149502   
2  0.957447  0.483871   [[360, 12], [4, 0]]  0.978261          0 -0.0162162   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
1    0.135402         1   0.028777  0.637097      1  
0     0.13387         1  0.0283688   0.63172      1  
4           0  0.989362          0         1      0  
5           0  0.989362          0         1      0  
8           0  0.989362          0         1      0  
9           0  0.989362          0         1      0  
6  -0.0053548  0.989333          0  0.997312      0  
7  -0.0053548  0.989333          0  0.997312      0  
3  -0.0162385  0.989101          0  0.975806      0  
2  -0.0188278  0.989011          0  0.967742      0  
Elapsed time 23.50 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv 
datetime: 2017-05-09 17:18:53.802000 
pca_target: 0 	 poly degree: 0 	 kselect: 0 
Imbalance: SMOTE(k=None, k_neighbors=5, kind='regular', m=None, m_neighbors=10, n_jobs=1,
   out_step=0.5, random_state=None, ratio='auto', svm_estimator=None) 
Extended target (count):  31485 325
('Total : Processed (count): ', (1252L, 20L), 13)
Final feature (count):  (1252L, 20L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.660 	0.141 	0.039 	0.828 	0.810 	0.678
[[244 128]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.66      0.79       372
          1       0.03      1.00      0.06         4

avg / total       0.99      0.66      0.78       376


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=10, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.835 	0.094 	0.041 	0.669 	0.648 	0.405
[[312  60]
 [  2   2]]
             precision    recall  f1-score   support

          0       0.99      0.84      0.91       372
          1       0.03      0.50      0.06         4

avg / total       0.98      0.84      0.90       376


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.001, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.001, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='modified_huber', n_iter=5, n_jobs=4,
       penalty='none', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.883 	0.124 	0.065 	0.694 	0.666 	0.426
[[330  42]
 [  2   2]]
             precision    recall  f1-score   support

          0       0.99      0.89      0.94       372
          1       0.05      0.50      0.08         4

avg / total       0.98      0.88      0.93       376


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 500},
           criterion='entropy', max_depth=32, max_features=0.33,
           max_leaf_nodes=None, min_impurity_split=1e-07,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=4,
           oob_score=False, random_state=None, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.981 	-0.009 	-0.009 	0.496 	0.000 	0.000
[[369   3]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       372
          1       0.00      0.00      0.00         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight='balanced',
            criterion='entropy', max_depth=16, max_features='auto',
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.973 	-0.013 	-0.013 	0.492 	0.000 	0.000
[[366   6]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.98      0.99       372
          1       0.00      0.00      0.00         4

avg / total       0.98      0.97      0.98       376


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.5, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.960 	-0.018 	-0.016 	0.485 	0.000 	0.000
[[361  11]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.97      0.98       372
          1       0.00      0.00      0.00         4

avg / total       0.98      0.96      0.97       376


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 50}, criterion='entropy',
            max_depth=16, max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=1.0, n_estimators=80, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.976 	-0.012 	-0.012 	0.493 	0.000 	0.000
[[367   5]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       372
          1       0.00      0.00      0.00         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=10, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.981 	-0.009 	-0.009 	0.496 	0.000 	0.000
[[369   3]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       372
          1       0.00      0.00      0.00         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=10.0, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', ...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.955 	-0.020 	-0.017 	0.483 	0.000 	0.000
[[359  13]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.97      0.98       372
          1       0.00      0.00      0.00         4

avg / total       0.98      0.95      0.97       376


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.949 	-0.021 	-0.017 	0.480 	0.000 	0.000
[[357  15]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.96      0.97       372
          1       0.00      0.00      0.00         4

avg / total       0.98      0.95      0.96       376


                estimator  min_score mean_score max_score    sd_score  \
0              GaussianNB   0.549198   0.549198  0.549198           0   
2           SGDClassifier -0.0603771   0.432602  0.828162     0.20307   
1      LogisticRegression          0   0.580188  0.808589    0.172075   
3    ExtraTreesClassifier   0.615144    0.90545  0.986332    0.107625   
7                     SVC          0   0.717255  0.985203    0.232315   
6      AdaBoostClassifier   0.822041   0.945576  0.982894   0.0279984   
4  RandomForestClassifier   0.774961   0.927753  0.973738   0.0584609   
5           MLPClassifier   0.969464   0.979068  0.987433  0.00435456   
8        VotingClassifier   0.855103   0.904296  0.936567   0.0201555   
9    KNeighborsClassifier    0.85981    0.89658  0.936845   0.0274715   

        acc       auc           conf_matrix     f1_c0      f1_c1       kappa  \
0  0.659574  0.827957  [[244, 128], [0, 4]]  0.792208  0.0588235   0.0389776   
2  0.882979  0.693548   [[330, 42], [2, 2]]    0.9375  0.0833333   0.0650995   
1  0.835106  0.669355   [[312, 60], [2, 2]]  0.909621  0.0606061   0.0414474   
3  0.981383  0.495968    [[369, 3], [4, 0]]  0.990604          0 -0.00920245   
7  0.981383  0.495968    [[369, 3], [4, 0]]  0.990604          0 -0.00920245   
6  0.976064   0.49328    [[367, 5], [4, 0]]  0.987887          0  -0.0119617   
4  0.973404  0.491935    [[366, 6], [4, 0]]  0.986523          0   -0.012931   
5  0.960106  0.485215   [[361, 11], [4, 0]]  0.979647          0  -0.0158501   
8  0.954787  0.482527   [[359, 13], [4, 0]]  0.976871          0  -0.0165394   
9  0.949468  0.479839   [[357, 15], [4, 0]]  0.974079          0  -0.0170843   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
0    0.140983         1   0.030303  0.655914      1  
2    0.123545  0.993976  0.0454545  0.887097    0.5  
1   0.0936415  0.993631  0.0322581   0.83871    0.5  
3 -0.00929961  0.989276          0  0.991935      0  
7 -0.00929961  0.989276          0  0.991935      0  
6  -0.0120381  0.989218          0  0.986559      0  
4  -0.0132048  0.989189          0  0.983871      0  
5  -0.0180015  0.989041          0   0.97043      0  
8  -0.0196235  0.988981          0  0.965054      0  
9  -0.0211374   0.98892          0  0.959677      0  
Elapsed time 41.32 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv 
datetime: 2017-05-09 18:00:12.757000 
pca_target: 0 	 poly degree: 0 	 kselect: 0 
Imbalance: ClusterCentroids(estimator=None, n_jobs=1, random_state=None, ratio='auto') 
Extended target (count):  31485 325
('Total : Processed (count): ', (1252L, 20L), 13)
Final feature (count):  (1252L, 20L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.620 	0.129 	0.033 	0.808 	0.785 	0.639
[[229 143]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.62      0.76       372
          1       0.03      1.00      0.05         4

avg / total       0.99      0.62      0.75       376


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.001, class_weight={1: 3}, dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.551 	0.112 	0.025 	0.773 	0.739 	0.570
[[203 169]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.55      0.71       372
          1       0.02      1.00      0.05         4

avg / total       0.99      0.55      0.70       376


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.1, average=False, class_weight={1: 15}, epsilon=0.1,
       eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='modified_huber', n_iter=5, n_jobs=4,
       penalty='none', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.577 	0.119 	0.028 	0.786 	0.757 	0.597
[[213 159]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.57      0.73       372
          1       0.02      1.00      0.05         4

avg / total       0.99      0.58      0.72       376


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 15}, criterion='gini',
           max_depth=32, max_features=0.75, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.612 	0.076 	0.019 	0.680 	0.677 	0.464
[[227 145]
 [  1   3]]
             precision    recall  f1-score   support

          0       1.00      0.61      0.76       372
          1       0.02      0.75      0.04         4

avg / total       0.99      0.61      0.75       376


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=16, max_features=0.33, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.585 	0.120 	0.029 	0.790 	0.762 	0.605
[[216 156]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.58      0.73       372
          1       0.03      1.00      0.05         4

avg / total       0.99      0.59      0.73       376


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.5, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.811 	0.018 	0.007 	0.534 	0.452 	0.193
[[304  68]
 [  3   1]]
             precision    recall  f1-score   support

          0       0.99      0.82      0.90       372
          1       0.01      0.25      0.03         4

avg / total       0.98      0.81      0.89       376


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 50}, criterion='gini', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=1.0, n_estimators=80, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.479 	0.097 	0.019 	0.737 	0.688 	0.498
[[176 196]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.47      0.64       372
          1       0.02      1.00      0.04         4

avg / total       0.99      0.48      0.64       376


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.5, cache_size=200, class_weight='balanced', coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='linear',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.713 	0.104 	0.033 	0.731 	0.731 	0.536
[[265 107]
 [  1   3]]
             precision    recall  f1-score   support

          0       1.00      0.71      0.83       372
          1       0.03      0.75      0.05         4

avg / total       0.99      0.71      0.82       376


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', R...owski',
           metric_params=None, n_jobs=4, n_neighbors=4, p=2,
           weights='uniform'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.593 	0.122 	0.030 	0.794 	0.767 	0.613
[[219 153]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.59      0.74       372
          1       0.03      1.00      0.05         4

avg / total       0.99      0.59      0.73       376


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=3, p=1,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.633 	0.133 	0.035 	0.815 	0.793 	0.652
[[234 138]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.63      0.77       372
          1       0.03      1.00      0.05         4

avg / total       0.99      0.63      0.76       376


                estimator min_score mean_score  max_score  sd_score       acc  \
9    KNeighborsClassifier   -0.5132  -0.265092          0  0.144938  0.632979   
0              GaussianNB         0          0          0         0  0.619681   
8        VotingClassifier -0.367711 -0.0384664   0.273789  0.128376  0.593085   
4  RandomForestClassifier -0.367711   0.139508   0.478822  0.160659  0.585106   
2           SGDClassifier -0.624311  0.0488304   0.496011  0.169503  0.577128   
1      LogisticRegression -0.367711 -0.0678481     0.2566  0.128093  0.550532   
6      AdaBoostClassifier   -0.5132   0.141274   0.701045  0.224858  0.478723   
7                     SVC -0.239411  0.0568221   0.367711  0.130467  0.712766   
3    ExtraTreesClassifier   -0.5132  0.0396492   0.572745  0.190091  0.611702   
5           MLPClassifier -0.624311  -0.274351  0.0939222  0.157362   0.81117   

        auc           conf_matrix     f1_c0      f1_c1       kappa  \
9  0.814516  [[234, 138], [0, 4]]  0.772277  0.0547945   0.0348214   
0  0.807796  [[229, 143], [0, 4]]  0.762063  0.0529801   0.0329496   
8  0.794355  [[219, 153], [0, 4]]  0.741117  0.0496894   0.0295547   
4  0.790323  [[216, 156], [0, 4]]  0.734694  0.0487805   0.0286169   
2   0.78629  [[213, 159], [0, 4]]  0.728205  0.0479042   0.0277127   
1  0.772849  [[203, 169], [0, 4]]  0.706087  0.0451977   0.0249202   
6  0.736559  [[176, 196], [0, 4]]  0.642336  0.0392157   0.0187473   
7  0.731183  [[265, 107], [1, 3]]  0.830721  0.0526316   0.0327744   
3  0.680108  [[227, 145], [1, 3]]  0.756667  0.0394737   0.0191538   
5  0.533602   [[304, 68], [3, 1]]  0.895434  0.0273973  0.00743605   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
9    0.133114         1   0.028169  0.629032      1  
0    0.129425         1  0.0272109  0.615591      1  
8     0.12247         1  0.0254777   0.58871      1  
4    0.120483         1      0.025  0.580645      1  
2    0.118537         1  0.0245399  0.572581      1  
1    0.112327         1  0.0231214  0.545699      1  
6   0.0972747         1       0.02  0.473118      1  
7    0.104268  0.996241  0.0272727  0.712366   0.75  
3   0.0756424  0.995614  0.0202703  0.610215   0.75  
5   0.0178117  0.990228  0.0144928  0.817204   0.25  
Elapsed time 14.74 mins 

************************************************************







Standard, lagged(3,4)x2, filter(tukey), None, UNtruncated








    pca = [0]
    poly = [0]
    ksel = [20, 0]
    imb = [None, SMOTE(), ClusterCentroids() ]
    
	
	


pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv 
datetime: 2017-05-09 20:08:43.108000 
pca_target: 0 	 poly degree: 0 	 kselect: 20 
Imbalance: None 
Extended target (count):  31485 325
('Total : Processed (count): ', (1252L, 22L), 13)
Final feature (count):  (1252L, 22L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.646 	0.137 	0.037 	0.821 	0.802 	0.665
[[239 133]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.64      0.78       372
          1       0.03      1.00      0.06         4

avg / total       0.99      0.65      0.77       376


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=10, class_weight={1: 500}, dual=False,
          fit_intercept=True, intercept_scaling=10, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='sag', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.535 	0.109 	0.023 	0.765 	0.728 	0.554
[[197 175]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.53      0.69       372
          1       0.02      1.00      0.04         4

avg / total       0.99      0.53      0.69       376


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.5, average=False, class_weight={1: 50}, epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='constant', loss='perceptron', n_iter=5, n_jobs=4,
       penalty='l2', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.676 	0.146 	0.042 	0.836 	0.820 	0.694
[[250 122]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.67      0.80       372
          1       0.03      1.00      0.06         4

avg / total       0.99      0.68      0.80       376


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight='balanced',
           criterion='gini', max_depth=16, max_features=0.33,
           max_leaf_nodes=None, min_impurity_split=1e-07,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=15, n_jobs=4,
           oob_score=False, random_state=None, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       372
          1       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 500},
            criterion='gini', max_depth=8, max_features=0.75,
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.968 	-0.015 	-0.014 	0.489 	0.000 	0.000
[[364   8]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.98      0.98       372
          1       0.00      0.00      0.00         4

avg / total       0.98      0.97      0.97       376


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.5, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(500,), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       372
          1       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight='balanced', criterion='entropy',
            max_depth=8, max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=2.0, n_estimators=80, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.960 	-0.018 	-0.016 	0.485 	0.000 	0.000
[[361  11]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.97      0.98       372
          1       0.00      0.00      0.00         4

avg / total       0.98      0.96      0.97       376


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.5, cache_size=200, class_weight='balanced', coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	-0.005 	-0.004 	0.499 	0.000 	0.000
[[371   1]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       372
          1       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 500}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Ran...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.984 	-0.008 	-0.007 	0.497 	0.000 	0.000
[[370   2]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       372
          1       0.00      0.00      0.00         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=4,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	-0.005 	-0.004 	0.499 	0.000 	0.000
[[371   1]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       372
          1       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


                estimator   min_score   mean_score  max_score    sd_score  \
2           SGDClassifier   -0.209429    0.0141276   0.203958   0.0327056   
0              GaussianNB   0.0531739    0.0531739  0.0531739           0   
1      LogisticRegression  -0.0475268    0.0126819  0.0953053   0.0308246   
3    ExtraTreesClassifier  -0.0197779   0.00221244  0.0960168   0.0147362   
5           MLPClassifier  -0.0121959  -0.00652531          0  0.00310152   
7                     SVC  -0.0231363    0.0151469  0.0969924   0.0264472   
9    KNeighborsClassifier -0.00837095    0.0126725  0.0759031   0.0298888   
8        VotingClassifier -0.00931825 -5.79364e-05     0.1352   0.0174599   
4  RandomForestClassifier  -0.0109714  3.75032e-05   0.064113  0.00462978   
6      AdaBoostClassifier  -0.0200866  -0.00160447   0.132285   0.0198454   

        acc       auc           conf_matrix     f1_c0      f1_c1       kappa  \
2  0.675532  0.836022  [[250, 122], [0, 4]]  0.803859  0.0615385   0.0417781   
0  0.646277  0.821237  [[239, 133], [0, 4]]  0.782324  0.0567376   0.0368259   
1  0.534574  0.764785  [[197, 175], [0, 4]]  0.692443  0.0437158   0.0233911   
3  0.989362       0.5    [[372, 0], [4, 0]]  0.994652          0           0   
5  0.989362       0.5    [[372, 0], [4, 0]]  0.994652          0           0   
7  0.986702  0.498656    [[371, 1], [4, 0]]  0.993307          0  -0.0042735   
9  0.986702  0.498656    [[371, 1], [4, 0]]  0.993307          0  -0.0042735   
8  0.984043  0.497312    [[370, 2], [4, 0]]  0.991957          0 -0.00714286   
4  0.968085  0.489247    [[364, 8], [4, 0]]  0.983784          0  -0.0143885   
6  0.960106  0.485215   [[361, 11], [4, 0]]  0.979647          0  -0.0158501   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
2    0.146064         1   0.031746  0.672043      1  
0    0.136961         1  0.0291971  0.642473      1  
1    0.108784         1  0.0223464   0.52957      1  
3           0  0.989362          0         1      0  
5           0  0.989362          0         1      0  
7  -0.0053548  0.989333          0  0.997312      0  
9  -0.0053548  0.989333          0  0.997312      0  
8 -0.00758294  0.989305          0  0.994624      0  
4   -0.015289   0.98913          0  0.978495      0  
6  -0.0180015  0.989041          0   0.97043      0  
Elapsed time 23.86 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv 
datetime: 2017-05-09 20:32:34.532000 
pca_target: 0 	 poly degree: 0 	 kselect: 20 
Imbalance: SMOTE(k=None, k_neighbors=5, kind='regular', m=None, m_neighbors=10, n_jobs=1,
   out_step=0.5, random_state=None, ratio='auto', svm_estimator=None) 
Extended target (count):  31485 325
('Total : Processed (count): ', (1252L, 22L), 13)
Final feature (count):  (1252L, 22L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.638 	0.135 	0.036 	0.817 	0.796 	0.658
[[236 136]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.63      0.78       372
          1       0.03      1.00      0.06         4

avg / total       0.99      0.64      0.77       376


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=10, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.838 	0.162 	0.071 	0.794 	0.793 	0.623
[[312  60]
 [  1   3]]
             precision    recall  f1-score   support

          0       1.00      0.84      0.91       372
          1       0.05      0.75      0.09         4

avg / total       0.99      0.84      0.90       376


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.001, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='modified_huber', n_iter=5, n_jobs=4,
       penalty='l1', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.840 	0.229 	0.100 	0.919 	0.916 	0.852
[[312  60]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.84      0.91       372
          1       0.06      1.00      0.12         4

avg / total       0.99      0.84      0.90       376


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 15}, criterion='gini',
           max_depth=32, max_features='auto', max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=50, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.976 	-0.012 	-0.012 	0.493 	0.000 	0.000
[[367   5]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       372
          1       0.00      0.00      0.00         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight='balanced',
            criterion='entropy', max_depth=32, max_features='auto',
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.979 	-0.011 	-0.011 	0.495 	0.000 	0.000
[[368   4]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       372
          1       0.00      0.00      0.00         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.1, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.976 	0.178 	0.171 	0.617 	0.496 	0.228
[[366   6]
 [  3   1]]
             precision    recall  f1-score   support

          0       0.99      0.98      0.99       372
          1       0.14      0.25      0.18         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight='balanced', criterion='gini',
            max_depth=16, max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=1.0, n_estimators=80, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.981 	0.214 	0.213 	0.620 	0.497 	0.229
[[368   4]
 [  3   1]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       372
          1       0.20      0.25      0.22         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=10, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.984 	0.242 	0.242 	0.621 	0.498 	0.230
[[369   3]
 [  3   1]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       372
          1       0.25      0.25      0.25         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=10.0, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', ...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.957 	0.117 	0.096 	0.608 	0.491 	0.224
[[359  13]
 [  3   1]]
             precision    recall  f1-score   support

          0       0.99      0.97      0.98       372
          1       0.07      0.25      0.11         4

avg / total       0.98      0.96      0.97       376


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.944 	0.094 	0.071 	0.601 	0.488 	0.221
[[354  18]
 [  3   1]]
             precision    recall  f1-score   support

          0       0.99      0.95      0.97       372
          1       0.05      0.25      0.09         4

avg / total       0.98      0.94      0.96       376


                estimator min_score mean_score max_score    sd_score  \
2           SGDClassifier -0.145987   0.434396  0.812113    0.204277   
0              GaussianNB  0.556605   0.556605  0.556605           0   
1      LogisticRegression  0.125944   0.581379   0.80333    0.154133   
7                     SVC         0   0.708333   0.98519    0.230078   
6      AdaBoostClassifier  0.804141   0.942919  0.983974   0.0298824   
5           MLPClassifier  0.963852   0.980376  0.986296  0.00474065   
8        VotingClassifier  0.849847   0.904823  0.941847   0.0219564   
9    KNeighborsClassifier  0.852981   0.892965  0.938691   0.0284868   
4  RandomForestClassifier  0.770582   0.925468  0.974747   0.0534956   
3    ExtraTreesClassifier  0.619584   0.906685   0.98855     0.10802   

        acc       auc           conf_matrix     f1_c0      f1_c1      kappa  \
2  0.840426  0.919355   [[312, 60], [0, 4]]  0.912281   0.117647  0.0996169   
0  0.638298  0.817204  [[236, 136], [0, 4]]  0.776316  0.0555556  0.0356065   
1  0.837766  0.794355   [[312, 60], [1, 3]]  0.910949  0.0895522  0.0709657   
7  0.984043  0.620968    [[369, 3], [3, 1]]  0.991935       0.25   0.241935   
6  0.981383  0.619624    [[368, 4], [3, 1]]  0.990579   0.222222   0.212919   
5  0.976064  0.616935    [[366, 6], [3, 1]]  0.987854   0.181818   0.170588   
8  0.957447  0.607527   [[359, 13], [3, 1]]  0.978202   0.111111  0.0961538   
9  0.944149  0.600806   [[354, 18], [3, 1]]  0.971193  0.0869565  0.0706215   
4  0.978723  0.494624    [[368, 4], [4, 0]]  0.989247          0 -0.0107527   
3  0.976064   0.49328    [[367, 5], [4, 0]]  0.987887          0 -0.0119617   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
2    0.228953         1     0.0625   0.83871      1  
0    0.134633         1  0.0285714  0.634409      1  
1    0.161719  0.996805   0.047619   0.83871   0.75  
7    0.241935  0.991935       0.25  0.991935   0.25  
6    0.214278  0.991914        0.2  0.989247   0.25  
5    0.177507   0.99187   0.142857  0.983871   0.25  
8    0.116528  0.991713  0.0714286  0.965054   0.25  
9   0.0944298  0.991597  0.0526316  0.951613   0.25  
4  -0.0107527  0.989247          0  0.989247      0  
3  -0.0120381  0.989218          0  0.986559      0  
Elapsed time 43.44 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv 
datetime: 2017-05-09 21:16:00.909000 
pca_target: 0 	 poly degree: 0 	 kselect: 20 
Imbalance: ClusterCentroids(estimator=None, n_jobs=1, random_state=None, ratio='auto') 
Extended target (count):  31485 325
('Total : Processed (count): ', (1252L, 22L), 13)
Final feature (count):  (1252L, 22L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.622 	0.130 	0.033 	0.809 	0.786 	0.642
[[230 142]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.62      0.76       372
          1       0.03      1.00      0.05         4

avg / total       0.99      0.62      0.76       376


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=5, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='sag', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.753 	0.119 	0.041 	0.751 	0.751 	0.564
[[280  92]
 [  1   3]]
             precision    recall  f1-score   support

          0       1.00      0.75      0.86       372
          1       0.03      0.75      0.06         4

avg / total       0.99      0.75      0.85       376


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.001, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='invscaling', loss='squared_hinge', n_iter=5,
       n_jobs=4, penalty='none', power_t=0.5, random_state=None,
       shuffle=True, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.444 	-0.012 	-0.002 	0.472 	0.471 	0.223
[[165 207]
 [  2   2]]
             precision    recall  f1-score   support

          0       0.99      0.44      0.61       372
          1       0.01      0.50      0.02         4

avg / total       0.98      0.44      0.61       376


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 50}, criterion='gini',
           max_depth=8, max_features=0.75, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=30, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.662 	0.142 	0.039 	0.829 	0.812 	0.681
[[245 127]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.66      0.79       372
          1       0.03      1.00      0.06         4

avg / total       0.99      0.66      0.79       376


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 50}, criterion='gini',
            max_depth=32, max_features=0.75, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.585 	0.120 	0.029 	0.790 	0.762 	0.605
[[216 156]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.58      0.73       372
          1       0.03      1.00      0.05         4

avg / total       0.99      0.59      0.73       376


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(500,), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.787 	0.073 	0.028 	0.645 	0.629 	0.384
[[294  78]
 [  2   2]]
             precision    recall  f1-score   support

          0       0.99      0.79      0.88       372
          1       0.03      0.50      0.05         4

avg / total       0.98      0.79      0.87       376


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 50}, criterion='gini', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=1.0, n_estimators=50, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.585 	0.120 	0.029 	0.790 	0.762 	0.605
[[216 156]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.58      0.73       372
          1       0.03      1.00      0.05         4

avg / total       0.99      0.59      0.73       376


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.1, cache_size=200, class_weight='balanced', coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='linear',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.596 	0.123 	0.030 	0.796 	0.769 	0.616
[[220 152]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.59      0.74       372
          1       0.03      1.00      0.05         4

avg / total       0.99      0.60      0.74       376


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', R...wski',
           metric_params=None, n_jobs=4, n_neighbors=4, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.638 	0.135 	0.036 	0.817 	0.796 	0.658
[[236 136]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.63      0.78       372
          1       0.03      1.00      0.06         4

avg / total       0.99      0.64      0.77       376


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=5, p=1,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.588 	0.121 	0.029 	0.792 	0.764 	0.608
[[217 155]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.58      0.74       372
          1       0.03      1.00      0.05         4

avg / total       0.99      0.59      0.73       376


                estimator min_score  mean_score max_score  sd_score       acc  \
3    ExtraTreesClassifier -0.607122  -0.0983156    0.2566  0.137069  0.662234   
8        VotingClassifier -0.239411 -0.00139507  0.367711  0.107908  0.638298   
0              GaussianNB    0.2566      0.2566    0.2566         0   0.62234   
7                     SVC   -0.2566   0.0404083  0.496011  0.144077  0.595745   
9    KNeighborsClassifier -0.589933   -0.250819    0.1283  0.213689  0.587766   
4  RandomForestClassifier -0.205033    0.224952  0.683856   0.13546  0.585106   
6      AdaBoostClassifier -0.607122    0.186465  0.666667  0.246739  0.585106   
1      LogisticRegression -0.239411   0.0412582  0.402089  0.127986   0.75266   
5           MLPClassifier -0.239411  0.00272434  0.367711  0.144631  0.787234   
2           SGDClassifier -0.718234   0.0848353  0.607122  0.184621  0.444149   

        auc           conf_matrix     f1_c0      f1_c1       kappa  \
3  0.829301  [[245, 127], [0, 4]]  0.794165  0.0592593   0.0394271   
8  0.817204  [[236, 136], [0, 4]]  0.776316  0.0555556   0.0356065   
0   0.80914  [[230, 142], [0, 4]]   0.76412  0.0533333    0.033314   
7  0.795699  [[220, 152], [0, 4]]  0.743243       0.05   0.0298751   
9  0.791667  [[217, 155], [0, 4]]  0.736842  0.0490798   0.0289256   
4  0.790323  [[216, 156], [0, 4]]  0.734694  0.0487805   0.0286169   
6  0.790323  [[216, 156], [0, 4]]  0.734694  0.0487805   0.0286169   
1  0.751344   [[280, 92], [1, 3]]   0.85758  0.0606061   0.0410268   
5  0.645161   [[294, 78], [2, 2]]   0.88024   0.047619   0.0279214   
2  0.471774  [[165, 207], [2, 2]]  0.612245  0.0187793 -0.00214242   

  model_score   prec_c0     prec_c1    rec_c0 rec_c1  
3     0.14181         1   0.0305344  0.658602      1  
8    0.134633         1   0.0285714  0.634409      1  
0    0.130151         1   0.0273973   0.61828      1  
7    0.123142         1    0.025641  0.591398      1  
9    0.121141         1   0.0251572  0.583333      1  
4    0.120483         1       0.025  0.580645      1  
6    0.120483         1       0.025  0.580645      1  
1    0.118682  0.996441   0.0315789  0.752688   0.75  
5   0.0727765  0.993243       0.025  0.790323    0.5  
2  -0.0116559  0.988024  0.00956938  0.443548    0.5  
Elapsed time 14.70 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv 
datetime: 2017-05-09 21:30:42.843000 
pca_target: 0 	 poly degree: 0 	 kselect: 0 
Imbalance: None 
Extended target (count):  31485 325
('Total : Processed (count): ', (1252L, 22L), 13)
Final feature (count):  (1252L, 22L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.646 	0.137 	0.037 	0.821 	0.802 	0.665
[[239 133]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.64      0.78       372
          1       0.03      1.00      0.06         4

avg / total       0.99      0.65      0.77       376


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.001, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=10, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='sag', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.657 	0.140 	0.039 	0.827 	0.808 	0.676
[[243 129]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.65      0.79       372
          1       0.03      1.00      0.06         4

avg / total       0.99      0.66      0.78       376


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=1, average=False, class_weight={1: 15}, epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='modified_huber', n_iter=5, n_jobs=4,
       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.984 	-0.008 	-0.007 	0.497 	0.000 	0.000
[[370   2]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       372
          1       0.00      0.00      0.00         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 50}, criterion='gini',
           max_depth=8, max_features='auto', max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=50, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.984 	-0.008 	-0.007 	0.497 	0.000 	0.000
[[370   2]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       372
          1       0.00      0.00      0.00         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 500},
            criterion='gini', max_depth=8, max_features=0.75,
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.973 	-0.013 	-0.013 	0.492 	0.000 	0.000
[[366   6]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.98      0.99       372
          1       0.00      0.00      0.00         4

avg / total       0.98      0.97      0.98       376


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.5, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(500,), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       372
          1       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight='balanced', criterion='entropy',
            max_depth=8, max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=0.5, n_estimators=50, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	-0.005 	-0.004 	0.499 	0.000 	0.000
[[371   1]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       372
          1       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.1, cache_size=200, class_weight={1: 50}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.981 	-0.009 	-0.009 	0.496 	0.000 	0.000
[[369   3]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       372
          1       0.00      0.00      0.00         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=10.0, class_weight={1: 500}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Ra...owski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='uniform'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	-0.005 	-0.004 	0.499 	0.000 	0.000
[[371   1]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       372
          1       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=2,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	-0.005 	-0.004 	0.499 	0.000 	0.000
[[371   1]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       372
          1       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


                estimator   min_score   mean_score  max_score    sd_score  \
1      LogisticRegression  -0.0409212    0.0129211  0.0920602   0.0274284   
0              GaussianNB   0.0313831    0.0313831  0.0313831           0   
5           MLPClassifier  -0.0141536   -0.0067189          0  0.00383335   
6      AdaBoostClassifier  -0.0222787   0.00285864   0.140032   0.0282486   
8        VotingClassifier -0.00893216    0.0103851   0.138375   0.0375078   
9    KNeighborsClassifier  -0.0097168    0.0121731  0.0746927    0.029972   
2           SGDClassifier   -0.217941    0.0127566   0.136761   0.0304894   
3    ExtraTreesClassifier  -0.0320425   0.00121653  0.0960168   0.0137321   
7                     SVC  -0.0206833     0.019644  0.0976736   0.0245111   
4  RandomForestClassifier  -0.0116698 -0.000151291  0.0521382  0.00298704   

        acc       auc           conf_matrix     f1_c0      f1_c1       kappa  \
1  0.656915  0.826613  [[243, 129], [0, 4]]  0.790244  0.0583942   0.0385347   
0  0.646277  0.821237  [[239, 133], [0, 4]]  0.782324  0.0567376   0.0368259   
5  0.989362       0.5    [[372, 0], [4, 0]]  0.994652          0           0   
6  0.986702  0.498656    [[371, 1], [4, 0]]  0.993307          0  -0.0042735   
8  0.986702  0.498656    [[371, 1], [4, 0]]  0.993307          0  -0.0042735   
9  0.986702  0.498656    [[371, 1], [4, 0]]  0.993307          0  -0.0042735   
2  0.984043  0.497312    [[370, 2], [4, 0]]  0.991957          0 -0.00714286   
3  0.984043  0.497312    [[370, 2], [4, 0]]  0.991957          0 -0.00714286   
7  0.981383  0.495968    [[369, 3], [4, 0]]  0.990604          0 -0.00920245   
4  0.973404  0.491935    [[366, 6], [4, 0]]  0.986523          0   -0.012931   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
1    0.140164         1  0.0300752  0.653226      1  
0    0.136961         1  0.0291971  0.642473      1  
5           0  0.989362          0         1      0  
6  -0.0053548  0.989333          0  0.997312      0  
8  -0.0053548  0.989333          0  0.997312      0  
9  -0.0053548  0.989333          0  0.997312      0  
2 -0.00758294  0.989305          0  0.994624      0  
3 -0.00758294  0.989305          0  0.994624      0  
7 -0.00929961  0.989276          0  0.991935      0  
4  -0.0132048  0.989189          0  0.983871      0  
Elapsed time 23.82 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv 
datetime: 2017-05-09 21:54:31.955000 
pca_target: 0 	 poly degree: 0 	 kselect: 0 
Imbalance: SMOTE(k=None, k_neighbors=5, kind='regular', m=None, m_neighbors=10, n_jobs=1,
   out_step=0.5, random_state=None, ratio='auto', svm_estimator=None) 
Extended target (count):  31485 325
('Total : Processed (count): ', (1252L, 22L), 13)
Final feature (count):  (1252L, 22L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.668 	0.143 	0.040 	0.832 	0.815 	0.686
[[247 125]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.66      0.80       372
          1       0.03      1.00      0.06         4

avg / total       0.99      0.67      0.79       376


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=10, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.838 	0.027 	0.012 	0.547 	0.459 	0.198
[[314  58]
 [  3   1]]
             precision    recall  f1-score   support

          0       0.99      0.84      0.91       372
          1       0.02      0.25      0.03         4

avg / total       0.98      0.84      0.90       376


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.001, average=False, class_weight='balanced',
       epsilon=0.1, eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='modified_huber', n_iter=5, n_jobs=4,
       penalty='none', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.856 	0.034 	0.016 	0.556 	0.464 	0.203
[[321  51]
 [  3   1]]
             precision    recall  f1-score   support

          0       0.99      0.86      0.92       372
          1       0.02      0.25      0.04         4

avg / total       0.98      0.86      0.91       376


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=None, max_features=0.75, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=30, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.981 	-0.009 	-0.009 	0.496 	0.000 	0.000
[[369   3]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       372
          1       0.00      0.00      0.00         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight='balanced',
            criterion='gini', max_depth=32, max_features='auto',
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=15, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.984 	-0.008 	-0.007 	0.497 	0.000 	0.000
[[370   2]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       372
          1       0.00      0.00      0.00         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.981 	-0.009 	-0.009 	0.496 	0.000 	0.000
[[369   3]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       372
          1       0.00      0.00      0.00         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 500}, criterion='entropy',
            max_depth=16, max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=1.0, n_estimators=80, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.979 	-0.011 	-0.011 	0.495 	0.000 	0.000
[[368   4]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       372
          1       0.00      0.00      0.00         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=10, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.984 	-0.008 	-0.007 	0.497 	0.000 	0.000
[[370   2]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       372
          1       0.00      0.00      0.00         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=10.0, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', ...owski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='uniform'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.963 	-0.017 	-0.015 	0.487 	0.000 	0.000
[[362  10]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.97      0.98       372
          1       0.00      0.00      0.00         4

avg / total       0.98      0.96      0.97       376


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=2,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.952 	-0.020 	-0.017 	0.481 	0.000 	0.000
[[358  14]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.96      0.98       372
          1       0.00      0.00      0.00         4

avg / total       0.98      0.95      0.97       376


                estimator  min_score mean_score max_score    sd_score  \
0              GaussianNB   0.591955   0.591955  0.591955           0   
2           SGDClassifier   -0.13705   0.428849  0.846219    0.209731   
1      LogisticRegression  0.0643292   0.596396  0.822084    0.160852   
4  RandomForestClassifier   0.783805   0.928924  0.977041   0.0565994   
7                     SVC          0   0.725717  0.987477    0.234323   
3    ExtraTreesClassifier   0.617807   0.907271  0.993125    0.110298   
5           MLPClassifier   0.968232    0.98105  0.989707  0.00482056   
6      AdaBoostClassifier   0.821647   0.953625  0.989695   0.0268695   
8        VotingClassifier    0.85896   0.910852  0.945231   0.0198171   
9    KNeighborsClassifier   0.866542   0.902289  0.941971   0.0256416   

        acc       auc           conf_matrix     f1_c0      f1_c1       kappa  \
0  0.667553  0.831989  [[247, 125], [0, 4]]  0.798061  0.0601504   0.0403463   
2  0.856383  0.556452   [[321, 51], [3, 1]]  0.922414  0.0357143   0.0162791   
1  0.837766  0.547043   [[314, 58], [3, 1]]  0.911466   0.031746   0.0120606   
4  0.984043  0.497312    [[370, 2], [4, 0]]  0.991957          0 -0.00714286   
7  0.984043  0.497312    [[370, 2], [4, 0]]  0.991957          0 -0.00714286   
3  0.981383  0.495968    [[369, 3], [4, 0]]  0.990604          0 -0.00920245   
5  0.981383  0.495968    [[369, 3], [4, 0]]  0.990604          0 -0.00920245   
6  0.978723  0.494624    [[368, 4], [4, 0]]  0.989247          0  -0.0107527   
8  0.962766  0.486559   [[362, 10], [4, 0]]   0.98103          0  -0.0154321   
9  0.952128  0.481183   [[358, 14], [4, 0]]  0.975477          0  -0.0168269   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
0    0.143487         1  0.0310078  0.663978      1  
2   0.0335532  0.990741  0.0192308  0.862903   0.25  
1   0.0265382  0.990536  0.0169492  0.844086   0.25  
4 -0.00758294  0.989305          0  0.994624      0  
7 -0.00758294  0.989305          0  0.994624      0  
3 -0.00929961  0.989276          0  0.991935      0  
5 -0.00929961  0.989276          0  0.991935      0  
6  -0.0107527  0.989247          0  0.989247      0  
8  -0.0171403  0.989071          0  0.973118      0  
9  -0.0203924   0.98895          0  0.962366      0  
Elapsed time 41.91 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv 
datetime: 2017-05-09 22:36:26.436000 
pca_target: 0 	 poly degree: 0 	 kselect: 0 
Imbalance: ClusterCentroids(estimator=None, n_jobs=1, random_state=None, ratio='auto') 
Extended target (count):  31485 325
('Total : Processed (count): ', (1252L, 22L), 13)
Final feature (count):  (1252L, 22L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.625 	0.131 	0.034 	0.810 	0.788 	0.645
[[231 141]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.62      0.77       372
          1       0.03      1.00      0.05         4

avg / total       0.99      0.62      0.76       376


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.001, class_weight={1: 3}, dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.545 	0.111 	0.024 	0.770 	0.735 	0.565
[[201 171]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.54      0.70       372
          1       0.02      1.00      0.04         4

avg / total       0.99      0.55      0.69       376


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=1, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='constant', loss='squared_hinge', n_iter=5, n_jobs=4,
       penalty='l2', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.335 	-0.143 	-0.021 	0.169 	0.000 	0.000
[[126 246]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.97      0.34      0.50       372
          1       0.00      0.00      0.00         4

avg / total       0.96      0.34      0.50       376


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3},
           criterion='entropy', max_depth=8, max_features=0.75,
           max_leaf_nodes=None, min_impurity_split=1e-07,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=15, n_jobs=4,
           oob_score=False, random_state=None, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.620 	0.078 	0.020 	0.684 	0.681 	0.470
[[230 142]
 [  1   3]]
             precision    recall  f1-score   support

          0       1.00      0.62      0.76       372
          1       0.02      0.75      0.04         4

avg / total       0.99      0.62      0.76       376


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 15},
            criterion='entropy', max_depth=None, max_features=0.33,
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=15, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.646 	0.137 	0.037 	0.821 	0.802 	0.665
[[239 133]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.64      0.78       372
          1       0.03      1.00      0.06         4

avg / total       0.99      0.65      0.77       376


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.01, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.819 	-0.047 	-0.020 	0.414 	0.000 	0.000
[[308  64]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.83      0.90       372
          1       0.00      0.00      0.00         4

avg / total       0.98      0.82      0.89       376


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='entropy', max_depth=16,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=0.5, n_estimators=15, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.617 	0.025 	0.006 	0.559 	0.556 	0.305
[[230 142]
 [  2   2]]
             precision    recall  f1-score   support

          0       0.99      0.62      0.76       372
          1       0.01      0.50      0.03         4

avg / total       0.98      0.62      0.75       376


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=10, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=10, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.973 	-0.013 	-0.013 	0.492 	0.000 	0.000
[[366   6]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.98      0.99       372
          1       0.00      0.00      0.00         4

avg / total       0.98      0.97      0.98       376


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', R...owski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='uniform'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.699 	0.154 	0.046 	0.848 	0.834 	0.717
[[259 113]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.70      0.82       372
          1       0.03      1.00      0.07         4

avg / total       0.99      0.70      0.81       376


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=3, p=1,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.641 	0.135 	0.036 	0.819 	0.798 	0.660
[[237 135]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.64      0.78       372
          1       0.03      1.00      0.06         4

avg / total       0.99      0.64      0.77       376


                estimator min_score  mean_score  max_score  sd_score  \
8        VotingClassifier   -0.2566   0.0376965     0.3849  0.130466   
4  RandomForestClassifier -0.333333    0.135883   0.478822  0.135974   
9    KNeighborsClassifier -0.496011   -0.216762  0.0171889  0.113627   
0              GaussianNB         0           0          0         0   
1      LogisticRegression   -0.2566  0.00119637     0.2566  0.119457   
3    ExtraTreesClassifier -0.367711   0.0708871   0.461633  0.145171   
6      AdaBoostClassifier   -0.3849    0.208007   0.701045  0.187573   
7                     SVC   -0.2566   0.0008903     0.2566  0.091536   
5           MLPClassifier -0.273789  -0.0074311  0.0939222  0.103862   
2           SGDClassifier -0.718234   0.0438756     0.5132  0.173497   

        acc       auc           conf_matrix     f1_c0      f1_c1       kappa  \
8  0.699468  0.848118  [[259, 113], [0, 4]]  0.820919  0.0661157   0.0464991   
4  0.646277  0.821237  [[239, 133], [0, 4]]  0.782324  0.0567376   0.0368259   
9  0.640957  0.818548  [[237, 135], [0, 4]]  0.778325  0.0559441   0.0360073   
0     0.625  0.810484  [[231, 141], [0, 4]]  0.766169  0.0536913   0.0336833   
1  0.545213  0.770161  [[201, 171], [0, 4]]  0.701571  0.0446927   0.0243991   
3  0.619681   0.68414  [[230, 142], [1, 3]]  0.762852  0.0402685   0.0199767   
6  0.617021   0.55914  [[230, 142], [2, 2]]  0.761589   0.027027  0.00645919   
7  0.973404  0.491935    [[366, 6], [4, 0]]  0.986523          0   -0.012931   
5  0.819149  0.413978   [[308, 64], [4, 0]]  0.900585          0  -0.0204342   
2  0.335106  0.169355  [[126, 246], [4, 0]]  0.501992          0  -0.0213839   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
8    0.154282         1   0.034188  0.696237      1  
4    0.136961         1  0.0291971  0.642473      1  
9    0.135402         1   0.028777  0.637097      1  
0    0.130882         1  0.0275862  0.620968      1  
1    0.111132         1  0.0228571  0.540323      1  
3   0.0776228  0.995671  0.0206897   0.61828   0.75  
6   0.0249624  0.991379  0.0138889   0.61828    0.5  
7  -0.0132048  0.989189          0  0.983871      0  
5  -0.0469647  0.987179          0  0.827957      0  
2   -0.142644  0.969231          0   0.33871      0  
Elapsed time 14.70 mins 

************************************************************









Standard, lagged(3,4)x2, filter(tukey & hp), None, UNtruncated








    pca = [0]
    poly = [0]
    ksel = [20, 0]
    imb = [None, SMOTE(), ClusterCentroids() ]
	
	

	

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv 
datetime: 2017-05-10 08:48:44.891000 
pca_target: 0 	 poly degree: 0 	 kselect: 20 
Imbalance: None 
Extended target (count):  31485 325
('Total : Processed (count): ', (1252L, 22L), 13)
Final feature (count):  (1252L, 22L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.715 	0.160 	0.050 	0.856 	0.844 	0.733
[[265 107]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.71      0.83       372
          1       0.04      1.00      0.07         4

avg / total       0.99      0.72      0.82       376


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.001, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.606 	0.126 	0.031 	0.801 	0.776 	0.626
[[224 148]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.60      0.75       372
          1       0.03      1.00      0.05         4

avg / total       0.99      0.61      0.74       376


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.1, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.001, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='perceptron', n_iter=5, n_jobs=4,
       penalty='l2', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.968 	-0.015 	-0.014 	0.489 	0.000 	0.000
[[364   8]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.98      0.98       372
          1       0.00      0.00      0.00         4

avg / total       0.98      0.97      0.97       376


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 500},
           criterion='entropy', max_depth=8, max_features=0.33,
           max_leaf_nodes=None, min_impurity_split=1e-07,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=4,
           oob_score=False, random_state=None, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.963 	0.129 	0.111 	0.610 	0.493 	0.225
[[361  11]
 [  3   1]]
             precision    recall  f1-score   support

          0       0.99      0.97      0.98       372
          1       0.08      0.25      0.12         4

avg / total       0.98      0.96      0.97       376


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 500},
            criterion='gini', max_depth=8, max_features=0.75,
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.931 	-0.026 	-0.018 	0.470 	0.000 	0.000
[[350  22]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.94      0.96       372
          1       0.00      0.00      0.00         4

avg / total       0.98      0.93      0.95       376


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.979 	-0.011 	-0.011 	0.495 	0.000 	0.000
[[368   4]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       372
          1       0.00      0.00      0.00         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=32,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=2.0, n_estimators=80, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.981 	-0.009 	-0.009 	0.496 	0.000 	0.000
[[369   3]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       372
          1       0.00      0.00      0.00         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.01, cache_size=200, class_weight={1: 500}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.418 	0.086 	0.015 	0.706 	0.641 	0.436
[[153 219]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.41      0.58       372
          1       0.02      1.00      0.04         4

avg / total       0.99      0.42      0.58       376


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       372
          1       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=1,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       372
          1       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


                estimator   min_score   mean_score  max_score    sd_score  \
0              GaussianNB   0.0571666    0.0571666  0.0571666           0   
1      LogisticRegression  -0.0636428   0.00234456   0.091449   0.0324389   
7                     SVC  -0.0459083  -0.00349398  0.0569453    0.020666   
3    ExtraTreesClassifier  -0.0301812  -0.00120186  0.0611636  0.00602499   
8        VotingClassifier -0.00393786 -0.000589239          0  0.00103248   
9    KNeighborsClassifier -0.00787573  -0.00159576          0  0.00258019   
6      AdaBoostClassifier  -0.0170288    0.0188253   0.169592   0.0470718   
5           MLPClassifier  -0.0107193 -0.000820993  0.0613364   0.0145254   
2           SGDClassifier   -0.192548    0.0079506    0.19863   0.0332843   
4  RandomForestClassifier  -0.0088813  0.000526789   0.129788  0.00788525   

        acc       auc           conf_matrix     f1_c0      f1_c1       kappa  \
0  0.715426  0.856183  [[265, 107], [0, 4]]  0.832025  0.0695652   0.0500567   
1  0.606383  0.801075  [[224, 148], [0, 4]]  0.751678  0.0512821   0.0311978   
7  0.417553  0.705645  [[153, 219], [0, 4]]  0.582857  0.0352423   0.0146468   
3  0.962766  0.610215   [[361, 11], [3, 1]]  0.980978      0.125    0.110811   
8  0.989362       0.5    [[372, 0], [4, 0]]  0.994652          0           0   
9  0.989362       0.5    [[372, 0], [4, 0]]  0.994652          0           0   
6  0.981383  0.495968    [[369, 3], [4, 0]]  0.990604          0 -0.00920245   
5  0.978723  0.494624    [[368, 4], [4, 0]]  0.989247          0  -0.0107527   
2  0.968085  0.489247    [[364, 8], [4, 0]]  0.983784          0  -0.0143885   
4  0.930851   0.47043   [[350, 22], [4, 0]]  0.964187          0  -0.0183333   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
0    0.160221         1   0.036036  0.712366      1  
1    0.125881         1  0.0263158  0.602151      1  
7   0.0858918         1  0.0179372   0.41129      1  
3    0.128656  0.991758  0.0833333   0.97043   0.25  
8           0  0.989362          0         1      0  
9           0  0.989362          0         1      0  
6 -0.00929961  0.989276          0  0.991935      0  
5  -0.0107527  0.989247          0  0.989247      0  
2   -0.015289   0.98913          0  0.978495      0  
4  -0.0258505  0.988701          0   0.94086      0  
Elapsed time 22.95 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv 
datetime: 2017-05-10 09:11:42.124000 
pca_target: 0 	 poly degree: 0 	 kselect: 20 
Imbalance: SMOTE(k=None, k_neighbors=5, kind='regular', m=None, m_neighbors=10, n_jobs=1,
   out_step=0.5, random_state=None, ratio='auto', svm_estimator=None) 
Extended target (count):  31485 325
('Total : Processed (count): ', (1252L, 22L), 13)
Final feature (count):  (1252L, 22L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.649 	0.138 	0.037 	0.823 	0.803 	0.668
[[240 132]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.65      0.78       372
          1       0.03      1.00      0.06         4

avg / total       0.99      0.65      0.78       376


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=10, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.769 	0.066 	0.024 	0.636 	0.621 	0.375
[[287  85]
 [  2   2]]
             precision    recall  f1-score   support

          0       0.99      0.77      0.87       372
          1       0.02      0.50      0.04         4

avg / total       0.98      0.77      0.86       376


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.001, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.001, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='modified_huber', n_iter=5, n_jobs=4,
       penalty='none', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.787 	0.073 	0.028 	0.645 	0.629 	0.384
[[294  78]
 [  2   2]]
             precision    recall  f1-score   support

          0       0.99      0.79      0.88       372
          1       0.03      0.50      0.05         4

avg / total       0.98      0.79      0.87       376


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 500},
           criterion='entropy', max_depth=None, max_features=0.75,
           max_leaf_nodes=None, min_impurity_split=1e-07,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=4,
           oob_score=False, random_state=None, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.984 	0.401 	0.392 	0.745 	0.703 	0.470
[[368   4]
 [  2   2]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       372
          1       0.33      0.50      0.40         4

avg / total       0.99      0.98      0.99       376


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 15},
            criterion='entropy', max_depth=None, max_features='auto',
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.947 	-0.022 	-0.017 	0.478 	0.000 	0.000
[[356  16]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.96      0.97       372
          1       0.00      0.00      0.00         4

avg / total       0.98      0.95      0.96       376


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.1, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.963 	0.129 	0.111 	0.610 	0.493 	0.225
[[361  11]
 [  3   1]]
             precision    recall  f1-score   support

          0       0.99      0.97      0.98       372
          1       0.08      0.25      0.12         4

avg / total       0.98      0.96      0.97       376


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 500}, criterion='entropy',
            max_depth=8, max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=1.0, n_estimators=80, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.965 	0.264 	0.223 	0.735 	0.697 	0.462
[[361  11]
 [  2   2]]
             precision    recall  f1-score   support

          0       0.99      0.97      0.98       372
          1       0.15      0.50      0.24         4

avg / total       0.99      0.97      0.97       376


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.973 	0.164 	0.155 	0.616 	0.495 	0.227
[[365   7]
 [  3   1]]
             precision    recall  f1-score   support

          0       0.99      0.98      0.99       372
          1       0.12      0.25      0.17         4

avg / total       0.98      0.97      0.98       376


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=1.0, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', R...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.947 	0.206 	0.152 	0.726 	0.690 	0.454
[[354  18]
 [  2   2]]
             precision    recall  f1-score   support

          0       0.99      0.95      0.97       372
          1       0.10      0.50      0.17         4

avg / total       0.98      0.95      0.96       376


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.939 	0.190 	0.132 	0.722 	0.687 	0.451
[[351  21]
 [  2   2]]
             precision    recall  f1-score   support

          0       0.99      0.94      0.97       372
          1       0.09      0.50      0.15         4

avg / total       0.98      0.94      0.96       376


                estimator  min_score mean_score max_score   sd_score  \
0              GaussianNB   0.559094   0.559094  0.559094          0   
3    ExtraTreesClassifier   0.592899   0.898926  0.981744   0.109683   
6      AdaBoostClassifier   0.789232   0.925105  0.978238  0.0371323   
8        VotingClassifier   0.842764   0.887984  0.924878   0.021284   
9    KNeighborsClassifier   0.857257   0.892181  0.929347  0.0223807   
2           SGDClassifier -0.0689651   0.414776  0.756066   0.202329   
1      LogisticRegression          0   0.551883  0.749557   0.182932   
7                     SVC          0   0.691459  0.978321   0.236922   
5           MLPClassifier   0.940546   0.970695   0.98514  0.0100344   
4  RandomForestClassifier   0.732268   0.902884  0.962395  0.0713267   

        acc       auc           conf_matrix     f1_c0      f1_c1      kappa  \
0  0.648936  0.822581  [[240, 132], [0, 4]]  0.784314  0.0571429  0.0372439   
3  0.984043  0.744624    [[368, 4], [2, 2]]  0.991914        0.4   0.392241   
6  0.965426  0.735215   [[361, 11], [2, 2]]  0.982313   0.235294   0.222646   
8  0.946809  0.725806   [[354, 18], [2, 2]]  0.972527   0.166667   0.151625   
9   0.93883  0.721774   [[351, 21], [2, 2]]  0.968276   0.148148   0.132424   
2  0.787234  0.645161   [[294, 78], [2, 2]]   0.88024   0.047619  0.0279214   
1  0.768617  0.635753   [[287, 85], [2, 2]]  0.868381   0.043956   0.024105   
7  0.973404  0.615591    [[365, 7], [3, 1]]  0.986486   0.166667   0.154676   
5  0.962766  0.610215   [[361, 11], [3, 1]]  0.980978      0.125   0.110811   
4  0.946809  0.478495   [[356, 16], [4, 0]]  0.972678          0  -0.017316   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
0    0.137751         1  0.0294118  0.645161      1  
3    0.400547  0.994595   0.333333  0.989247    0.5  
6    0.264163   0.99449   0.153846   0.97043    0.5  
8    0.206456  0.994382        0.1  0.951613    0.5  
9    0.189885  0.994334  0.0869565  0.943548    0.5  
2   0.0727765  0.993243      0.025  0.790323    0.5  
1   0.0660498   0.99308  0.0229885  0.771505    0.5  
7    0.164357  0.991848      0.125  0.981183   0.25  
5    0.128656  0.991758  0.0833333   0.97043   0.25  
4  -0.0218609  0.988889          0  0.956989      0  
Elapsed time 43.83 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv 
datetime: 2017-05-10 09:55:31.810000 
pca_target: 0 	 poly degree: 0 	 kselect: 20 
Imbalance: ClusterCentroids(estimator=None, n_jobs=1, random_state=None, ratio='auto') 
Extended target (count):  31485 325
('Total : Processed (count): ', (1252L, 22L), 13)
Final feature (count):  (1252L, 22L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.601 	0.125 	0.031 	0.798 	0.773 	0.621
[[222 150]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.60      0.75       372
          1       0.03      1.00      0.05         4

avg / total       0.99      0.60      0.74       376


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.001, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=10, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.596 	0.123 	0.030 	0.796 	0.769 	0.616
[[220 152]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.59      0.74       372
          1       0.03      1.00      0.05         4

avg / total       0.99      0.60      0.74       376


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.0001, average=False, class_weight={1: 15}, epsilon=0.1,
       eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='constant', loss='perceptron', n_iter=5, n_jobs=4,
       penalty='l1', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.545 	0.111 	0.024 	0.770 	0.735 	0.565
[[201 171]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.54      0.70       372
          1       0.02      1.00      0.04         4

avg / total       0.99      0.55      0.69       376


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3},
           criterion='entropy', max_depth=32, max_features='auto',
           max_leaf_nodes=None, min_impurity_split=1e-07,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=4,
           oob_score=False, random_state=None, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.769 	0.066 	0.024 	0.636 	0.621 	0.375
[[287  85]
 [  2   2]]
             precision    recall  f1-score   support

          0       0.99      0.77      0.87       372
          1       0.02      0.50      0.04         4

avg / total       0.98      0.77      0.86       376


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight='balanced',
            criterion='gini', max_depth=None, max_features=0.75,
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=15, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.779 	0.070 	0.026 	0.641 	0.625 	0.380
[[291  81]
 [  2   2]]
             precision    recall  f1-score   support

          0       0.99      0.78      0.88       372
          1       0.02      0.50      0.05         4

avg / total       0.98      0.78      0.87       376


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.707 	0.047 	0.015 	0.605 	0.596 	0.347
[[264 108]
 [  2   2]]
             precision    recall  f1-score   support

          0       0.99      0.71      0.83       372
          1       0.02      0.50      0.04         4

avg / total       0.98      0.71      0.82       376


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight='balanced', criterion='gini', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=1.0, n_estimators=50, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.662 	0.089 	0.025 	0.706 	0.704 	0.500
[[246 126]
 [  1   3]]
             precision    recall  f1-score   support

          0       1.00      0.66      0.79       372
          1       0.02      0.75      0.05         4

avg / total       0.99      0.66      0.79       376


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.574 	0.118 	0.027 	0.785 	0.755 	0.594
[[212 160]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.57      0.73       372
          1       0.02      1.00      0.05         4

avg / total       0.99      0.57      0.72       376


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...wski',
           metric_params=None, n_jobs=4, n_neighbors=4, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.580 	0.119 	0.028 	0.788 	0.758 	0.600
[[214 158]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.58      0.73       372
          1       0.02      1.00      0.05         4

avg / total       0.99      0.58      0.72       376


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=5, p=1,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.689 	0.097 	0.029 	0.719 	0.718 	0.519
[[256 116]
 [  1   3]]
             precision    recall  f1-score   support

          0       1.00      0.69      0.81       372
          1       0.03      0.75      0.05         4

avg / total       0.99      0.69      0.81       376


                estimator min_score mean_score max_score  sd_score       acc  \
0              GaussianNB  0.145489   0.145489  0.145489         0  0.601064   
1      LogisticRegression -0.718234  -0.141935  0.478822  0.323689  0.595745   
8        VotingClassifier -0.555556 -0.0935814    0.3849  0.231743  0.579787   
7                     SVC -0.718234  -0.200963    0.1283  0.226255  0.574468   
2           SGDClassifier   -0.5132   0.216817  0.624311   0.18505  0.545213   
9    KNeighborsClassifier   -0.2566   0.111546    0.3849  0.183494   0.68883   
6      AdaBoostClassifier -0.718234 -0.0809695  0.572745  0.212555  0.662234   
4  RandomForestClassifier -0.624311  -0.293662    0.2566  0.157919  0.779255   
3    ExtraTreesClassifier   -0.3849 -0.0613314  0.367711  0.143803  0.768617   
5           MLPClassifier -0.718234  -0.507227   -0.2566  0.104013  0.707447   

        auc           conf_matrix     f1_c0      f1_c1      kappa model_score  \
0  0.798387  [[222, 150], [0, 4]]  0.747475  0.0506329  0.0305281    0.124502   
1  0.795699  [[220, 152], [0, 4]]  0.743243       0.05  0.0298751    0.123142   
8  0.787634  [[214, 158], [0, 4]]  0.730375  0.0481928  0.0280105    0.119181   
7  0.784946  [[212, 160], [0, 4]]  0.726027   0.047619  0.0274185    0.117897   
2  0.770161  [[201, 171], [0, 4]]  0.701571  0.0446927  0.0243991    0.111132   
9  0.719086  [[256, 116], [1, 3]]   0.81399  0.0487805  0.0287884   0.0966509   
6  0.705645  [[246, 126], [1, 3]]   0.79483  0.0451128  0.0249918   0.0888805   
4  0.641129   [[291, 81], [2, 2]]  0.875188   0.045977  0.0262107   0.0698192   
3  0.635753   [[287, 85], [2, 2]]  0.868381   0.043956   0.024105   0.0660498   
5  0.604839  [[264, 108], [2, 2]]  0.827586  0.0350877  0.0148628   0.0472842   

    prec_c0    prec_c1    rec_c0 rec_c1  
0         1   0.025974  0.596774      1  
1         1   0.025641  0.591398      1  
8         1  0.0246914  0.575269      1  
7         1  0.0243902  0.569892      1  
2         1  0.0228571  0.540323      1  
9  0.996109  0.0252101  0.688172   0.75  
6  0.995951  0.0232558   0.66129   0.75  
4  0.993174  0.0240964  0.782258    0.5  
3   0.99308  0.0229885  0.771505    0.5  
5  0.992481  0.0181818  0.709677    0.5  
Elapsed time 14.82 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv 
datetime: 2017-05-10 10:10:21.272000 
pca_target: 0 	 poly degree: 0 	 kselect: 0 
Imbalance: None 
Extended target (count):  31485 325
('Total : Processed (count): ', (1252L, 22L), 13)
Final feature (count):  (1252L, 22L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.702 	0.155 	0.047 	0.849 	0.836 	0.720
[[260 112]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.70      0.82       372
          1       0.03      1.00      0.07         4

avg / total       0.99      0.70      0.81       376


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.001, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.617 	0.129 	0.033 	0.806 	0.783 	0.637
[[228 144]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.61      0.76       372
          1       0.03      1.00      0.05         4

avg / total       0.99      0.62      0.75       376


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.1, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='modified_huber', n_iter=5, n_jobs=4,
       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       372
          1       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 500},
           criterion='entropy', max_depth=8, max_features='auto',
           max_leaf_nodes=None, min_impurity_split=1e-07,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=15, n_jobs=4,
           oob_score=False, random_state=None, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.918 	0.324 	0.190 	0.958 	0.957 	0.924
[[341  31]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.92      0.96       372
          1       0.11      1.00      0.21         4

avg / total       0.99      0.92      0.95       376


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 500},
            criterion='gini', max_depth=8, max_features=0.33,
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=15, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.965 	-0.016 	-0.015 	0.488 	0.000 	0.000
[[363   9]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.98      0.98       372
          1       0.00      0.00      0.00         4

avg / total       0.98      0.97      0.97       376


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.5, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(500,), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       372
          1       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 50}, criterion='entropy', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=2.0, n_estimators=50, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	-0.005 	-0.004 	0.499 	0.000 	0.000
[[371   1]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       372
          1       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.01, cache_size=200, class_weight={1: 500}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.447 	0.091 	0.016 	0.720 	0.664 	0.466
[[164 208]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.44      0.61       372
          1       0.02      1.00      0.04         4

avg / total       0.99      0.45      0.61       376


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       372
          1       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=1,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       372
          1       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


                estimator   min_score   mean_score   max_score    sd_score  \
3    ExtraTreesClassifier  -0.0353712   -0.0019077   0.0187578   0.0048662   
0              GaussianNB   0.0530572    0.0530572   0.0530572           0   
1      LogisticRegression  -0.0957196  -0.00441034    0.091405   0.0362555   
7                     SVC   -0.054618   -0.0133936   0.0664679   0.0256943   
2           SGDClassifier   -0.140046   0.00843685    0.197002   0.0336487   
5           MLPClassifier  -0.0146338  -0.00666899 -0.00114815  0.00327381   
8        VotingClassifier -0.00488501 -0.000669747           0  0.00105733   
9    KNeighborsClassifier   -0.004619 -0.000882688           0  0.00163044   
6      AdaBoostClassifier  -0.0184849 -0.000792386    0.146573   0.0224195   
4  RandomForestClassifier   -0.013808  5.29726e-05   0.0748162   0.0046826   

        acc       auc           conf_matrix     f1_c0      f1_c1      kappa  \
3  0.917553  0.958333   [[341, 31], [0, 4]]  0.956522   0.205128   0.189655   
0  0.702128  0.849462  [[260, 112], [0, 4]]  0.822785  0.0666667  0.0470673   
1  0.617021  0.806452  [[228, 144], [0, 4]]      0.76  0.0526316  0.0325901   
7  0.446809   0.72043  [[164, 208], [0, 4]]   0.61194   0.037037   0.016499   
2  0.989362       0.5    [[372, 0], [4, 0]]  0.994652          0          0   
5  0.989362       0.5    [[372, 0], [4, 0]]  0.994652          0          0   
8  0.989362       0.5    [[372, 0], [4, 0]]  0.994652          0          0   
9  0.989362       0.5    [[372, 0], [4, 0]]  0.994652          0          0   
6  0.986702  0.498656    [[371, 1], [4, 0]]  0.993307          0 -0.0042735   
4  0.965426  0.487903    [[363, 9], [4, 0]]  0.982409          0 -0.0149502   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
3    0.323669         1   0.114286  0.916667      1  
0    0.155244         1  0.0344828  0.698925      1  
1    0.128705         1   0.027027  0.612903      1  
7   0.0912037         1  0.0188679   0.44086      1  
2           0  0.989362          0         1      0  
5           0  0.989362          0         1      0  
8           0  0.989362          0         1      0  
9           0  0.989362          0         1      0  
6  -0.0053548  0.989333          0  0.997312      0  
4  -0.0162385  0.989101          0  0.975806      0  
Elapsed time 22.90 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv 
datetime: 2017-05-10 10:33:15.487000 
pca_target: 0 	 poly degree: 0 	 kselect: 0 
Imbalance: SMOTE(k=None, k_neighbors=5, kind='regular', m=None, m_neighbors=10, n_jobs=1,
   out_step=0.5, random_state=None, ratio='auto', svm_estimator=None) 
Extended target (count):  31485 325
('Total : Processed (count): ', (1252L, 22L), 13)
Final feature (count):  (1252L, 22L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.638 	0.135 	0.036 	0.817 	0.796 	0.658
[[236 136]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.63      0.78       372
          1       0.03      1.00      0.06         4

avg / total       0.99      0.64      0.77       376


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=10, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='sag', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.777 	0.129 	0.047 	0.763 	0.763 	0.581
[[289  83]
 [  1   3]]
             precision    recall  f1-score   support

          0       1.00      0.78      0.87       372
          1       0.03      0.75      0.07         4

avg / total       0.99      0.78      0.86       376


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.001, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='squared_hinge', n_iter=5, n_jobs=4,
       penalty='none', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.814 	0.084 	0.035 	0.659 	0.639 	0.396
[[304  68]
 [  2   2]]
             precision    recall  f1-score   support

          0       0.99      0.82      0.90       372
          1       0.03      0.50      0.05         4

avg / total       0.98      0.81      0.89       376


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 50}, criterion='gini',
           max_depth=None, max_features=0.75, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=50, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.981 	-0.009 	-0.009 	0.496 	0.000 	0.000
[[369   3]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       372
          1       0.00      0.00      0.00         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight='balanced',
            criterion='entropy', max_depth=32, max_features='auto',
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.963 	-0.017 	-0.015 	0.487 	0.000 	0.000
[[362  10]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.97      0.98       372
          1       0.00      0.00      0.00         4

avg / total       0.98      0.96      0.97       376


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.01, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(500,), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.981 	0.214 	0.213 	0.620 	0.497 	0.229
[[368   4]
 [  3   1]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       372
          1       0.20      0.25      0.22         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight='balanced', criterion='entropy',
            max_depth=8, max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=1.0, n_estimators=50, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.973 	0.305 	0.275 	0.739 	0.699 	0.466
[[364   8]
 [  2   2]]
             precision    recall  f1-score   support

          0       0.99      0.98      0.99       372
          1       0.20      0.50      0.29         4

avg / total       0.99      0.97      0.98       376


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=10, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.979 	0.194 	0.190 	0.618 	0.497 	0.228
[[367   5]
 [  3   1]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       372
          1       0.17      0.25      0.20         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=1.0, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', R...owski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='uniform'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.915 	0.154 	0.094 	0.710 	0.678 	0.440
[[342  30]
 [  2   2]]
             precision    recall  f1-score   support

          0       0.99      0.92      0.96       372
          1       0.06      0.50      0.11         4

avg / total       0.98      0.91      0.95       376


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.934 	0.082 	0.057 	0.595 	0.485 	0.219
[[350  22]
 [  3   1]]
             precision    recall  f1-score   support

          0       0.99      0.94      0.97       372
          1       0.04      0.25      0.07         4

avg / total       0.98      0.93      0.96       376


                estimator min_score mean_score max_score   sd_score       acc  \
0              GaussianNB  0.554554   0.554554  0.554554          0  0.638298   
1      LogisticRegression         0   0.590029  0.796178   0.182457  0.776596   
6      AdaBoostClassifier  0.700782   0.924473  0.976109  0.0386818  0.973404   
8        VotingClassifier  0.833965   0.881029  0.916771  0.0206077  0.914894   
2           SGDClassifier -0.170748   0.437856  0.813145   0.217578   0.81383   
5           MLPClassifier   0.94385   0.973367  0.985177  0.0077733  0.981383   
7                     SVC         0   0.707682  0.984002   0.237941  0.978723   
9    KNeighborsClassifier  0.836484   0.881159  0.927614  0.0275264  0.933511   
3    ExtraTreesClassifier  0.596463   0.893324  0.978218   0.104403  0.981383   
4  RandomForestClassifier    0.7507   0.891895   0.95883  0.0673222  0.962766   

        auc           conf_matrix     f1_c0      f1_c1       kappa  \
0  0.817204  [[236, 136], [0, 4]]  0.776316  0.0555556   0.0356065   
1  0.763441   [[289, 83], [1, 3]]  0.873112  0.0666667   0.0472973   
6  0.739247    [[364, 8], [2, 2]]   0.98645   0.285714    0.274691   
8  0.709677   [[342, 30], [2, 2]]  0.955307   0.111111   0.0939759   
2  0.658602   [[304, 68], [2, 2]]  0.896755  0.0540541   0.0346244   
5  0.619624    [[368, 4], [3, 1]]  0.990579   0.222222    0.212919   
7   0.61828    [[367, 5], [3, 1]]  0.989218        0.2    0.189655   
9   0.59543   [[350, 22], [3, 1]]  0.965517  0.0740741   0.0569823   
3  0.495968    [[369, 3], [4, 0]]  0.990604          0 -0.00920245   
4  0.486559   [[362, 10], [4, 0]]   0.98103          0  -0.0154321   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
0    0.134633         1  0.0285714  0.634409      1  
1    0.128696  0.996552  0.0348837  0.776882   0.75  
6    0.305097  0.994536        0.2  0.978495    0.5  
8     0.15418  0.994186     0.0625  0.919355    0.5  
2   0.0836047  0.993464  0.0285714  0.817204    0.5  
5    0.214278  0.991914        0.2  0.989247   0.25  
7    0.193671  0.991892   0.166667  0.986559   0.25  
9   0.0817082  0.991501  0.0434783   0.94086   0.25  
3 -0.00929961  0.989276          0  0.991935      0  
4  -0.0171403  0.989071          0  0.973118      0  
Elapsed time 45.22 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv 
datetime: 2017-05-10 11:18:28.715000 
pca_target: 0 	 poly degree: 0 	 kselect: 0 
Imbalance: ClusterCentroids(estimator=None, n_jobs=1, random_state=None, ratio='auto') 
Extended target (count):  31485 325
('Total : Processed (count): ', (1252L, 22L), 13)
Final feature (count):  (1252L, 22L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.604 	0.125 	0.031 	0.800 	0.774 	0.623
[[223 149]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.60      0.75       372
          1       0.03      1.00      0.05         4

avg / total       0.99      0.60      0.74       376


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.001, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=0.01, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='sag', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.697 	0.153 	0.046 	0.847 	0.833 	0.715
[[258 114]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.69      0.82       372
          1       0.03      1.00      0.07         4

avg / total       0.99      0.70      0.81       376


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.1, average=False, class_weight='balanced', epsilon=0.1,
       eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='constant', loss='modified_huber', n_iter=5, n_jobs=4,
       penalty='none', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.620 	0.129 	0.033 	0.808 	0.785 	0.639
[[229 143]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.62      0.76       372
          1       0.03      1.00      0.05         4

avg / total       0.99      0.62      0.75       376


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3},
           criterion='entropy', max_depth=8, max_features='auto',
           max_leaf_nodes=None, min_impurity_split=1e-07,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=15, n_jobs=4,
           oob_score=False, random_state=None, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.697 	0.044 	0.014 	0.599 	0.591 	0.343
[[260 112]
 [  2   2]]
             precision    recall  f1-score   support

          0       0.99      0.70      0.82       372
          1       0.02      0.50      0.03         4

avg / total       0.98      0.70      0.81       376


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight='balanced',
            criterion='entropy', max_depth=16, max_features=0.75,
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=15, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.686 	0.042 	0.012 	0.594 	0.587 	0.338
[[256 116]
 [  2   2]]
             precision    recall  f1-score   support

          0       0.99      0.69      0.81       372
          1       0.02      0.50      0.03         4

avg / total       0.98      0.69      0.80       376


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.790 	0.074 	0.029 	0.647 	0.630 	0.385
[[295  77]
 [  2   2]]
             precision    recall  f1-score   support

          0       0.99      0.79      0.88       372
          1       0.03      0.50      0.05         4

avg / total       0.98      0.79      0.87       376


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight='balanced', criterion='entropy',
            max_depth=8, max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=0.5, n_estimators=80, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.657 	0.034 	0.010 	0.579 	0.574 	0.324
[[245 127]
 [  2   2]]
             precision    recall  f1-score   support

          0       0.99      0.66      0.79       372
          1       0.02      0.50      0.03         4

avg / total       0.98      0.66      0.78       376


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.548 	0.112 	0.025 	0.772 	0.737 	0.568
[[202 170]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.54      0.70       372
          1       0.02      1.00      0.04         4

avg / total       0.99      0.55      0.70       376


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...wski',
           metric_params=None, n_jobs=4, n_neighbors=4, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.580 	0.119 	0.028 	0.788 	0.758 	0.600
[[214 158]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.58      0.73       372
          1       0.02      1.00      0.05         4

avg / total       0.99      0.58      0.72       376


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=5, p=2,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.686 	0.096 	0.028 	0.718 	0.717 	0.517
[[255 117]
 [  1   3]]
             precision    recall  f1-score   support

          0       1.00      0.69      0.81       372
          1       0.03      0.75      0.05         4

avg / total       0.99      0.69      0.80       376


                estimator min_score  mean_score max_score  sd_score       acc  \
1      LogisticRegression -0.461633   -0.050448  0.496011  0.226302  0.696809   
2           SGDClassifier -0.589933    0.082821  0.496011  0.179047  0.619681   
0              GaussianNB    0.1283      0.1283    0.1283         0  0.603723   
8        VotingClassifier -0.367711    0.112212  0.478822   0.16009  0.579787   
7                     SVC   -0.3849  -0.0751537  0.367711  0.167554  0.547872   
9    KNeighborsClassifier   -0.2566  0.00537155  0.367711  0.169423   0.68617   
5           MLPClassifier -0.589933   -0.327374 -0.111111  0.140131  0.789894   
3    ExtraTreesClassifier -0.718234   -0.333263  0.145489  0.140867  0.696809   
4  RandomForestClassifier -0.496011   -0.203648    0.3849  0.146486   0.68617   
6      AdaBoostClassifier -0.718234   -0.135521    0.3849  0.181605  0.656915   

        auc           conf_matrix     f1_c0      f1_c1       kappa  \
1  0.846774  [[258, 114], [0, 4]]  0.819048  0.0655738   0.0459402   
2  0.807796  [[229, 143], [0, 4]]  0.762063  0.0529801   0.0329496   
0  0.799731  [[223, 149], [0, 4]]   0.74958  0.0509554   0.0308608   
8  0.787634  [[214, 158], [0, 4]]  0.730375  0.0481928   0.0280105   
7  0.771505  [[202, 170], [0, 4]]  0.703833  0.0449438   0.0246582   
9  0.717742  [[255, 117], [1, 3]]  0.812102  0.0483871   0.0283812   
5  0.646505   [[295, 77], [2, 2]]  0.881913  0.0481928   0.0285191   
3  0.599462  [[260, 112], [2, 2]]  0.820189  0.0338983    0.013623   
4  0.594086  [[256, 116], [2, 2]]  0.812698  0.0327869   0.0124644   
6  0.579301  [[245, 127], [2, 2]]  0.791599  0.0300752  0.00963737   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
1     0.15333         1  0.0338983  0.693548      1  
2    0.129425         1  0.0272109  0.615591      1  
0    0.125189         1  0.0261438  0.599462      1  
8    0.119181         1  0.0246914  0.575269      1  
7    0.111727         1  0.0229885  0.543011      1  
9   0.0958436  0.996094      0.025  0.685484   0.75  
5   0.0737893  0.993266  0.0253165  0.793011    0.5  
3   0.0444004  0.992366  0.0175439  0.698925    0.5  
4   0.0416012  0.992248  0.0169492  0.688172    0.5  
6   0.0342742  0.991903  0.0155039  0.658602    0.5  
Elapsed time 14.68 mins 

************************************************************










Standard, lagged(3,4)x2, filter(tukey), None, truncated








    pca = [0]
    poly = [0]
    ksel = [20, 0]
    imb = [None, SMOTE(), ClusterCentroids() ]

	
	
	
pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv 
datetime: 2017-05-10 18:52:01.718000 
pca_target: 0 	 poly degree: 0 	 kselect: 20 
Imbalance: None 
Extended target (count):  25141 325
('Total : Processed (count): ', (998L, 22L), 13)
Final feature (count):  (998L, 22L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.597 	0.138 	0.037 	0.796 	0.769 	0.615
[[175 121]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.59      0.74       296
          1       0.03      1.00      0.06         4

avg / total       0.99      0.60      0.73       300


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.1, class_weight={1: 500}, dual=False,
          fit_intercept=True, intercept_scaling=10, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='sag', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.433 	0.099 	0.019 	0.713 	0.652 	0.450
[[126 170]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.43      0.60       296
          1       0.02      1.00      0.04         4

avg / total       0.99      0.43      0.59       300


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.5, average=False, class_weight='balanced', epsilon=0.1,
       eta0=0.001, fit_intercept=True, l1_ratio=0.15,
       learning_rate='constant', loss='perceptron', n_iter=5, n_jobs=4,
       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.190 	0.054 	0.006 	0.590 	0.423 	0.194
[[ 53 243]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.18      0.30       296
          1       0.02      1.00      0.03         4

avg / total       0.99      0.19      0.30       300


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 500}, criterion='gini',
           max_depth=16, max_features='auto', max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.967 	-0.017 	-0.016 	0.490 	0.000 	0.000
[[290   6]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.98      0.98       296
          1       0.00      0.00      0.00         4

avg / total       0.97      0.97      0.97       300


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	0.000 	0.000 	0.500 	0.000 	0.000
[[296   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       296
          1       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       300


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.5, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(500,), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	0.000 	0.000 	0.500 	0.000 	0.000
[[296   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       296
          1       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       300


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=2.0, n_estimators=50, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.973 	-0.014 	-0.014 	0.493 	0.000 	0.000
[[292   4]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       296
          1       0.00      0.00      0.00         4

avg / total       0.97      0.97      0.97       300


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.627 	0.089 	0.026 	0.688 	0.685 	0.475
[[185 111]
 [  1   3]]
             precision    recall  f1-score   support

          0       0.99      0.62      0.77       296
          1       0.03      0.75      0.05         4

avg / total       0.98      0.63      0.76       300


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	0.000 	0.000 	0.500 	0.000 	0.000
[[296   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       296
          1       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       300


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=1,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	0.000 	0.000 	0.500 	0.000 	0.000
[[296   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       296
          1       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       300


                estimator  min_score  mean_score  max_score    sd_score  \
0              GaussianNB  0.0269678   0.0269678  0.0269678           0   
1      LogisticRegression -0.0557333  0.00189586  0.0804729   0.0277863   
7                     SVC -0.0558203 -0.00201621  0.0483149   0.0195474   
2           SGDClassifier   -0.19066  0.00454995   0.158913   0.0294469   
4  RandomForestClassifier -0.0194423 -0.00055015          0  0.00221361   
5           MLPClassifier  -0.017279 -0.00982657          0  0.00368727   
8        VotingClassifier  -0.013237 -0.00304006          0  0.00381818   
9    KNeighborsClassifier -0.0153837 -0.00344569          0  0.00599813   
6      AdaBoostClassifier -0.0195189  0.00124352   0.135731   0.0279753   
3    ExtraTreesClassifier -0.0292171  0.00412879   0.132787   0.0199589   

        acc       auc           conf_matrix     f1_c0      f1_c1       kappa  \
0  0.596667  0.795608  [[175, 121], [0, 4]]    0.7431  0.0620155   0.0371353   
1  0.433333  0.712838  [[126, 170], [0, 4]]  0.597156  0.0449438   0.0193816   
7  0.626667    0.6875  [[185, 111], [1, 3]]  0.767635  0.0508475   0.0257481   
2      0.19  0.589527   [[53, 243], [0, 4]]  0.303725  0.0318725  0.00578255   
4  0.986667       0.5    [[296, 0], [4, 0]]  0.993289          0           0   
5  0.986667       0.5    [[296, 0], [4, 0]]  0.993289          0           0   
8  0.986667       0.5    [[296, 0], [4, 0]]  0.993289          0           0   
9  0.986667       0.5    [[296, 0], [4, 0]]  0.993289          0           0   
6  0.973333  0.493243    [[292, 4], [4, 0]]  0.986486          0  -0.0135135   
3  0.966667  0.489865    [[290, 6], [4, 0]]  0.983051          0  -0.0162602   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
0    0.137546         1      0.032  0.591216      1  
1   0.0989224         1  0.0229885  0.425676      1  
7   0.0886132  0.994624  0.0263158     0.625   0.75  
2   0.0538485         1  0.0161943  0.179054      1  
4           0  0.986667          0         1      0  
5           0  0.986667          0         1      0  
8           0  0.986667          0         1      0  
9           0  0.986667          0         1      0  
6  -0.0135135  0.986486          0  0.986486      0  
3  -0.0166068  0.986395          0   0.97973      0  
Elapsed time 22.36 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv 
datetime: 2017-05-10 19:14:23.374000 
pca_target: 0 	 poly degree: 0 	 kselect: 20 
Imbalance: SMOTE(k=None, k_neighbors=5, kind='regular', m=None, m_neighbors=10, n_jobs=1,
   out_step=0.5, random_state=None, ratio='auto', svm_estimator=None) 
Extended target (count):  25141 325
('Total : Processed (count): ', (998L, 22L), 13)
Final feature (count):  (998L, 22L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.557 	0.127 	0.032 	0.775 	0.742 	0.575
[[163 133]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.55      0.71       296
          1       0.03      1.00      0.06         4

avg / total       0.99      0.56      0.70       300


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=10, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.777 	0.144 	0.058 	0.764 	0.763 	0.581
[[230  66]
 [  1   3]]
             precision    recall  f1-score   support

          0       1.00      0.78      0.87       296
          1       0.04      0.75      0.08         4

avg / total       0.98      0.78      0.86       300


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.001, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.001, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='perceptron', n_iter=5, n_jobs=4,
       penalty='l1', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.820 	0.168 	0.077 	0.785 	0.785 	0.611
[[243  53]
 [  1   3]]
             precision    recall  f1-score   support

          0       1.00      0.82      0.90       296
          1       0.05      0.75      0.10         4

avg / total       0.98      0.82      0.89       300


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight='balanced',
           criterion='entropy', max_depth=None, max_features='auto',
           max_leaf_nodes=None, min_impurity_split=1e-07,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=4,
           oob_score=False, random_state=None, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.973 	0.191 	0.187 	0.617 	0.496 	0.228
[[291   5]
 [  3   1]]
             precision    recall  f1-score   support

          0       0.99      0.98      0.99       296
          1       0.17      0.25      0.20         4

avg / total       0.98      0.97      0.98       300


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight='balanced',
            criterion='entropy', max_depth=16, max_features=0.33,
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.973 	0.191 	0.187 	0.617 	0.496 	0.228
[[291   5]
 [  3   1]]
             precision    recall  f1-score   support

          0       0.99      0.98      0.99       296
          1       0.17      0.25      0.20         4

avg / total       0.98      0.97      0.98       300


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.01, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(500,), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.970 	0.175 	0.168 	0.615 	0.495 	0.227
[[290   6]
 [  3   1]]
             precision    recall  f1-score   support

          0       0.99      0.98      0.98       296
          1       0.14      0.25      0.18         4

avg / total       0.98      0.97      0.97       300


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 500}, criterion='entropy',
            max_depth=16, max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=1.0, n_estimators=50, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.977 	0.212 	0.211 	0.618 	0.497 	0.228
[[292   4]
 [  3   1]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       296
          1       0.20      0.25      0.22         4

avg / total       0.98      0.98      0.98       300


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=10, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.970 	0.175 	0.168 	0.615 	0.495 	0.227
[[290   6]
 [  3   1]]
             precision    recall  f1-score   support

          0       0.99      0.98      0.98       296
          1       0.14      0.25      0.18         4

avg / total       0.98      0.97      0.97       300


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=10.0, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', ...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.937 	0.310 	0.223 	0.845 	0.839 	0.691
[[278  18]
 [  1   3]]
             precision    recall  f1-score   support

          0       1.00      0.94      0.97       296
          1       0.14      0.75      0.24         4

avg / total       0.99      0.94      0.96       300


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.940 	0.413 	0.292 	0.970 	0.969 	0.945
[[278  18]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.94      0.97       296
          1       0.18      1.00      0.31         4

avg / total       0.99      0.94      0.96       300


                estimator  min_score mean_score max_score    sd_score  \
9    KNeighborsClassifier   0.816569   0.861722   0.91176   0.0316789   
8        VotingClassifier   0.810283   0.874157  0.911611   0.0250093   
2           SGDClassifier -0.0973581   0.403574   0.77994    0.197559   
0              GaussianNB   0.484835   0.484835  0.484835           0   
1      LogisticRegression          0   0.553265  0.775862    0.168908   
6      AdaBoostClassifier   0.771142   0.922934   0.98122   0.0382826   
3    ExtraTreesClassifier   0.540837   0.881357  0.984184    0.130624   
4  RandomForestClassifier   0.719255   0.910055  0.962784   0.0690078   
5           MLPClassifier   0.943022   0.968208    0.9856  0.00943265   
7                     SVC          0   0.675432  0.978467    0.243957   

        acc       auc           conf_matrix     f1_c0      f1_c1      kappa  \
9      0.94  0.969595   [[278, 18], [0, 4]]  0.968641   0.307692    0.29171   
8  0.936667  0.844595   [[278, 18], [1, 3]]  0.966957       0.24   0.222586   
2      0.82  0.785473   [[243, 53], [1, 3]]       0.9        0.1  0.0770283   
0  0.556667  0.775338  [[163, 133], [0, 4]]   0.71024  0.0567376  0.0316474   
1  0.776667  0.763514   [[230, 66], [1, 3]]  0.872865  0.0821918  0.0584598   
6  0.976667  0.618243    [[292, 4], [3, 1]]  0.988156   0.222222   0.210526   
3  0.973333  0.616554    [[291, 5], [3, 1]]  0.986441        0.2   0.186992   
4  0.973333  0.616554    [[291, 5], [3, 1]]  0.986441        0.2   0.186992   
5      0.97  0.614865    [[290, 6], [3, 1]]   0.98472   0.181818   0.167694   
7      0.97  0.614865    [[290, 6], [3, 1]]   0.98472   0.181818   0.167694   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
9    0.413233         1   0.181818  0.939189      1  
8    0.309815  0.996416   0.142857  0.939189   0.75  
2    0.168067  0.995902  0.0535714  0.820946   0.75  
0      0.1268         1  0.0291971  0.550676      1  
1    0.143641  0.995671  0.0434783  0.777027   0.75  
6    0.211878  0.989831        0.2  0.986486   0.25  
3    0.190978  0.989796   0.166667  0.983108   0.25  
4    0.190978  0.989796   0.166667  0.983108   0.25  
5    0.174546  0.989761   0.142857   0.97973   0.25  
7    0.174546  0.989761   0.142857   0.97973   0.25  
Elapsed time 36.12 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv 
datetime: 2017-05-10 19:50:30.427000 
pca_target: 0 	 poly degree: 0 	 kselect: 20 
Imbalance: ClusterCentroids(estimator=None, n_jobs=1, random_state=None, ratio='auto') 
Extended target (count):  25141 325
('Total : Processed (count): ', (998L, 22L), 13)
Final feature (count):  (998L, 22L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.507 	0.115 	0.026 	0.750 	0.707 	0.525
[[148 148]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.50      0.67       296
          1       0.03      1.00      0.05         4

avg / total       0.99      0.51      0.66       300


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=5, class_weight={1: 50}, dual=False, fit_intercept=True,
          intercept_scaling=10, max_iter=100, multi_class='ovr', n_jobs=4,
          penalty='l2', random_state=None, solver='sag', tol=0.0001,
          verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.393 	0.033 	0.006 	0.569 	0.540 	0.302
[[115 181]
 [  1   3]]
             precision    recall  f1-score   support

          0       0.99      0.39      0.56       296
          1       0.02      0.75      0.03         4

avg / total       0.98      0.39      0.55       300


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=1, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='squared_hinge', n_iter=5, n_jobs=4,
       penalty='l2', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.637 	0.033 	0.010 	0.569 	0.565 	0.315
[[189 107]
 [  2   2]]
             precision    recall  f1-score   support

          0       0.99      0.64      0.78       296
          1       0.02      0.50      0.04         4

avg / total       0.98      0.64      0.77       300


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3},
           criterion='entropy', max_depth=None, max_features=0.75,
           max_leaf_nodes=None, min_impurity_split=1e-07,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=15, n_jobs=4,
           oob_score=False, random_state=None, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.583 	0.077 	0.020 	0.666 	0.660 	0.443
[[172 124]
 [  1   3]]
             precision    recall  f1-score   support

          0       0.99      0.58      0.73       296
          1       0.02      0.75      0.05         4

avg / total       0.98      0.58      0.72       300


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight='balanced',
            criterion='gini', max_depth=8, max_features='auto',
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=15, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.590 	0.021 	0.006 	0.546 	0.544 	0.293
[[175 121]
 [  2   2]]
             precision    recall  f1-score   support

          0       0.99      0.59      0.74       296
          1       0.02      0.50      0.03         4

avg / total       0.98      0.59      0.73       300


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(500,), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.793 	0.084 	0.036 	0.649 	0.631 	0.387
[[236  60]
 [  2   2]]
             precision    recall  f1-score   support

          0       0.99      0.80      0.88       296
          1       0.03      0.50      0.06         4

avg / total       0.98      0.79      0.87       300


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 500}, criterion='entropy',
            max_depth=8, max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=2.0, n_estimators=15, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.703 	0.113 	0.039 	0.726 	0.726 	0.530
[[208  88]
 [  1   3]]
             precision    recall  f1-score   support

          0       1.00      0.70      0.82       296
          1       0.03      0.75      0.06         4

avg / total       0.98      0.70      0.81       300


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=1, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='linear',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.530 	0.064 	0.015 	0.639 	0.629 	0.404
[[156 140]
 [  1   3]]
             precision    recall  f1-score   support

          0       0.99      0.53      0.69       296
          1       0.02      0.75      0.04         4

avg / total       0.98      0.53      0.68       300


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=10.0, class_weight={1: 500}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Ra...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.583 	0.134 	0.035 	0.789 	0.760 	0.602
[[171 125]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.58      0.73       296
          1       0.03      1.00      0.06         4

avg / total       0.99      0.58      0.72       300


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=6, p=2,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.507 	0.115 	0.026 	0.750 	0.707 	0.525
[[148 148]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.50      0.67       296
          1       0.03      1.00      0.05         4

avg / total       0.99      0.51      0.66       300


                estimator min_score mean_score max_score  sd_score       acc  \
8        VotingClassifier   -0.2566   0.148154  0.478822   0.15592  0.583333   
0              GaussianNB    0.1283     0.1283    0.1283         0  0.506667   
9    KNeighborsClassifier   -0.3849  -0.222133    0.1283   0.13476  0.506667   
6      AdaBoostClassifier   -0.3849   0.140903  0.701045  0.169144  0.703333   
3    ExtraTreesClassifier -0.111111   0.173766  0.666667  0.126261  0.583333   
5           MLPClassifier -0.461633  -0.259503         0  0.159593  0.793333   
7                     SVC -0.496011   0.024137  0.350522  0.204766      0.53   
1      LogisticRegression -0.111111   0.161497    0.3849  0.124265  0.393333   
2           SGDClassifier   -0.5132   0.109336  0.607122    0.1421  0.636667   
4  RandomForestClassifier -0.333333   0.100423  0.649478  0.172664      0.59   

        auc           conf_matrix     f1_c0      f1_c1       kappa  \
8  0.788851  [[171, 125], [0, 4]]  0.732334  0.0601504    0.035196   
0      0.75  [[148, 148], [0, 4]]  0.666667  0.0512821    0.025974   
9      0.75  [[148, 148], [0, 4]]  0.666667  0.0512821    0.025974   
6  0.726351   [[208, 88], [1, 3]]  0.823762  0.0631579      0.0386   
3  0.665541  [[172, 124], [1, 3]]  0.733475  0.0458015   0.0204785   
5  0.648649   [[236, 60], [2, 2]]  0.883895  0.0606061   0.0364691   
7  0.638514  [[156, 140], [1, 3]]  0.688742  0.0408163   0.0152714   
1  0.569257  [[115, 181], [1, 3]]  0.558252  0.0319149  0.00597145   
2  0.569257  [[189, 107], [2, 2]]  0.776181  0.0353982  0.00993097   
4  0.545608  [[175, 121], [2, 2]]  0.739958  0.0314961  0.00581959   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
8     0.13384         1  0.0310078  0.577703      1  
0    0.114708         1  0.0263158       0.5      1  
9    0.114708         1  0.0263158       0.5      1  
6    0.112952  0.995215   0.032967  0.702703   0.75  
3   0.0768573   0.99422   0.023622  0.581081   0.75  
5   0.0842136  0.991597  0.0322581  0.797297    0.5  
7    0.063618  0.993631   0.020979  0.527027   0.75  
1   0.0326235  0.991379  0.0163043  0.388514   0.75  
2   0.0330322  0.989529  0.0183486  0.638514    0.5  
4    0.021272  0.988701  0.0162602  0.591216    0.5  
Elapsed time 14.65 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv 
datetime: 2017-05-10 20:05:09.456000 
pca_target: 0 	 poly degree: 0 	 kselect: 0 
Imbalance: None 
Extended target (count):  25141 325
('Total : Processed (count): ', (998L, 22L), 13)
Final feature (count):  (998L, 22L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.600 	0.138 	0.038 	0.797 	0.771 	0.619
[[176 120]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.59      0.75       296
          1       0.03      1.00      0.06         4

avg / total       0.99      0.60      0.74       300


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.01, class_weight={1: 3}, dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.650 	0.095 	0.029 	0.699 	0.697 	0.491
[[192 104]
 [  1   3]]
             precision    recall  f1-score   support

          0       0.99      0.65      0.79       296
          1       0.03      0.75      0.05         4

avg / total       0.98      0.65      0.78       300


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.0001, average=False, class_weight='balanced',
       epsilon=0.1, eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='constant', loss='modified_huber', n_iter=5, n_jobs=4,
       penalty='l1', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.830 	-0.050 	-0.025 	0.421 	0.000 	0.000
[[249  47]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.98      0.84      0.91       296
          1       0.00      0.00      0.00         4

avg / total       0.97      0.83      0.90       300


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 50}, criterion='gini',
           max_depth=16, max_features=0.33, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	0.000 	0.000 	0.500 	0.000 	0.000
[[296   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       296
          1       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       300


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 500},
            criterion='gini', max_depth=8, max_features=0.75,
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=15, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.960 	0.273 	0.235 	0.733 	0.695 	0.461
[[286  10]
 [  2   2]]
             precision    recall  f1-score   support

          0       0.99      0.97      0.98       296
          1       0.17      0.50      0.25         4

avg / total       0.98      0.96      0.97       300


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.5, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(500,), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	0.000 	0.000 	0.500 	0.000 	0.000
[[296   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       296
          1       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       300


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=2.0, n_estimators=50, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.970 	-0.015 	-0.015 	0.492 	0.000 	0.000
[[291   5]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.98      0.98       296
          1       0.00      0.00      0.00         4

avg / total       0.97      0.97      0.97       300


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.5, cache_size=200, class_weight={1: 500}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.600 	0.138 	0.038 	0.797 	0.771 	0.619
[[176 120]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.59      0.75       296
          1       0.03      1.00      0.06         4

avg / total       0.99      0.60      0.74       300


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	0.000 	0.000 	0.500 	0.000 	0.000
[[296   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       296
          1       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       300


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=1,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	0.000 	0.000 	0.500 	0.000 	0.000
[[296   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       296
          1       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       300


                estimator  min_score   mean_score  max_score    sd_score  \
0              GaussianNB  0.0283309    0.0283309  0.0283309           0   
7                     SVC -0.0551698  -0.00325769  0.0698342   0.0235257   
4  RandomForestClassifier -0.0177357 -0.000415519  0.0393988  0.00294974   
1      LogisticRegression  -0.061547   0.00123349   0.100961   0.0288807   
3    ExtraTreesClassifier -0.0257637   0.00469686   0.139267   0.0217574   
5           MLPClassifier  -0.014971  -0.00905996          0  0.00344334   
8        VotingClassifier -0.0134459    -0.003241          0  0.00376434   
9    KNeighborsClassifier -0.0158896  -0.00432661          0  0.00605726   
6      AdaBoostClassifier  -0.021854    0.0017954   0.137742   0.0293196   
2           SGDClassifier  -0.133705   0.00637313   0.108734   0.0285199   

        acc       auc           conf_matrix     f1_c0      f1_c1      kappa  \
0       0.6  0.797297  [[176, 120], [0, 4]]  0.745763     0.0625   0.037639   
7       0.6  0.797297  [[176, 120], [0, 4]]  0.745763     0.0625   0.037639   
4      0.96  0.733108   [[286, 10], [2, 2]]  0.979452       0.25   0.234694   
1      0.65  0.699324  [[192, 104], [1, 3]]  0.785276  0.0540541  0.0290963   
3  0.986667       0.5    [[296, 0], [4, 0]]  0.993289          0          0   
5  0.986667       0.5    [[296, 0], [4, 0]]  0.993289          0          0   
8  0.986667       0.5    [[296, 0], [4, 0]]  0.993289          0          0   
9  0.986667       0.5    [[296, 0], [4, 0]]  0.993289          0          0   
6      0.97  0.491554    [[291, 5], [4, 0]]  0.984772          0 -0.0150376   
2      0.83  0.420608   [[249, 47], [4, 0]]  0.907104          0 -0.0251943   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
0    0.138494         1  0.0322581  0.594595      1  
7    0.138494         1  0.0322581  0.594595      1  
4    0.272883  0.993056   0.166667  0.966216    0.5  
1   0.0954543  0.994819  0.0280374  0.648649   0.75  
3           0  0.986667          0         1      0  
5           0  0.986667          0         1      0  
8           0  0.986667          0         1      0  
9           0  0.986667          0         1      0  
6  -0.0151342  0.986441          0  0.983108      0  
2   -0.050104   0.98419          0  0.841216      0  
Elapsed time 21.54 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv 
datetime: 2017-05-10 20:26:41.825000 
pca_target: 0 	 poly degree: 0 	 kselect: 0 
Imbalance: SMOTE(k=None, k_neighbors=5, kind='regular', m=None, m_neighbors=10, n_jobs=1,
   out_step=0.5, random_state=None, ratio='auto', svm_estimator=None) 
Extended target (count):  25141 325
('Total : Processed (count): ', (998L, 22L), 13)
Final feature (count):  (998L, 22L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.597 	0.138 	0.037 	0.796 	0.769 	0.615
[[175 121]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.59      0.74       296
          1       0.03      1.00      0.06         4

avg / total       0.99      0.60      0.73       300


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=10, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.803 	0.158 	0.069 	0.777 	0.777 	0.600
[[238  58]
 [  1   3]]
             precision    recall  f1-score   support

          0       1.00      0.80      0.89       296
          1       0.05      0.75      0.09         4

avg / total       0.98      0.80      0.88       300


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.001, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='perceptron', n_iter=5, n_jobs=4,
       penalty='l1', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.820 	0.097 	0.045 	0.662 	0.642 	0.399
[[244  52]
 [  2   2]]
             precision    recall  f1-score   support

          0       0.99      0.82      0.90       296
          1       0.04      0.50      0.07         4

avg / total       0.98      0.82      0.89       300


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 50}, criterion='gini',
           max_depth=None, max_features=0.33, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=50, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	0.493 	0.493 	0.747 	0.705 	0.472
[[294   2]
 [  2   2]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       296
          1       0.50      0.50      0.50         4

avg / total       0.99      0.99      0.99       300


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 15}, criterion='gini',
            max_depth=None, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=30, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.973 	0.191 	0.187 	0.617 	0.496 	0.228
[[291   5]
 [  3   1]]
             precision    recall  f1-score   support

          0       0.99      0.98      0.99       296
          1       0.17      0.25      0.20         4

avg / total       0.98      0.97      0.98       300


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.1, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(500,), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.967 	0.161 	0.152 	0.613 	0.494 	0.226
[[289   7]
 [  3   1]]
             precision    recall  f1-score   support

          0       0.99      0.98      0.98       296
          1       0.12      0.25      0.17         4

avg / total       0.98      0.97      0.97       300


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 50}, criterion='entropy',
            max_depth=16, max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=1.0, n_estimators=80, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.973 	-0.014 	-0.014 	0.493 	0.000 	0.000
[[292   4]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       296
          1       0.00      0.00      0.00         4

avg / total       0.97      0.97      0.97       300


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=10, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.970 	0.175 	0.168 	0.615 	0.495 	0.227
[[290   6]
 [  3   1]]
             precision    recall  f1-score   support

          0       0.99      0.98      0.98       296
          1       0.14      0.25      0.18         4

avg / total       0.98      0.97      0.97       300


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=10.0, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', ...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.940 	0.215 	0.164 	0.723 	0.688 	0.452
[[280  16]
 [  2   2]]
             precision    recall  f1-score   support

          0       0.99      0.95      0.97       296
          1       0.11      0.50      0.18         4

avg / total       0.98      0.94      0.96       300


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=3,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.930 	0.089 	0.066 	0.595 	0.485 	0.219
[[278  18]
 [  3   1]]
             precision    recall  f1-score   support

          0       0.99      0.94      0.96       296
          1       0.05      0.25      0.09         4

avg / total       0.98      0.93      0.95       300


                estimator  min_score mean_score max_score    sd_score  \
0              GaussianNB    0.50752    0.50752   0.50752           0   
1      LogisticRegression          0   0.560973  0.790827    0.178356   
3    ExtraTreesClassifier   0.549931   0.881932  0.988492    0.129299   
8        VotingClassifier   0.838187   0.891444  0.933233   0.0246482   
2           SGDClassifier -0.0526354   0.422281  0.790847    0.204158   
4  RandomForestClassifier   0.729589   0.906848  0.960888   0.0696959   
7                     SVC          0   0.687672  0.981289    0.244764   
5           MLPClassifier    0.95629    0.97449  0.991354  0.00867073   
9    KNeighborsClassifier    0.83773   0.878296   0.92889   0.0292456   
6      AdaBoostClassifier    0.77271   0.931583   0.98561   0.0370707   

        acc       auc           conf_matrix     f1_c0      f1_c1      kappa  \
0  0.596667  0.795608  [[175, 121], [0, 4]]    0.7431  0.0620155  0.0371353   
1  0.803333  0.777027   [[238, 58], [1, 3]]   0.88972  0.0923077   0.069009   
3  0.986667  0.746622    [[294, 2], [2, 2]]  0.993243        0.5   0.493243   
8      0.94  0.722973   [[280, 16], [2, 2]]  0.968858   0.181818   0.163569   
2      0.82  0.662162   [[244, 52], [2, 2]]  0.900369  0.0689655  0.0452617   
4  0.973333  0.616554    [[291, 5], [3, 1]]  0.986441        0.2   0.186992   
7      0.97  0.614865    [[290, 6], [3, 1]]   0.98472   0.181818   0.167694   
5  0.966667  0.613176    [[289, 7], [3, 1]]  0.982993   0.166667   0.151584   
9      0.93  0.594595   [[278, 18], [3, 1]]  0.963605  0.0869565    0.06639   
6  0.973333  0.493243    [[292, 4], [4, 0]]  0.986486          0 -0.0135135   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
0    0.137546         1      0.032  0.591216      1  
1    0.157893  0.995816  0.0491803  0.804054   0.75  
3    0.493243  0.993243        0.5  0.993243    0.5  
8    0.215376  0.992908   0.111111  0.945946    0.5  
2   0.0968258   0.99187   0.037037  0.824324    0.5  
4    0.190978  0.989796   0.166667  0.983108   0.25  
7    0.174546  0.989761   0.142857   0.97973   0.25  
5    0.161147  0.989726      0.125  0.976351   0.25  
9   0.0890927  0.989324  0.0526316  0.939189   0.25  
6  -0.0135135  0.986486          0  0.986486      0  
Elapsed time 35.46 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv 
datetime: 2017-05-10 21:02:09.517000 
pca_target: 0 	 poly degree: 0 	 kselect: 0 
Imbalance: ClusterCentroids(estimator=None, n_jobs=1, random_state=None, ratio='auto') 
Extended target (count):  25141 325
('Total : Processed (count): ', (998L, 22L), 13)
Final feature (count):  (998L, 22L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.533 	0.121 	0.029 	0.764 	0.726 	0.552
[[156 140]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.53      0.69       296
          1       0.03      1.00      0.05         4

avg / total       0.99      0.53      0.68       300


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.001, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=10, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='sag', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.460 	0.104 	0.022 	0.726 	0.673 	0.477
[[134 162]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.45      0.62       296
          1       0.02      1.00      0.05         4

avg / total       0.99      0.46      0.62       300


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.001, average=False, class_weight={1: 500}, epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='constant', loss='squared_hinge', n_iter=5, n_jobs=4,
       penalty='none', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.377 	0.088 	0.015 	0.684 	0.607 	0.392
[[109 187]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.37      0.54       296
          1       0.02      1.00      0.04         4

avg / total       0.99      0.38      0.53       300


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=8, max_features=0.33, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.537 	0.065 	0.016 	0.642 	0.633 	0.409
[[158 138]
 [  1   3]]
             precision    recall  f1-score   support

          0       0.99      0.53      0.69       296
          1       0.02      0.75      0.04         4

avg / total       0.98      0.54      0.69       300


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight='balanced',
            criterion='entropy', max_depth=None, max_features=0.75,
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.540 	0.066 	0.016 	0.644 	0.635 	0.411
[[159 137]
 [  1   3]]
             precision    recall  f1-score   support

          0       0.99      0.54      0.70       296
          1       0.02      0.75      0.04         4

avg / total       0.98      0.54      0.69       300


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.710 	0.054 	0.019 	0.606 	0.597 	0.349
[[211  85]
 [  2   2]]
             precision    recall  f1-score   support

          0       0.99      0.71      0.83       296
          1       0.02      0.50      0.04         4

avg / total       0.98      0.71      0.82       300


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight='balanced', criterion='entropy',
            max_depth=4, max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=0.5, n_estimators=80, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.487 	0.054 	0.012 	0.617 	0.602 	0.372
[[143 153]
 [  1   3]]
             precision    recall  f1-score   support

          0       0.99      0.48      0.65       296
          1       0.02      0.75      0.04         4

avg / total       0.98      0.49      0.64       300


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='linear',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.347 	0.082 	0.013 	0.669 	0.581 	0.360
[[100 196]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.34      0.51       296
          1       0.02      1.00      0.04         4

avg / total       0.99      0.35      0.50       300


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=10.0, class_weight={1: 500}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Ra...wski',
           metric_params=None, n_jobs=4, n_neighbors=4, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.550 	0.125 	0.031 	0.772 	0.738 	0.569
[[161 135]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.54      0.70       296
          1       0.03      1.00      0.06         4

avg / total       0.99      0.55      0.70       300


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=4,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.930 	-0.028 	-0.022 	0.471 	0.000 	0.000
[[279  17]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.94      0.96       296
          1       0.00      0.00      0.00         4

avg / total       0.97      0.93      0.95       300


                estimator  min_score  mean_score  max_score   sd_score  \
8        VotingClassifier    -0.2566 -0.00669255     0.2566   0.118978   
0              GaussianNB     0.1283      0.1283     0.1283          0   
1      LogisticRegression    -0.2566    0.106501   0.461633   0.116305   
2           SGDClassifier    -0.3849    0.146915   0.624311   0.118943   
7                     SVC  -0.367711  -0.0432241   0.350522   0.160853   
4  RandomForestClassifier  -0.205033    0.158781   0.589933   0.137767   
3    ExtraTreesClassifier  0.0171889    0.227807   0.478822  0.0802663   
6      AdaBoostClassifier  -0.589933  -0.0612915   0.589933   0.252256   
5           MLPClassifier    -0.3849  -0.0983737     0.1283   0.163865   
9    KNeighborsClassifier  -0.624311   -0.366611  0.0171889   0.151295   

        acc       auc           conf_matrix     f1_c0      f1_c1      kappa  \
8      0.55  0.771959  [[161, 135], [0, 4]]  0.704595  0.0559441  0.0308222   
0  0.533333  0.763514  [[156, 140], [0, 4]]  0.690265  0.0540541  0.0288568   
1      0.46  0.726351  [[134, 162], [0, 4]]  0.623256  0.0470588  0.0215816   
2  0.376667  0.684122  [[109, 187], [0, 4]]  0.538272  0.0410256  0.0153058   
7  0.346667  0.668919  [[100, 196], [0, 4]]  0.505051  0.0392157  0.0134228   
4      0.54  0.643581  [[159, 137], [1, 3]]  0.697368  0.0416667  0.0161597   
3  0.536667  0.641892  [[158, 138], [1, 3]]  0.694505  0.0413793  0.0158595   
6  0.486667  0.616554  [[143, 153], [1, 3]]      0.65     0.0375   0.011807   
5      0.71  0.606419   [[211, 85], [2, 2]]  0.829077   0.043956  0.0189445   
9      0.93  0.471284   [[279, 17], [4, 0]]  0.963731          0 -0.0220636   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
8    0.125109         1   0.028777  0.543919      1  
0    0.120994         1  0.0277778  0.527027      1  
1    0.104444         1  0.0240964  0.452703      1  
2   0.0878174         1  0.0209424  0.368243      1  
7   0.0821995         1       0.02  0.337838      1  
4   0.0660205   0.99375  0.0214286  0.537162   0.75  
3   0.0652162  0.993711  0.0212766  0.533784   0.75  
6   0.0535167  0.993056  0.0192308  0.483108   0.75  
5   0.0537991   0.99061  0.0229885  0.712838    0.5  
9  -0.0284915  0.985866          0  0.942568      0  
Elapsed time 14.62 mins 

************************************************************

















Standard, lagged(3,4)x1, filter(tukey), None, UNtruncated










pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv 
datetime: 2017-05-11 13:23:41.695000 
pca_target: 0 	 poly degree: 0 	 kselect: 20 
Imbalance: None 
Extended target (count):  31485 325
('Total : Processed (count): ', (1252L, 20L), 13)
Final feature (count):  (1252L, 20L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.617 	0.129 	0.033 	0.806 	0.783 	0.637
[[228 144]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.61      0.76       372
          1       0.03      1.00      0.05         4

avg / total       0.99      0.62      0.75       376


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.1, class_weight={1: 500}, dual=False,
          fit_intercept=True, intercept_scaling=10, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='sag', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.561 	0.115 	0.026 	0.778 	0.746 	0.581
[[207 165]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.56      0.72       372
          1       0.02      1.00      0.05         4

avg / total       0.99      0.56      0.71       376


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=1, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.001, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='perceptron', n_iter=5, n_jobs=4,
       penalty='none', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.971 	-0.014 	-0.014 	0.491 	0.000 	0.000
[[365   7]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.98      0.99       372
          1       0.00      0.00      0.00         4

avg / total       0.98      0.97      0.97       376


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 500},
           criterion='entropy', max_depth=8, max_features=0.75,
           max_leaf_nodes=None, min_impurity_split=1e-07,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=4,
           oob_score=False, random_state=None, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.896 	0.135 	0.075 	0.700 	0.671 	0.432
[[335  37]
 [  2   2]]
             precision    recall  f1-score   support

          0       0.99      0.90      0.94       372
          1       0.05      0.50      0.09         4

avg / total       0.98      0.90      0.94       376


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       372
          1       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.5, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(500,), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       372
          1       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='entropy', max_depth=32,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=1.0, n_estimators=15, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.976 	0.178 	0.171 	0.617 	0.496 	0.228
[[366   6]
 [  3   1]]
             precision    recall  f1-score   support

          0       0.99      0.98      0.99       372
          1       0.14      0.25      0.18         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='linear',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.551 	0.112 	0.025 	0.773 	0.739 	0.570
[[203 169]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.55      0.71       372
          1       0.02      1.00      0.05         4

avg / total       0.99      0.55      0.70       376


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       372
          1       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=1,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       372
          1       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


                estimator  min_score  mean_score  max_score    sd_score  \
0              GaussianNB  0.0372741   0.0372741  0.0372741           0   
1      LogisticRegression -0.0540588  0.00608401  0.0986087   0.0380966   
7                     SVC -0.0572367 -0.00665292  0.0938753   0.0341092   
3    ExtraTreesClassifier  -0.036758 -0.00392505  0.0814378  0.00862533   
6      AdaBoostClassifier -0.0180795 -0.00808174   0.060833  0.00782014   
4  RandomForestClassifier -0.0173929 -0.00071917          0  0.00222399   
5           MLPClassifier -0.0148838 -0.00947588          0  0.00339151   
8        VotingClassifier -0.0136863 -0.00388835          0  0.00394993   
9    KNeighborsClassifier -0.0125892 -0.00351496          0  0.00515942   
2           SGDClassifier -0.0904447   0.0184597   0.236961   0.0389582   

        acc       auc           conf_matrix     f1_c0      f1_c1      kappa  \
0  0.617021  0.806452  [[228, 144], [0, 4]]      0.76  0.0526316  0.0325901   
1   0.56117  0.778226  [[207, 165], [0, 4]]  0.715026  0.0462428  0.0259985   
7  0.550532  0.772849  [[203, 169], [0, 4]]  0.706087  0.0451977  0.0249202   
3  0.896277  0.700269   [[335, 37], [2, 2]]  0.944993  0.0930233  0.0751766   
6  0.976064  0.616935    [[366, 6], [3, 1]]  0.987854   0.181818   0.170588   
4  0.989362       0.5    [[372, 0], [4, 0]]  0.994652          0          0   
5  0.989362       0.5    [[372, 0], [4, 0]]  0.994652          0          0   
8  0.989362       0.5    [[372, 0], [4, 0]]  0.994652          0          0   
9  0.989362       0.5    [[372, 0], [4, 0]]  0.994652          0          0   
2  0.970745  0.490591    [[365, 7], [4, 0]]  0.985155          0 -0.0137255   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
0    0.128705         1   0.027027  0.612903      1  
1    0.114763         1  0.0236686  0.556452      1  
7    0.112327         1  0.0231214  0.545699      1  
3    0.134771  0.994065  0.0512821  0.900538    0.5  
6    0.177507   0.99187   0.142857  0.983871   0.25  
4           0  0.989362          0         1      0  
5           0  0.989362          0         1      0  
8           0  0.989362          0         1      0  
9           0  0.989362          0         1      0  
2  -0.0142822   0.98916          0  0.981183      0  
Elapsed time 23.77 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv 
datetime: 2017-05-11 13:47:27.935000 
pca_target: 0 	 poly degree: 0 	 kselect: 20 
Imbalance: SMOTE(k=None, k_neighbors=5, kind='regular', m=None, m_neighbors=10, n_jobs=1,
   out_step=0.5, random_state=None, ratio='auto', svm_estimator=None) 
Extended target (count):  31485 325
('Total : Processed (count): ', (1252L, 20L), 13)
Final feature (count):  (1252L, 20L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.649 	0.138 	0.037 	0.823 	0.803 	0.668
[[240 132]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.65      0.78       372
          1       0.03      1.00      0.06         4

avg / total       0.99      0.65      0.78       376


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=5, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.723 	0.052 	0.017 	0.613 	0.602 	0.355
[[270 102]
 [  2   2]]
             precision    recall  f1-score   support

          0       0.99      0.73      0.84       372
          1       0.02      0.50      0.04         4

avg / total       0.98      0.72      0.83       376


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.001, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.001, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='modified_huber', n_iter=5, n_jobs=4,
       penalty='none', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.702 	-0.010 	-0.003 	0.478 	0.420 	0.169
[[263 109]
 [  3   1]]
             precision    recall  f1-score   support

          0       0.99      0.71      0.82       372
          1       0.01      0.25      0.02         4

avg / total       0.98      0.70      0.82       376


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 500},
           criterion='entropy', max_depth=32, max_features=0.33,
           max_leaf_nodes=None, min_impurity_split=1e-07,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=4,
           oob_score=False, random_state=None, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.963 	0.129 	0.111 	0.610 	0.493 	0.225
[[361  11]
 [  3   1]]
             precision    recall  f1-score   support

          0       0.99      0.97      0.98       372
          1       0.08      0.25      0.12         4

avg / total       0.98      0.96      0.97       376


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight='balanced',
            criterion='entropy', max_depth=32, max_features='auto',
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.955 	0.111 	0.090 	0.606 	0.491 	0.223
[[358  14]
 [  3   1]]
             precision    recall  f1-score   support

          0       0.99      0.96      0.98       372
          1       0.07      0.25      0.11         4

avg / total       0.98      0.95      0.97       376


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.1, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(500,), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.976 	0.178 	0.171 	0.617 	0.496 	0.228
[[366   6]
 [  3   1]]
             precision    recall  f1-score   support

          0       0.99      0.98      0.99       372
          1       0.14      0.25      0.18         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='entropy', max_depth=16,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=1.0, n_estimators=80, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.971 	0.153 	0.141 	0.614 	0.495 	0.227
[[364   8]
 [  3   1]]
             precision    recall  f1-score   support

          0       0.99      0.98      0.99       372
          1       0.11      0.25      0.15         4

avg / total       0.98      0.97      0.98       376


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=10, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.965 	0.136 	0.120 	0.612 	0.493 	0.226
[[362  10]
 [  3   1]]
             precision    recall  f1-score   support

          0       0.99      0.97      0.98       372
          1       0.09      0.25      0.13         4

avg / total       0.98      0.97      0.97       376


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=10.0, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', ...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.923 	0.164 	0.104 	0.714 	0.681 	0.444
[[345  27]
 [  2   2]]
             precision    recall  f1-score   support

          0       0.99      0.93      0.96       372
          1       0.07      0.50      0.12         4

avg / total       0.98      0.92      0.95       376


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=1,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.934 	0.082 	0.057 	0.595 	0.485 	0.219
[[350  22]
 [  3   1]]
             precision    recall  f1-score   support

          0       0.99      0.94      0.97       372
          1       0.04      0.25      0.07         4

avg / total       0.98      0.93      0.96       376


                estimator   min_score mean_score max_score   sd_score  \
0              GaussianNB    0.627758   0.627758  0.627758          0   
8        VotingClassifier    0.837895   0.885046  0.919323  0.0212155   
5           MLPClassifier    0.900277    0.96283  0.978371  0.0131099   
6      AdaBoostClassifier    0.814033   0.934718  0.978372  0.0306336   
1      LogisticRegression    0.236318   0.600782  0.719946  0.0930826   
7                     SVC           0   0.692629  0.963782   0.199091   
3    ExtraTreesClassifier     0.64916   0.893101  0.982845   0.104805   
4  RandomForestClassifier    0.805009   0.919423  0.959073   0.043545   
9    KNeighborsClassifier     0.84359   0.892937  0.936855  0.0266311   
2           SGDClassifier -0.00368884   0.475548  0.720796   0.193457   

        acc       auc           conf_matrix     f1_c0      f1_c1       kappa  \
0  0.648936  0.822581  [[240, 132], [0, 4]]  0.784314  0.0571429   0.0372439   
8  0.922872   0.71371   [[345, 27], [2, 2]]  0.959666   0.121212    0.104468   
5  0.976064  0.616935    [[366, 6], [3, 1]]  0.987854   0.181818    0.170588   
6  0.970745  0.614247    [[364, 8], [3, 1]]  0.985115   0.153846    0.141196   
1  0.723404  0.612903  [[270, 102], [2, 2]]  0.838509   0.037037   0.0168946   
7  0.965426  0.611559   [[362, 10], [3, 1]]  0.982361   0.133333    0.119597   
3  0.962766  0.610215   [[361, 11], [3, 1]]  0.980978      0.125    0.110811   
4  0.954787  0.606183   [[358, 14], [3, 1]]  0.976808   0.105263   0.0899772   
9  0.933511   0.59543   [[350, 22], [3, 1]]  0.965517  0.0740741   0.0569823   
2  0.702128  0.478495  [[263, 109], [3, 1]]  0.824451  0.0175439 -0.00304878   

  model_score   prec_c0     prec_c1    rec_c0 rec_c1  
0    0.137751         1   0.0294118  0.645161      1  
8    0.164358  0.994236   0.0689655  0.927419    0.5  
5    0.177507   0.99187    0.142857  0.983871   0.25  
6    0.153364  0.991826    0.111111  0.978495   0.25  
1   0.0517889  0.992647   0.0192308  0.725806    0.5  
7    0.135829  0.991781   0.0909091  0.973118   0.25  
3    0.128656  0.991758   0.0833333   0.97043   0.25  
4    0.111323   0.99169   0.0666667  0.962366   0.25  
9   0.0817082  0.991501   0.0434783   0.94086   0.25  
2 -0.00969932  0.988722  0.00909091  0.706989   0.25  
Elapsed time 44.61 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv 
datetime: 2017-05-11 14:32:04.387000 
pca_target: 0 	 poly degree: 0 	 kselect: 20 
Imbalance: ClusterCentroids(estimator=None, n_jobs=1, random_state=None, ratio='auto') 
Extended target (count):  31485 325
('Total : Processed (count): ', (1252L, 20L), 13)
Final feature (count):  (1252L, 20L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.606 	0.126 	0.031 	0.801 	0.776 	0.626
[[224 148]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.60      0.75       372
          1       0.03      1.00      0.05         4

avg / total       0.99      0.61      0.74       376


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.001, class_weight={1: 3}, dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.492 	0.100 	0.020 	0.743 	0.698 	0.512
[[181 191]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.49      0.65       372
          1       0.02      1.00      0.04         4

avg / total       0.99      0.49      0.65       376


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.001, average=False, class_weight={1: 50}, epsilon=0.1,
       eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='modified_huber', n_iter=5, n_jobs=4,
       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.492 	0.100 	0.020 	0.743 	0.698 	0.512
[[181 191]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.49      0.65       372
          1       0.02      1.00      0.04         4

avg / total       0.99      0.49      0.65       376


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 50},
           criterion='entropy', max_depth=16, max_features=0.75,
           max_leaf_nodes=None, min_impurity_split=1e-07,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=4,
           oob_score=False, random_state=None, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.771 	0.185 	0.066 	0.884 	0.877 	0.787
[[286  86]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.77      0.87       372
          1       0.04      1.00      0.09         4

avg / total       0.99      0.77      0.86       376


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight='balanced',
            criterion='entropy', max_depth=16, max_features=0.33,
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.657 	0.034 	0.010 	0.579 	0.574 	0.324
[[245 127]
 [  2   2]]
             precision    recall  f1-score   support

          0       0.99      0.66      0.79       372
          1       0.02      0.50      0.03         4

avg / total       0.98      0.66      0.78       376


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.5, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.737 	0.169 	0.055 	0.867 	0.857 	0.753
[[273  99]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.73      0.85       372
          1       0.04      1.00      0.07         4

avg / total       0.99      0.74      0.84       376


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 500}, criterion='gini', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=2.0, n_estimators=15, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.625 	0.131 	0.034 	0.810 	0.788 	0.645
[[231 141]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.62      0.77       372
          1       0.03      1.00      0.05         4

avg / total       0.99      0.62      0.76       376


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.5, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='linear',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.548 	0.112 	0.025 	0.772 	0.737 	0.568
[[202 170]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.54      0.70       372
          1       0.02      1.00      0.04         4

avg / total       0.99      0.55      0.70       376


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 500}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Ran...wski',
           metric_params=None, n_jobs=4, n_neighbors=4, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.497 	0.101 	0.020 	0.746 	0.701 	0.517
[[183 189]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.49      0.66       372
          1       0.02      1.00      0.04         4

avg / total       0.99      0.50      0.65       376


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=5, p=2,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.537 	0.109 	0.024 	0.766 	0.730 	0.557
[[198 174]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.53      0.69       372
          1       0.02      1.00      0.04         4

avg / total       0.99      0.54      0.69       376


                estimator  min_score  mean_score  max_score  sd_score  \
3    ExtraTreesClassifier  -0.624311   -0.239569   0.239411  0.140442   
5           MLPClassifier  -0.496011   -0.362557    -0.1283  0.111294   
6      AdaBoostClassifier  -0.683856   -0.316383   0.350522  0.157353   
0              GaussianNB  0.0171889   0.0171889  0.0171889         0   
7                     SVC  -0.496011   0.0917859   0.496011  0.242441   
9    KNeighborsClassifier  -0.496011   -0.230152     0.2566  0.176308   
8        VotingClassifier  -0.367711  0.00744079     0.3849   0.16591   
1      LogisticRegression  -0.683856  -0.0131341   0.350522  0.197698   
2           SGDClassifier  -0.572745    0.177335   0.589933  0.204794   
4  RandomForestClassifier  -0.402089  -0.0340907   0.367711  0.153164   

        acc       auc           conf_matrix     f1_c0      f1_c1       kappa  \
3  0.771277  0.884409   [[286, 86], [0, 4]]  0.869301  0.0851064   0.0660813   
5  0.736702  0.866935   [[273, 99], [0, 4]]  0.846512  0.0747664   0.0554202   
6     0.625  0.810484  [[231, 141], [0, 4]]  0.766169  0.0536913   0.0336833   
0  0.606383  0.801075  [[224, 148], [0, 4]]  0.751678  0.0512821   0.0311978   
7  0.547872  0.771505  [[202, 170], [0, 4]]  0.703833  0.0449438   0.0246582   
9  0.537234  0.766129  [[198, 174], [0, 4]]  0.694737   0.043956    0.023639   
8   0.49734  0.745968  [[183, 189], [0, 4]]  0.659459  0.0406091   0.0201853   
1  0.492021   0.74328  [[181, 191], [0, 4]]  0.654611   0.040201   0.0197641   
2  0.492021   0.74328  [[181, 191], [0, 4]]  0.654611   0.040201   0.0197641   
4  0.656915  0.579301  [[245, 127], [2, 2]]  0.791599  0.0300752  0.00963737   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
3     0.18485         1  0.0444444  0.768817      1  
5    0.168819         1   0.038835  0.733871      1  
6    0.130882         1  0.0275862  0.620968      1  
0    0.125881         1  0.0263158  0.602151      1  
7    0.111727         1  0.0229885  0.543011      1  
9    0.109366         1  0.0224719  0.532258      1  
8    0.100973         1  0.0207254  0.491935      1  
1   0.0999035         1  0.0205128  0.486559      1  
2   0.0999035         1  0.0205128  0.486559      1  
4   0.0342742  0.991903  0.0155039  0.658602    0.5  
Elapsed time 14.91 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv 
datetime: 2017-05-11 14:46:58.922000 
pca_target: 0 	 poly degree: 0 	 kselect: 0 
Imbalance: None 
Extended target (count):  31485 325
('Total : Processed (count): ', (1252L, 20L), 13)
Final feature (count):  (1252L, 20L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.617 	0.129 	0.033 	0.806 	0.783 	0.637
[[228 144]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.61      0.76       372
          1       0.03      1.00      0.05         4

avg / total       0.99      0.62      0.75       376


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.001, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.503 	0.102 	0.021 	0.749 	0.705 	0.522
[[185 187]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.50      0.66       372
          1       0.02      1.00      0.04         4

avg / total       0.99      0.50      0.66       376


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=1, average=False, class_weight={1: 50}, epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='constant', loss='squared_hinge', n_iter=5, n_jobs=4,
       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.981 	-0.009 	-0.009 	0.496 	0.000 	0.000
[[369   3]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       372
          1       0.00      0.00      0.00         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 500},
           criterion='entropy', max_depth=8, max_features=0.33,
           max_leaf_nodes=None, min_impurity_split=1e-07,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=15, n_jobs=4,
           oob_score=False, random_state=None, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.902 	0.056 	0.033 	0.579 	0.477 	0.212
[[338  34]
 [  3   1]]
             precision    recall  f1-score   support

          0       0.99      0.91      0.95       372
          1       0.03      0.25      0.05         4

avg / total       0.98      0.90      0.94       376


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       372
          1       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.5, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(500,), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       372
          1       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight='balanced', criterion='entropy',
            max_depth=32, max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=1.0, n_estimators=50, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.965 	-0.016 	-0.015 	0.488 	0.000 	0.000
[[363   9]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.98      0.98       372
          1       0.00      0.00      0.00         4

avg / total       0.98      0.97      0.97       376


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='linear',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.551 	0.112 	0.025 	0.773 	0.739 	0.570
[[203 169]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.55      0.71       372
          1       0.02      1.00      0.05         4

avg / total       0.99      0.55      0.70       376


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       372
          1       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=1,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       372
          1       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


                estimator  min_score   mean_score  max_score    sd_score  \
0              GaussianNB  0.0372741    0.0372741  0.0372741           0   
7                     SVC -0.0572367  -0.00665292  0.0938753   0.0341092   
1      LogisticRegression -0.0540588   0.00683704  0.0963076   0.0385736   
3    ExtraTreesClassifier -0.0351981  -0.00362852  0.0630676  0.00952302   
4  RandomForestClassifier  -0.019116 -0.000709494          0  0.00202798   
5           MLPClassifier -0.0135878  -0.00986132          0  0.00335852   
8        VotingClassifier -0.0131381  -0.00377919          0  0.00386009   
9    KNeighborsClassifier -0.0125892  -0.00351496          0  0.00515942   
2           SGDClassifier -0.0902127    0.0187807   0.242036   0.0382629   
6      AdaBoostClassifier -0.0179785  -0.00786381   0.189252    0.012547   

        acc       auc           conf_matrix     f1_c0      f1_c1       kappa  \
0  0.617021  0.806452  [[228, 144], [0, 4]]      0.76  0.0526316   0.0325901   
7  0.550532  0.772849  [[203, 169], [0, 4]]  0.706087  0.0451977   0.0249202   
1   0.50266  0.748656  [[185, 187], [0, 4]]  0.664273  0.0410256   0.0206151   
3  0.901596  0.579301   [[338, 34], [3, 1]]  0.948107  0.0512821   0.0328142   
4  0.989362       0.5    [[372, 0], [4, 0]]  0.994652          0           0   
5  0.989362       0.5    [[372, 0], [4, 0]]  0.994652          0           0   
8  0.989362       0.5    [[372, 0], [4, 0]]  0.994652          0           0   
9  0.989362       0.5    [[372, 0], [4, 0]]  0.994652          0           0   
2  0.981383  0.495968    [[369, 3], [4, 0]]  0.990604          0 -0.00920245   
6  0.965426  0.487903    [[363, 9], [4, 0]]  0.982409          0  -0.0149502   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
0    0.128705         1   0.027027  0.612903      1  
7    0.112327         1  0.0231214  0.545699      1  
1    0.102053         1  0.0209424  0.497312      1  
3   0.0560015  0.991202  0.0285714  0.908602   0.25  
4           0  0.989362          0         1      0  
5           0  0.989362          0         1      0  
8           0  0.989362          0         1      0  
9           0  0.989362          0         1      0  
2 -0.00929961  0.989276          0  0.991935      0  
6  -0.0162385  0.989101          0  0.975806      0  
Elapsed time 23.75 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv 
datetime: 2017-05-11 15:10:43.775000 
pca_target: 0 	 poly degree: 0 	 kselect: 0 
Imbalance: SMOTE(k=None, k_neighbors=5, kind='regular', m=None, m_neighbors=10, n_jobs=1,
   out_step=0.5, random_state=None, ratio='auto', svm_estimator=None) 
Extended target (count):  31485 325
('Total : Processed (count): ', (1252L, 20L), 13)
Final feature (count):  (1252L, 20L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.636 	0.134 	0.035 	0.816 	0.795 	0.655
[[235 137]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.63      0.77       372
          1       0.03      1.00      0.06         4

avg / total       0.99      0.64      0.77       376


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=5, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.723 	0.052 	0.017 	0.613 	0.602 	0.355
[[270 102]
 [  2   2]]
             precision    recall  f1-score   support

          0       0.99      0.73      0.84       372
          1       0.02      0.50      0.04         4

avg / total       0.98      0.72      0.83       376


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.001, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='modified_huber', n_iter=5, n_jobs=4,
       penalty='none', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.771 	0.007 	0.002 	0.513 	0.441 	0.184
[[289  83]
 [  3   1]]
             precision    recall  f1-score   support

          0       0.99      0.78      0.87       372
          1       0.01      0.25      0.02         4

avg / total       0.98      0.77      0.86       376


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=32, max_features=0.75, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=50, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.971 	0.290 	0.255 	0.738 	0.699 	0.465
[[363   9]
 [  2   2]]
             precision    recall  f1-score   support

          0       0.99      0.98      0.99       372
          1       0.18      0.50      0.27         4

avg / total       0.99      0.97      0.98       376


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight='balanced',
            criterion='entropy', max_depth=None, max_features=0.33,
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.955 	0.227 	0.176 	0.730 	0.693 	0.458
[[357  15]
 [  2   2]]
             precision    recall  f1-score   support

          0       0.99      0.96      0.98       372
          1       0.12      0.50      0.19         4

avg / total       0.99      0.95      0.97       376


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.01, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.976 	0.178 	0.171 	0.617 	0.496 	0.228
[[366   6]
 [  3   1]]
             precision    recall  f1-score   support

          0       0.99      0.98      0.99       372
          1       0.14      0.25      0.18         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=8,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=1.0, n_estimators=80, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.973 	0.305 	0.275 	0.739 	0.699 	0.466
[[364   8]
 [  2   2]]
             precision    recall  f1-score   support

          0       0.99      0.98      0.99       372
          1       0.20      0.50      0.29         4

avg / total       0.99      0.97      0.98       376


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=10, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.965 	0.136 	0.120 	0.612 	0.493 	0.226
[[362  10]
 [  3   1]]
             precision    recall  f1-score   support

          0       0.99      0.97      0.98       372
          1       0.09      0.25      0.13         4

avg / total       0.98      0.97      0.97       376


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=10.0, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', ...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.934 	0.180 	0.122 	0.719 	0.685 	0.449
[[349  23]
 [  2   2]]
             precision    recall  f1-score   support

          0       0.99      0.94      0.97       372
          1       0.08      0.50      0.14         4

avg / total       0.98      0.93      0.96       376


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=1,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.934 	0.082 	0.057 	0.595 	0.485 	0.219
[[350  22]
 [  3   1]]
             precision    recall  f1-score   support

          0       0.99      0.94      0.97       372
          1       0.04      0.25      0.07         4

avg / total       0.98      0.93      0.96       376


                estimator min_score mean_score max_score    sd_score  \
0              GaussianNB  0.627268   0.627268  0.627268           0   
6      AdaBoostClassifier  0.800132   0.935978  0.979514   0.0312513   
3    ExtraTreesClassifier  0.649151   0.894079  0.986308    0.105427   
4  RandomForestClassifier   0.80993   0.922809  0.963748   0.0448524   
8        VotingClassifier  0.833107    0.88653   0.92567   0.0216029   
5           MLPClassifier  0.946581   0.966064  0.985126  0.00796048   
1      LogisticRegression  0.241813   0.602218  0.722904   0.0914926   
7                     SVC         0   0.692355  0.959129    0.198021   
9    KNeighborsClassifier  0.836587   0.885421  0.931251   0.0279032   
2           SGDClassifier -0.106494   0.473804    0.7392    0.195051   

        acc       auc           conf_matrix     f1_c0      f1_c1       kappa  \
0  0.635638   0.81586  [[235, 137], [0, 4]]    0.7743  0.0551724   0.0352113   
6  0.973404  0.739247    [[364, 8], [2, 2]]   0.98645   0.285714    0.274691   
3  0.970745  0.737903    [[363, 9], [2, 2]]  0.985075   0.266667    0.255043   
4  0.954787  0.729839   [[357, 15], [2, 2]]  0.976744   0.190476    0.176289   
8  0.933511  0.719086   [[349, 23], [2, 2]]  0.965422   0.137931    0.121824   
5  0.976064  0.616935    [[366, 6], [3, 1]]  0.987854   0.181818    0.170588   
1  0.723404  0.612903  [[270, 102], [2, 2]]  0.838509   0.037037   0.0168946   
7  0.965426  0.611559   [[362, 10], [3, 1]]  0.982361   0.133333    0.119597   
9  0.933511   0.59543   [[350, 22], [3, 1]]  0.965517  0.0740741   0.0569823   
2  0.771277  0.513441   [[289, 83], [3, 1]]  0.870482  0.0227273  0.00246792   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
0     0.13387         1  0.0283688   0.63172      1  
6    0.305097  0.994536        0.2  0.978495    0.5  
3     0.28966  0.994521   0.181818  0.975806    0.5  
4    0.226978  0.994429   0.117647  0.959677    0.5  
8    0.180436  0.994302       0.08  0.938172    0.5  
5    0.177507   0.99187   0.142857  0.983871   0.25  
1   0.0517889  0.992647  0.0192308  0.725806    0.5  
7    0.135829  0.991781  0.0909091  0.973118   0.25  
9   0.0817082  0.991501  0.0434783   0.94086   0.25  
2  0.00662106  0.989726  0.0119048  0.776882   0.25  
Elapsed time 44.67 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv 
datetime: 2017-05-11 15:55:24.155000 
pca_target: 0 	 poly degree: 0 	 kselect: 0 
Imbalance: ClusterCentroids(estimator=None, n_jobs=1, random_state=None, ratio='auto') 
Extended target (count):  31485 325
('Total : Processed (count): ', (1252L, 20L), 13)
Final feature (count):  (1252L, 20L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.606 	0.126 	0.031 	0.801 	0.776 	0.626
[[224 148]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.60      0.75       372
          1       0.03      1.00      0.05         4

avg / total       0.99      0.61      0.74       376


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.01, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=5, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.529 	0.108 	0.023 	0.762 	0.724 	0.549
[[195 177]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.52      0.69       372
          1       0.02      1.00      0.04         4

avg / total       0.99      0.53      0.68       376


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.0001, average=False, class_weight={1: 15}, epsilon=0.1,
       eta0=0.001, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='modified_huber', n_iter=5, n_jobs=4,
       penalty='l2', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.503 	0.102 	0.021 	0.749 	0.705 	0.522
[[185 187]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.50      0.66       372
          1       0.02      1.00      0.04         4

avg / total       0.99      0.50      0.66       376


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=16, max_features='auto', max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=30, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.702 	0.046 	0.014 	0.602 	0.593 	0.345
[[262 110]
 [  2   2]]
             precision    recall  f1-score   support

          0       0.99      0.70      0.82       372
          1       0.02      0.50      0.03         4

avg / total       0.98      0.70      0.82       376


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight='balanced',
            criterion='entropy', max_depth=None, max_features=0.33,
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.617 	0.077 	0.020 	0.683 	0.679 	0.468
[[229 143]
 [  1   3]]
             precision    recall  f1-score   support

          0       1.00      0.62      0.76       372
          1       0.02      0.75      0.04         4

avg / total       0.99      0.62      0.75       376


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.5, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.699 	0.154 	0.046 	0.848 	0.834 	0.717
[[259 113]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.70      0.82       372
          1       0.03      1.00      0.07         4

avg / total       0.99      0.70      0.81       376


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='entropy', max_depth=8,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=0.5, n_estimators=80, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.561 	0.115 	0.026 	0.778 	0.746 	0.581
[[207 165]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.56      0.72       372
          1       0.02      1.00      0.05         4

avg / total       0.99      0.56      0.71       376


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.1, cache_size=200, class_weight='balanced', coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='linear',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.553 	0.113 	0.025 	0.774 	0.741 	0.573
[[204 168]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.55      0.71       372
          1       0.02      1.00      0.05         4

avg / total       0.99      0.55      0.70       376


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 500}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Ran...wski',
           metric_params=None, n_jobs=4, n_neighbors=4, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.495 	0.100 	0.020 	0.745 	0.699 	0.514
[[182 190]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.49      0.66       372
          1       0.02      1.00      0.04         4

avg / total       0.99      0.49      0.65       376


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=5, p=1,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.548 	0.061 	0.014 	0.648 	0.640 	0.418
[[203 169]
 [  1   3]]
             precision    recall  f1-score   support

          0       1.00      0.55      0.70       372
          1       0.02      0.75      0.03         4

avg / total       0.98      0.55      0.70       376


                estimator  min_score mean_score  max_score   sd_score  \
5           MLPClassifier  -0.718234  -0.547717  -0.333333  0.0925268   
0              GaussianNB  0.0171889  0.0171889  0.0171889          0   
6      AdaBoostClassifier  -0.589933   0.079845   0.607122   0.187172   
7                     SVC  -0.555556  0.0238455   0.402089   0.275225   
1      LogisticRegression  -0.239411   0.109955     0.5132   0.170124   
2           SGDClassifier  -0.607122   0.215966     0.5132   0.203683   
8        VotingClassifier  -0.461633 -0.0910204     0.3849   0.208678   
4  RandomForestClassifier  -0.111111   0.231189   0.589933   0.114831   
9    KNeighborsClassifier  -0.478822  -0.258838     0.2566   0.141414   
3    ExtraTreesClassifier    -0.2566  0.0660341   0.478822   0.149511   

        acc       auc           conf_matrix     f1_c0      f1_c1      kappa  \
5  0.699468  0.848118  [[259, 113], [0, 4]]  0.820919  0.0661157  0.0464991   
0  0.606383  0.801075  [[224, 148], [0, 4]]  0.751678  0.0512821  0.0311978   
6   0.56117  0.778226  [[207, 165], [0, 4]]  0.715026  0.0462428  0.0259985   
7  0.553191  0.774194  [[204, 168], [0, 4]]  0.708333  0.0454545  0.0251852   
1  0.529255  0.762097  [[195, 177], [0, 4]]  0.687831  0.0432432  0.0229035   
2   0.50266  0.748656  [[185, 187], [0, 4]]  0.664273  0.0410256  0.0206151   
8  0.494681  0.744624  [[182, 190], [0, 4]]   0.65704   0.040404  0.0199737   
4  0.617021  0.682796  [[229, 143], [1, 3]]  0.760797       0.04  0.0196987   
9  0.547872  0.647849  [[203, 169], [1, 3]]  0.704861  0.0340909  0.0135802   
3  0.702128  0.602151  [[262, 110], [2, 2]]  0.823899  0.0344828  0.0142322   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
5    0.154282         1   0.034188  0.696237      1  
0    0.125881         1  0.0263158  0.602151      1  
6    0.114763         1  0.0236686  0.556452      1  
7     0.11293         1  0.0232558  0.548387      1  
1    0.107631         1  0.0220994  0.524194      1  
2    0.102053         1  0.0209424  0.497312      1  
8    0.100437         1  0.0206186  0.489247      1  
4   0.0769586  0.995652  0.0205479  0.615591   0.75  
9   0.0608936  0.995098  0.0174419  0.545699   0.75  
3   0.0458312  0.992424  0.0178571  0.704301    0.5  
Elapsed time 14.80 mins 

************************************************************







Standard, lagged(3,4)x1, poly(2), None, UNtruncated



pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv 
datetime: 2017-05-11 22:40:28.333000 
pca_target: 0 	 poly degree: 2 	 kselect: 40 
Imbalance: None 
Extended target (count):  31485 325
('Total : Processed (count): ', (1252L, 231L), 13)
Final feature (count):  (1252L, 231L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.734 	0.055 	0.018 	0.618 	0.607 	0.360
[[274  98]
 [  2   2]]
             precision    recall  f1-score   support

          0       0.99      0.74      0.85       372
          1       0.02      0.50      0.04         4

avg / total       0.98      0.73      0.84       376


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.001, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.551 	0.112 	0.025 	0.773 	0.739 	0.570
[[203 169]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.55      0.71       372
          1       0.02      1.00      0.05         4

avg / total       0.99      0.55      0.70       376


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=1, average=False, class_weight={1: 15}, epsilon=0.1,
       eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='invscaling', loss='perceptron', n_iter=5, n_jobs=4,
       penalty='l2', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.920 	0.069 	0.045 	0.589 	0.482 	0.216
[[345  27]
 [  3   1]]
             precision    recall  f1-score   support

          0       0.99      0.93      0.96       372
          1       0.04      0.25      0.06         4

avg / total       0.98      0.92      0.95       376


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 500}, criterion='gini',
           max_depth=16, max_features=0.75, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=50, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.944 	0.298 	0.208 	0.848 	0.842 	0.696
[[352  20]
 [  1   3]]
             precision    recall  f1-score   support

          0       1.00      0.95      0.97       372
          1       0.13      0.75      0.22         4

avg / total       0.99      0.94      0.96       376


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=30, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       372
          1       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.5, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	-0.005 	-0.004 	0.499 	0.000 	0.000
[[371   1]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       372
          1       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 500}, criterion='gini', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=2.0, n_estimators=80, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.957 	-0.019 	-0.016 	0.484 	0.000 	0.000
[[360  12]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.97      0.98       372
          1       0.00      0.00      0.00         4

avg / total       0.98      0.96      0.97       376


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.01, cache_size=200, class_weight={1: 500}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.521 	0.106 	0.022 	0.758 	0.718 	0.541
[[192 180]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.52      0.68       372
          1       0.02      1.00      0.04         4

avg / total       0.99      0.52      0.67       376


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       372
          1       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=1,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       372
          1       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


                estimator   min_score   mean_score   max_score    sd_score  \
3    ExtraTreesClassifier  -0.0360363  -0.00441404   0.0583298  0.00996043   
1      LogisticRegression  -0.0801201  -0.00114427    0.106836   0.0442356   
7                     SVC  -0.0658899    -0.012921    0.104465   0.0362235   
0              GaussianNB   0.0448181    0.0448181   0.0448181           0   
2           SGDClassifier   -0.194764    0.0235556    0.223724   0.0403686   
4  RandomForestClassifier -0.00820512 -0.000331092           0  0.00102406   
8        VotingClassifier  -0.0130618  -0.00428408           0  0.00369673   
9    KNeighborsClassifier  -0.0101401  -0.00293884           0  0.00401578   
5           MLPClassifier  -0.0144439  -0.00856091 -0.00162828  0.00353296   
6      AdaBoostClassifier  -0.0168769  -0.00757845    0.158858   0.0117795   

        acc       auc           conf_matrix     f1_c0      f1_c1      kappa  \
3  0.944149  0.848118   [[352, 20], [1, 3]]  0.971034   0.222222   0.207865   
1  0.550532  0.772849  [[203, 169], [0, 4]]  0.706087  0.0451977  0.0249202   
7  0.521277  0.758065  [[192, 180], [0, 4]]  0.680851  0.0425532  0.0221914   
0  0.734043   0.61828   [[274, 98], [2, 2]]  0.845679  0.0384615  0.0183793   
2  0.920213   0.58871   [[345, 27], [3, 1]]  0.958333     0.0625  0.0447154   
4  0.989362       0.5    [[372, 0], [4, 0]]  0.994652          0          0   
8  0.989362       0.5    [[372, 0], [4, 0]]  0.994652          0          0   
9  0.989362       0.5    [[372, 0], [4, 0]]  0.994652          0          0   
5  0.986702  0.498656    [[371, 1], [4, 0]]  0.993307          0 -0.0042735   
6  0.957447  0.483871   [[360, 12], [4, 0]]  0.978261          0 -0.0162162   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
3    0.298062  0.997167   0.130435  0.946237   0.75  
1    0.112327         1  0.0231214  0.545699      1  
7    0.105925         1  0.0217391  0.516129      1  
0   0.0549271  0.992754       0.02  0.736559    0.5  
2    0.069332  0.991379  0.0357143  0.927419   0.25  
4           0  0.989362          0         1      0  
8           0  0.989362          0         1      0  
9           0  0.989362          0         1      0  
5  -0.0053548  0.989333          0  0.997312      0  
6  -0.0188278  0.989011          0  0.967742      0  
Elapsed time 27.21 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv 
datetime: 2017-05-11 23:07:41.104000 
pca_target: 0 	 poly degree: 2 	 kselect: 40 
Imbalance: SMOTE(k=None, k_neighbors=5, kind='regular', m=None, m_neighbors=10, n_jobs=1,
   out_step=0.5, random_state=None, ratio='auto', svm_estimator=None) 
Extended target (count):  31485 325
('Total : Processed (count): ', (1252L, 231L), 13)
Final feature (count):  (1252L, 231L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.646 	0.137 	0.037 	0.821 	0.802 	0.665
[[239 133]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.64      0.78       372
          1       0.03      1.00      0.06         4

avg / total       0.99      0.65      0.77       376


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=10, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.785 	0.192 	0.071 	0.891 	0.884 	0.799
[[291  81]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.78      0.88       372
          1       0.05      1.00      0.09         4

avg / total       0.99      0.78      0.87       376


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.001, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.001, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='modified_huber', n_iter=5, n_jobs=4,
       penalty='none', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.676 	0.146 	0.042 	0.836 	0.820 	0.694
[[250 122]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.67      0.80       372
          1       0.03      1.00      0.06         4

avg / total       0.99      0.68      0.80       376


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 15}, criterion='gini',
           max_depth=None, max_features=0.33, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=50, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.944 	0.094 	0.071 	0.601 	0.488 	0.221
[[354  18]
 [  3   1]]
             precision    recall  f1-score   support

          0       0.99      0.95      0.97       372
          1       0.05      0.25      0.09         4

avg / total       0.98      0.94      0.96       376


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 500},
            criterion='entropy', max_depth=32, max_features='auto',
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.920 	0.069 	0.045 	0.589 	0.482 	0.216
[[345  27]
 [  3   1]]
             precision    recall  f1-score   support

          0       0.99      0.93      0.96       372
          1       0.04      0.25      0.06         4

avg / total       0.98      0.92      0.95       376


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.01, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(500,), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.965 	0.264 	0.223 	0.735 	0.697 	0.462
[[361  11]
 [  2   2]]
             precision    recall  f1-score   support

          0       0.99      0.97      0.98       372
          1       0.15      0.50      0.24         4

avg / total       0.99      0.97      0.97       376


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 50}, criterion='gini', max_depth=32,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=1.0, n_estimators=15, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.936 	0.085 	0.060 	0.597 	0.486 	0.220
[[351  21]
 [  3   1]]
             precision    recall  f1-score   support

          0       0.99      0.94      0.97       372
          1       0.05      0.25      0.08         4

avg / total       0.98      0.94      0.96       376


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=10, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.965 	0.136 	0.120 	0.612 	0.493 	0.226
[[362  10]
 [  3   1]]
             precision    recall  f1-score   support

          0       0.99      0.97      0.98       372
          1       0.09      0.25      0.13         4

avg / total       0.98      0.97      0.97       376


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=10.0, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', ...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.910 	0.148 	0.088 	0.707 	0.676 	0.438
[[340  32]
 [  2   2]]
             precision    recall  f1-score   support

          0       0.99      0.91      0.95       372
          1       0.06      0.50      0.11         4

avg / total       0.98      0.91      0.94       376


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.934 	0.082 	0.057 	0.595 	0.485 	0.219
[[350  22]
 [  3   1]]
             precision    recall  f1-score   support

          0       0.99      0.94      0.97       372
          1       0.04      0.25      0.07         4

avg / total       0.98      0.93      0.96       376


                estimator min_score mean_score max_score   sd_score       acc  \
1      LogisticRegression  0.418919   0.599758  0.777276  0.0724784  0.784574   
2           SGDClassifier -0.159141   0.453783   0.70262   0.193275  0.675532   
0              GaussianNB  0.641199   0.641199  0.641199          0  0.646277   
5           MLPClassifier  0.921783   0.964458  0.981771  0.0119836  0.965426   
8        VotingClassifier  0.819158   0.871991  0.913106  0.0250521  0.909574   
7                     SVC  0.292557   0.691549  0.970505    0.16319  0.965426   
3    ExtraTreesClassifier  0.660818   0.866623  0.955329  0.0937561  0.944149   
6      AdaBoostClassifier  0.755199   0.897544  0.945839  0.0346817   0.93617   
9    KNeighborsClassifier  0.835212   0.885586  0.933231  0.0327782  0.933511   
4  RandomForestClassifier  0.781774   0.883031  0.934295  0.0468347  0.920213   

        auc           conf_matrix     f1_c0      f1_c1      kappa model_score  \
1  0.891129   [[291, 81], [0, 4]]  0.877828  0.0898876  0.0710102    0.191865   
2  0.836022  [[250, 122], [0, 4]]  0.803859  0.0615385  0.0417781    0.146064   
0  0.821237  [[239, 133], [0, 4]]  0.782324  0.0567376  0.0368259    0.136961   
5  0.735215   [[361, 11], [2, 2]]  0.982313   0.235294   0.222646    0.264163   
8  0.706989   [[340, 32], [2, 2]]  0.952381   0.105263  0.0878995     0.14809   
7  0.611559   [[362, 10], [3, 1]]  0.982361   0.133333   0.119597    0.135829   
3  0.600806   [[354, 18], [3, 1]]  0.971193  0.0869565  0.0706215   0.0944298   
6  0.596774   [[351, 21], [3, 1]]  0.966942  0.0769231       0.06   0.0846015   
9   0.59543   [[350, 22], [3, 1]]  0.965517  0.0740741  0.0569823   0.0817082   
4   0.58871   [[345, 27], [3, 1]]  0.958333     0.0625  0.0447154    0.069332   

    prec_c0    prec_c1    rec_c0 rec_c1  
1         1  0.0470588  0.782258      1  
2         1   0.031746  0.672043      1  
0         1  0.0291971  0.642473      1  
5   0.99449   0.153846   0.97043    0.5  
8  0.994152  0.0588235  0.913978    0.5  
7  0.991781  0.0909091  0.973118   0.25  
3  0.991597  0.0526316  0.951613   0.25  
6  0.991525  0.0454545  0.943548   0.25  
9  0.991501  0.0434783   0.94086   0.25  
4  0.991379  0.0357143  0.927419   0.25  
Elapsed time 61.64 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv 
datetime: 2017-05-12 00:09:19.238000 
pca_target: 0 	 poly degree: 2 	 kselect: 40 
Imbalance: ClusterCentroids(estimator=None, n_jobs=1, random_state=None, ratio='auto') 
Extended target (count):  31485 325
('Total : Processed (count): ', (1252L, 231L), 13)
Final feature (count):  (1252L, 231L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.652 	0.139 	0.038 	0.824 	0.805 	0.671
[[241 131]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.65      0.79       372
          1       0.03      1.00      0.06         4

avg / total       0.99      0.65      0.78       376


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.521 	0.106 	0.022 	0.758 	0.718 	0.541
[[192 180]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.52      0.68       372
          1       0.02      1.00      0.04         4

avg / total       0.99      0.52      0.67       376


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.0001, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.001, fit_intercept=True, l1_ratio=0.15,
       learning_rate='invscaling', loss='perceptron', n_iter=5, n_jobs=4,
       penalty='none', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.511 	0.104 	0.021 	0.753 	0.711 	0.530
[[188 184]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.51      0.67       372
          1       0.02      1.00      0.04         4

avg / total       0.99      0.51      0.66       376


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 500},
           criterion='entropy', max_depth=32, max_features=0.75,
           max_leaf_nodes=None, min_impurity_split=1e-07,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=15, n_jobs=4,
           oob_score=False, random_state=None, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.590 	0.122 	0.029 	0.793 	0.766 	0.610
[[218 154]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.59      0.74       372
          1       0.03      1.00      0.05         4

avg / total       0.99      0.59      0.73       376


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3},
            criterion='entropy', max_depth=32, max_features='auto',
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=15, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.734 	0.055 	0.018 	0.618 	0.607 	0.360
[[274  98]
 [  2   2]]
             precision    recall  f1-score   support

          0       0.99      0.74      0.85       372
          1       0.02      0.50      0.04         4

avg / total       0.98      0.73      0.84       376


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.01, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.697 	0.099 	0.030 	0.723 	0.723 	0.525
[[259 113]
 [  1   3]]
             precision    recall  f1-score   support

          0       1.00      0.70      0.82       372
          1       0.03      0.75      0.05         4

avg / total       0.99      0.70      0.81       376


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 500}, criterion='gini', max_depth=8,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=0.5, n_estimators=15, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.777 	0.069 	0.026 	0.640 	0.624 	0.379
[[290  82]
 [  2   2]]
             precision    recall  f1-score   support

          0       0.99      0.78      0.87       372
          1       0.02      0.50      0.05         4

avg / total       0.98      0.78      0.86       376


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.1, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='linear',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.495 	0.100 	0.020 	0.745 	0.699 	0.514
[[182 190]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.49      0.66       372
          1       0.02      1.00      0.04         4

avg / total       0.99      0.49      0.65       376


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 500}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Ran...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.548 	0.112 	0.025 	0.772 	0.737 	0.568
[[202 170]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.54      0.70       372
          1       0.02      1.00      0.04         4

avg / total       0.99      0.55      0.70       376


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=3, p=4,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.622 	0.130 	0.033 	0.809 	0.786 	0.642
[[230 142]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.62      0.76       372
          1       0.03      1.00      0.05         4

avg / total       0.99      0.62      0.76       376


                estimator min_score mean_score max_score  sd_score       acc  \
0              GaussianNB  0.239411   0.239411  0.239411         0  0.651596   
9    KNeighborsClassifier -0.478822 -0.0104107  0.222222  0.219957   0.62234   
3    ExtraTreesClassifier   -0.5132 -0.0803136  0.367711  0.157509  0.590426   
8        VotingClassifier -0.367711  0.0502014  0.350522  0.229638  0.547872   
1      LogisticRegression -0.624311 -0.0332434  0.444444  0.188849  0.521277   
2           SGDClassifier -0.478822   0.273185  0.718234  0.154384  0.510638   
7                     SVC   -0.2566  0.0407384  0.478822  0.191285  0.494681   
5           MLPClassifier   -0.3849  -0.104244  0.239411  0.141974  0.696809   
6      AdaBoostClassifier -0.607122  -0.015363  0.496011  0.226475  0.776596   
4  RandomForestClassifier -0.718234  -0.239302    0.2566  0.189272  0.734043   

        auc           conf_matrix     f1_c0      f1_c1      kappa model_score  \
0  0.823925  [[241, 131], [0, 4]]  0.786297   0.057554   0.037668    0.138548   
9   0.80914  [[230, 142], [0, 4]]   0.76412  0.0533333   0.033314    0.130151   
3  0.793011  [[218, 154], [0, 4]]  0.738983  0.0493827  0.0292382    0.121803   
8  0.771505  [[202, 170], [0, 4]]  0.703833  0.0449438  0.0246582    0.111727   
1  0.758065  [[192, 180], [0, 4]]  0.680851  0.0425532  0.0221914    0.105925   
2  0.752688  [[188, 184], [0, 4]]  0.671429  0.0416667  0.0212766    0.103695   
7  0.744624  [[182, 190], [0, 4]]   0.65704   0.040404  0.0199737    0.100437   
5  0.723118  [[259, 113], [1, 3]]   0.81962       0.05  0.0300507   0.0991176   
6  0.639785   [[290, 82], [2, 2]]  0.873494  0.0454545  0.0256663    0.068859   
4   0.61828   [[274, 98], [2, 2]]  0.845679  0.0384615  0.0183793   0.0549271   

    prec_c0    prec_c1    rec_c0 rec_c1  
0         1  0.0296296  0.647849      1  
9         1  0.0273973   0.61828      1  
3         1  0.0253165  0.586022      1  
8         1  0.0229885  0.543011      1  
1         1  0.0217391  0.516129      1  
2         1  0.0212766  0.505376      1  
7         1  0.0206186  0.489247      1  
5  0.996154  0.0258621  0.696237   0.75  
6  0.993151  0.0238095   0.77957    0.5  
4  0.992754       0.02  0.736559    0.5  
Elapsed time 15.54 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv 
datetime: 2017-05-12 00:24:51.518000 
pca_target: 0 	 poly degree: 2 	 kselect: 0 
Imbalance: None 
Extended target (count):  31485 325
('Total : Processed (count): ', (1252L, 231L), 13)
Final feature (count):  (1252L, 231L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.673 	0.145 	0.041 	0.835 	0.818 	0.691
[[249 123]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.67      0.80       372
          1       0.03      1.00      0.06         4

avg / total       0.99      0.67      0.79       376


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.001, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.545 	0.111 	0.024 	0.770 	0.735 	0.565
[[201 171]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.54      0.70       372
          1       0.02      1.00      0.04         4

avg / total       0.99      0.55      0.69       376


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.5, average=False, class_weight={1: 50}, epsilon=0.1,
       eta0=0.001, fit_intercept=True, l1_ratio=0.15,
       learning_rate='constant', loss='modified_huber', n_iter=5, n_jobs=4,
       penalty='l2', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.875 	0.042 	0.022 	0.566 	0.469 	0.207
[[328  44]
 [  3   1]]
             precision    recall  f1-score   support

          0       0.99      0.88      0.93       372
          1       0.02      0.25      0.04         4

avg / total       0.98      0.88      0.92       376


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 500}, criterion='gini',
           max_depth=8, max_features='auto', max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.769 	0.184 	0.065 	0.883 	0.875 	0.784
[[285  87]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.77      0.87       372
          1       0.04      1.00      0.08         4

avg / total       0.99      0.77      0.86       376


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       372
          1       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.01, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.979 	-0.011 	-0.011 	0.495 	0.000 	0.000
[[368   4]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       372
          1       0.00      0.00      0.00         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 50}, criterion='gini', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=2.0, n_estimators=80, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.981 	-0.009 	-0.009 	0.496 	0.000 	0.000
[[369   3]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       372
          1       0.00      0.00      0.00         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.01, cache_size=200, class_weight={1: 500}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.476 	0.097 	0.019 	0.735 	0.686 	0.495
[[175 197]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.47      0.64       372
          1       0.02      1.00      0.04         4

avg / total       0.99      0.48      0.63       376


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       372
          1       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=1,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.989 	0.000 	0.000 	0.500 	0.000 	0.000
[[372   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       372
          1       0.00      0.00      0.00         4

avg / total       0.98      0.99      0.98       376


                estimator   min_score   mean_score   max_score    sd_score  \
3    ExtraTreesClassifier  -0.0367221  -0.00409199   0.0469045  0.00674608   
0              GaussianNB  0.00732248   0.00732248  0.00732248           0   
1      LogisticRegression  -0.0623675   -0.0150401   0.0825362   0.0269799   
7                     SVC  -0.0458896   -0.0120836   0.0613594   0.0180116   
2           SGDClassifier   -0.127876 -2.21955e-05     0.11188   0.0373892   
4  RandomForestClassifier  -0.0144576 -0.000531894           0  0.00153506   
8        VotingClassifier  -0.0127746  -0.00455233           0  0.00354887   
9    KNeighborsClassifier  -0.0122174  -0.00342086           0  0.00488457   
6      AdaBoostClassifier   -0.019368  -0.00650546     0.13191    0.013657   
5           MLPClassifier  -0.0142704   -0.0102329 -0.00556607  0.00209283   

        acc       auc           conf_matrix     f1_c0      f1_c1       kappa  \
3  0.768617  0.883065   [[285, 87], [0, 4]]   0.86758  0.0842105   0.0651578   
0  0.672872  0.834677  [[249, 123], [0, 4]]  0.801932  0.0610687   0.0412935   
1  0.545213  0.770161  [[201, 171], [0, 4]]  0.701571  0.0446927   0.0243991   
7  0.476064  0.735215  [[175, 197], [0, 4]]  0.639854  0.0390244   0.0185499   
2     0.875   0.56586   [[328, 44], [3, 1]]  0.933144  0.0408163   0.0217006   
4  0.989362       0.5    [[372, 0], [4, 0]]  0.994652          0           0   
8  0.989362       0.5    [[372, 0], [4, 0]]  0.994652          0           0   
9  0.989362       0.5    [[372, 0], [4, 0]]  0.994652          0           0   
6  0.981383  0.495968    [[369, 3], [4, 0]]  0.990604          0 -0.00920245   
5  0.978723  0.494624    [[368, 4], [4, 0]]  0.989247          0  -0.0107527   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
3     0.18351         1   0.043956  0.766129      1  
0    0.145197         1  0.0314961  0.669355      1  
1    0.111132         1  0.0228571  0.540323      1  
7   0.0967564         1  0.0199005   0.47043      1  
2   0.0416327  0.990937  0.0222222   0.88172   0.25  
4           0  0.989362          0         1      0  
8           0  0.989362          0         1      0  
9           0  0.989362          0         1      0  
6 -0.00929961  0.989276          0  0.991935      0  
5  -0.0107527  0.989247          0  0.989247      0  
Elapsed time 43.29 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv 
datetime: 2017-05-12 01:08:09.128000 
pca_target: 0 	 poly degree: 2 	 kselect: 0 
Imbalance: SMOTE(k=None, k_neighbors=5, kind='regular', m=None, m_neighbors=10, n_jobs=1,
   out_step=0.5, random_state=None, ratio='auto', svm_estimator=None) 
Extended target (count):  31485 325
('Total : Processed (count): ', (1252L, 231L), 13)
Final feature (count):  (1252L, 231L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.689 	0.097 	0.029 	0.719 	0.718 	0.519
[[256 116]
 [  1   3]]
             precision    recall  f1-score   support

          0       1.00      0.69      0.81       372
          1       0.03      0.75      0.05         4

avg / total       0.99      0.69      0.81       376


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=10, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.936 	0.185 	0.127 	0.720 	0.686 	0.450
[[350  22]
 [  2   2]]
             precision    recall  f1-score   support

          0       0.99      0.94      0.97       372
          1       0.08      0.50      0.14         4

avg / total       0.98      0.94      0.96       376


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.001, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.001, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='perceptron', n_iter=5, n_jobs=4,
       penalty='l1', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.864 	-0.039 	-0.020 	0.437 	0.000 	0.000
[[325  47]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.87      0.93       372
          1       0.00      0.00      0.00         4

avg / total       0.98      0.86      0.92       376


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 15},
           criterion='entropy', max_depth=None, max_features='auto',
           max_leaf_nodes=None, min_impurity_split=1e-07,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=4,
           oob_score=False, random_state=None, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.971 	0.153 	0.141 	0.614 	0.495 	0.227
[[364   8]
 [  3   1]]
             precision    recall  f1-score   support

          0       0.99      0.98      0.99       372
          1       0.11      0.25      0.15         4

avg / total       0.98      0.97      0.98       376


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight='balanced',
            criterion='entropy', max_depth=None, max_features=0.33,
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.963 	0.129 	0.111 	0.610 	0.493 	0.225
[[361  11]
 [  3   1]]
             precision    recall  f1-score   support

          0       0.99      0.97      0.98       372
          1       0.08      0.25      0.12         4

avg / total       0.98      0.96      0.97       376


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.1, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.984 	0.242 	0.242 	0.621 	0.498 	0.230
[[369   3]
 [  3   1]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       372
          1       0.25      0.25      0.25         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 500}, criterion='gini', max_depth=32,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=1.0, n_estimators=80, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.968 	0.144 	0.130 	0.613 	0.494 	0.226
[[363   9]
 [  3   1]]
             precision    recall  f1-score   support

          0       0.99      0.98      0.98       372
          1       0.10      0.25      0.14         4

avg / total       0.98      0.97      0.97       376


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=1, cache_size=200, class_weight={1: 50}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.979 	0.194 	0.190 	0.618 	0.497 	0.228
[[367   5]
 [  3   1]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       372
          1       0.17      0.25      0.20         4

avg / total       0.98      0.98      0.98       376


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=10.0, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', ...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.955 	0.111 	0.090 	0.606 	0.491 	0.223
[[358  14]
 [  3   1]]
             precision    recall  f1-score   support

          0       0.99      0.96      0.98       372
          1       0.07      0.25      0.11         4

avg / total       0.98      0.95      0.97       376


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=1,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.944 	0.094 	0.071 	0.601 	0.488 	0.221
[[354  18]
 [  3   1]]
             precision    recall  f1-score   support

          0       0.99      0.95      0.97       372
          1       0.05      0.25      0.09         4

avg / total       0.98      0.94      0.96       376


                estimator  min_score mean_score max_score    sd_score  \
1      LogisticRegression   0.520821   0.714055  0.927703    0.115344   
0              GaussianNB   0.683471   0.683471  0.683471           0   
5           MLPClassifier   0.957186   0.974715  0.989708  0.00773347   
7                     SVC          0   0.769686  0.980454     0.26384   
3    ExtraTreesClassifier   0.689948   0.917204  0.989714   0.0808782   
6      AdaBoostClassifier   0.858435   0.955106  0.988551   0.0235527   
4  RandomForestClassifier   0.840684   0.940317  0.979529   0.0392596   
8        VotingClassifier    0.87127   0.926558  0.963794   0.0206973   
9    KNeighborsClassifier   0.858172   0.908699   0.95059   0.0273942   
2           SGDClassifier -0.0152583   0.519615  0.862047    0.219181   

        acc       auc           conf_matrix     f1_c0      f1_c1      kappa  \
1   0.93617   0.72043   [[350, 22], [2, 2]]  0.966851   0.142857   0.126935   
0   0.68883  0.719086  [[256, 116], [1, 3]]   0.81399  0.0487805  0.0287884   
5  0.984043  0.620968    [[369, 3], [3, 1]]  0.991935       0.25   0.241935   
7  0.978723   0.61828    [[367, 5], [3, 1]]  0.989218        0.2   0.189655   
3  0.970745  0.614247    [[364, 8], [3, 1]]  0.985115   0.153846   0.141196   
6  0.968085  0.612903    [[363, 9], [3, 1]]   0.98374   0.142857    0.12963   
4  0.962766  0.610215   [[361, 11], [3, 1]]  0.980978      0.125   0.110811   
8  0.954787  0.606183   [[358, 14], [3, 1]]  0.976808   0.105263  0.0899772   
9  0.944149  0.600806   [[354, 18], [3, 1]]  0.971193  0.0869565  0.0706215   
2  0.864362  0.436828   [[325, 47], [4, 0]]  0.927247          0      -0.02   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
1    0.185023  0.994318  0.0833333   0.94086    0.5  
0   0.0966509  0.996109  0.0252101  0.688172   0.75  
5    0.241935  0.991935       0.25  0.991935   0.25  
7    0.193671  0.991892   0.166667  0.986559   0.25  
3    0.153364  0.991826   0.111111  0.978495   0.25  
6    0.143978  0.991803        0.1  0.975806   0.25  
4    0.128656  0.991758  0.0833333   0.97043   0.25  
8    0.111323   0.99169  0.0666667  0.962366   0.25  
9   0.0944298  0.991597  0.0526316  0.951613   0.25  
2  -0.0391931  0.987842          0  0.873656      0  
Elapsed time 145.09 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv 
datetime: 2017-05-12 03:33:14.271000 
pca_target: 0 	 poly degree: 2 	 kselect: 0 
Imbalance: ClusterCentroids(estimator=None, n_jobs=1, random_state=None, ratio='auto') 
Extended target (count):  31485 325
('Total : Processed (count): ', (1252L, 231L), 13)
Final feature (count):  (1252L, 231L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.628 	0.080 	0.021 	0.688 	0.685 	0.476
[[233 139]
 [  1   3]]
             precision    recall  f1-score   support

          0       1.00      0.63      0.77       372
          1       0.02      0.75      0.04         4

avg / total       0.99      0.63      0.76       376


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=10, class_weight={1: 500}, dual=False,
          fit_intercept=True, intercept_scaling=10, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='sag', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.561 	0.115 	0.026 	0.778 	0.746 	0.581
[[207 165]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.56      0.72       372
          1       0.02      1.00      0.05         4

avg / total       0.99      0.56      0.71       376


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.1, average=False, class_weight={1: 50}, epsilon=0.1,
       eta0=0.001, fit_intercept=True, l1_ratio=0.15,
       learning_rate='constant', loss='squared_hinge', n_iter=5, n_jobs=4,
       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.572 	0.066 	0.015 	0.660 	0.654 	0.435
[[212 160]
 [  1   3]]
             precision    recall  f1-score   support

          0       1.00      0.57      0.72       372
          1       0.02      0.75      0.04         4

avg / total       0.98      0.57      0.72       376


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 15}, criterion='gini',
           max_depth=None, max_features=0.75, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.729 	0.165 	0.053 	0.863 	0.852 	0.746
[[270 102]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.73      0.84       372
          1       0.04      1.00      0.07         4

avg / total       0.99      0.73      0.83       376


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 15}, criterion='gini',
            max_depth=8, max_features=0.33, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.731 	0.111 	0.036 	0.741 	0.741 	0.549
[[272 100]
 [  1   3]]
             precision    recall  f1-score   support

          0       1.00      0.73      0.84       372
          1       0.03      0.75      0.06         4

avg / total       0.99      0.73      0.84       376


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.721 	-0.006 	-0.002 	0.488 	0.426 	0.173
[[270 102]
 [  3   1]]
             precision    recall  f1-score   support

          0       0.99      0.73      0.84       372
          1       0.01      0.25      0.02         4

avg / total       0.98      0.72      0.83       376


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='entropy', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=2.0, n_estimators=80, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.734 	0.112 	0.037 	0.742 	0.742 	0.551
[[273  99]
 [  1   3]]
             precision    recall  f1-score   support

          0       1.00      0.73      0.85       372
          1       0.03      0.75      0.06         4

avg / total       0.99      0.73      0.84       376


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='linear',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.569 	0.117 	0.027 	0.782 	0.751 	0.589
[[210 162]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.56      0.72       372
          1       0.02      1.00      0.05         4

avg / total       0.99      0.57      0.71       376


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 500}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Ran...owski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='uniform'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.548 	0.112 	0.025 	0.772 	0.737 	0.568
[[202 170]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.54      0.70       372
          1       0.02      1.00      0.04         4

avg / total       0.99      0.55      0.70       376


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=4, p=1,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.726 	0.053 	0.017 	0.614 	0.604 	0.356
[[271 101]
 [  2   2]]
             precision    recall  f1-score   support

          0       0.99      0.73      0.84       372
          1       0.02      0.50      0.04         4

avg / total       0.98      0.73      0.83       376


                estimator min_score mean_score  max_score  sd_score       acc  \
3    ExtraTreesClassifier -0.572745 -0.0950567     0.2566  0.168585  0.728723   
7                     SVC -0.589933   -0.21247  0.0171889  0.171276  0.569149   
1      LogisticRegression -0.812156   -0.25123     0.3849  0.271399   0.56117   
8        VotingClassifier -0.478822   -0.19954     0.1283  0.180469  0.547872   
6      AdaBoostClassifier -0.589933  -0.149457   0.402089  0.146883  0.734043   
4  RandomForestClassifier -0.683856  -0.264097   0.273789  0.180859  0.731383   
0              GaussianNB   -0.1283    -0.1283    -0.1283         0   0.62766   
2           SGDClassifier -0.718234   0.050224   0.572745  0.214755  0.571809   
9    KNeighborsClassifier -0.589933   -0.29232     0.1283  0.202389  0.726064   
5           MLPClassifier -0.624311  -0.309239 -0.0767332  0.136753  0.720745   

        auc           conf_matrix     f1_c0      f1_c1       kappa  \
3  0.862903  [[270, 102], [0, 4]]  0.841121  0.0727273   0.0533175   
7  0.782258  [[210, 162], [0, 4]]  0.721649  0.0470588   0.0268405   
1  0.778226  [[207, 165], [0, 4]]  0.715026  0.0462428   0.0259985   
8  0.771505  [[202, 170], [0, 4]]  0.703833  0.0449438   0.0246582   
6  0.741935   [[273, 99], [1, 3]]  0.845201  0.0566038   0.0368852   
4  0.740591  [[272, 100], [1, 3]]  0.843411  0.0560748   0.0363378   
0  0.688172  [[233, 139], [1, 3]]  0.768977  0.0410959   0.0208333   
2  0.659946  [[212, 160], [1, 3]]  0.724786  0.0359281   0.0154827   
9  0.614247  [[271, 101], [2, 2]]   0.84031  0.0373832   0.0172554   
5  0.487903  [[270, 102], [3, 1]]  0.837209  0.0186916 -0.00182704   

  model_score   prec_c0     prec_c1    rec_c0 rec_c1  
3    0.165496         1   0.0377358  0.725806      1  
7    0.116631         1   0.0240964  0.564516      1  
1    0.114763         1   0.0236686  0.556452      1  
8    0.111727         1   0.0229885  0.543011      1  
6    0.111649   0.99635   0.0294118  0.733871   0.75  
4    0.110691  0.996337   0.0291262  0.731183   0.75  
0   0.0796406  0.995726   0.0211268  0.626344   0.75  
2    0.066225  0.995305   0.0184049  0.569892   0.75  
9   0.0525627  0.992674   0.0194175  0.728495    0.5  
5 -0.00556546  0.989011  0.00970874  0.725806   0.25  
Elapsed time 20.96 mins 

************************************************************









lagged (3,4)x1, standard, truncated


    pca = [0]
    poly = [0]
    ksel = [0]
    imb = [SMOTE(k_neighbors=3), SMOTE(k_neighbors=2)]
	
	
	
	
	




pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv 
datetime: 2017-05-16 08:34:58.363000 
pca_target: 0 	 poly degree: 0 	 kselect: 0 
Imbalance: SMOTE(k=None, k_neighbors=3, kind='regular', m=None, m_neighbors=10, n_jobs=1,
   out_step=0.5, random_state=None, ratio='auto', svm_estimator=None) 
Extended target (count):  25141 325
('Total : Processed (count): ', (998L, 20L), 13)
Final feature (count):  (998L, 20L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.620 	0.144 	0.041 	0.807 	0.784 	0.639
[[182 114]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.61      0.76       296
          1       0.03      1.00      0.07         4

avg / total       0.99      0.62      0.75       300


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=10, class_weight={1: 3}, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=4,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.653 	0.037 	0.012 	0.578 	0.572 	0.323
[[194 102]
 [  2   2]]
             precision    recall  f1-score   support

          0       0.99      0.66      0.79       296
          1       0.02      0.50      0.04         4

avg / total       0.98      0.65      0.78       300


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.1, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='modified_huber', n_iter=5, n_jobs=4,
       penalty='none', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.690 	-0.013 	-0.005 	0.473 	0.417 	0.166
[[206  90]
 [  3   1]]
             precision    recall  f1-score   support

          0       0.99      0.70      0.82       296
          1       0.01      0.25      0.02         4

avg / total       0.97      0.69      0.81       300


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 50},
           criterion='entropy', max_depth=None, max_features=0.75,
           max_leaf_nodes=None, min_impurity_split=1e-07,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=4,
           oob_score=False, random_state=None, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.970 	-0.015 	-0.015 	0.492 	0.000 	0.000
[[291   5]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.98      0.98       296
          1       0.00      0.00      0.00         4

avg / total       0.97      0.97      0.97       300


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight='balanced',
            criterion='entropy', max_depth=None, max_features=0.33,
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.963 	-0.018 	-0.017 	0.488 	0.000 	0.000
[[289   7]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.98      0.98       296
          1       0.00      0.00      0.00         4

avg / total       0.97      0.96      0.97       300


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(500,), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.973 	-0.014 	-0.014 	0.493 	0.000 	0.000
[[292   4]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       296
          1       0.00      0.00      0.00         4

avg / total       0.97      0.97      0.97       300


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 50}, criterion='gini', max_depth=16,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=1.0, n_estimators=80, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.970 	-0.015 	-0.015 	0.492 	0.000 	0.000
[[291   5]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.98      0.98       296
          1       0.00      0.00      0.00         4

avg / total       0.97      0.97      0.97       300


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.5, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=10, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.983 	-0.007 	-0.005 	0.498 	0.000 	0.000
[[295   1]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       296
          1       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.98       300


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=10.0, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', ...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.957 	0.132 	0.116 	0.608 	0.491 	0.224
[[286  10]
 [  3   1]]
             precision    recall  f1-score   support

          0       0.99      0.97      0.98       296
          1       0.09      0.25      0.13         4

avg / total       0.98      0.96      0.97       300


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=1,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.940 	0.102 	0.080 	0.600 	0.487 	0.221
[[281  15]
 [  3   1]]
             precision    recall  f1-score   support

          0       0.99      0.95      0.97       296
          1       0.06      0.25      0.10         4

avg / total       0.98      0.94      0.96       300


                estimator min_score mean_score max_score   sd_score       acc  \
0              GaussianNB  0.539736   0.539736  0.539736          0      0.62   
8        VotingClassifier  0.842803   0.893094  0.935364  0.0233307  0.956667   
9    KNeighborsClassifier  0.830864   0.875828  0.924821  0.0285342      0.94   
1      LogisticRegression  0.065495   0.532636  0.683807   0.117068  0.653333   
7                     SVC         0   0.642533  0.975596   0.230609  0.983333   
5           MLPClassifier   0.92797   0.954754   0.97435  0.0104295  0.973333   
3    ExtraTreesClassifier  0.591352     0.8922  0.988502   0.112969      0.97   
6      AdaBoostClassifier  0.728253   0.940931  0.984214  0.0282228      0.97   
4  RandomForestClassifier  0.803668   0.924752  0.969889  0.0475262  0.963333   
2           SGDClassifier -0.175211   0.420936  0.691459   0.177522      0.69   

        auc           conf_matrix     f1_c0      f1_c1       kappa  \
0  0.807432  [[182, 114], [0, 4]]  0.761506  0.0655738   0.0408346   
8  0.608108   [[286, 10], [3, 1]]  0.977778   0.133333    0.116047   
9  0.599662   [[281, 15], [3, 1]]  0.968966        0.1   0.0803815   
1  0.577703  [[194, 102], [2, 2]]  0.788618   0.037037   0.0116574   
7  0.498311    [[295, 1], [4, 0]]  0.991597          0 -0.00536193   
5  0.493243    [[292, 4], [4, 0]]  0.986486          0  -0.0135135   
3  0.491554    [[291, 5], [4, 0]]  0.984772          0  -0.0150376   
6  0.491554    [[291, 5], [4, 0]]  0.984772          0  -0.0150376   
4  0.488176    [[289, 7], [4, 0]]  0.981324          0  -0.0172626   
2  0.472973   [[206, 90], [3, 1]]  0.815842  0.0210526 -0.00460896   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
0    0.144371         1  0.0338983  0.614865      1  
8    0.131953  0.989619  0.0909091  0.966216   0.25  
9    0.101746  0.989437     0.0625  0.949324   0.25  
1   0.0374539  0.989796  0.0192308  0.655405    0.5  
7 -0.00672277  0.986622          0  0.996622      0  
5  -0.0135135  0.986486          0  0.986486      0  
3  -0.0151342  0.986441          0  0.983108      0  
6  -0.0151342  0.986441          0  0.983108      0  
4   -0.017968  0.986348          0  0.976351      0  
2  -0.0134868  0.985646   0.010989  0.695946   0.25  
Elapsed time 36.88 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv 
datetime: 2017-05-16 09:11:51.004000 
pca_target: 0 	 poly degree: 0 	 kselect: 0 
Imbalance: SMOTE(k=None, k_neighbors=2, kind='regular', m=None, m_neighbors=10, n_jobs=1,
   out_step=0.5, random_state=None, ratio='auto', svm_estimator=None) 
Extended target (count):  25141 325
('Total : Processed (count): ', (998L, 20L), 13)
Final feature (count):  (998L, 20L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.610 	0.141 	0.039 	0.802 	0.778 	0.629
[[179 117]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.60      0.75       296
          1       0.03      1.00      0.06         4

avg / total       0.99      0.61      0.74       300


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=10, class_weight={1: 3}, dual=False, fit_intercept=True,
          intercept_scaling=5, max_iter=100, multi_class='ovr', n_jobs=4,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.670 	0.042 	0.014 	0.586 	0.580 	0.330
[[199  97]
 [  2   2]]
             precision    recall  f1-score   support

          0       0.99      0.67      0.80       296
          1       0.02      0.50      0.04         4

avg / total       0.98      0.67      0.79       300


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.1, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.001, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='modified_huber', n_iter=5, n_jobs=4,
       penalty='none', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.697 	-0.074 	-0.026 	0.353 	0.000 	0.000
[[209  87]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.98      0.71      0.82       296
          1       0.00      0.00      0.00         4

avg / total       0.97      0.70      0.81       300


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 15},
           criterion='entropy', max_depth=None, max_features=0.75,
           max_leaf_nodes=None, min_impurity_split=1e-07,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=4,
           oob_score=False, random_state=None, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.980 	-0.010 	-0.009 	0.497 	0.000 	0.000
[[294   2]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       296
          1       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.98       300


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight='balanced',
            criterion='entropy', max_depth=32, max_features='auto',
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.977 	-0.012 	-0.012 	0.495 	0.000 	0.000
[[293   3]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       296
          1       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.98       300


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.970 	-0.015 	-0.015 	0.492 	0.000 	0.000
[[291   5]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.98      0.98       296
          1       0.00      0.00      0.00         4

avg / total       0.97      0.97      0.97       300


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight='balanced', criterion='gini', max_depth=8,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=1.0, n_estimators=80, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.983 	-0.007 	-0.005 	0.498 	0.000 	0.000
[[295   1]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       296
          1       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.98       300


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.5, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=10, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.983 	-0.007 	-0.005 	0.498 	0.000 	0.000
[[295   1]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       296
          1       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.98       300


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=10.0, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', ...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.967 	0.161 	0.152 	0.613 	0.494 	0.226
[[289   7]
 [  3   1]]
             precision    recall  f1-score   support

          0       0.99      0.98      0.98       296
          1       0.12      0.25      0.17         4

avg / total       0.98      0.97      0.97       300


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.967 	0.161 	0.152 	0.613 	0.494 	0.226
[[289   7]
 [  3   1]]
             precision    recall  f1-score   support

          0       0.99      0.98      0.98       296
          1       0.12      0.25      0.17         4

avg / total       0.98      0.97      0.97       300


                estimator min_score mean_score max_score    sd_score  \
0              GaussianNB  0.549799   0.549799  0.549799           0   
8        VotingClassifier  0.872032   0.910009  0.946313   0.0202139   
9    KNeighborsClassifier  0.854295   0.895033  0.934169   0.0256153   
1      LogisticRegression  0.065495    0.53703  0.696433    0.119841   
6      AdaBoostClassifier  0.818682   0.949907  0.988482   0.0248912   
7                     SVC         0   0.653703  0.988461    0.227546   
3    ExtraTreesClassifier   0.61938   0.903127  0.991364    0.110764   
4  RandomForestClassifier  0.802735   0.929315  0.976932   0.0518987   
5           MLPClassifier  0.939565    0.95778  0.974339  0.00837286   
2           SGDClassifier -0.131339   0.427764  0.693497    0.180593   

        acc       auc           conf_matrix     f1_c0     f1_c1       kappa  \
0      0.61  0.802365  [[179, 117], [0, 4]]  0.753684     0.064   0.0391985   
8  0.966667  0.613176    [[289, 7], [3, 1]]  0.982993  0.166667    0.151584   
9  0.966667  0.613176    [[289, 7], [3, 1]]  0.982993  0.166667    0.151584   
1      0.67  0.586149   [[199, 97], [2, 2]]  0.800805  0.038835   0.0135512   
6  0.983333  0.498311    [[295, 1], [4, 0]]  0.991597         0 -0.00536193   
7  0.983333  0.498311    [[295, 1], [4, 0]]  0.991597         0 -0.00536193   
3      0.98  0.496622    [[294, 2], [4, 0]]  0.989899         0 -0.00896861   
4  0.976667  0.494932    [[293, 3], [4, 0]]  0.988196         0  -0.0115607   
5      0.97  0.491554    [[291, 5], [4, 0]]  0.984772         0  -0.0150376   
2  0.696667  0.353041   [[209, 87], [4, 0]]  0.821218         0  -0.0261615   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
0     0.14139         1  0.0330579   0.60473      1  
8    0.161147  0.989726      0.125  0.976351   0.25  
9    0.161147  0.989726      0.125  0.976351   0.25  
1    0.042028   0.99005   0.020202  0.672297    0.5  
6 -0.00672277  0.986622          0  0.996622      0  
7 -0.00672277  0.986622          0  0.996622      0  
3 -0.00952338  0.986577          0  0.993243      0  
4  -0.0116833  0.986532          0  0.989865      0  
5  -0.0151342  0.986441          0  0.983108      0  
2   -0.074294  0.981221          0  0.706081      0  
Elapsed time 36.76 mins 

************************************************************




