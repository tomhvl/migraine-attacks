




Standard, lagged (3,4)x1, filter(hp), NT+, truncated




    pca = [0]
    poly = [0]
    ksel = [0, 20]
    imb = [None, SMOTE(), ClusterCentroids() ]
	

	


pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv 
datetime: 2017-05-06 17:14:48.049000 
pca_target: 0 	 poly degree: 0 	 kselect: 0 
Imbalance: None 
Extended target (count):  25141 325
('Total : Processed (count): ', (998L, 221L), 13)
Final feature (count):  (998L, 221L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.563 	0.129 	0.032 	0.779 	0.747 	0.582
[[165 131]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.56      0.72       296
          1       0.03      1.00      0.06         4

avg / total       0.99      0.56      0.71       300


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.01, class_weight={1: 500}, dual=False,
          fit_intercept=True, intercept_scaling=0.01, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='sag', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.547 	0.011 	0.003 	0.524 	0.523 	0.272
[[162 134]
 [  2   2]]
             precision    recall  f1-score   support

          0       0.99      0.55      0.70       296
          1       0.01      0.50      0.03         4

avg / total       0.97      0.55      0.70       300


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=1, average=False, class_weight={1: 50}, epsilon=0.1,
       eta0=0.001, fit_intercept=True, l1_ratio=0.15,
       learning_rate='constant', loss='perceptron', n_iter=5, n_jobs=4,
       penalty='none', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.750 	0.067 	0.026 	0.627 	0.614 	0.367
[[223  73]
 [  2   2]]
             precision    recall  f1-score   support

          0       0.99      0.75      0.86       296
          1       0.03      0.50      0.05         4

avg / total       0.98      0.75      0.85       300


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 500}, criterion='gini',
           max_depth=16, max_features=0.75, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=50, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.960 	-0.019 	-0.018 	0.486 	0.000 	0.000
[[288   8]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.97      0.98       296
          1       0.00      0.00      0.00         4

avg / total       0.97      0.96      0.97       300


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	0.000 	0.000 	0.500 	0.000 	0.000
[[296   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       296
          1       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       300


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(500,), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.983 	-0.007 	-0.005 	0.498 	0.000 	0.000
[[295   1]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       296
          1       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.98       300


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight='balanced', criterion='entropy',
            max_depth=8, max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=2.0, n_estimators=15, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.983 	-0.007 	-0.005 	0.498 	0.000 	0.000
[[295   1]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       296
          1       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.98       300


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.01, cache_size=200, class_weight={1: 500}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.407 	0.094 	0.017 	0.699 	0.631 	0.423
[[118 178]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.40      0.57       296
          1       0.02      1.00      0.04         4

avg / total       0.99      0.41      0.56       300


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	0.000 	0.000 	0.500 	0.000 	0.000
[[296   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       296
          1       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       300


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=1,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	0.000 	0.000 	0.500 	0.000 	0.000
[[296   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       296
          1       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       300


                estimator   min_score   mean_score   max_score     sd_score  \
0              GaussianNB  0.00732806   0.00732806  0.00732806            0   
7                     SVC  -0.0210498    0.0110886   0.0843103    0.0204573   
2           SGDClassifier  -0.0709586    0.0129482    0.121379    0.0346261   
1      LogisticRegression  -0.0511313   0.00317311   0.0890328      0.02959   
4  RandomForestClassifier -0.00204805 -0.000124126           0  0.000478654   
8        VotingClassifier  -0.0040961  -0.00116625           0   0.00159471   
9    KNeighborsClassifier    -0.01083  -0.00227281           0   0.00366203   
5           MLPClassifier  -0.0157356  -0.00824305 -0.00204805   0.00294157   
6      AdaBoostClassifier  -0.0218771  -0.00368674    0.131251    0.0212548   
3    ExtraTreesClassifier  -0.0426063  -0.00160141   0.0404474   0.00726004   

        acc       auc           conf_matrix     f1_c0      f1_c1       kappa  \
0  0.563333  0.778716  [[165, 131], [0, 4]]  0.715835   0.057554   0.0324963   
7  0.406667  0.699324  [[118, 178], [0, 4]]  0.570048  0.0430108   0.0173708   
2      0.75  0.626689   [[223, 73], [2, 2]]  0.856046  0.0506329    0.025974   
1  0.546667  0.523649  [[162, 134], [2, 2]]  0.704348  0.0285714  0.00273758   
4  0.986667       0.5    [[296, 0], [4, 0]]  0.993289          0           0   
8  0.986667       0.5    [[296, 0], [4, 0]]  0.993289          0           0   
9  0.986667       0.5    [[296, 0], [4, 0]]  0.993289          0           0   
5  0.983333  0.498311    [[295, 1], [4, 0]]  0.991597          0 -0.00536193   
6  0.983333  0.498311    [[295, 1], [4, 0]]  0.991597          0 -0.00536193   
3      0.96  0.486486    [[288, 8], [4, 0]]  0.979592          0  -0.0180995   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
0    0.128517         1  0.0296296  0.557432      1  
7   0.0936029         1   0.021978  0.398649      1  
2   0.0671156  0.991111  0.0266667  0.753378    0.5  
1   0.0108973  0.987805  0.0147059  0.547297    0.5  
4           0  0.986667          0         1      0  
8           0  0.986667          0         1      0  
9           0  0.986667          0         1      0  
5 -0.00672277  0.986622          0  0.996622      0  
6 -0.00672277  0.986622          0  0.996622      0  
3  -0.0192414  0.986301          0  0.972973      0  
Elapsed time 36.45 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv 
datetime: 2017-05-06 17:51:15.185000 
pca_target: 0 	 poly degree: 0 	 kselect: 0 
Imbalance: SMOTE(k=None, k_neighbors=5, kind='regular', m=None, m_neighbors=10, n_jobs=1,
   out_step=0.5, random_state=None, ratio='auto', svm_estimator=None) 
Extended target (count):  25141 325
('Total : Processed (count): ', (998L, 221L), 13)
Final feature (count):  (998L, 221L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.637 	0.091 	0.027 	0.693 	0.690 	0.482
[[188 108]
 [  1   3]]
             precision    recall  f1-score   support

          0       0.99      0.64      0.78       296
          1       0.03      0.75      0.05         4

avg / total       0.98      0.64      0.77       300


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=10, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=5, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.953 	0.125 	0.107 	0.606 	0.491 	0.224
[[285  11]
 [  3   1]]
             precision    recall  f1-score   support

          0       0.99      0.96      0.98       296
          1       0.08      0.25      0.12         4

avg / total       0.98      0.95      0.96       300


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.001, average=False, class_weight='balanced',
       epsilon=0.1, eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='modified_huber', n_iter=5, n_jobs=4,
       penalty='l1', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.960 	0.273 	0.235 	0.733 	0.695 	0.461
[[286  10]
 [  2   2]]
             precision    recall  f1-score   support

          0       0.99      0.97      0.98       296
          1       0.17      0.50      0.25         4

avg / total       0.98      0.96      0.97       300


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3},
           criterion='entropy', max_depth=32, max_features=0.75,
           max_leaf_nodes=None, min_impurity_split=1e-07,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=4,
           oob_score=False, random_state=None, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	0.000 	0.000 	0.500 	0.000 	0.000
[[296   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       296
          1       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       300


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight='balanced',
            criterion='entropy', max_depth=16, max_features='auto',
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.977 	-0.012 	-0.012 	0.495 	0.000 	0.000
[[293   3]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       296
          1       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.98       300


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.977 	0.212 	0.211 	0.618 	0.497 	0.228
[[292   4]
 [  3   1]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       296
          1       0.20      0.25      0.22         4

avg / total       0.98      0.98      0.98       300


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=16,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=1.0, n_estimators=80, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.983 	-0.007 	-0.005 	0.498 	0.000 	0.000
[[295   1]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       296
          1       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.98       300


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.5, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	0.000 	0.000 	0.500 	0.000 	0.000
[[296   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       296
          1       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       300


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=10.0, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', ...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.977 	0.212 	0.211 	0.618 	0.497 	0.228
[[292   4]
 [  3   1]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       296
          1       0.20      0.25      0.22         4

avg / total       0.98      0.98      0.98       300


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=1,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.943 	0.107 	0.086 	0.601 	0.488 	0.221
[[282  14]
 [  3   1]]
             precision    recall  f1-score   support

          0       0.99      0.95      0.97       296
          1       0.07      0.25      0.11         4

avg / total       0.98      0.94      0.96       300


                estimator  min_score mean_score max_score    sd_score  \
2           SGDClassifier -0.0933385   0.577171   0.95216     0.26338   
0              GaussianNB   0.662181   0.662181  0.662181           0   
5           MLPClassifier   0.956033   0.972451  0.988482  0.00841943   
8        VotingClassifier   0.885178   0.937646  0.975629   0.0218362   
1      LogisticRegression  0.0785648   0.790464  0.949185    0.163909   
9    KNeighborsClassifier   0.766961     0.8515  0.930184   0.0454177   
3    ExtraTreesClassifier   0.684986   0.942426         1   0.0732117   
7                     SVC          0   0.795943         1    0.318702   
6      AdaBoostClassifier   0.887572   0.969377         1   0.0217688   
4  RandomForestClassifier   0.870847    0.96045  0.992769   0.0240105   

        acc       auc           conf_matrix     f1_c0      f1_c1       kappa  \
2      0.96  0.733108   [[286, 10], [2, 2]]  0.979452       0.25    0.234694   
0  0.636667  0.692568  [[188, 108], [1, 3]]  0.775258  0.0521739   0.0271332   
5  0.976667  0.618243    [[292, 4], [3, 1]]  0.988156   0.222222    0.210526   
8  0.976667  0.618243    [[292, 4], [3, 1]]  0.988156   0.222222    0.210526   
1  0.953333  0.606419   [[285, 11], [3, 1]]  0.976027      0.125    0.107143   
9  0.943333  0.601351   [[282, 14], [3, 1]]   0.97074   0.105263   0.0860215   
3  0.986667       0.5    [[296, 0], [4, 0]]  0.993289          0           0   
7  0.986667       0.5    [[296, 0], [4, 0]]  0.993289          0           0   
6  0.983333  0.498311    [[295, 1], [4, 0]]  0.991597          0 -0.00536193   
4  0.976667  0.494932    [[293, 3], [4, 0]]  0.988196          0  -0.0115607   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
2    0.272883  0.993056   0.166667  0.966216    0.5  
0   0.0914948  0.994709   0.027027  0.635135   0.75  
5    0.211878  0.989831        0.2  0.986486   0.25  
8    0.211878  0.989831        0.2  0.986486   0.25  
1    0.124577  0.989583  0.0833333  0.962838   0.25  
9    0.106676  0.989474  0.0666667  0.952703   0.25  
3           0  0.986667          0         1      0  
7           0  0.986667          0         1      0  
6 -0.00672277  0.986622          0  0.996622      0  
4  -0.0116833  0.986532          0  0.989865      0  
Elapsed time 97.08 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv 
datetime: 2017-05-06 19:28:20.251000 
pca_target: 0 	 poly degree: 0 	 kselect: 0 
Imbalance: ClusterCentroids(estimator=None, n_jobs=1, random_state=None, ratio='auto') 
Extended target (count):  25141 325
('Total : Processed (count): ', (998L, 221L), 13)
Final feature (count):  (998L, 221L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.473 	0.050 	0.011 	0.610 	0.593 	0.362
[[139 157]
 [  1   3]]
             precision    recall  f1-score   support

          0       0.99      0.47      0.64       296
          1       0.02      0.75      0.04         4

avg / total       0.98      0.47      0.63       300


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=1, class_weight={1: 500}, dual=False, fit_intercept=True,
          intercept_scaling=0.01, max_iter=100, multi_class='ovr',
          n_jobs=4, penalty='l2', random_state=None, solver='sag',
          tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.430 	0.041 	0.008 	0.588 	0.565 	0.330
[[126 170]
 [  1   3]]
             precision    recall  f1-score   support

          0       0.99      0.43      0.60       296
          1       0.02      0.75      0.03         4

avg / total       0.98      0.43      0.59       300


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.001, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='modified_huber', n_iter=5, n_jobs=4,
       penalty='l2', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.497 	0.056 	0.013 	0.622 	0.608 	0.379
[[146 150]
 [  1   3]]
             precision    recall  f1-score   support

          0       0.99      0.49      0.66       296
          1       0.02      0.75      0.04         4

avg / total       0.98      0.50      0.65       300


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight='balanced',
           criterion='entropy', max_depth=32, max_features=0.75,
           max_leaf_nodes=None, min_impurity_split=1e-07,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=4,
           oob_score=False, random_state=None, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.107 	0.037 	0.003 	0.547 	0.308 	0.103
[[ 28 268]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.09      0.17       296
          1       0.01      1.00      0.03         4

avg / total       0.99      0.11      0.17       300


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features=0.75, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=30, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.287 	0.071 	0.010 	0.639 	0.526 	0.297
[[ 82 214]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.28      0.43       296
          1       0.02      1.00      0.04         4

avg / total       0.99      0.29      0.43       300


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.01, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.797 	0.016 	0.007 	0.527 	0.448 	0.190
[[238  58]
 [  3   1]]
             precision    recall  f1-score   support

          0       0.99      0.80      0.89       296
          1       0.02      0.25      0.03         4

avg / total       0.97      0.80      0.88       300


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=0.5, n_estimators=50, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.347 	0.082 	0.013 	0.669 	0.581 	0.360
[[100 196]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.34      0.51       296
          1       0.02      1.00      0.04         4

avg / total       0.99      0.35      0.50       300


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=1, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=10, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.520 	0.005 	0.001 	0.510 	0.510 	0.260
[[154 142]
 [  2   2]]
             precision    recall  f1-score   support

          0       0.99      0.52      0.68       296
          1       0.01      0.50      0.03         4

avg / total       0.97      0.52      0.67       300


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...wski',
           metric_params=None, n_jobs=4, n_neighbors=4, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.617 	0.028 	0.008 	0.559 	0.556 	0.305
[[183 113]
 [  2   2]]
             precision    recall  f1-score   support

          0       0.99      0.62      0.76       296
          1       0.02      0.50      0.03         4

avg / total       0.98      0.62      0.75       300


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=6, p=1,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.897 	0.060 	0.038 	0.578 	0.476 	0.212
[[268  28]
 [  3   1]]
             precision    recall  f1-score   support

          0       0.99      0.91      0.95       296
          1       0.03      0.25      0.06         4

avg / total       0.98      0.90      0.93       300


                estimator  min_score mean_score max_score  sd_score       acc  \
6      AdaBoostClassifier   0.205033   0.821834         1   0.18157  0.346667   
4  RandomForestClassifier  -0.222222   0.712007         1  0.333387  0.286667   
2           SGDClassifier  -0.812156  0.0271223    0.5132  0.208891  0.496667   
0              GaussianNB   0.777778   0.777778  0.777778         0  0.473333   
1      LogisticRegression  -0.589933  -0.103926  0.444444  0.223943      0.43   
9    KNeighborsClassifier  -0.478822  -0.200085    0.1283  0.153877  0.896667   
8        VotingClassifier -0.0343779   0.291801  0.683856  0.134013  0.616667   
3    ExtraTreesClassifier    -0.1283    0.51855         1  0.202955  0.106667   
5           MLPClassifier  -0.718234  -0.161014  0.239411  0.248232  0.796667   
7                     SVC    -0.2566 -0.0414981    0.2566  0.125526      0.52   

        auc           conf_matrix     f1_c0      f1_c1       kappa  \
6  0.668919  [[100, 196], [0, 4]]  0.505051  0.0392157   0.0134228   
4  0.638514   [[82, 214], [0, 4]]  0.433862   0.036036   0.0101147   
2  0.621622  [[146, 150], [1, 3]]  0.659142  0.0382166   0.0125556   
0  0.609797  [[139, 157], [1, 3]]  0.637615  0.0365854   0.0108514   
1  0.587838  [[126, 170], [1, 3]]  0.595745  0.0338983  0.00804393   
9  0.577703   [[268, 28], [3, 1]]  0.945326  0.0606061   0.0380637   
8  0.559122  [[183, 113], [2, 2]]  0.760915  0.0336134   0.0080506   
3  0.547297   [[28, 268], [0, 4]]   0.17284  0.0289855  0.00277833   
5  0.527027   [[238, 58], [3, 1]]  0.886406   0.031746  0.00694595   
7  0.510135  [[154, 142], [2, 2]]  0.681416   0.027027  0.00110988   

  model_score   prec_c0    prec_c1     rec_c0 rec_c1  
6   0.0821995         1       0.02   0.337838      1  
4   0.0712956         1  0.0183486   0.277027      1  
2     0.05581  0.993197  0.0196078   0.493243   0.75  
0   0.0504863  0.992857    0.01875   0.469595   0.75  
1   0.0407814  0.992126   0.017341   0.425676   0.75  
9   0.0603196   0.98893  0.0344828   0.905405   0.25  
8   0.0278944  0.989189  0.0173913   0.618243    0.5  
3   0.0372974         1  0.0147059  0.0945946      1  
5    0.015598  0.987552  0.0169492   0.804054   0.25  
7  0.00465363  0.987179  0.0138889    0.52027    0.5  
Elapsed time 22.31 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv 
datetime: 2017-05-06 19:50:38.913000 
pca_target: 0 	 poly degree: 0 	 kselect: 20 
Imbalance: None 
Extended target (count):  25141 325
('Total : Processed (count): ', (998L, 221L), 13)
Final feature (count):  (998L, 221L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.770 	-0.061 	-0.026 	0.390 	0.000 	0.000
[[231  65]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.98      0.78      0.87       296
          1       0.00      0.00      0.00         4

avg / total       0.97      0.77      0.86       300


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.001, class_weight={1: 50}, dual=False,
          fit_intercept=True, intercept_scaling=5, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='sag', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.783 	-0.059 	-0.026 	0.397 	0.000 	0.000
[[235  61]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.98      0.79      0.88       296
          1       0.00      0.00      0.00         4

avg / total       0.97      0.78      0.87       300


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.5, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='perceptron', n_iter=5, n_jobs=4,
       penalty='none', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.953 	-0.022 	-0.019 	0.483 	0.000 	0.000
[[286  10]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.97      0.98       296
          1       0.00      0.00      0.00         4

avg / total       0.97      0.95      0.96       300


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=8, max_features='auto', max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.983 	-0.007 	-0.005 	0.498 	0.000 	0.000
[[295   1]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       296
          1       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.98       300


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	0.000 	0.000 	0.500 	0.000 	0.000
[[296   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       296
          1       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       300


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.01, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(500,), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.980 	-0.010 	-0.009 	0.497 	0.000 	0.000
[[294   2]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       296
          1       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.98       300


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 500}, criterion='gini', max_depth=8,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=2.0, n_estimators=50, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.977 	-0.012 	-0.012 	0.495 	0.000 	0.000
[[293   3]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       296
          1       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.98       300


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.370 	0.087 	0.015 	0.681 	0.601 	0.385
[[107 189]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.36      0.53       296
          1       0.02      1.00      0.04         4

avg / total       0.99      0.37      0.52       300


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	0.000 	0.000 	0.500 	0.000 	0.000
[[296   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       296
          1       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       300


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=1,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	0.000 	0.000 	0.500 	0.000 	0.000
[[296   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       296
          1       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       300


                estimator    min_score   mean_score    max_score    sd_score  \
7                     SVC   -0.0843425   -0.0194217    0.0818301   0.0292923   
4  RandomForestClassifier  -0.00874303 -0.000541057            0  0.00119072   
8        VotingClassifier   -0.0112873  -0.00342163            0  0.00355637   
9    KNeighborsClassifier   -0.0112873  -0.00324431            0   0.0039952   
3    ExtraTreesClassifier   -0.0364099  -0.00587807            0   0.0066673   
5           MLPClassifier   -0.0187542  -0.00506844    0.0721306   0.0164067   
6      AdaBoostClassifier   -0.0201572  -0.00938444    0.0975814   0.0114592   
2           SGDClassifier    -0.183915   -0.0138891     0.149255   0.0353629   
1      LogisticRegression    -0.101419   -0.0194924     0.119785   0.0356568   
0              GaussianNB -6.52742e-05 -6.52742e-05 -6.52742e-05           0   

        acc       auc           conf_matrix     f1_c0      f1_c1       kappa  \
7      0.37  0.680743  [[107, 189], [0, 4]]  0.531017  0.0406091   0.0148725   
4  0.986667       0.5    [[296, 0], [4, 0]]  0.993289          0           0   
8  0.986667       0.5    [[296, 0], [4, 0]]  0.993289          0           0   
9  0.986667       0.5    [[296, 0], [4, 0]]  0.993289          0           0   
3  0.983333  0.498311    [[295, 1], [4, 0]]  0.991597          0 -0.00536193   
5      0.98  0.496622    [[294, 2], [4, 0]]  0.989899          0 -0.00896861   
6  0.976667  0.494932    [[293, 3], [4, 0]]  0.988196          0  -0.0115607   
2  0.953333  0.483108   [[286, 10], [4, 0]]  0.976109          0  -0.0194175   
1  0.783333  0.396959   [[235, 61], [4, 0]]  0.878505          0   -0.025668   
0      0.77  0.390203   [[231, 65], [4, 0]]  0.870056          0  -0.0257681   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
7    0.086556         1  0.0207254  0.361486      1  
4           0  0.986667          0         1      0  
8           0  0.986667          0         1      0  
9           0  0.986667          0         1      0  
3 -0.00672277  0.986622          0  0.996622      0  
5 -0.00952338  0.986577          0  0.993243      0  
6  -0.0116833  0.986532          0  0.989865      0  
2  -0.0215866  0.986207          0  0.966216      0  
1  -0.0587287  0.983264          0  0.793919      0  
0  -0.0611374  0.982979          0  0.780405      0  
Elapsed time 26.59 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv 
datetime: 2017-05-06 20:17:14.460000 
pca_target: 0 	 poly degree: 0 	 kselect: 20 
Imbalance: SMOTE(k=None, k_neighbors=5, kind='regular', m=None, m_neighbors=10, n_jobs=1,
   out_step=0.5, random_state=None, ratio='auto', svm_estimator=None) 
Extended target (count):  25141 325
('Total : Processed (count): ', (998L, 221L), 13)
Final feature (count):  (998L, 221L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.540 	0.123 	0.030 	0.767 	0.731 	0.559
[[158 138]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.53      0.70       296
          1       0.03      1.00      0.05         4

avg / total       0.99      0.54      0.69       300


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=10, class_weight={1: 3}, dual=False, fit_intercept=True,
          intercept_scaling=0.1, max_iter=100, multi_class='ovr', n_jobs=4,
          penalty='l2', random_state=None, solver='lbfgs', tol=0.0001,
          verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.723 	-0.005 	-0.002 	0.490 	0.427 	0.174
[[216  80]
 [  3   1]]
             precision    recall  f1-score   support

          0       0.99      0.73      0.84       296
          1       0.01      0.25      0.02         4

avg / total       0.97      0.72      0.83       300


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.001, average=False, class_weight={1: 15}, epsilon=0.1,
       eta0=0.001, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='modified_huber', n_iter=5, n_jobs=4,
       penalty='none', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.643 	0.093 	0.028 	0.696 	0.694 	0.487
[[190 106]
 [  1   3]]
             precision    recall  f1-score   support

          0       0.99      0.64      0.78       296
          1       0.03      0.75      0.05         4

avg / total       0.98      0.64      0.77       300


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 15}, criterion='gini',
           max_depth=32, max_features=0.75, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=30, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.970 	-0.015 	-0.015 	0.492 	0.000 	0.000
[[291   5]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.98      0.98       296
          1       0.00      0.00      0.00         4

avg / total       0.97      0.97      0.97       300


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 50},
            criterion='entropy', max_depth=None, max_features=0.75,
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.967 	-0.017 	-0.016 	0.490 	0.000 	0.000
[[290   6]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.98      0.98       296
          1       0.00      0.00      0.00         4

avg / total       0.97      0.97      0.97       300


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.01, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.957 	0.132 	0.116 	0.608 	0.491 	0.224
[[286  10]
 [  3   1]]
             precision    recall  f1-score   support

          0       0.99      0.97      0.98       296
          1       0.09      0.25      0.13         4

avg / total       0.98      0.96      0.97       300


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 50}, criterion='entropy', max_depth=8,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=1.0, n_estimators=80, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.963 	-0.018 	-0.017 	0.488 	0.000 	0.000
[[289   7]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.98      0.98       296
          1       0.00      0.00      0.00         4

avg / total       0.97      0.96      0.97       300


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=10, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.977 	-0.012 	-0.012 	0.495 	0.000 	0.000
[[293   3]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       296
          1       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.98       300


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=10.0, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', ...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.937 	0.208 	0.155 	0.721 	0.687 	0.450
[[279  17]
 [  2   2]]
             precision    recall  f1-score   support

          0       0.99      0.94      0.97       296
          1       0.11      0.50      0.17         4

avg / total       0.98      0.94      0.96       300


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=1,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.937 	-0.027 	-0.022 	0.475 	0.000 	0.000
[[281  15]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.95      0.97       296
          1       0.00      0.00      0.00         4

avg / total       0.97      0.94      0.95       300


                estimator min_score mean_score max_score    sd_score  \
0              GaussianNB  0.599202   0.599202  0.599202           0   
8        VotingClassifier  0.782254    0.84841  0.895005     0.02796   
2           SGDClassifier -0.105603   0.469354  0.742137    0.199783   
5           MLPClassifier  0.938047   0.969302  0.982885  0.00661594   
7                     SVC         0   0.694806  0.978549    0.233694   
3    ExtraTreesClassifier  0.687397   0.898851  0.974048   0.0891798   
1      LogisticRegression         0   0.579016  0.762077     0.15171   
4  RandomForestClassifier  0.731558   0.908942  0.959909   0.0592564   
6      AdaBoostClassifier  0.805643   0.937174  0.979834   0.0272811   
9    KNeighborsClassifier  0.829885   0.878317  0.929424   0.0284315   

        acc       auc           conf_matrix     f1_c0      f1_c1       kappa  \
0      0.54  0.766892  [[158, 138], [0, 4]]  0.696035  0.0547945   0.0296269   
8  0.936667  0.721284   [[279, 17], [2, 2]]  0.967071   0.173913    0.155305   
2  0.643333  0.695946  [[190, 106], [1, 3]]  0.780287  0.0530973   0.0280974   
5  0.956667  0.608108   [[286, 10], [3, 1]]  0.977778   0.133333    0.116047   
7  0.976667  0.494932    [[293, 3], [4, 0]]  0.988196          0  -0.0115607   
3      0.97  0.491554    [[291, 5], [4, 0]]  0.984772          0  -0.0150376   
1  0.723333  0.489865   [[216, 80], [3, 1]]  0.838835  0.0235294 -0.00193143   
4  0.966667  0.489865    [[290, 6], [4, 0]]  0.983051          0  -0.0162602   
6  0.963333  0.488176    [[289, 7], [4, 0]]  0.981324          0  -0.0172626   
9  0.936667  0.474662   [[281, 15], [4, 0]]  0.967298          0  -0.0215054   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
0    0.122622         1   0.028169  0.533784      1  
8    0.208413  0.992883   0.105263  0.942568    0.5  
2   0.0934571  0.994764  0.0275229  0.641892   0.75  
5    0.131953  0.989619  0.0909091  0.966216   0.25  
7  -0.0116833  0.986532          0  0.989865      0  
3  -0.0151342  0.986441          0  0.983108      0  
1 -0.00523686  0.986301  0.0123457   0.72973   0.25  
4  -0.0166068  0.986395          0   0.97973      0  
6   -0.017968  0.986348          0  0.976351      0  
9   -0.026669  0.985965          0  0.949324      0  
Elapsed time 40.30 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv 
datetime: 2017-05-06 20:57:32.341000 
pca_target: 0 	 poly degree: 0 	 kselect: 20 
Imbalance: ClusterCentroids(estimator=None, n_jobs=1, random_state=None, ratio='auto') 
Extended target (count):  25141 325
('Total : Processed (count): ', (998L, 221L), 13)
Final feature (count):  (998L, 221L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.477 	0.051 	0.011 	0.611 	0.596 	0.365
[[140 156]
 [  1   3]]
             precision    recall  f1-score   support

          0       0.99      0.47      0.64       296
          1       0.02      0.75      0.04         4

avg / total       0.98      0.48      0.63       300


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=10, class_weight={1: 15}, dual=False, fit_intercept=True,
          intercept_scaling=0.1, max_iter=100, multi_class='ovr', n_jobs=4,
          penalty='l2', random_state=None, solver='lbfgs', tol=0.0001,
          verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.640 	0.034 	0.010 	0.571 	0.567 	0.316
[[190 106]
 [  2   2]]
             precision    recall  f1-score   support

          0       0.99      0.64      0.78       296
          1       0.02      0.50      0.04         4

avg / total       0.98      0.64      0.77       300


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.1, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='modified_huber', n_iter=5, n_jobs=4,
       penalty='l1', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.503 	0.057 	0.013 	0.625 	0.612 	0.384
[[148 148]
 [  1   3]]
             precision    recall  f1-score   support

          0       0.99      0.50      0.67       296
          1       0.02      0.75      0.04         4

avg / total       0.98      0.50      0.66       300


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=8, max_features='auto', max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.390 	0.090 	0.016 	0.691 	0.618 	0.405
[[113 183]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.38      0.55       296
          1       0.02      1.00      0.04         4

avg / total       0.99      0.39      0.55       300


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.227 	0.061 	0.007 	0.608 	0.465 	0.233
[[ 64 232]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.22      0.36       296
          1       0.02      1.00      0.03         4

avg / total       0.99      0.23      0.35       300


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.490 	0.054 	0.012 	0.618 	0.604 	0.374
[[144 152]
 [  1   3]]
             precision    recall  f1-score   support

          0       0.99      0.49      0.65       296
          1       0.02      0.75      0.04         4

avg / total       0.98      0.49      0.64       300


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=0.5, n_estimators=15, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.170 	-0.027 	-0.003 	0.456 	0.349 	0.129
[[ 48 248]
 [  1   3]]
             precision    recall  f1-score   support

          0       0.98      0.16      0.28       296
          1       0.01      0.75      0.02         4

avg / total       0.97      0.17      0.27       300


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.417 	-0.020 	-0.004 	0.458 	0.456 	0.210
[[123 173]
 [  2   2]]
             precision    recall  f1-score   support

          0       0.98      0.42      0.58       296
          1       0.01      0.50      0.02         4

avg / total       0.97      0.42      0.58       300


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=1.0, class_weight={1: 500}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Ran...owski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='uniform'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.443 	0.044 	0.009 	0.595 	0.574 	0.340
[[130 166]
 [  1   3]]
             precision    recall  f1-score   support

          0       0.99      0.44      0.61       296
          1       0.02      0.75      0.03         4

avg / total       0.98      0.44      0.60       300


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=3, p=1,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.400 	0.034 	0.006 	0.573 	0.544 	0.307
[[117 179]
 [  1   3]]
             precision    recall  f1-score   support

          0       0.99      0.40      0.57       296
          1       0.02      0.75      0.03         4

avg / total       0.98      0.40      0.56       300


                estimator min_score mean_score max_score   sd_score       acc  \
3    ExtraTreesClassifier  0.701045   0.965516         1  0.0619372      0.39   
2           SGDClassifier -0.402089     0.3318  0.812156   0.173496  0.503333   
5           MLPClassifier    0.2566   0.487557  0.718234   0.192473      0.49   
0              GaussianNB         1          1         1          0  0.476667   
4  RandomForestClassifier  0.812156    0.98244         1  0.0405192  0.226667   
8        VotingClassifier    0.5132    0.76807         1   0.116083  0.443333   
9    KNeighborsClassifier    0.2566   0.564765  0.718234   0.108865       0.4   
1      LogisticRegression -0.367711   0.300593  0.701045    0.22917      0.64   
7                     SVC         0   0.296624  0.718234   0.253264  0.416667   
6      AdaBoostClassifier  0.333333   0.902236         1   0.102772      0.17   

        auc           conf_matrix     f1_c0      f1_c1       kappa  \
3  0.690878  [[113, 183], [0, 4]]  0.552567  0.0418848   0.0161996   
2     0.625  [[148, 148], [1, 3]]  0.665169  0.0387097   0.0130707   
5  0.618243  [[144, 152], [1, 3]]  0.653061  0.0377358   0.0120534   
0  0.611486  [[140, 156], [1, 3]]  0.640732  0.0368098   0.0110859   
4  0.608108   [[64, 232], [0, 4]]  0.355556  0.0333333   0.0073026   
8  0.594595  [[130, 166], [1, 3]]  0.608899  0.0346821  0.00886286   
9  0.572635  [[117, 179], [1, 3]]  0.565217  0.0322581  0.00633005   
1  0.570946  [[190, 106], [2, 2]]  0.778689  0.0357143   0.0102639   
7   0.45777  [[123, 173], [2, 2]]  0.584323  0.0223464 -0.00382409   
6  0.456081   [[48, 248], [1, 3]]  0.278261  0.0235294 -0.00279225   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
3   0.0903655         1  0.0213904  0.381757      1  
2   0.0573501  0.993289  0.0198675       0.5   0.75  
5   0.0542791  0.993103  0.0193548  0.486486   0.75  
0   0.0512413  0.992908  0.0188679  0.472973   0.75  
4   0.0605366         1  0.0169492  0.216216      1  
8   0.0437515  0.992366  0.0177515  0.439189   0.75  
9   0.0341095  0.991525  0.0164835   0.39527   0.75  
1   0.0339056  0.989583  0.0185185  0.641892    0.5  
7  -0.0196494     0.984  0.0114286  0.415541    0.5  
6  -0.0272535  0.979592  0.0119522  0.162162   0.75  
Elapsed time 18.42 mins 

************************************************************






Standard, lagged (3,4)x1, filter(tukey), NT+, truncated





    pca = [0]
    poly = [0]
    ksel = [20, 0]
    imb = [None, SMOTE(), ClusterCentroids() ]


pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv 
datetime: 2017-05-07 08:14:50.211000 
pca_target: 0 	 poly degree: 0 	 kselect: 0 
Imbalance: None 
Extended target (count):  25141 325
('Total : Processed (count): ', (998L, 221L), 13)
Final feature (count):  (998L, 221L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.583 	0.134 	0.035 	0.789 	0.760 	0.602
[[171 125]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.58      0.73       296
          1       0.03      1.00      0.06         4

avg / total       0.99      0.58      0.72       300


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.001, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.523 	0.119 	0.028 	0.758 	0.719 	0.542
[[153 143]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.52      0.68       296
          1       0.03      1.00      0.05         4

avg / total       0.99      0.52      0.67       300


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=1, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='modified_huber', n_iter=5, n_jobs=4,
       penalty='l2', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.977 	-0.012 	-0.012 	0.495 	0.000 	0.000
[[293   3]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       296
          1       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.98       300


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight='balanced',
           criterion='gini', max_depth=8, max_features=0.33,
           max_leaf_nodes=None, min_impurity_split=1e-07,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=15, n_jobs=4,
           oob_score=False, random_state=None, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	0.000 	0.000 	0.500 	0.000 	0.000
[[296   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       296
          1       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       300


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	0.000 	0.000 	0.500 	0.000 	0.000
[[296   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       296
          1       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       300


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.1, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	0.000 	0.000 	0.500 	0.000 	0.000
[[296   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       296
          1       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       300


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight='balanced', criterion='entropy',
            max_depth=32, max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=2.0, n_estimators=50, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.973 	-0.014 	-0.014 	0.493 	0.000 	0.000
[[292   4]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       296
          1       0.00      0.00      0.00         4

avg / total       0.97      0.97      0.97       300


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.01, cache_size=200, class_weight={1: 500}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.413 	0.095 	0.018 	0.703 	0.637 	0.430
[[120 176]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.41      0.58       296
          1       0.02      1.00      0.04         4

avg / total       0.99      0.41      0.57       300


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	0.000 	0.000 	0.500 	0.000 	0.000
[[296   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       296
          1       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       300


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=1,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	0.000 	0.000 	0.500 	0.000 	0.000
[[296   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       296
          1       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       300


                estimator   min_score   mean_score   max_score     sd_score  \
0              GaussianNB  0.00866966   0.00866966  0.00866966            0   
1      LogisticRegression  -0.0643224  -0.00524257   0.0874881    0.0282698   
7                     SVC  -0.0347461  -0.00811151   0.0662962    0.0119727   
3    ExtraTreesClassifier  -0.0291599 -0.000275451    0.133843   0.00967048   
4  RandomForestClassifier -0.00495491  -0.00011433           0  0.000595801   
5           MLPClassifier  -0.0122117  -0.00714234 -0.00204805   0.00225687   
8        VotingClassifier -0.00349117 -0.000326259           0  0.000762255   
9    KNeighborsClassifier  -0.0101862  -0.00257816           0   0.00385755   
2           SGDClassifier   -0.107212   0.00877766    0.134334    0.0409419   
6      AdaBoostClassifier  -0.0240373  -0.00349438    0.230386    0.0253094   

        acc       auc           conf_matrix     f1_c0      f1_c1      kappa  \
0  0.583333  0.788851  [[171, 125], [0, 4]]  0.732334  0.0601504   0.035196   
1  0.523333  0.758446  [[153, 143], [0, 4]]  0.681514  0.0529801    0.02774   
7  0.413333  0.702703  [[120, 176], [0, 4]]  0.576923  0.0434783  0.0178571   
3  0.986667       0.5    [[296, 0], [4, 0]]  0.993289          0          0   
4  0.986667       0.5    [[296, 0], [4, 0]]  0.993289          0          0   
5  0.986667       0.5    [[296, 0], [4, 0]]  0.993289          0          0   
8  0.986667       0.5    [[296, 0], [4, 0]]  0.993289          0          0   
9  0.986667       0.5    [[296, 0], [4, 0]]  0.993289          0          0   
2  0.976667  0.494932    [[293, 3], [4, 0]]  0.988196          0 -0.0115607   
6  0.973333  0.493243    [[292, 4], [4, 0]]  0.986486          0 -0.0135135   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
0     0.13384         1  0.0310078  0.577703      1  
1    0.118596         1  0.0272109  0.516892      1  
7   0.0949158         1  0.0222222  0.405405      1  
3           0  0.986667          0         1      0  
4           0  0.986667          0         1      0  
5           0  0.986667          0         1      0  
8           0  0.986667          0         1      0  
9           0  0.986667          0         1      0  
2  -0.0116833  0.986532          0  0.989865      0  
6  -0.0135135  0.986486          0  0.986486      0  
Elapsed time 39.25 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv 
datetime: 2017-05-07 08:54:04.946000 
pca_target: 0 	 poly degree: 0 	 kselect: 0 
Imbalance: SMOTE(k=None, k_neighbors=5, kind='regular', m=None, m_neighbors=10, n_jobs=1,
   out_step=0.5, random_state=None, ratio='auto', svm_estimator=None) 
Extended target (count):  25141 325
('Total : Processed (count): ', (998L, 221L), 13)
Final feature (count):  (998L, 221L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.693 	0.169 	0.056 	0.845 	0.830 	0.711
[[204  92]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.69      0.82       296
          1       0.04      1.00      0.08         4

avg / total       0.99      0.69      0.81       300


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=10, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.973 	0.191 	0.187 	0.617 	0.496 	0.228
[[291   5]
 [  3   1]]
             precision    recall  f1-score   support

          0       0.99      0.98      0.99       296
          1       0.17      0.25      0.20         4

avg / total       0.98      0.97      0.98       300


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.0001, average=False, class_weight='balanced',
       epsilon=0.1, eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='perceptron', n_iter=5, n_jobs=4,
       penalty='l1', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.973 	0.191 	0.187 	0.617 	0.496 	0.228
[[291   5]
 [  3   1]]
             precision    recall  f1-score   support

          0       0.99      0.98      0.99       296
          1       0.17      0.25      0.20         4

avg / total       0.98      0.97      0.98       300


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=32, max_features='auto', max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=30, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.990 	0.497 	0.397 	0.625 	0.500 	0.231
[[296   0]
 [  3   1]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       296
          1       1.00      0.25      0.40         4

avg / total       0.99      0.99      0.99       300


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight='balanced',
            criterion='gini', max_depth=None, max_features='auto',
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.983 	-0.007 	-0.005 	0.498 	0.000 	0.000
[[295   1]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       296
          1       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.98       300


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	0.348 	0.327 	0.623 	0.499 	0.231
[[295   1]
 [  3   1]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       296
          1       0.50      0.25      0.33         4

avg / total       0.98      0.99      0.98       300


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=1.0, n_estimators=50, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	0.000 	0.000 	0.500 	0.000 	0.000
[[296   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       296
          1       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       300


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.1, cache_size=200, class_weight={1: 50}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	0.000 	0.000 	0.500 	0.000 	0.000
[[296   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       296
          1       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       300


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=10.0, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', ...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.983 	0.439 	0.436 	0.745 	0.704 	0.471
[[293   3]
 [  2   2]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       296
          1       0.40      0.50      0.44         4

avg / total       0.99      0.98      0.98       300


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=1,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.933 	0.202 	0.148 	0.720 	0.685 	0.449
[[278  18]
 [  2   2]]
             precision    recall  f1-score   support

          0       0.99      0.94      0.97       296
          1       0.10      0.50      0.17         4

avg / total       0.98      0.93      0.95       300


                estimator  min_score mean_score max_score    sd_score  \
0              GaussianNB    0.64458    0.64458   0.64458           0   
8        VotingClassifier   0.884821   0.949298  0.982758   0.0243232   
9    KNeighborsClassifier   0.767963   0.834737    0.9031   0.0426808   
3    ExtraTreesClassifier   0.680392   0.963796         1    0.058071   
5           MLPClassifier   0.965776   0.978014  0.989898  0.00631683   
1      LogisticRegression   0.255694   0.810822  0.957385    0.153291   
2           SGDClassifier -0.0862289   0.602956  0.977065    0.270152   
6      AdaBoostClassifier   0.894895   0.974051         1   0.0185095   
7                     SVC          0   0.808059         1    0.320476   
4  RandomForestClassifier   0.939289   0.980705  0.997108   0.0102265   

        acc       auc          conf_matrix     f1_c0     f1_c1       kappa  \
0  0.693333  0.844595  [[204, 92], [0, 4]]     0.816      0.08   0.0558292   
8  0.983333  0.744932   [[293, 3], [2, 2]]   0.99154  0.444444     0.43609   
9  0.933333  0.719595  [[278, 18], [2, 2]]  0.965278  0.166667    0.147727   
3      0.99     0.625   [[296, 0], [3, 1]]  0.994958       0.4    0.396783   
5  0.986667  0.623311   [[295, 1], [3, 1]]  0.993266  0.333333    0.327354   
1  0.973333  0.616554   [[291, 5], [3, 1]]  0.986441       0.2    0.186992   
2  0.973333  0.616554   [[291, 5], [3, 1]]  0.986441       0.2    0.186992   
6  0.986667       0.5   [[296, 0], [4, 0]]  0.993289         0           0   
7  0.986667       0.5   [[296, 0], [4, 0]]  0.993289         0           0   
4  0.983333  0.498311   [[295, 1], [4, 0]]  0.991597         0 -0.00536193   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
0    0.169459         1  0.0416667  0.689189      1  
8     0.43889   0.99322        0.4  0.989865    0.5  
9    0.201945  0.992857        0.1  0.939189    0.5  
3    0.497485  0.989967          1         1   0.25  
5    0.347603  0.989933        0.5  0.996622   0.25  
1    0.190978  0.989796   0.166667  0.983108   0.25  
2    0.190978  0.989796   0.166667  0.983108   0.25  
6           0  0.986667          0         1      0  
7           0  0.986667          0         1      0  
4 -0.00672277  0.986622          0  0.996622      0  
Elapsed time 89.69 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv 
datetime: 2017-05-07 10:23:46.449000 
pca_target: 0 	 poly degree: 0 	 kselect: 0 
Imbalance: ClusterCentroids(estimator=None, n_jobs=1, random_state=None, ratio='auto') 
Extended target (count):  25141 325
('Total : Processed (count): ', (998L, 221L), 13)
Final feature (count):  (998L, 221L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.540 	0.123 	0.030 	0.767 	0.731 	0.559
[[158 138]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.53      0.70       296
          1       0.03      1.00      0.05         4

avg / total       0.99      0.54      0.69       300


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=5, class_weight={1: 500}, dual=False, fit_intercept=True,
          intercept_scaling=0.01, max_iter=100, multi_class='ovr',
          n_jobs=4, penalty='l2', random_state=None, solver='sag',
          tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.523 	0.119 	0.028 	0.758 	0.719 	0.542
[[153 143]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.52      0.68       296
          1       0.03      1.00      0.05         4

avg / total       0.99      0.52      0.67       300


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.001, average=False, class_weight={1: 50}, epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='constant', loss='squared_hinge', n_iter=5, n_jobs=4,
       penalty='l1', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.480 	0.052 	0.011 	0.613 	0.598 	0.367
[[141 155]
 [  1   3]]
             precision    recall  f1-score   support

          0       0.99      0.48      0.64       296
          1       0.02      0.75      0.04         4

avg / total       0.98      0.48      0.64       300


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 15}, criterion='gini',
           max_depth=8, max_features=0.75, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.540 	0.123 	0.030 	0.767 	0.731 	0.559
[[158 138]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.53      0.70       296
          1       0.03      1.00      0.05         4

avg / total       0.99      0.54      0.69       300


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features=0.33, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.497 	0.112 	0.025 	0.745 	0.700 	0.515
[[145 151]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.49      0.66       296
          1       0.03      1.00      0.05         4

avg / total       0.99      0.50      0.65       300


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.01, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.863 	0.123 	0.066 	0.684 	0.659 	0.418
[[257  39]
 [  2   2]]
             precision    recall  f1-score   support

          0       0.99      0.87      0.93       296
          1       0.05      0.50      0.09         4

avg / total       0.98      0.86      0.91       300


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=0.5, n_estimators=15, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.490 	0.111 	0.024 	0.742 	0.695 	0.508
[[143 153]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.48      0.65       296
          1       0.03      1.00      0.05         4

avg / total       0.99      0.49      0.64       300


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=1, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.347 	0.022 	0.004 	0.546 	0.506 	0.266
[[101 195]
 [  1   3]]
             precision    recall  f1-score   support

          0       0.99      0.34      0.51       296
          1       0.02      0.75      0.03         4

avg / total       0.98      0.35      0.50       300


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 500}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Ran...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.703 	0.113 	0.039 	0.726 	0.726 	0.530
[[208  88]
 [  1   3]]
             precision    recall  f1-score   support

          0       1.00      0.70      0.82       296
          1       0.03      0.75      0.06         4

avg / total       0.98      0.70      0.81       300


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=3, p=1,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.860 	-0.044 	-0.025 	0.436 	0.000 	0.000
[[258  38]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.98      0.87      0.92       296
          1       0.00      0.00      0.00         4

avg / total       0.97      0.86      0.91       300


                estimator  min_score mean_score max_score  sd_score       acc  \
0              GaussianNB   0.444444   0.444444  0.444444         0      0.54   
3    ExtraTreesClassifier          0   0.487607  0.812156  0.137641      0.54   
1      LogisticRegression  -0.607122  0.0350932  0.624311  0.188965  0.523333   
4  RandomForestClassifier -0.0171889     0.6875         1  0.218262  0.496667   
6      AdaBoostClassifier  -0.222222   0.613467         1  0.273961      0.49   
8        VotingClassifier    -0.1283   0.172343  0.589933  0.129407  0.703333   
5           MLPClassifier  -0.478822  0.0174699    0.2566  0.158766  0.863333   
2           SGDClassifier  -0.496011   0.289057  0.718234  0.172529      0.48   
7                     SVC    -0.1283   0.064334  0.350522  0.107781  0.346667   
9    KNeighborsClassifier    -0.1283  0.0215495    0.2566  0.109394      0.86   

        auc           conf_matrix     f1_c0      f1_c1       kappa  \
0  0.766892  [[158, 138], [0, 4]]  0.696035  0.0547945   0.0296269   
3  0.766892  [[158, 138], [0, 4]]  0.696035  0.0547945   0.0296269   
1  0.758446  [[153, 143], [0, 4]]  0.681514  0.0529801     0.02774   
4  0.744932  [[145, 151], [0, 4]]  0.657596  0.0503145   0.0249677   
6  0.741554  [[143, 153], [0, 4]]  0.651481  0.0496894   0.0243177   
8  0.726351   [[208, 88], [1, 3]]  0.823762  0.0631579      0.0386   
5  0.684122   [[257, 39], [2, 2]]  0.926126  0.0888889    0.066201   
2  0.613176  [[141, 155], [1, 3]]  0.643836   0.037037   0.0113233   
7  0.545608  [[101, 195], [1, 3]]  0.507538   0.029703  0.00366002   
9  0.435811   [[258, 38], [4, 0]]  0.924731          0  -0.0247235   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
0    0.122622         1   0.028169  0.533784      1  
3    0.122622         1   0.028169  0.533784      1  
1    0.118596         1  0.0272109  0.516892      1  
4    0.112435         1  0.0258065  0.489865      1  
6    0.110944         1  0.0254777  0.483108      1  
8    0.112952  0.995215   0.032967  0.702703   0.75  
5    0.122961  0.992278  0.0487805  0.868243    0.5  
2    0.051998  0.992958  0.0189873  0.476351   0.75  
7   0.0220859  0.990196  0.0151515  0.341216   0.75  
9  -0.0442716  0.984733          0  0.871622      0  
Elapsed time 23.77 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv 
datetime: 2017-05-07 10:47:32.605000 
pca_target: 0 	 poly degree: 0 	 kselect: 20 
Imbalance: None 
Extended target (count):  25141 325
('Total : Processed (count): ', (998L, 221L), 13)
Final feature (count):  (998L, 221L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.793 	0.015 	0.006 	0.525 	0.447 	0.189
[[237  59]
 [  3   1]]
             precision    recall  f1-score   support

          0       0.99      0.80      0.88       296
          1       0.02      0.25      0.03         4

avg / total       0.97      0.79      0.87       300


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=1, class_weight={1: 15}, dual=False, fit_intercept=True,
          intercept_scaling=0.01, max_iter=100, multi_class='ovr',
          n_jobs=4, penalty='l2', random_state=None, solver='sag',
          tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.963 	-0.018 	-0.017 	0.488 	0.000 	0.000
[[289   7]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.98      0.98       296
          1       0.00      0.00      0.00         4

avg / total       0.97      0.96      0.97       300


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.1, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='modified_huber', n_iter=5, n_jobs=4,
       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.977 	-0.012 	-0.012 	0.495 	0.000 	0.000
[[293   3]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       296
          1       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.98       300


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight='balanced',
           criterion='gini', max_depth=8, max_features=0.33,
           max_leaf_nodes=None, min_impurity_split=1e-07,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=4,
           oob_score=False, random_state=None, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.953 	-0.022 	-0.019 	0.483 	0.000 	0.000
[[286  10]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.97      0.98       296
          1       0.00      0.00      0.00         4

avg / total       0.97      0.95      0.96       300


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3},
            criterion='entropy', max_depth=8, max_features=0.33,
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=15, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	0.000 	0.000 	0.500 	0.000 	0.000
[[296   0]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       296
          1       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       300


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(500,), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.960 	-0.019 	-0.018 	0.486 	0.000 	0.000
[[288   8]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.97      0.98       296
          1       0.00      0.00      0.00         4

avg / total       0.97      0.96      0.97       300


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='entropy', max_depth=16,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=1.0, n_estimators=80, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.960 	-0.019 	-0.018 	0.486 	0.000 	0.000
[[288   8]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.97      0.98       296
          1       0.00      0.00      0.00         4

avg / total       0.97      0.96      0.97       300


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=1, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.977 	-0.012 	-0.012 	0.495 	0.000 	0.000
[[293   3]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       296
          1       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.98       300


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', R...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.983 	-0.007 	-0.005 	0.498 	0.000 	0.000
[[295   1]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       296
          1       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.98       300


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=3,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.967 	-0.017 	-0.016 	0.490 	0.000 	0.000
[[290   6]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.98      0.98       296
          1       0.00      0.00      0.00         4

avg / total       0.97      0.97      0.97       300


                estimator  min_score   mean_score max_score    sd_score  \
0              GaussianNB   0.130015     0.130015  0.130015           0   
4  RandomForestClassifier -0.0107934 -0.000627508  0.141315  0.00763128   
8        VotingClassifier -0.0124278    0.0404034   0.27914   0.0686156   
2           SGDClassifier  -0.136382    0.0317456  0.197708   0.0408575   
7                     SVC  -0.122348    0.0379705  0.139872    0.042975   
9    KNeighborsClassifier          0    0.0354539  0.161735   0.0631791   
1      LogisticRegression -0.0576972     0.055479  0.195028   0.0511942   
5           MLPClassifier  -0.013662   0.00970992    0.2139   0.0406044   
6      AdaBoostClassifier  -0.018543    0.0265327  0.272665   0.0547637   
3    ExtraTreesClassifier  -0.011569    0.0353182  0.277676   0.0637296   

        acc       auc          conf_matrix     f1_c0    f1_c1       kappa  \
0  0.793333  0.525338  [[237, 59], [3, 1]]  0.884328  0.03125  0.00641026   
4  0.986667       0.5   [[296, 0], [4, 0]]  0.993289        0           0   
8  0.983333  0.498311   [[295, 1], [4, 0]]  0.991597        0 -0.00536193   
2  0.976667  0.494932   [[293, 3], [4, 0]]  0.988196        0  -0.0115607   
7  0.976667  0.494932   [[293, 3], [4, 0]]  0.988196        0  -0.0115607   
9  0.966667  0.489865   [[290, 6], [4, 0]]  0.983051        0  -0.0162602   
1  0.963333  0.488176   [[289, 7], [4, 0]]  0.981324        0  -0.0172626   
5      0.96  0.486486   [[288, 8], [4, 0]]  0.979592        0  -0.0180995   
6      0.96  0.486486   [[288, 8], [4, 0]]  0.979592        0  -0.0180995   
3  0.953333  0.483108  [[286, 10], [4, 0]]  0.976109        0  -0.0194175   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
0    0.014531    0.9875  0.0166667  0.800676   0.25  
4           0  0.986667          0         1      0  
8 -0.00672277  0.986622          0  0.996622      0  
2  -0.0116833  0.986532          0  0.989865      0  
7  -0.0116833  0.986532          0  0.989865      0  
9  -0.0166068  0.986395          0   0.97973      0  
1   -0.017968  0.986348          0  0.976351      0  
5  -0.0192414  0.986301          0  0.972973      0  
6  -0.0192414  0.986301          0  0.972973      0  
3  -0.0215866  0.986207          0  0.966216      0  
Elapsed time 29.27 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv 
datetime: 2017-05-07 11:16:48.755000 
pca_target: 0 	 poly degree: 0 	 kselect: 20 
Imbalance: SMOTE(k=None, k_neighbors=5, kind='regular', m=None, m_neighbors=10, n_jobs=1,
   out_step=0.5, random_state=None, ratio='auto', svm_estimator=None) 
Extended target (count):  25141 325
('Total : Processed (count): ', (998L, 221L), 13)
Final feature (count):  (998L, 221L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.687 	0.107 	0.035 	0.718 	0.717 	0.518
[[203  93]
 [  1   3]]
             precision    recall  f1-score   support

          0       1.00      0.69      0.81       296
          1       0.03      0.75      0.06         4

avg / total       0.98      0.69      0.80       300


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=5, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='sag', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.797 	0.154 	0.066 	0.774 	0.773 	0.595
[[236  60]
 [  1   3]]
             precision    recall  f1-score   support

          0       1.00      0.80      0.89       296
          1       0.05      0.75      0.09         4

avg / total       0.98      0.80      0.87       300


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.1, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.001, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='modified_huber', n_iter=5, n_jobs=4,
       penalty='none', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.817 	0.095 	0.044 	0.660 	0.641 	0.397
[[243  53]
 [  2   2]]
             precision    recall  f1-score   support

          0       0.99      0.82      0.90       296
          1       0.04      0.50      0.07         4

avg / total       0.98      0.82      0.89       300


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 50},
           criterion='entropy', max_depth=None, max_features=0.75,
           max_leaf_nodes=None, min_impurity_split=1e-07,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=15, n_jobs=4,
           oob_score=False, random_state=None, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.933 	0.093 	0.071 	0.596 	0.485 	0.219
[[279  17]
 [  3   1]]
             precision    recall  f1-score   support

          0       0.99      0.94      0.97       296
          1       0.06      0.25      0.09         4

avg / total       0.98      0.93      0.95       300


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight='balanced',
            criterion='gini', max_depth=32, max_features=0.33,
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.920 	0.180 	0.123 	0.713 	0.680 	0.443
[[274  22]
 [  2   2]]
             precision    recall  f1-score   support

          0       0.99      0.93      0.96       296
          1       0.08      0.50      0.14         4

avg / total       0.98      0.92      0.95       300


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.5, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.957 	-0.020 	-0.019 	0.485 	0.000 	0.000
[[287   9]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.97      0.98       296
          1       0.00      0.00      0.00         4

avg / total       0.97      0.96      0.96       300


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 50}, criterion='entropy', max_depth=8,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=0.5, n_estimators=80, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.937 	0.208 	0.155 	0.721 	0.687 	0.450
[[279  17]
 [  2   2]]
             precision    recall  f1-score   support

          0       0.99      0.94      0.97       296
          1       0.11      0.50      0.17         4

avg / total       0.98      0.94      0.96       300


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=10, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.943 	-0.025 	-0.021 	0.478 	0.000 	0.000
[[283  13]
 [  4   0]]
             precision    recall  f1-score   support

          0       0.99      0.96      0.97       296
          1       0.00      0.00      0.00         4

avg / total       0.97      0.94      0.96       300


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=10.0, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', ...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.923 	0.185 	0.128 	0.715 	0.682 	0.445
[[275  21]
 [  2   2]]
             precision    recall  f1-score   support

          0       0.99      0.93      0.96       296
          1       0.09      0.50      0.15         4

avg / total       0.98      0.92      0.95       300


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=4,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.923 	0.082 	0.059 	0.591 	0.483 	0.217
[[276  20]
 [  3   1]]
             precision    recall  f1-score   support

          0       0.99      0.93      0.96       296
          1       0.05      0.25      0.08         4

avg / total       0.98      0.92      0.95       300


                estimator  min_score mean_score max_score    sd_score  \
1      LogisticRegression          0   0.583666  0.723909    0.159156   
6      AdaBoostClassifier   0.650419   0.860985  0.921801   0.0389876   
0              GaussianNB   0.584932   0.584932  0.584932           0   
8        VotingClassifier   0.817704   0.866582  0.907016   0.0208868   
4  RandomForestClassifier   0.759569    0.89866  0.936397   0.0407421   
2           SGDClassifier -0.0710029   0.456803  0.745589    0.194211   
3    ExtraTreesClassifier   0.636303   0.866552  0.933161   0.0645329   
9    KNeighborsClassifier   0.803766   0.865622  0.917808   0.0308462   
5           MLPClassifier   0.929025   0.951773  0.967202  0.00979438   
7                     SVC          0   0.671332  0.954478    0.197419   

        acc       auc          conf_matrix     f1_c0      f1_c1      kappa  \
1  0.796667  0.773649  [[236, 60], [1, 3]]  0.885553  0.0895522  0.0661359   
6  0.936667  0.721284  [[279, 17], [2, 2]]  0.967071   0.173913   0.155305   
0  0.686667  0.717905  [[203, 93], [1, 3]]     0.812       0.06  0.0353038   
8  0.923333  0.714527  [[275, 21], [2, 2]]   0.95986   0.148148   0.128348   
4      0.92  0.712838  [[274, 22], [2, 2]]  0.958042   0.142857   0.122807   
2  0.816667  0.660473  [[243, 53], [2, 2]]  0.898336  0.0677966  0.0440324   
3  0.933333  0.596284  [[279, 17], [3, 1]]  0.965398  0.0909091   0.070632   
9  0.923333  0.591216  [[276, 20], [3, 1]]      0.96       0.08  0.0589198   
5  0.956667  0.484797   [[287, 9], [4, 0]]  0.977853          0 -0.0188088   
7  0.943333  0.478041  [[283, 13], [4, 0]]   0.97084          0 -0.0208167   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
1    0.154118  0.995781   0.047619  0.797297   0.75  
6    0.208413  0.992883   0.105263  0.942568    0.5  
0    0.107158  0.995098    0.03125  0.685811   0.75  
8    0.184963   0.99278  0.0869565  0.929054    0.5  
4    0.179968  0.992754  0.0833333  0.925676    0.5  
2   0.0951357  0.991837  0.0363636  0.820946    0.5  
3   0.0930033  0.989362  0.0555556  0.942568   0.25  
9   0.0820099  0.989247   0.047619  0.932432   0.25  
5  -0.0204437  0.986254          0  0.969595      0  
7  -0.0247409  0.986063          0  0.956081      0  
Elapsed time 45.02 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv 
datetime: 2017-05-07 12:01:49.742000 
pca_target: 0 	 poly degree: 0 	 kselect: 20 
Imbalance: ClusterCentroids(estimator=None, n_jobs=1, random_state=None, ratio='auto') 
Extended target (count):  25141 325
('Total : Processed (count): ', (998L, 221L), 13)
Final feature (count):  (998L, 221L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.567 	0.129 	0.033 	0.780 	0.749 	0.585
[[166 130]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.56      0.72       296
          1       0.03      1.00      0.06         4

avg / total       0.99      0.57      0.71       300


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=5, class_weight={1: 50}, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=4,
          penalty='l2', random_state=None, solver='sag', tol=0.0001,
          verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.703 	0.113 	0.039 	0.726 	0.726 	0.530
[[208  88]
 [  1   3]]
             precision    recall  f1-score   support

          0       1.00      0.70      0.82       296
          1       0.03      0.75      0.06         4

avg / total       0.98      0.70      0.81       300


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.5, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='squared_hinge', n_iter=5, n_jobs=4,
       penalty='l2', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.597 	0.080 	0.022 	0.672 	0.668 	0.453
[[176 120]
 [  1   3]]
             precision    recall  f1-score   support

          0       0.99      0.59      0.74       296
          1       0.02      0.75      0.05         4

avg / total       0.98      0.60      0.73       300


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=None, max_features='auto', max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=30, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.577 	0.132 	0.034 	0.785 	0.756 	0.595
[[169 127]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.57      0.73       296
          1       0.03      1.00      0.06         4

avg / total       0.99      0.58      0.72       300


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features=0.75, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=30, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.490 	0.111 	0.024 	0.742 	0.695 	0.508
[[143 153]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.48      0.65       296
          1       0.03      1.00      0.05         4

avg / total       0.99      0.49      0.64       300


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.730 	0.060 	0.022 	0.617 	0.605 	0.358
[[217  79]
 [  2   2]]
             precision    recall  f1-score   support

          0       0.99      0.73      0.84       296
          1       0.02      0.50      0.05         4

avg / total       0.98      0.73      0.83       300


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=1.0, n_estimators=50, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.490 	0.111 	0.024 	0.742 	0.695 	0.508
[[143 153]
 [  0   4]]
             precision    recall  f1-score   support

          0       1.00      0.48      0.65       296
          1       0.03      1.00      0.05         4

avg / total       0.99      0.49      0.64       300


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=10, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.607 	0.025 	0.007 	0.554 	0.551 	0.301
[[180 116]
 [  2   2]]
             precision    recall  f1-score   support

          0       0.99      0.61      0.75       296
          1       0.02      0.50      0.03         4

avg / total       0.98      0.61      0.74       300


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', R...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.703 	0.113 	0.039 	0.726 	0.726 	0.530
[[208  88]
 [  1   3]]
             precision    recall  f1-score   support

          0       1.00      0.70      0.82       296
          1       0.03      0.75      0.06         4

avg / total       0.98      0.70      0.81       300


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=5, p=1,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.797 	0.086 	0.037 	0.650 	0.633 	0.388
[[237  59]
 [  2   2]]
             precision    recall  f1-score   support

          0       0.99      0.80      0.89       296
          1       0.03      0.50      0.06         4

avg / total       0.98      0.80      0.87       300


                estimator  min_score mean_score max_score   sd_score  \
3    ExtraTreesClassifier   0.333333   0.766974         1   0.101652   
0              GaussianNB   0.888889   0.888889  0.888889          0   
4  RandomForestClassifier   0.478822   0.929722         1   0.082802   
6      AdaBoostClassifier     0.1283   0.809604         1   0.140457   
1      LogisticRegression -0.0171889   0.307152  0.624311   0.199418   
8        VotingClassifier   0.461633   0.751883  0.906078  0.0743363   
2           SGDClassifier    -0.2566   0.322343  0.812156   0.149093   
9    KNeighborsClassifier   0.111111   0.450328  0.718234    0.11913   
5           MLPClassifier   0.333333   0.495141  0.589933  0.0687879   
7                     SVC          0   0.366963  0.701045   0.271885   

        acc       auc           conf_matrix     f1_c0      f1_c1       kappa  \
3  0.576667  0.785473  [[169, 127], [0, 4]]  0.726882  0.0592593   0.0342695   
0  0.566667  0.780405  [[166, 130], [0, 4]]  0.718615   0.057971     0.03293   
4      0.49  0.741554  [[143, 153], [0, 4]]  0.651481  0.0496894   0.0243177   
6      0.49  0.741554  [[143, 153], [0, 4]]  0.651481  0.0496894   0.0243177   
1  0.703333  0.726351   [[208, 88], [1, 3]]  0.823762  0.0631579      0.0386   
8  0.703333  0.726351   [[208, 88], [1, 3]]  0.823762  0.0631579      0.0386   
2  0.596667  0.672297  [[176, 120], [1, 3]]  0.744186  0.0472441   0.0219851   
9  0.796667  0.650338   [[237, 59], [2, 2]]  0.885981  0.0615385     0.03745   
5      0.73  0.616554   [[217, 79], [2, 2]]  0.842718  0.0470588   0.0222115   
7  0.606667  0.554054  [[180, 116], [2, 2]]  0.753138  0.0327869  0.00717972   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
3    0.132036         1  0.0305344  0.570946      1  
0    0.129386         1  0.0298507  0.560811      1  
4    0.110944         1  0.0254777  0.483108      1  
6    0.110944         1  0.0254777  0.483108      1  
1    0.112952  0.995215   0.032967  0.702703   0.75  
8    0.112952  0.995215   0.032967  0.702703   0.75  
2    0.080361   0.99435  0.0243902  0.594595   0.75  
9   0.0856861  0.991632  0.0327869  0.800676    0.5  
5   0.0602239  0.990868  0.0246914  0.733108    0.5  
7   0.0253838  0.989011  0.0169492  0.608108    0.5  
Elapsed time 19.65 mins 

************************************************************






    pca = [0, 80]
    poly = [2]
    ksel = [40, 80]
    imb = [None, SMOTE(), ClusterCentroids() ]
	
	
	



pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv 
datetime: 2017-05-07 13:13:40.460000 
pca_target: 0 	 poly degree: 2 	 kselect: 40 
Imbalance: None 
Extended target (count):  25141 325
('Total : Processed (count): ', (998L, 24976L), 13)
Final feature (count):  (998L, 24976L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.870 	0.045 	0.025 	0.564 	0.469 	0.206
[[260  36]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.88      0.93       296
        1.0       0.03      0.25      0.05         4

avg / total       0.98      0.87      0.92       300


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.001, class_weight={1: 50}, dual=False,
          fit_intercept=True, intercept_scaling=10, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.877 	0.048 	0.028 	0.568 	0.470 	0.207
[[262  34]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.89      0.93       296
        1.0       0.03      0.25      0.05         4

avg / total       0.98      0.88      0.92       300


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.1, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='invscaling', loss='modified_huber', n_iter=5,
       n_jobs=4, penalty='l1', power_t=0.5, random_state=None,
       shuffle=True, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	0.000 	0.000 	0.500 	0.000 	0.000
[[296   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       296
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       300


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 15}, criterion='gini',
           max_depth=16, max_features=0.33, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.983 	-0.007 	-0.005 	0.498 	0.000 	0.000
[[295   1]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       296
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.98       300


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=30, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	0.000 	0.000 	0.500 	0.000 	0.000
[[296   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       296
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       300


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.5, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.967 	-0.017 	-0.016 	0.490 	0.000 	0.000
[[290   6]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.98      0.98       296
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.97      0.97       300


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 50}, criterion='entropy', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=2.0, n_estimators=50, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.973 	-0.014 	-0.014 	0.493 	0.000 	0.000
[[292   4]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       296
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.97      0.97       300


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.1, cache_size=200, class_weight={1: 50}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.907 	0.067 	0.045 	0.583 	0.478 	0.214
[[271  25]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.92      0.95       296
        1.0       0.04      0.25      0.07         4

avg / total       0.98      0.91      0.94       300


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	0.000 	0.000 	0.500 	0.000 	0.000
[[296   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       296
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       300


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=1,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.977 	-0.012 	-0.012 	0.495 	0.000 	0.000
[[293   3]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       296
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.98       300


                estimator   min_score   mean_score  max_score    sd_score  \
7                     SVC   -0.198884    -0.019515   0.118025   0.0487086   
1      LogisticRegression   -0.164594  -0.00325371   0.166601   0.0647707   
0              GaussianNB    0.100672     0.100672   0.100672           0   
2           SGDClassifier   -0.198324    0.0295904   0.197708   0.0490119   
4  RandomForestClassifier  -0.0189141  -0.00130805          0  0.00186365   
8        VotingClassifier -0.00991014  -0.00216978          0  0.00304652   
3    ExtraTreesClassifier  -0.0303074 -4.63893e-05   0.139267   0.0133928   
9    KNeighborsClassifier  -0.0140624   0.00145899  0.0683534   0.0179034   
6      AdaBoostClassifier  -0.0262498   -0.0023588   0.243499   0.0288097   
5           MLPClassifier  -0.0184376  -0.00215991   0.185607   0.0330923   

        acc       auc          conf_matrix     f1_c0      f1_c1       kappa  \
7  0.906667   0.58277  [[271, 25], [3, 1]]  0.950877  0.0666667    0.044586   
1  0.876667  0.567568  [[262, 34], [3, 1]]  0.934046  0.0512821    0.028021   
0      0.87  0.564189  [[260, 36], [3, 1]]  0.930233  0.0487805   0.0253249   
2  0.986667       0.5   [[296, 0], [4, 0]]  0.993289          0           0   
4  0.986667       0.5   [[296, 0], [4, 0]]  0.993289          0           0   
8  0.986667       0.5   [[296, 0], [4, 0]]  0.993289          0           0   
3  0.983333  0.498311   [[295, 1], [4, 0]]  0.991597          0 -0.00536193   
9  0.976667  0.494932   [[293, 3], [4, 0]]  0.988196          0  -0.0115607   
6  0.973333  0.493243   [[292, 4], [4, 0]]  0.986486          0  -0.0135135   
5  0.966667  0.489865   [[290, 6], [4, 0]]  0.983051          0  -0.0162602   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
7   0.0674867  0.989051  0.0384615  0.915541   0.25  
1   0.0482822  0.988679  0.0285714  0.885135   0.25  
0   0.0447805  0.988593   0.027027  0.878378   0.25  
2           0  0.986667          0         1      0  
4           0  0.986667          0         1      0  
8           0  0.986667          0         1      0  
3 -0.00672277  0.986622          0  0.996622      0  
9  -0.0116833  0.986532          0  0.989865      0  
6  -0.0135135  0.986486          0  0.986486      0  
5  -0.0166068  0.986395          0   0.97973      0  
Elapsed time 25.25 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv 
datetime: 2017-05-07 13:38:55.265000 
pca_target: 0 	 poly degree: 2 	 kselect: 40 
Imbalance: SMOTE(k=None, k_neighbors=5, kind='regular', m=None, m_neighbors=10, n_jobs=1,
   out_step=0.5, random_state=None, ratio='auto', svm_estimator=None) 
Extended target (count):  25141 325
('Total : Processed (count): ', (998L, 24976L), 13)
Final feature (count):  (998L, 24976L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.707 	0.175 	0.059 	0.851 	0.838 	0.724
[[208  88]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.70      0.83       296
        1.0       0.04      1.00      0.08         4

avg / total       0.99      0.71      0.82       300


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=10, class_weight={1: 3}, dual=False, fit_intercept=True,
          intercept_scaling=0.1, max_iter=100, multi_class='ovr', n_jobs=4,
          penalty='l2', random_state=None, solver='lbfgs', tol=0.0001,
          verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.843 	0.184 	0.091 	0.797 	0.796 	0.627
[[250  46]
 [  1   3]]
             precision    recall  f1-score   support

        0.0       1.00      0.84      0.91       296
        1.0       0.06      0.75      0.11         4

avg / total       0.98      0.84      0.90       300


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.001, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.001, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='perceptron', n_iter=5, n_jobs=4,
       penalty='l1', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.887 	0.142 	0.083 	0.696 	0.668 	0.428
[[264  32]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      0.89      0.94       296
        1.0       0.06      0.50      0.11         4

avg / total       0.98      0.89      0.93       300


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 500},
           criterion='entropy', max_depth=None, max_features=0.75,
           max_leaf_nodes=None, min_impurity_split=1e-07,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=4,
           oob_score=False, random_state=None, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.957 	-0.020 	-0.019 	0.485 	0.000 	0.000
[[287   9]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.97      0.98       296
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.96      0.96       300


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3},
            criterion='entropy', max_depth=16, max_features=0.33,
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.950 	-0.023 	-0.020 	0.481 	0.000 	0.000
[[285  11]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.96      0.97       296
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.95      0.96       300


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.01, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.980 	0.240 	0.240 	0.620 	0.497 	0.229
[[293   3]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       296
        1.0       0.25      0.25      0.25         4

avg / total       0.98      0.98      0.98       300


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 500}, criterion='entropy',
            max_depth=16, max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=1.0, n_estimators=50, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.943 	0.107 	0.086 	0.601 	0.488 	0.221
[[282  14]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.95      0.97       296
        1.0       0.07      0.25      0.11         4

avg / total       0.98      0.94      0.96       300


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=10, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.980 	-0.010 	-0.009 	0.497 	0.000 	0.000
[[294   2]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       296
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.98       300


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', R...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.957 	0.261 	0.219 	0.731 	0.694 	0.459
[[285  11]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      0.96      0.98       296
        1.0       0.15      0.50      0.24         4

avg / total       0.98      0.96      0.97       300


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=3,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.940 	0.102 	0.080 	0.600 	0.487 	0.221
[[281  15]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.95      0.97       296
        1.0       0.06      0.25      0.10         4

avg / total       0.98      0.94      0.96       300


                estimator min_score mean_score max_score    sd_score  \
0              GaussianNB  0.608726   0.608726  0.608726           0   
1      LogisticRegression         0   0.666266  0.842935    0.129667   
8        VotingClassifier  0.839932   0.881076  0.908654    0.014947   
2           SGDClassifier -0.253281   0.481694  0.879656    0.220056   
5           MLPClassifier  0.941495   0.965151  0.975763  0.00791765   
6      AdaBoostClassifier  0.695174   0.873967  0.930161    0.032656   
9    KNeighborsClassifier  0.850035   0.902845  0.947941   0.0279419   
7                     SVC         0    0.75758  0.991323    0.209978   
3    ExtraTreesClassifier  0.699382   0.909167  0.968502   0.0779729   
4  RandomForestClassifier  0.771997   0.933183  0.968612   0.0437026   

        acc       auc          conf_matrix     f1_c0      f1_c1       kappa  \
0  0.706667  0.851351  [[208, 88], [0, 4]]  0.825397  0.0833333    0.059293   
1  0.843333  0.797297  [[250, 46], [1, 3]]  0.914077   0.113208   0.0907918   
8  0.956667  0.731419  [[285, 11], [2, 2]]  0.977702   0.235294    0.219376   
2  0.886667  0.695946  [[264, 32], [2, 2]]  0.939502   0.105263   0.0833932   
5      0.98  0.619932   [[293, 3], [3, 1]]  0.989865       0.25    0.239865   
6  0.943333  0.601351  [[282, 14], [3, 1]]   0.97074   0.105263   0.0860215   
9      0.94  0.599662  [[281, 15], [3, 1]]  0.968966        0.1   0.0803815   
7      0.98  0.496622   [[294, 2], [4, 0]]  0.989899          0 -0.00896861   
3  0.956667  0.484797   [[287, 9], [4, 0]]  0.977853          0  -0.0188088   
4      0.95  0.481419  [[285, 11], [4, 0]]  0.974359          0  -0.0199456   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
0    0.174792         1  0.0434783  0.702703      1  
1    0.184485  0.996016  0.0612245  0.844595   0.75  
8    0.260731  0.993031   0.153846  0.962838    0.5  
2    0.141795  0.992481  0.0588235  0.891892    0.5  
5    0.239865  0.989865       0.25  0.989865   0.25  
6    0.106676  0.989474  0.0666667  0.952703   0.25  
9    0.101746  0.989437     0.0625  0.949324   0.25  
7 -0.00952338  0.986577          0  0.993243      0  
3  -0.0204437  0.986254          0  0.969595      0  
4  -0.0226794  0.986159          0  0.962838      0  
Elapsed time 40.84 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv 
datetime: 2017-05-07 14:19:45.688000 
pca_target: 0 	 poly degree: 2 	 kselect: 40 
Imbalance: ClusterCentroids(estimator=None, n_jobs=1, random_state=None, ratio='auto') 
Extended target (count):  25141 325
('Total : Processed (count): ', (998L, 24976L), 13)
Final feature (count):  (998L, 24976L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.547 	0.068 	0.017 	0.647 	0.639 	0.416
[[161 135]
 [  1   3]]
             precision    recall  f1-score   support

        0.0       0.99      0.54      0.70       296
        1.0       0.02      0.75      0.04         4

avg / total       0.98      0.55      0.69       300


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=10, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.273 	-0.059 	-0.008 	0.385 	0.368 	0.138
[[ 80 216]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.98      0.27      0.42       296
        1.0       0.01      0.50      0.02         4

avg / total       0.96      0.27      0.42       300


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.0001, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='perceptron', n_iter=5, n_jobs=4,
       penalty='l2', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.180 	-0.024 	-0.002 	0.461 	0.359 	0.137
[[ 51 245]
 [  1   3]]
             precision    recall  f1-score   support

        0.0       0.98      0.17      0.29       296
        1.0       0.01      0.75      0.02         4

avg / total       0.97      0.18      0.29       300


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=8, max_features='auto', max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.220 	-0.010 	-0.001 	0.481 	0.400 	0.168
[[ 63 233]
 [  1   3]]
             precision    recall  f1-score   support

        0.0       0.98      0.21      0.35       296
        1.0       0.01      0.75      0.03         4

avg / total       0.97      0.22      0.35       300


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.273 	-0.122 	-0.018 	0.262 	0.262 	0.068
[[ 81 215]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.96      0.27      0.43       296
        1.0       0.00      0.25      0.01         4

avg / total       0.95      0.27      0.42       300


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.01, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.470 	-0.120 	-0.027 	0.238 	0.000 	0.000
[[141 155]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.97      0.48      0.64       296
        1.0       0.00      0.00      0.00         4

avg / total       0.96      0.47      0.63       300


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=0.5, n_estimators=15, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.280 	0.070 	0.010 	0.635 	0.520 	0.290
[[ 80 216]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.27      0.43       296
        1.0       0.02      1.00      0.04         4

avg / total       0.99      0.28      0.42       300


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.467 	0.049 	0.010 	0.606 	0.589 	0.357
[[137 159]
 [  1   3]]
             precision    recall  f1-score   support

        0.0       0.99      0.46      0.63       296
        1.0       0.02      0.75      0.04         4

avg / total       0.98      0.47      0.62       300


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.267 	0.068 	0.009 	0.628 	0.507 	0.276
[[ 76 220]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.26      0.41       296
        1.0       0.02      1.00      0.04         4

avg / total       0.99      0.27      0.40       300


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=3,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.340 	-0.039 	-0.007 	0.419 	0.411 	0.172
[[100 196]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.98      0.34      0.50       296
        1.0       0.01      0.50      0.02         4

avg / total       0.97      0.34      0.50       300


                estimator min_score mean_score max_score     sd_score  \
0              GaussianNB  0.888889   0.888889  0.888889            0   
6      AdaBoostClassifier  0.461633   0.810881         1     0.141357   
8        VotingClassifier  0.683856   0.753877         1     0.106239   
7                     SVC         0   0.549065  0.906078     0.359611   
3    ExtraTreesClassifier  0.812156   0.812156  0.812156  2.22045e-16   
2           SGDClassifier   -0.2566   0.491278         1     0.258144   
9    KNeighborsClassifier  0.701045   0.819599         1    0.0924358   
1      LogisticRegression         0   0.506452  0.906078     0.317244   
4  RandomForestClassifier  0.572745   0.919779         1     0.089633   
5           MLPClassifier  0.367711   0.537601  0.718234    0.0735316   

        acc       auc           conf_matrix     f1_c0       f1_c1       kappa  \
0  0.546667  0.646959  [[161, 135], [1, 3]]  0.703057   0.0422535   0.0167727   
6      0.28  0.635135   [[80, 216], [0, 4]]  0.425532   0.0357143  0.00977995   
8  0.266667  0.628378   [[76, 220], [0, 4]]  0.408602   0.0350877  0.00912803   
7  0.466667  0.606419  [[137, 159], [1, 3]]  0.631336   0.0361446   0.0103909   
3      0.22  0.481419   [[63, 233], [1, 3]]      0.35       0.025 -0.00125513   
2      0.18  0.461149   [[51, 245], [1, 3]]  0.293103   0.0238095 -0.00249946   
9      0.34  0.418919  [[100, 196], [2, 2]]  0.502513    0.019802 -0.00650671   
1  0.273333  0.385135   [[80, 216], [2, 2]]   0.42328    0.018018 -0.00838781   
4  0.273333  0.261824   [[81, 215], [3, 1]]  0.426316  0.00909091  -0.0175504   
5      0.47  0.238176  [[141, 155], [4, 0]]  0.639456           0  -0.0266896   

  model_score   prec_c0     prec_c1    rec_c0 rec_c1  
0   0.0676404  0.993827   0.0217391  0.543919   0.75  
6      0.0701         1   0.0181818   0.27027      1  
8   0.0677122         1   0.0178571  0.256757      1  
7    0.048981  0.992754   0.0185185  0.462838   0.75  
3  -0.0104047  0.984375   0.0127119  0.212838   0.75  
2  -0.0235442  0.980769   0.0120968  0.172297   0.75  
9  -0.0392638  0.980392    0.010101  0.337838    0.5  
1  -0.0591232   0.97561  0.00917431   0.27027    0.5  
4   -0.121685  0.964286  0.00462963  0.273649   0.25  
5   -0.120189  0.972414           0  0.476351      0  
Elapsed time 19.39 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv 
datetime: 2017-05-07 14:39:09.276000 
pca_target: 0 	 poly degree: 2 	 kselect: 80 
Imbalance: None 
Extended target (count):  25141 325
('Total : Processed (count): ', (998L, 24976L), 13)
Final feature (count):  (998L, 24976L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.873 	0.047 	0.027 	0.566 	0.470 	0.207
[[261  35]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.88      0.93       296
        1.0       0.03      0.25      0.05         4

avg / total       0.98      0.87      0.92       300


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.001, class_weight={1: 3}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.927 	-0.029 	-0.022 	0.470 	0.000 	0.000
[[278  18]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.94      0.96       296
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.93      0.95       300


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=1, average=False, class_weight={1: 50}, epsilon=0.1,
       eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='invscaling', loss='modified_huber', n_iter=5,
       n_jobs=4, penalty='l2', power_t=0.5, random_state=None,
       shuffle=True, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.197 	-0.018 	-0.002 	0.470 	0.377 	0.150
[[ 56 240]
 [  1   3]]
             precision    recall  f1-score   support

        0.0       0.98      0.19      0.32       296
        1.0       0.01      0.75      0.02         4

avg / total       0.97      0.20      0.31       300


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 50}, criterion='gini',
           max_depth=32, max_features=0.33, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.977 	-0.012 	-0.012 	0.495 	0.000 	0.000
[[293   3]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       296
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.98       300


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.983 	-0.007 	-0.005 	0.498 	0.000 	0.000
[[295   1]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       296
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.98       300


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.5, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(500,), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	0.000 	0.000 	0.500 	0.000 	0.000
[[296   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       296
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       300


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=16,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=1.0, n_estimators=80, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.970 	-0.015 	-0.015 	0.492 	0.000 	0.000
[[291   5]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.98      0.98       296
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.97      0.97       300


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.1, cache_size=200, class_weight={1: 50}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.963 	0.150 	0.138 	0.611 	0.493 	0.226
[[288   8]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.97      0.98       296
        1.0       0.11      0.25      0.15         4

avg / total       0.98      0.96      0.97       300


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	0.000 	0.000 	0.500 	0.000 	0.000
[[296   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       296
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       300


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=1,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.970 	-0.015 	-0.015 	0.492 	0.000 	0.000
[[291   5]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.98      0.98       296
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.97      0.97       300


                estimator   min_score   mean_score   max_score    sd_score  \
7                     SVC   -0.116351      -0.0192    0.096565   0.0424956   
0              GaussianNB    0.113616     0.113616    0.113616           0   
5           MLPClassifier  -0.0208415   -0.0124807 -0.00349117  0.00418304   
8        VotingClassifier   -0.012878  -0.00285148           0  0.00368313   
4  RandomForestClassifier -0.00844608 -0.000731091           0  0.00137369   
3    ExtraTreesClassifier  -0.0167814  0.000303221    0.139267   0.0162406   
6      AdaBoostClassifier  -0.0213734  -0.00143977    0.137593   0.0280739   
9    KNeighborsClassifier  -0.0167781  0.000735388   0.0692234   0.0187384   
1      LogisticRegression   -0.176659   -0.0022282    0.160492   0.0531277   
2           SGDClassifier   -0.296541    0.0289845     0.24414   0.0481618   

        acc       auc          conf_matrix     f1_c0      f1_c1       kappa  \
7  0.963333  0.611486   [[288, 8], [3, 1]]  0.981261   0.153846    0.137931   
0  0.873333  0.565878  [[261, 35], [3, 1]]  0.932143       0.05   0.0266393   
5  0.986667       0.5   [[296, 0], [4, 0]]  0.993289          0           0   
8  0.986667       0.5   [[296, 0], [4, 0]]  0.993289          0           0   
4  0.983333  0.498311   [[295, 1], [4, 0]]  0.991597          0 -0.00536193   
3  0.976667  0.494932   [[293, 3], [4, 0]]  0.988196          0  -0.0115607   
6      0.97  0.491554   [[291, 5], [4, 0]]  0.984772          0  -0.0150376   
9      0.97  0.491554   [[291, 5], [4, 0]]  0.984772          0  -0.0150376   
1  0.926667  0.469595  [[278, 18], [4, 0]]  0.961938          0  -0.0223048   
2  0.196667  0.469595  [[56, 240], [1, 3]]   0.31728  0.0242915 -0.00199568   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
7     0.14992  0.989691   0.111111  0.972973   0.25  
0   0.0465046  0.988636  0.0277778  0.881757   0.25  
5           0  0.986667          0         1      0  
8           0  0.986667          0         1      0  
4 -0.00672277  0.986622          0  0.996622      0  
3  -0.0116833  0.986532          0  0.989865      0  
6  -0.0151342  0.986441          0  0.983108      0  
9  -0.0151342  0.986441          0  0.983108      0  
1  -0.0293695  0.985816          0  0.939189      0  
2  -0.0177794  0.982456  0.0123457  0.189189   0.75  
Elapsed time 29.04 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv 
datetime: 2017-05-07 15:08:11.471000 
pca_target: 0 	 poly degree: 2 	 kselect: 80 
Imbalance: SMOTE(k=None, k_neighbors=5, kind='regular', m=None, m_neighbors=10, n_jobs=1,
   out_step=0.5, random_state=None, ratio='auto', svm_estimator=None) 
Extended target (count):  25141 325
('Total : Processed (count): ', (998L, 24976L), 13)
Final feature (count):  (998L, 24976L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.787 	0.149 	0.062 	0.769 	0.768 	0.588
[[233  63]
 [  1   3]]
             precision    recall  f1-score   support

        0.0       1.00      0.79      0.88       296
        1.0       0.05      0.75      0.09         4

avg / total       0.98      0.79      0.87       300


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=10, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=5, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.950 	0.240 	0.194 	0.728 	0.691 	0.456
[[283  13]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      0.96      0.97       296
        1.0       0.13      0.50      0.21         4

avg / total       0.98      0.95      0.96       300


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.001, average=False, class_weight='balanced',
       epsilon=0.1, eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='modified_huber', n_iter=5, n_jobs=4,
       penalty='none', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.920 	0.180 	0.123 	0.713 	0.680 	0.443
[[274  22]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      0.93      0.96       296
        1.0       0.08      0.50      0.14         4

avg / total       0.98      0.92      0.95       300


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 500}, criterion='gini',
           max_depth=None, max_features=0.33, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=30, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.970 	-0.015 	-0.015 	0.492 	0.000 	0.000
[[291   5]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.98      0.98       296
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.97      0.97       300


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 500},
            criterion='entropy', max_depth=32, max_features='auto',
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.963 	0.287 	0.252 	0.735 	0.696 	0.462
[[287   9]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      0.97      0.98       296
        1.0       0.18      0.50      0.27         4

avg / total       0.98      0.96      0.97       300


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.01, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.980 	0.240 	0.240 	0.620 	0.497 	0.229
[[293   3]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       296
        1.0       0.25      0.25      0.25         4

avg / total       0.98      0.98      0.98       300


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight='balanced', criterion='entropy',
            max_depth=8, max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=1.0, n_estimators=80, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	0.000 	0.000 	0.500 	0.000 	0.000
[[296   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       296
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       300


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.5, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.983 	-0.007 	-0.005 	0.498 	0.000 	0.000
[[295   1]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       296
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.98       300


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=10.0, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', ...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.957 	0.132 	0.116 	0.608 	0.491 	0.224
[[286  10]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.97      0.98       296
        1.0       0.09      0.25      0.13         4

avg / total       0.98      0.96      0.97       300


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=3,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.950 	0.118 	0.099 	0.605 	0.490 	0.223
[[284  12]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.96      0.97       296
        1.0       0.08      0.25      0.12         4

avg / total       0.98      0.95      0.96       300


                estimator  min_score mean_score max_score   sd_score  \
0              GaussianNB    0.64974    0.64974   0.64974          0   
4  RandomForestClassifier     0.7928   0.932709  0.967238  0.0387378   
1      LogisticRegression   0.194146   0.768837  0.936948   0.137781   
2           SGDClassifier -0.0940643   0.550869  0.891465   0.220072   
5           MLPClassifier   0.964472   0.973089  0.988462  0.0049645   
8        VotingClassifier   0.857733   0.920934  0.964491  0.0258413   
9    KNeighborsClassifier   0.870741    0.90192  0.942383  0.0264939   
6      AdaBoostClassifier   0.882457   0.950357  0.987076  0.0210913   
7                     SVC          0   0.794846  0.982837   0.237953   
3    ExtraTreesClassifier   0.626096   0.926507  0.982818  0.0772922   

        acc       auc          conf_matrix     f1_c0      f1_c1       kappa  \
0  0.786667  0.768581  [[233, 63], [1, 3]]  0.879245  0.0857143   0.0621336   
4  0.963333  0.734797   [[287, 9], [2, 2]]  0.981197   0.266667     0.25204   
1      0.95  0.728041  [[283, 13], [2, 2]]  0.974182   0.210526    0.193548   
2      0.92  0.712838  [[274, 22], [2, 2]]  0.958042   0.142857    0.122807   
5      0.98  0.619932   [[293, 3], [3, 1]]  0.989865       0.25    0.239865   
8  0.956667  0.608108  [[286, 10], [3, 1]]  0.977778   0.133333    0.116047   
9      0.95   0.60473  [[284, 12], [3, 1]]  0.974271   0.117647   0.0992794   
6  0.986667       0.5   [[296, 0], [4, 0]]  0.993289          0           0   
7  0.983333  0.498311   [[295, 1], [4, 0]]  0.991597          0 -0.00536193   
3      0.97  0.491554   [[291, 5], [4, 0]]  0.984772          0  -0.0150376   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
0    0.148731  0.995726  0.0454545  0.787162   0.75  
4    0.286585   0.99308   0.181818  0.969595    0.5  
1    0.240021  0.992982   0.133333  0.956081    0.5  
2    0.179968  0.992754  0.0833333  0.925676    0.5  
5    0.239865  0.989865       0.25  0.989865   0.25  
8    0.131953  0.989619  0.0909091  0.966216   0.25  
9    0.117995  0.989547  0.0769231  0.959459   0.25  
6           0  0.986667          0         1      0  
7 -0.00672277  0.986622          0  0.996622      0  
3  -0.0151342  0.986441          0  0.983108      0  
Elapsed time 50.79 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv 
datetime: 2017-05-07 15:58:58.625000 
pca_target: 0 	 poly degree: 2 	 kselect: 80 
Imbalance: ClusterCentroids(estimator=None, n_jobs=1, random_state=None, ratio='auto') 
Extended target (count):  25141 325
('Total : Processed (count): ', (998L, 24976L), 13)
Final feature (count):  (998L, 24976L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.800 	0.156 	0.068 	0.775 	0.775 	0.597
[[237  59]
 [  1   3]]
             precision    recall  f1-score   support

        0.0       1.00      0.80      0.89       296
        1.0       0.05      0.75      0.09         4

avg / total       0.98      0.80      0.88       300


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.001, class_weight={1: 3}, dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.410 	-0.079 	-0.015 	0.331 	0.321 	0.101
[[122 174]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.98      0.41      0.58       296
        1.0       0.01      0.25      0.01         4

avg / total       0.96      0.41      0.57       300


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.0001, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.001, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='modified_huber', n_iter=5, n_jobs=4,
       penalty='l1', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.480 	0.109 	0.023 	0.736 	0.688 	0.498
[[140 156]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.47      0.64       296
        1.0       0.03      1.00      0.05         4

avg / total       0.99      0.48      0.63       300


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 15},
           criterion='entropy', max_depth=16, max_features='auto',
           max_leaf_nodes=None, min_impurity_split=1e-07,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=15, n_jobs=4,
           oob_score=False, random_state=None, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.590 	-0.036 	-0.010 	0.422 	0.386 	0.144
[[176 120]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.98      0.59      0.74       296
        1.0       0.01      0.25      0.02         4

avg / total       0.97      0.59      0.73       300


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.133 	0.043 	0.004 	0.561 	0.349 	0.132
[[ 36 260]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.12      0.22       296
        1.0       0.02      1.00      0.03         4

avg / total       0.99      0.13      0.21       300


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.440 	0.043 	0.009 	0.593 	0.572 	0.337
[[129 167]
 [  1   3]]
             precision    recall  f1-score   support

        0.0       0.99      0.44      0.61       296
        1.0       0.02      0.75      0.03         4

avg / total       0.98      0.44      0.60       300


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=2.0, n_estimators=50, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.037 	-0.150 	-0.006 	0.389 	0.142 	0.022
[[  8 288]
 [  1   3]]
             precision    recall  f1-score   support

        0.0       0.89      0.03      0.05       296
        1.0       0.01      0.75      0.02         4

avg / total       0.88      0.04      0.05       300


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=1, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.600 	0.024 	0.007 	0.551 	0.548 	0.298
[[178 118]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      0.60      0.75       296
        1.0       0.02      0.50      0.03         4

avg / total       0.98      0.60      0.74       300


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.450 	0.045 	0.009 	0.598 	0.578 	0.345
[[132 164]
 [  1   3]]
             precision    recall  f1-score   support

        0.0       0.99      0.45      0.62       296
        1.0       0.02      0.75      0.04         4

avg / total       0.98      0.45      0.61       300


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=1,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.347 	-0.037 	-0.006 	0.422 	0.415 	0.175
[[102 194]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.98      0.34      0.51       296
        1.0       0.01      0.50      0.02         4

avg / total       0.97      0.35      0.50       300


                estimator min_score mean_score max_score   sd_score  \
0              GaussianNB  0.888889   0.888889  0.888889          0   
2           SGDClassifier   -0.2566   0.510555         1    0.25141   
8        VotingClassifier  0.555556   0.713964  0.777778  0.0673479   
5           MLPClassifier  0.683856    0.79342  0.906078  0.0539275   
4  RandomForestClassifier  0.683856   0.937904         1   0.066344   
7                     SVC         0   0.449694  0.906078   0.323274   
3    ExtraTreesClassifier  0.589933   0.765141  0.906078  0.0413604   
9    KNeighborsClassifier    0.5132     0.7173  0.906078   0.112817   
6      AdaBoostClassifier  0.478822   0.834756         1  0.0872933   
1      LogisticRegression         0   0.433712  0.718234   0.205355   

         acc       auc           conf_matrix     f1_c0      f1_c1       kappa  \
0        0.8  0.775338   [[237, 59], [1, 3]]   0.88764  0.0909091   0.0675508   
2       0.48  0.736486  [[140, 156], [0, 4]]  0.642202  0.0487805   0.0233723   
8       0.45  0.597973  [[132, 164], [1, 3]]  0.615385  0.0350877  0.00928669   
5       0.44  0.592905  [[129, 167], [1, 3]]  0.605634  0.0344828   0.0086546   
4   0.133333  0.560811   [[36, 260], [0, 4]]  0.216867  0.0298507  0.00367872   
7        0.6  0.550676  [[178, 118], [2, 2]]  0.747899  0.0322581  0.00662252   
3       0.59  0.422297  [[176, 120], [3, 1]]  0.741053      0.016  -0.0100734   
9   0.346667  0.422297  [[102, 194], [2, 2]]      0.51       0.02 -0.00629792   
6  0.0366667  0.388514    [[8, 288], [1, 3]]  0.052459   0.020339 -0.00612728   
1       0.41  0.331081  [[122, 174], [3, 1]]  0.579572  0.0111732  -0.0152964   

  model_score   prec_c0     prec_c1    rec_c0 rec_c1  
0    0.155987  0.995798   0.0483871  0.800676   0.75  
2     0.10874         1       0.025  0.472973      1  
8   0.0452406  0.992481   0.0179641  0.445946   0.75  
5   0.0430081  0.992308   0.0176471  0.435811   0.75  
4   0.0429273         1   0.0151515  0.121622      1  
7   0.0237289  0.988889   0.0166667  0.601351    0.5  
3  -0.0363348   0.98324  0.00826446  0.594595   0.25  
9  -0.0374539  0.980769   0.0102041  0.344595    0.5  
6    -0.14992  0.888889   0.0103093  0.027027   0.75  
1  -0.0785977     0.976  0.00571429  0.412162   0.25  
Elapsed time 20.26 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv 
datetime: 2017-05-07 16:19:13.929000 
pca_target: 80 	 poly degree: 2 	 kselect: 40 
Imbalance: None 
Extended target (count):  25141 325
('Total : Processed (count): ', (998L, 24976L), 13)
Final feature (count):  (998L, 24976L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.927 	0.085 	0.063 	0.593 	0.484 	0.218
[[277  19]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.94      0.96       296
        1.0       0.05      0.25      0.08         4

avg / total       0.98      0.93      0.95       300


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.001, class_weight={1: 50}, dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.893 	0.058 	0.036 	0.576 	0.475 	0.211
[[267  29]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.90      0.94       296
        1.0       0.03      0.25      0.06         4

avg / total       0.98      0.89      0.93       300


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.1, average=False, class_weight='balanced', epsilon=0.1,
       eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='constant', loss='perceptron', n_iter=5, n_jobs=4,
       penalty='l2', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.690 	0.108 	0.036 	0.720 	0.719 	0.520
[[204  92]
 [  1   3]]
             precision    recall  f1-score   support

        0.0       1.00      0.69      0.81       296
        1.0       0.03      0.75      0.06         4

avg / total       0.98      0.69      0.80       300


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=8, max_features='auto', max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	0.000 	0.000 	0.500 	0.000 	0.000
[[296   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       296
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       300


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	0.000 	0.000 	0.500 	0.000 	0.000
[[296   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       296
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       300


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.1, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(500,), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.983 	0.280 	0.277 	0.622 	0.498 	0.230
[[294   2]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       296
        1.0       0.33      0.25      0.29         4

avg / total       0.98      0.98      0.98       300


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 50}, criterion='gini', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=2.0, n_estimators=15, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.980 	-0.010 	-0.009 	0.497 	0.000 	0.000
[[294   2]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       296
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.98       300


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.490 	0.111 	0.024 	0.742 	0.695 	0.508
[[143 153]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.48      0.65       296
        1.0       0.03      1.00      0.05         4

avg / total       0.99      0.49      0.64       300


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...owski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='uniform'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	0.000 	0.000 	0.500 	0.000 	0.000
[[296   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       296
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       300


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=1,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	0.000 	0.000 	0.500 	0.000 	0.000
[[296   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       296
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       300


                estimator   min_score   mean_score  max_score     sd_score  \
7                     SVC  -0.0255618  -0.00863329  0.0458677    0.0114207   
2           SGDClassifier   -0.217549    0.0353484   0.202889    0.0491543   
5           MLPClassifier  -0.0171125   -0.0118437 -0.0040961   0.00386963   
0              GaussianNB    0.181567     0.181567   0.181567            0   
1      LogisticRegression  -0.0489844   0.00857948   0.171986    0.0478178   
3    ExtraTreesClassifier -0.00914513  -0.00012829          0  0.000841661   
4  RandomForestClassifier  -0.0040961 -8.32742e-05          0  0.000428889   
8        VotingClassifier  -0.0111604  -0.00319604          0   0.00299096   
9    KNeighborsClassifier  -0.0104941  -0.00211021          0    0.0037107   
6      AdaBoostClassifier  -0.0196468  -0.00348087   0.193612    0.0265863   

        acc       auc           conf_matrix     f1_c0      f1_c1       kappa  \
7      0.49  0.741554  [[143, 153], [0, 4]]  0.651481  0.0496894   0.0243177   
2      0.69  0.719595   [[204, 92], [1, 3]]  0.814371  0.0606061   0.0359364   
5  0.983333  0.621622    [[294, 2], [3, 1]]  0.991568   0.285714    0.277457   
0  0.926667  0.592905   [[277, 19], [3, 1]]  0.961806  0.0833333      0.0625   
1  0.893333  0.576014   [[267, 29], [3, 1]]  0.943463  0.0588235   0.0361446   
3  0.986667       0.5    [[296, 0], [4, 0]]  0.993289          0           0   
4  0.986667       0.5    [[296, 0], [4, 0]]  0.993289          0           0   
8  0.986667       0.5    [[296, 0], [4, 0]]  0.993289          0           0   
9  0.986667       0.5    [[296, 0], [4, 0]]  0.993289          0           0   
6      0.98  0.496622    [[294, 2], [4, 0]]  0.989899          0 -0.00896861   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
7    0.110944         1  0.0254777  0.483108      1  
2     0.10829  0.995122  0.0315789  0.689189   0.75  
5      0.2804  0.989899   0.333333  0.993243   0.25  
0   0.0854383  0.989286       0.05  0.935811   0.25  
1   0.0581238  0.988889  0.0333333  0.902027   0.25  
3           0  0.986667          0         1      0  
4           0  0.986667          0         1      0  
8           0  0.986667          0         1      0  
9           0  0.986667          0         1      0  
6 -0.00952338  0.986577          0  0.993243      0  
Elapsed time 25.28 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv 
datetime: 2017-05-07 16:44:30.984000 
pca_target: 80 	 poly degree: 2 	 kselect: 40 
Imbalance: SMOTE(k=None, k_neighbors=5, kind='regular', m=None, m_neighbors=10, n_jobs=1,
   out_step=0.5, random_state=None, ratio='auto', svm_estimator=None) 
Extended target (count):  25141 325
('Total : Processed (count): ', (998L, 24976L), 13)
Final feature (count):  (998L, 24976L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	0.000 	0.000 	0.500 	0.000 	0.000
[[296   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       296
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       300


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=5, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.967 	0.302 	0.272 	0.736 	0.697 	0.463
[[288   8]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      0.97      0.98       296
        1.0       0.20      0.50      0.29         4

avg / total       0.98      0.97      0.97       300


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.0001, average=False, class_weight='balanced',
       epsilon=0.1, eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='squared_hinge', n_iter=5, n_jobs=4,
       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	0.348 	0.327 	0.623 	0.499 	0.231
[[295   1]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       296
        1.0       0.50      0.25      0.33         4

avg / total       0.98      0.99      0.98       300


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=8, max_features=0.75, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	0.000 	0.000 	0.500 	0.000 	0.000
[[296   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       296
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       300


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=32, max_features=0.75, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=50, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	0.000 	0.000 	0.500 	0.000 	0.000
[[296   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       296
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       300


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.990 	0.497 	0.397 	0.625 	0.500 	0.231
[[296   0]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       296
        1.0       1.00      0.25      0.40         4

avg / total       0.99      0.99      0.99       300


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=1.0, n_estimators=15, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	0.000 	0.000 	0.500 	0.000 	0.000
[[296   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       296
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       300


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.1, cache_size=200, class_weight={1: 50}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	0.000 	0.000 	0.500 	0.000 	0.000
[[296   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       296
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       300


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=1.0, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', R...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.983 	0.439 	0.436 	0.745 	0.704 	0.471
[[293   3]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       296
        1.0       0.40      0.50      0.44         4

avg / total       0.99      0.98      0.98       300


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=4,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.963 	0.403 	0.339 	0.858 	0.851 	0.709
[[286  10]
 [  1   3]]
             precision    recall  f1-score   support

        0.0       1.00      0.97      0.98       296
        1.0       0.23      0.75      0.35         4

avg / total       0.99      0.96      0.97       300


                estimator min_score mean_score max_score     sd_score  \
9    KNeighborsClassifier  0.732431    0.83635  0.924579    0.0578227   
8        VotingClassifier  0.942219   0.978184  0.989898     0.010834   
1      LogisticRegression  0.472722   0.875984  0.980003     0.135225   
5           MLPClassifier  0.972864   0.985801         1   0.00888085   
2           SGDClassifier -0.109372   0.687817   0.99281     0.291425   
0              GaussianNB  0.963164   0.963164  0.963164            0   
3    ExtraTreesClassifier   0.98567   0.999547         1   0.00134288   
4  RandomForestClassifier  0.994226      0.998         1  0.000824575   
6      AdaBoostClassifier  0.901234   0.985504         1    0.0104357   
7                     SVC         0   0.835592         1     0.323957   

        acc       auc          conf_matrix     f1_c0     f1_c1     kappa  \
9  0.963333  0.858108  [[286, 10], [1, 3]]  0.981132  0.352941  0.339472   
8  0.983333  0.744932   [[293, 3], [2, 2]]   0.99154  0.444444   0.43609   
1  0.966667  0.736486   [[288, 8], [2, 2]]  0.982935  0.285714  0.271845   
5      0.99     0.625   [[296, 0], [3, 1]]  0.994958       0.4  0.396783   
2  0.986667  0.623311   [[295, 1], [3, 1]]  0.993266  0.333333  0.327354   
0  0.986667       0.5   [[296, 0], [4, 0]]  0.993289         0         0   
3  0.986667       0.5   [[296, 0], [4, 0]]  0.993289         0         0   
4  0.986667       0.5   [[296, 0], [4, 0]]  0.993289         0         0   
6  0.986667       0.5   [[296, 0], [4, 0]]  0.993289         0         0   
7  0.986667       0.5   [[296, 0], [4, 0]]  0.993289         0         0   

  model_score   prec_c0   prec_c1    rec_c0 rec_c1  
9    0.403466  0.996516  0.230769  0.966216   0.75  
8     0.43889   0.99322       0.4  0.989865    0.5  
1    0.302213  0.993103       0.2  0.972973    0.5  
5    0.497485  0.989967         1         1   0.25  
2    0.347603  0.989933       0.5  0.996622   0.25  
0           0  0.986667         0         1      0  
3           0  0.986667         0         1      0  
4           0  0.986667         0         1      0  
6           0  0.986667         0         1      0  
7           0  0.986667         0         1      0  
Elapsed time 40.21 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv 
datetime: 2017-05-07 17:24:43.439000 
pca_target: 80 	 poly degree: 2 	 kselect: 40 
Imbalance: ClusterCentroids(estimator=None, n_jobs=1, random_state=None, ratio='auto') 
Extended target (count):  25141 325
('Total : Processed (count): ', (998L, 24976L), 13)
Final feature (count):  (998L, 24976L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.013 	0.000 	0.000 	0.500 	0.000 	0.000
[[  0 296]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       0.00      0.00      0.00       296
        1.0       0.01      1.00      0.03         4

avg / total       0.00      0.01      0.00       300


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.001, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.497 	-0.057 	-0.013 	0.375 	0.354 	0.122
[[148 148]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.98      0.50      0.66       296
        1.0       0.01      0.25      0.01         4

avg / total       0.97      0.50      0.65       300


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.1, average=False, class_weight='balanced', epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='squared_hinge', n_iter=5, n_jobs=4,
       penalty='l1', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.797 	0.086 	0.037 	0.650 	0.633 	0.388
[[237  59]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      0.80      0.89       296
        1.0       0.03      0.50      0.06         4

avg / total       0.98      0.80      0.87       300


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=16, max_features='auto', max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.253 	-0.066 	-0.009 	0.375 	0.354 	0.128
[[ 74 222]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.97      0.25      0.40       296
        1.0       0.01      0.50      0.02         4

avg / total       0.96      0.25      0.39       300


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features=0.33, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=50, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.260 	0.067 	0.009 	0.625 	0.500 	0.269
[[ 74 222]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.25      0.40       296
        1.0       0.02      1.00      0.03         4

avg / total       0.99      0.26      0.40       300


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(500,), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.557 	-0.044 	-0.011 	0.405 	0.374 	0.136
[[166 130]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.98      0.56      0.71       296
        1.0       0.01      0.25      0.01         4

avg / total       0.97      0.56      0.70       300


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=0.5, n_estimators=15, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.297 	0.073 	0.011 	0.644 	0.536 	0.308
[[ 85 211]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.29      0.45       296
        1.0       0.02      1.00      0.04         4

avg / total       0.99      0.30      0.44       300


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.1, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='linear',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.513 	0.060 	0.014 	0.630 	0.619 	0.392
[[151 145]
 [  1   3]]
             precision    recall  f1-score   support

        0.0       0.99      0.51      0.67       296
        1.0       0.02      0.75      0.04         4

avg / total       0.98      0.51      0.67       300


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', R...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.513 	-0.054 	-0.013 	0.383 	0.359 	0.126
[[153 143]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.98      0.52      0.68       296
        1.0       0.01      0.25      0.01         4

avg / total       0.97      0.51      0.67       300


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=1,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.557 	0.127 	0.032 	0.775 	0.742 	0.575
[[163 133]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.55      0.71       296
        1.0       0.03      1.00      0.06         4

avg / total       0.99      0.56      0.70       300


                estimator min_score mean_score max_score   sd_score  \
9    KNeighborsClassifier   -0.1283   0.435506  0.812156   0.287906   
2           SGDClassifier -0.496011   0.395607  0.906078   0.220626   
6      AdaBoostClassifier  0.333333   0.863938         1   0.138181   
7                     SVC         0     0.5019  0.812156   0.326871   
4  RandomForestClassifier  0.607122   0.916677         1  0.0770279   
0              GaussianNB  0.794967   0.794967  0.794967          0   
5           MLPClassifier  0.555556   0.687207  0.812156  0.0647656   
8        VotingClassifier  0.701045   0.802658  0.906078  0.0351081   
1      LogisticRegression         0   0.432169  0.812156   0.307931   
3    ExtraTreesClassifier  0.624311   0.880249         1  0.0794762   

         acc       auc           conf_matrix     f1_c0      f1_c1       kappa  \
9   0.556667  0.775338  [[163, 133], [0, 4]]   0.71024  0.0567376   0.0316474   
2   0.796667  0.650338   [[237, 59], [2, 2]]  0.885981  0.0615385     0.03745   
6   0.296667  0.643581   [[85, 211], [0, 4]]  0.446194  0.0365297   0.0106283   
7   0.513333  0.630068  [[151, 145], [1, 3]]  0.674107  0.0394737   0.0138689   
4       0.26     0.625   [[74, 222], [0, 4]]       0.4  0.0347826  0.00881057   
0  0.0133333       0.5    [[0, 296], [0, 4]]         0  0.0263158           0   
5   0.556667  0.405405  [[166, 130], [3, 1]]  0.713978  0.0148148  -0.0113556   
8   0.513333  0.383446  [[153, 143], [3, 1]]  0.676991  0.0135135  -0.0127636   
1   0.496667     0.375  [[148, 148], [3, 1]]  0.662192  0.0130719  -0.0132415   
3   0.253333     0.375   [[74, 222], [2, 2]]  0.397849  0.0175439 -0.00888782   

  model_score   prec_c0     prec_c1    rec_c0 rec_c1  
9      0.1268         1   0.0291971  0.550676      1  
2   0.0856861  0.991632   0.0327869  0.800676    0.5  
6   0.0730928         1   0.0186047  0.287162      1  
7   0.0596791  0.993421   0.0202703  0.510135   0.75  
4    0.066519         1   0.0176991      0.25      1  
0           0         0   0.0133333         0      1  
5  -0.0437515  0.982249  0.00763359  0.560811   0.25  
8  -0.0535167  0.980769  0.00694444  0.516892   0.25  
1  -0.0573501  0.980132  0.00671141       0.5   0.25  
3  -0.0659303  0.973684  0.00892857      0.25    0.5  
Elapsed time 18.80 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv 
datetime: 2017-05-07 17:43:31.651000 
pca_target: 80 	 poly degree: 2 	 kselect: 80 
Imbalance: None 
Extended target (count):  25141 325
('Total : Processed (count): ', (998L, 24976L), 13)
Final feature (count):  (998L, 24976L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.897 	0.060 	0.038 	0.578 	0.476 	0.212
[[268  28]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.91      0.95       296
        1.0       0.03      0.25      0.06         4

avg / total       0.98      0.90      0.93       300


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.001, class_weight={1: 50}, dual=False,
          fit_intercept=True, intercept_scaling=0.01, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='sag', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.933 	0.202 	0.148 	0.720 	0.685 	0.449
[[278  18]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      0.94      0.97       296
        1.0       0.10      0.50      0.17         4

avg / total       0.98      0.93      0.95       300


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.5, average=False, class_weight={1: 15}, epsilon=0.1,
       eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='invscaling', loss='modified_huber', n_iter=5,
       n_jobs=4, penalty='l1', power_t=0.5, random_state=None,
       shuffle=True, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.967 	-0.017 	-0.016 	0.490 	0.000 	0.000
[[290   6]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.98      0.98       296
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.97      0.97       300


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=8, max_features='auto', max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	0.000 	0.000 	0.500 	0.000 	0.000
[[296   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       296
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       300


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	0.000 	0.000 	0.500 	0.000 	0.000
[[296   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       296
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       300


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	0.348 	0.327 	0.623 	0.499 	0.231
[[295   1]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       296
        1.0       0.50      0.25      0.33         4

avg / total       0.98      0.99      0.98       300


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='entropy', max_depth=32,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=0.5, n_estimators=15, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.967 	-0.017 	-0.016 	0.490 	0.000 	0.000
[[290   6]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.98      0.98       296
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.97      0.97       300


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.01, cache_size=200, class_weight={1: 500}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.450 	0.102 	0.021 	0.721 	0.665 	0.467
[[131 165]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.44      0.61       296
        1.0       0.02      1.00      0.05         4

avg / total       0.99      0.45      0.61       300


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...owski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='uniform'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.990 	0.497 	0.397 	0.625 	0.500 	0.231
[[296   0]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       296
        1.0       1.00      0.25      0.40         4

avg / total       0.99      0.99      0.99       300


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=2,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	0.348 	0.327 	0.623 	0.499 	0.231
[[295   1]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       296
        1.0       0.50      0.25      0.33         4

avg / total       0.98      0.99      0.98       300


                estimator   min_score   mean_score   max_score     sd_score  \
7                     SVC  -0.0263599  -0.00827254   0.0698334    0.0122765   
1      LogisticRegression  -0.0586331   0.00757133    0.167322    0.0452577   
8        VotingClassifier -0.00758727  -0.00186204           0   0.00191883   
5           MLPClassifier  -0.0156858   -0.0111643 -0.00434998   0.00284415   
9    KNeighborsClassifier -0.00992133   0.00996786   0.0906939    0.0303141   
0              GaussianNB   0.0998311    0.0998311   0.0998311            0   
3    ExtraTreesClassifier -0.00819252 -0.000143912           0  0.000831967   
4  RandomForestClassifier  -0.0040961 -8.59834e-05           0  0.000429806   
2           SGDClassifier   -0.113316     0.030689    0.225974    0.0479803   
6      AdaBoostClassifier  -0.0203176  -0.00383467    0.204925    0.0269367   

        acc       auc           conf_matrix     f1_c0      f1_c1      kappa  \
7      0.45  0.721284  [[131, 165], [0, 4]]  0.613583  0.0462428  0.0207328   
1  0.933333  0.719595   [[278, 18], [2, 2]]  0.965278   0.166667   0.147727   
8      0.99     0.625    [[296, 0], [3, 1]]  0.994958        0.4   0.396783   
5  0.986667  0.623311    [[295, 1], [3, 1]]  0.993266   0.333333   0.327354   
9  0.986667  0.623311    [[295, 1], [3, 1]]  0.993266   0.333333   0.327354   
0  0.896667  0.577703   [[268, 28], [3, 1]]  0.945326  0.0606061  0.0380637   
3  0.986667       0.5    [[296, 0], [4, 0]]  0.993289          0          0   
4  0.986667       0.5    [[296, 0], [4, 0]]  0.993289          0          0   
2  0.966667  0.489865    [[290, 6], [4, 0]]  0.983051          0 -0.0162602   
6  0.966667  0.489865    [[290, 6], [4, 0]]  0.983051          0 -0.0162602   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
7    0.102347         1  0.0236686  0.442568      1  
1    0.201945  0.992857        0.1  0.939189    0.5  
8    0.497485  0.989967          1         1   0.25  
5    0.347603  0.989933        0.5  0.996622   0.25  
9    0.347603  0.989933        0.5  0.996622   0.25  
0   0.0603196   0.98893  0.0344828  0.905405   0.25  
3           0  0.986667          0         1      0  
4           0  0.986667          0         1      0  
2  -0.0166068  0.986395          0   0.97973      0  
6  -0.0166068  0.986395          0   0.97973      0  
Elapsed time 29.25 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv 
datetime: 2017-05-07 18:12:46.835000 
pca_target: 80 	 poly degree: 2 	 kselect: 80 
Imbalance: SMOTE(k=None, k_neighbors=5, kind='regular', m=None, m_neighbors=10, n_jobs=1,
   out_step=0.5, random_state=None, ratio='auto', svm_estimator=None) 
Extended target (count):  25141 325
('Total : Processed (count): ', (998L, 24976L), 13)
Final feature (count):  (998L, 24976L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	0.000 	0.000 	0.500 	0.000 	0.000
[[296   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       296
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       300


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=5, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.970 	0.320 	0.295 	0.738 	0.699 	0.465
[[289   7]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      0.98      0.98       296
        1.0       0.22      0.50      0.31         4

avg / total       0.98      0.97      0.98       300


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.0001, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.001, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='squared_hinge', n_iter=5, n_jobs=4,
       penalty='l2', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.980 	0.240 	0.240 	0.620 	0.497 	0.229
[[293   3]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       296
        1.0       0.25      0.25      0.25         4

avg / total       0.98      0.98      0.98       300


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 15},
           criterion='entropy', max_depth=32, max_features=0.75,
           max_leaf_nodes=None, min_impurity_split=1e-07,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=15, n_jobs=4,
           oob_score=False, random_state=None, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	0.000 	0.000 	0.500 	0.000 	0.000
[[296   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       296
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       300


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=16, max_features=0.33, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	0.000 	0.000 	0.500 	0.000 	0.000
[[296   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       296
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       300


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.990 	0.497 	0.397 	0.625 	0.500 	0.231
[[296   0]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       296
        1.0       1.00      0.25      0.40         4

avg / total       0.99      0.99      0.99       300


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=0.5, n_estimators=15, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	0.000 	0.000 	0.500 	0.000 	0.000
[[296   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       296
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       300


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.1, cache_size=200, class_weight={1: 50}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	0.000 	0.000 	0.500 	0.000 	0.000
[[296   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       296
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       300


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=10.0, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', ...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	0.493 	0.493 	0.747 	0.705 	0.472
[[294   2]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       296
        1.0       0.50      0.50      0.50         4

avg / total       0.99      0.99      0.99       300


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=4,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.957 	0.373 	0.301 	0.855 	0.848 	0.705
[[284  12]
 [  1   3]]
             precision    recall  f1-score   support

        0.0       1.00      0.96      0.98       296
        1.0       0.20      0.75      0.32         4

avg / total       0.99      0.96      0.97       300


                estimator min_score mean_score max_score     sd_score  \
9    KNeighborsClassifier  0.778573   0.850613  0.935403    0.0502449   
8        VotingClassifier  0.934279   0.976922  0.991354    0.0131619   
1      LogisticRegression  0.423029   0.882725  0.979926     0.126801   
5           MLPClassifier   0.97007   0.986033  0.998554   0.00822468   
2           SGDClassifier -0.120994   0.698467  0.994276     0.283797   
0              GaussianNB   0.96167    0.96167   0.96167            0   
3    ExtraTreesClassifier  0.979966   0.997933         1   0.00185046   
4  RandomForestClassifier  0.994205   0.997867         1  0.000932344   
6      AdaBoostClassifier  0.956201   0.986245         1   0.00868499   
7                     SVC         0    0.83113         1     0.323818   

        acc       auc          conf_matrix     f1_c0     f1_c1     kappa  \
9  0.956667   0.85473  [[284, 12], [1, 3]]  0.977625  0.315789  0.301075   
8  0.986667  0.746622   [[294, 2], [2, 2]]  0.993243       0.5  0.493243   
1      0.97  0.738176   [[289, 7], [2, 2]]  0.984668  0.307692  0.294671   
5      0.99     0.625   [[296, 0], [3, 1]]  0.994958       0.4  0.396783   
2      0.98  0.619932   [[293, 3], [3, 1]]  0.989865      0.25  0.239865   
0  0.986667       0.5   [[296, 0], [4, 0]]  0.993289         0         0   
3  0.986667       0.5   [[296, 0], [4, 0]]  0.993289         0         0   
4  0.986667       0.5   [[296, 0], [4, 0]]  0.993289         0         0   
6  0.986667       0.5   [[296, 0], [4, 0]]  0.993289         0         0   
7  0.986667       0.5   [[296, 0], [4, 0]]  0.993289         0         0   

  model_score   prec_c0   prec_c1    rec_c0 rec_c1  
9    0.373367  0.996491       0.2  0.959459   0.75  
8    0.493243  0.993243       0.5  0.993243    0.5  
1    0.320284  0.993127  0.222222  0.976351    0.5  
5    0.497485  0.989967         1         1   0.25  
2    0.239865  0.989865      0.25  0.989865   0.25  
0           0  0.986667         0         1      0  
3           0  0.986667         0         1      0  
4           0  0.986667         0         1      0  
6           0  0.986667         0         1      0  
7           0  0.986667         0         1      0  
Elapsed time 47.25 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv 
datetime: 2017-05-07 19:00:02.108000 
pca_target: 80 	 poly degree: 2 	 kselect: 80 
Imbalance: ClusterCentroids(estimator=None, n_jobs=1, random_state=None, ratio='auto') 
Extended target (count):  25141 325
('Total : Processed (count): ', (998L, 24976L), 13)
Final feature (count):  (998L, 24976L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.013 	0.000 	0.000 	0.500 	0.000 	0.000
[[  0 296]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       0.00      0.00      0.00       296
        1.0       0.01      1.00      0.03         4

avg / total       0.00      0.01      0.00       300


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.001, class_weight={1: 500}, dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.463 	0.105 	0.022 	0.728 	0.675 	0.481
[[135 161]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.46      0.63       296
        1.0       0.02      1.00      0.05         4

avg / total       0.99      0.46      0.62       300


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.0001, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='invscaling', loss='perceptron', n_iter=5, n_jobs=4,
       penalty='l1', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.517 	0.004 	0.001 	0.508 	0.508 	0.258
[[153 143]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      0.52      0.68       296
        1.0       0.01      0.50      0.03         4

avg / total       0.97      0.52      0.67       300


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=8, max_features='auto', max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.440 	-0.014 	-0.003 	0.470 	0.469 	0.221
[[130 166]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.98      0.44      0.61       296
        1.0       0.01      0.50      0.02         4

avg / total       0.97      0.44      0.60       300


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=16, max_features=0.75, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.287 	0.071 	0.010 	0.639 	0.526 	0.297
[[ 82 214]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.28      0.43       296
        1.0       0.02      1.00      0.04         4

avg / total       0.99      0.29      0.43       300


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.487 	-0.060 	-0.014 	0.370 	0.350 	0.120
[[145 151]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.98      0.49      0.65       296
        1.0       0.01      0.25      0.01         4

avg / total       0.97      0.49      0.64       300


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=32,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=2.0, n_estimators=15, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.347 	0.082 	0.013 	0.669 	0.581 	0.360
[[100 196]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.34      0.51       296
        1.0       0.02      1.00      0.04         4

avg / total       0.99      0.35      0.50       300


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='linear',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.490 	0.054 	0.012 	0.618 	0.604 	0.374
[[144 152]
 [  1   3]]
             precision    recall  f1-score   support

        0.0       0.99      0.49      0.65       296
        1.0       0.02      0.75      0.04         4

avg / total       0.98      0.49      0.64       300


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', R...owski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='uniform'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.420 	0.039 	0.007 	0.583 	0.558 	0.322
[[123 173]
 [  1   3]]
             precision    recall  f1-score   support

        0.0       0.99      0.42      0.59       296
        1.0       0.02      0.75      0.03         4

avg / total       0.98      0.42      0.58       300


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=1,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.663 	0.100 	0.031 	0.706 	0.705 	0.501
[[196 100]
 [  1   3]]
             precision    recall  f1-score   support

        0.0       0.99      0.66      0.80       296
        1.0       0.03      0.75      0.06         4

avg / total       0.98      0.66      0.79       300


                estimator  min_score mean_score max_score   sd_score  \
1      LogisticRegression          0   0.513973  0.906078   0.343278   
9    KNeighborsClassifier  0.0939222   0.534135  0.812156   0.203897   
6      AdaBoostClassifier     0.1283   0.709272         1   0.146294   
4  RandomForestClassifier   0.444444   0.772751  0.888889   0.070969   
7                     SVC          0   0.487585  0.718234    0.29319   
8        VotingClassifier     0.5132   0.716161         1  0.0964467   
2           SGDClassifier    -0.1283   0.589168  0.906078   0.182535   
0              GaussianNB          1          1         1          0   
3    ExtraTreesClassifier   0.701045   0.938546         1  0.0648466   
5           MLPClassifier   0.367711   0.634952  0.812156  0.0745607   

         acc       auc           conf_matrix     f1_c0      f1_c1  \
1   0.463333  0.728041  [[135, 161], [0, 4]]   0.62645  0.0473373   
9   0.663333  0.706081  [[196, 100], [1, 3]]  0.795132  0.0560748   
6   0.346667  0.668919  [[100, 196], [0, 4]]  0.505051  0.0392157   
4   0.286667  0.638514   [[82, 214], [0, 4]]  0.433862   0.036036   
7       0.49  0.618243  [[144, 152], [1, 3]]  0.653061  0.0377358   
8       0.42   0.58277  [[123, 173], [1, 3]]  0.585714  0.0333333   
2   0.516667  0.508446  [[153, 143], [2, 2]]  0.678492  0.0268456   
0  0.0133333       0.5    [[0, 296], [0, 4]]         0  0.0263158   
3       0.44  0.469595  [[130, 166], [2, 2]]  0.607477  0.0232558   
5   0.486667  0.369932  [[145, 151], [3, 1]]  0.653153  0.0128205   

         kappa model_score   prec_c0     prec_c1    rec_c0 rec_c1  
1    0.0218712     0.10515         1   0.0242424  0.456081      1  
9     0.031206   0.0995617  0.994924   0.0291262  0.662162   0.75  
6    0.0134228   0.0821995         1        0.02  0.337838      1  
4    0.0101147   0.0712956         1   0.0183486  0.277027      1  
7    0.0120534   0.0542791  0.993103   0.0193548  0.486486   0.75  
8   0.00745361   0.0385579  0.991935   0.0170455  0.415541   0.75  
2  0.000918695  0.00387708  0.987097   0.0137931  0.516892    0.5  
0            0           0         0   0.0133333         0      1  
3  -0.00286533  -0.0140513  0.984848   0.0119048  0.439189    0.5  
5   -0.0135135  -0.0596791   0.97973  0.00657895  0.489865   0.25  
Elapsed time 19.08 mins 

************************************************************










Standard, lagged (3,4)x2, filter(tukey), NT+, truncated






    pca = [0, 80]
    poly = [2]
    ksel = [40, 80]
    imb = [None, SMOTE(), ClusterCentroids() ]
	
	
	

	
	pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv 
datetime: 2017-05-08 23:13:50.500000 
pca_target: 0 	 poly degree: 2 	 kselect: 40 
Imbalance: None 
Extended target (count):  25141 325
('Total : Processed (count): ', (998L, 25425L), 13)
Final feature (count):  (998L, 25425L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.870 	0.045 	0.025 	0.564 	0.469 	0.206
[[260  36]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.88      0.93       296
        1.0       0.03      0.25      0.05         4

avg / total       0.98      0.87      0.92       300


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.001, class_weight={1: 50}, dual=False,
          fit_intercept=True, intercept_scaling=10, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.877 	0.048 	0.028 	0.568 	0.470 	0.207
[[262  34]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.89      0.93       296
        1.0       0.03      0.25      0.05         4

avg / total       0.98      0.88      0.92       300


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=1, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='constant', loss='perceptron', n_iter=5, n_jobs=4,
       penalty='l2', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	0.000 	0.000 	0.500 	0.000 	0.000
[[296   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       296
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       300


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight='balanced',
           criterion='gini', max_depth=8, max_features='auto',
           max_leaf_nodes=None, min_impurity_split=1e-07,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=15, n_jobs=4,
           oob_score=False, random_state=None, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.983 	-0.007 	-0.005 	0.498 	0.000 	0.000
[[295   1]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       296
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.98       300


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=50, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.983 	-0.007 	-0.005 	0.498 	0.000 	0.000
[[295   1]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       296
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.98       300


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.5, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.983 	-0.007 	-0.005 	0.498 	0.000 	0.000
[[295   1]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       296
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.98       300


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 50}, criterion='entropy', max_depth=8,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=2.0, n_estimators=15, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.967 	-0.017 	-0.016 	0.490 	0.000 	0.000
[[290   6]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.98      0.98       296
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.97      0.97       300


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.1, cache_size=200, class_weight={1: 50}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.907 	0.067 	0.045 	0.583 	0.478 	0.214
[[271  25]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.92      0.95       296
        1.0       0.04      0.25      0.07         4

avg / total       0.98      0.91      0.94       300


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	0.000 	0.000 	0.500 	0.000 	0.000
[[296   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       296
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       300


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=1,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.977 	-0.012 	-0.012 	0.495 	0.000 	0.000
[[293   3]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       296
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.98       300


                estimator  min_score  mean_score  max_score    sd_score  \
7                     SVC  -0.198884   -0.019515   0.118025   0.0487086   
1      LogisticRegression  -0.193567 -0.00198117   0.166601   0.0664478   
0              GaussianNB   0.100672    0.100672   0.100672           0   
2           SGDClassifier   -0.19566   0.0305185   0.225694   0.0491095   
8        VotingClassifier -0.0119582 -0.00205781          0  0.00295389   
3    ExtraTreesClassifier  -0.024549 -0.00108245   0.136749   0.0101281   
4  RandomForestClassifier -0.0148962 -0.00125046          0  0.00159025   
5           MLPClassifier  -0.017217 -0.00136139   0.131052   0.0318674   
9    KNeighborsClassifier -0.0140624  0.00145899  0.0683534   0.0179034   
6      AdaBoostClassifier -0.0195448 -0.00332302   0.173208   0.0244899   

        acc       auc          conf_matrix     f1_c0      f1_c1       kappa  \
7  0.906667   0.58277  [[271, 25], [3, 1]]  0.950877  0.0666667    0.044586   
1  0.876667  0.567568  [[262, 34], [3, 1]]  0.934046  0.0512821    0.028021   
0      0.87  0.564189  [[260, 36], [3, 1]]  0.930233  0.0487805   0.0253249   
2  0.986667       0.5   [[296, 0], [4, 0]]  0.993289          0           0   
8  0.986667       0.5   [[296, 0], [4, 0]]  0.993289          0           0   
3  0.983333  0.498311   [[295, 1], [4, 0]]  0.991597          0 -0.00536193   
4  0.983333  0.498311   [[295, 1], [4, 0]]  0.991597          0 -0.00536193   
5  0.983333  0.498311   [[295, 1], [4, 0]]  0.991597          0 -0.00536193   
9  0.976667  0.494932   [[293, 3], [4, 0]]  0.988196          0  -0.0115607   
6  0.966667  0.489865   [[290, 6], [4, 0]]  0.983051          0  -0.0162602   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
7   0.0674867  0.989051  0.0384615  0.915541   0.25  
1   0.0482822  0.988679  0.0285714  0.885135   0.25  
0   0.0447805  0.988593   0.027027  0.878378   0.25  
2           0  0.986667          0         1      0  
8           0  0.986667          0         1      0  
3 -0.00672277  0.986622          0  0.996622      0  
4 -0.00672277  0.986622          0  0.996622      0  
5 -0.00672277  0.986622          0  0.996622      0  
9  -0.0116833  0.986532          0  0.989865      0  
6  -0.0166068  0.986395          0   0.97973      0  
Elapsed time 24.99 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv 
datetime: 2017-05-08 23:38:49.988000 
pca_target: 0 	 poly degree: 2 	 kselect: 40 
Imbalance: SMOTE(k=None, k_neighbors=5, kind='regular', m=None, m_neighbors=10, n_jobs=1,
   out_step=0.5, random_state=None, ratio='auto', svm_estimator=None) 
Extended target (count):  25141 325
('Total : Processed (count): ', (998L, 25425L), 13)
Final feature (count):  (998L, 25425L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.760 	0.136 	0.053 	0.755 	0.755 	0.570
[[225  71]
 [  1   3]]
             precision    recall  f1-score   support

        0.0       1.00      0.76      0.86       296
        1.0       0.04      0.75      0.08         4

avg / total       0.98      0.76      0.85       300


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=10, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.917 	0.175 	0.118 	0.711 	0.679 	0.442
[[273  23]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      0.92      0.96       296
        1.0       0.08      0.50      0.14         4

avg / total       0.98      0.92      0.95       300


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.001, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.001, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='perceptron', n_iter=5, n_jobs=4,
       penalty='l1', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.897 	0.238 	0.142 	0.824 	0.821 	0.664
[[266  30]
 [  1   3]]
             precision    recall  f1-score   support

        0.0       1.00      0.90      0.94       296
        1.0       0.09      0.75      0.16         4

avg / total       0.98      0.90      0.93       300


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 500}, criterion='gini',
           max_depth=None, max_features='auto', max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=30, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.957 	-0.020 	-0.019 	0.485 	0.000 	0.000
[[287   9]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.97      0.98       296
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.96      0.96       300


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 15},
            criterion='entropy', max_depth=None, max_features=0.33,
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.950 	-0.023 	-0.020 	0.481 	0.000 	0.000
[[285  11]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.96      0.97       296
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.95      0.96       300


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(500,), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.973 	0.191 	0.187 	0.617 	0.496 	0.228
[[291   5]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.98      0.99       296
        1.0       0.17      0.25      0.20         4

avg / total       0.98      0.97      0.98       300


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=16,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=1.0, n_estimators=50, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.967 	-0.017 	-0.016 	0.490 	0.000 	0.000
[[290   6]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.98      0.98       296
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.97      0.97       300


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.5, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.980 	-0.010 	-0.009 	0.497 	0.000 	0.000
[[294   2]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       296
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.98       300


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=1.0, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', R...owski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='uniform'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.927 	0.190 	0.134 	0.716 	0.683 	0.446
[[276  20]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      0.93      0.96       296
        1.0       0.09      0.50      0.15         4

avg / total       0.98      0.93      0.95       300


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=4,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.940 	0.102 	0.080 	0.600 	0.487 	0.221
[[281  15]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.95      0.97       296
        1.0       0.06      0.25      0.10         4

avg / total       0.98      0.94      0.96       300


                estimator min_score mean_score max_score   sd_score       acc  \
2           SGDClassifier -0.161568    0.41952  0.830971   0.237257  0.896667   
0              GaussianNB  0.671061   0.671061  0.671061          0      0.76   
8        VotingClassifier  0.826183   0.879566  0.916183  0.0204902  0.926667   
1      LogisticRegression         0   0.685171  0.915322   0.172922  0.916667   
5           MLPClassifier  0.950593   0.966368  0.979966  0.0072755  0.973333   
9    KNeighborsClassifier  0.854245   0.892091  0.929233  0.0249592      0.94   
7                     SVC         0   0.776054  0.975587   0.234114      0.98   
6      AdaBoostClassifier  0.824344   0.925788  0.965935  0.0260946  0.966667   
3    ExtraTreesClassifier  0.714912   0.918335    0.9771  0.0772288  0.956667   
4  RandomForestClassifier  0.742698    0.91712   0.95441    0.04508      0.95   

        auc          conf_matrix     f1_c0      f1_c1       kappa model_score  \
2  0.824324  [[266, 30], [1, 3]]  0.944938   0.162162     0.14175    0.237779   
0  0.755068  [[225, 71], [1, 3]]  0.862069  0.0769231   0.0529639    0.135735   
8  0.716216  [[276, 20], [2, 2]]  0.961672   0.153846    0.134313    0.190266   
1  0.711149  [[273, 23], [2, 2]]  0.956217   0.137931    0.117647     0.17525   
5  0.616554   [[291, 5], [3, 1]]  0.986441        0.2    0.186992    0.190978   
9  0.599662  [[281, 15], [3, 1]]  0.968966        0.1   0.0803815    0.101746   
7  0.496622   [[294, 2], [4, 0]]  0.989899          0 -0.00896861 -0.00952338   
6  0.489865   [[290, 6], [4, 0]]  0.983051          0  -0.0162602  -0.0166068   
3  0.484797   [[287, 9], [4, 0]]  0.977853          0  -0.0188088  -0.0204437   
4  0.481419  [[285, 11], [4, 0]]  0.974359          0  -0.0199456  -0.0226794   

    prec_c0    prec_c1    rec_c0 rec_c1  
2  0.996255  0.0909091  0.898649   0.75  
0  0.995575  0.0405405  0.760135   0.75  
8  0.992806  0.0909091  0.932432    0.5  
1  0.992727       0.08  0.922297    0.5  
5  0.989796   0.166667  0.983108   0.25  
9  0.989437     0.0625  0.949324   0.25  
7  0.986577          0  0.993243      0  
6  0.986395          0   0.97973      0  
3  0.986254          0  0.969595      0  
4  0.986159          0  0.962838      0  
Elapsed time 42.92 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv 
datetime: 2017-05-09 00:21:44.912000 
pca_target: 0 	 poly degree: 2 	 kselect: 40 
Imbalance: ClusterCentroids(estimator=None, n_jobs=1, random_state=None, ratio='auto') 
Extended target (count):  25141 325
('Total : Processed (count): ', (998L, 25425L), 13)
Final feature (count):  (998L, 25425L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.440 	-0.071 	-0.015 	0.346 	0.333 	0.109
[[131 165]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.98      0.44      0.61       296
        1.0       0.01      0.25      0.01         4

avg / total       0.96      0.44      0.60       300


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.001, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.533 	-0.049 	-0.012 	0.394 	0.366 	0.130
[[159 137]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.98      0.54      0.69       296
        1.0       0.01      0.25      0.01         4

avg / total       0.97      0.53      0.69       300


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.0001, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.001, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='modified_huber', n_iter=5, n_jobs=4,
       penalty='l2', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.073 	-0.085 	-0.005 	0.407 	0.219 	0.051
[[ 19 277]
 [  1   3]]
             precision    recall  f1-score   support

        0.0       0.95      0.06      0.12       296
        1.0       0.01      0.75      0.02         4

avg / total       0.94      0.07      0.12       300


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3},
           criterion='entropy', max_depth=32, max_features='auto',
           max_leaf_nodes=None, min_impurity_split=1e-07,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=4,
           oob_score=False, random_state=None, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.327 	0.079 	0.012 	0.659 	0.564 	0.339
[[ 94 202]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.32      0.48       296
        1.0       0.02      1.00      0.04         4

avg / total       0.99      0.33      0.48       300


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 15}, criterion='gini',
            max_depth=None, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.283 	0.007 	0.001 	0.514 	0.456 	0.218
[[ 82 214]
 [  1   3]]
             precision    recall  f1-score   support

        0.0       0.99      0.28      0.43       296
        1.0       0.01      0.75      0.03         4

avg / total       0.97      0.28      0.43       300


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.493 	0.055 	0.012 	0.620 	0.606 	0.377
[[145 151]
 [  1   3]]
             precision    recall  f1-score   support

        0.0       0.99      0.49      0.66       296
        1.0       0.02      0.75      0.04         4

avg / total       0.98      0.49      0.65       300


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=2.0, n_estimators=15, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.270 	-0.185 	-0.027 	0.137 	0.000 	0.000
[[ 81 215]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.27      0.43       296
        1.0       0.00      0.00      0.00         4

avg / total       0.94      0.27      0.42       300


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=10, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.400 	0.034 	0.006 	0.573 	0.544 	0.307
[[117 179]
 [  1   3]]
             precision    recall  f1-score   support

        0.0       0.99      0.40      0.57       296
        1.0       0.02      0.75      0.03         4

avg / total       0.98      0.40      0.56       300


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=10.0, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Ran...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.507 	0.115 	0.026 	0.750 	0.707 	0.525
[[148 148]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.50      0.67       296
        1.0       0.03      1.00      0.05         4

avg / total       0.99      0.51      0.66       300


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=1,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.217 	0.059 	0.007 	0.603 	0.454 	0.222
[[ 61 235]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.21      0.34       296
        1.0       0.02      1.00      0.03         4

avg / total       0.99      0.22      0.34       300


                estimator min_score mean_score max_score   sd_score  \
8        VotingClassifier  0.572745   0.787908  0.906078  0.0963341   
3    ExtraTreesClassifier  0.812156   0.851812         1  0.0479479   
5           MLPClassifier  0.906078   0.906078  0.906078          0   
9    KNeighborsClassifier  0.624311   0.741714  0.812156  0.0778761   
7                     SVC         0   0.480863  0.906078   0.324333   
4  RandomForestClassifier  0.572745   0.823878         1  0.0617574   
2           SGDClassifier -0.222222   0.514584         1   0.255291   
1      LogisticRegression         0   0.357577  0.812156   0.282819   
0              GaussianNB  0.906078   0.906078  0.906078          0   
6      AdaBoostClassifier  0.350522   0.793592         1  0.0977575   

         acc       auc           conf_matrix     f1_c0      f1_c1  \
8   0.506667      0.75  [[148, 148], [0, 4]]  0.666667  0.0512821   
3   0.326667  0.658784   [[94, 202], [0, 4]]  0.482051  0.0380952   
5   0.493333  0.619932  [[145, 151], [1, 3]]  0.656109  0.0379747   
9   0.216667  0.603041   [[61, 235], [0, 4]]  0.341737  0.0329218   
7        0.4  0.572635  [[117, 179], [1, 3]]  0.565217  0.0322581   
4   0.283333  0.513514   [[82, 214], [1, 3]]  0.432718  0.0271493   
2  0.0733333  0.407095   [[19, 277], [1, 3]]  0.120253  0.0211268   
1   0.533333  0.393581  [[159, 137], [3, 1]]  0.694323  0.0140845   
0       0.44  0.346284  [[131, 165], [3, 1]]  0.609302  0.0117647   
6       0.27  0.136824   [[81, 215], [4, 0]]  0.425197          0   

         kappa model_score   prec_c0     prec_c1     rec_c0 rec_c1  
8     0.025974    0.114708         1   0.0263158        0.5      1  
3    0.0122571   0.0785262         1   0.0194175   0.317568      1  
5    0.0123029   0.0550435  0.993151   0.0194805   0.489865   0.75  
9    0.0068744   0.0587287         1   0.0167364   0.206081      1  
7   0.00633005   0.0341095  0.991525   0.0164835    0.39527   0.75  
4  0.000991264  0.00692955  0.987952   0.0138249   0.277027   0.75  
2  -0.00530376  -0.0854383      0.95   0.0107143  0.0641892   0.75  
1   -0.0121457   -0.048981  0.981481  0.00724638   0.537162   0.25  
0   -0.0146561  -0.0709282  0.977612   0.0060241   0.442568   0.25  
6   -0.0268834   -0.184882  0.952941           0   0.273649      0  
Elapsed time 18.56 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv 
datetime: 2017-05-09 00:40:18.308000 
pca_target: 0 	 poly degree: 2 	 kselect: 80 
Imbalance: None 
Extended target (count):  25141 325
('Total : Processed (count): ', (998L, 25425L), 13)
Final feature (count):  (998L, 25425L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.873 	0.047 	0.027 	0.566 	0.470 	0.207
[[261  35]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.88      0.93       296
        1.0       0.03      0.25      0.05         4

avg / total       0.98      0.87      0.92       300


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.001, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='sag', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.980 	-0.010 	-0.009 	0.497 	0.000 	0.000
[[294   2]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       296
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.98       300


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.5, average=False, class_weight={1: 15}, epsilon=0.1,
       eta0=0.001, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='modified_huber', n_iter=5, n_jobs=4,
       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.977 	-0.012 	-0.012 	0.495 	0.000 	0.000
[[293   3]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       296
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.98       300


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 50}, criterion='gini',
           max_depth=8, max_features=0.33, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.963 	-0.018 	-0.017 	0.488 	0.000 	0.000
[[289   7]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.98      0.98       296
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.96      0.97       300


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	0.000 	0.000 	0.500 	0.000 	0.000
[[296   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       296
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       300


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.5, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(500,), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	0.000 	0.000 	0.500 	0.000 	0.000
[[296   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       296
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       300


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=8,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=0.5, n_estimators=15, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.983 	-0.007 	-0.005 	0.498 	0.000 	0.000
[[295   1]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       296
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.98       300


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.1, cache_size=200, class_weight={1: 50}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.963 	0.150 	0.138 	0.611 	0.493 	0.226
[[288   8]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.97      0.98       296
        1.0       0.11      0.25      0.15         4

avg / total       0.98      0.96      0.97       300


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	0.000 	0.000 	0.500 	0.000 	0.000
[[296   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       296
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       300


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=1,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.970 	-0.015 	-0.015 	0.492 	0.000 	0.000
[[291   5]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.98      0.98       296
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.97      0.97       300


                estimator  min_score   mean_score   max_score    sd_score  \
7                     SVC  -0.116351      -0.0192    0.096565   0.0424956   
0              GaussianNB   0.113616     0.113616    0.113616           0   
4  RandomForestClassifier -0.0109108 -0.000686932           0  0.00125305   
5           MLPClassifier -0.0194295    -0.012949 -0.00553922  0.00383587   
8        VotingClassifier -0.0141495  -0.00303239           0  0.00386653   
6      AdaBoostClassifier -0.0254016   0.00041353      0.1596   0.0312179   
1      LogisticRegression  -0.156712  -0.00271737    0.169549   0.0553348   
2           SGDClassifier  -0.197708    0.0282363    0.254696    0.047658   
9    KNeighborsClassifier -0.0167781  0.000735388   0.0692234   0.0187384   
3    ExtraTreesClassifier  -0.016193 -0.000572544    0.133392   0.0128955   

        acc       auc          conf_matrix     f1_c0     f1_c1       kappa  \
7  0.963333  0.611486   [[288, 8], [3, 1]]  0.981261  0.153846    0.137931   
0  0.873333  0.565878  [[261, 35], [3, 1]]  0.932143      0.05   0.0266393   
4  0.986667       0.5   [[296, 0], [4, 0]]  0.993289         0           0   
5  0.986667       0.5   [[296, 0], [4, 0]]  0.993289         0           0   
8  0.986667       0.5   [[296, 0], [4, 0]]  0.993289         0           0   
6  0.983333  0.498311   [[295, 1], [4, 0]]  0.991597         0 -0.00536193   
1      0.98  0.496622   [[294, 2], [4, 0]]  0.989899         0 -0.00896861   
2  0.976667  0.494932   [[293, 3], [4, 0]]  0.988196         0  -0.0115607   
9      0.97  0.491554   [[291, 5], [4, 0]]  0.984772         0  -0.0150376   
3  0.963333  0.488176   [[289, 7], [4, 0]]  0.981324         0  -0.0172626   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
7     0.14992  0.989691   0.111111  0.972973   0.25  
0   0.0465046  0.988636  0.0277778  0.881757   0.25  
4           0  0.986667          0         1      0  
5           0  0.986667          0         1      0  
8           0  0.986667          0         1      0  
6 -0.00672277  0.986622          0  0.996622      0  
1 -0.00952338  0.986577          0  0.993243      0  
2  -0.0116833  0.986532          0  0.989865      0  
9  -0.0151342  0.986441          0  0.983108      0  
3   -0.017968  0.986348          0  0.976351      0  
Elapsed time 28.09 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv 
datetime: 2017-05-09 01:08:23.798000 
pca_target: 0 	 poly degree: 2 	 kselect: 80 
Imbalance: SMOTE(k=None, k_neighbors=5, kind='regular', m=None, m_neighbors=10, n_jobs=1,
   out_step=0.5, random_state=None, ratio='auto', svm_estimator=None) 
Extended target (count):  25141 325
('Total : Processed (count): ', (998L, 25425L), 13)
Final feature (count):  (998L, 25425L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.740 	0.190 	0.069 	0.868 	0.858 	0.756
[[218  78]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.74      0.85       296
        1.0       0.05      1.00      0.09         4

avg / total       0.99      0.74      0.84       300


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=10, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.920 	0.180 	0.123 	0.713 	0.680 	0.443
[[274  22]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      0.93      0.96       296
        1.0       0.08      0.50      0.14         4

avg / total       0.98      0.92      0.95       300


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.5, average=False, class_weight='balanced', epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='invscaling', loss='perceptron', n_iter=5, n_jobs=4,
       penalty='none', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.900 	0.063 	0.040 	0.579 	0.477 	0.212
[[269  27]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.91      0.95       296
        1.0       0.04      0.25      0.06         4

avg / total       0.98      0.90      0.94       300


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 500}, criterion='gini',
           max_depth=None, max_features=0.75, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=50, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.963 	0.150 	0.138 	0.611 	0.493 	0.226
[[288   8]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.97      0.98       296
        1.0       0.11      0.25      0.15         4

avg / total       0.98      0.96      0.97       300


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3},
            criterion='entropy', max_depth=32, max_features='auto',
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.967 	0.161 	0.152 	0.613 	0.494 	0.226
[[289   7]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.98      0.98       296
        1.0       0.12      0.25      0.17         4

avg / total       0.98      0.97      0.97       300


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.980 	0.399 	0.390 	0.743 	0.702 	0.469
[[292   4]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       296
        1.0       0.33      0.50      0.40         4

avg / total       0.98      0.98      0.98       300


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 500}, criterion='gini', max_depth=16,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=1.0, n_estimators=80, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.980 	-0.010 	-0.009 	0.497 	0.000 	0.000
[[294   2]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       296
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.98       300


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=10, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.977 	0.212 	0.211 	0.618 	0.497 	0.228
[[292   4]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       296
        1.0       0.20      0.25      0.22         4

avg / total       0.98      0.98      0.98       300


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=10.0, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', ...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.953 	0.125 	0.107 	0.606 	0.491 	0.224
[[285  11]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.96      0.98       296
        1.0       0.08      0.25      0.12         4

avg / total       0.98      0.95      0.96       300


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=4,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.930 	-0.028 	-0.022 	0.471 	0.000 	0.000
[[279  17]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.94      0.96       296
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.93      0.95       300


                estimator min_score mean_score max_score    sd_score  \
0              GaussianNB  0.617761   0.617761  0.617761           0   
5           MLPClassifier  0.959686   0.970051  0.979917  0.00490938   
1      LogisticRegression  0.197565   0.723409  0.899389    0.123547   
7                     SVC         0   0.796704  0.975546    0.256279   
4  RandomForestClassifier  0.754578   0.939973  0.972874   0.0417953   
3    ExtraTreesClassifier  0.708321   0.924882  0.977102   0.0653878   
8        VotingClassifier  0.863014   0.922605  0.961668   0.0234005   
2           SGDClassifier  -0.10079   0.510984  0.884829    0.242316   
6      AdaBoostClassifier  0.856451   0.946621  0.982848   0.0219143   
9    KNeighborsClassifier  0.861724   0.900373  0.939513   0.0269158   

        acc       auc          conf_matrix     f1_c0      f1_c1       kappa  \
0      0.74  0.868243  [[218, 78], [0, 4]]  0.848249  0.0930233   0.0693605   
5      0.98  0.743243   [[292, 4], [2, 2]]  0.989831        0.4    0.390244   
1      0.92  0.712838  [[274, 22], [2, 2]]  0.958042   0.142857    0.122807   
7  0.976667  0.618243   [[292, 4], [3, 1]]  0.988156   0.222222    0.210526   
4  0.966667  0.613176   [[289, 7], [3, 1]]  0.982993   0.166667    0.151584   
3  0.963333  0.611486   [[288, 8], [3, 1]]  0.981261   0.153846    0.137931   
8  0.953333  0.606419  [[285, 11], [3, 1]]  0.976027      0.125    0.107143   
2       0.9  0.579392  [[269, 27], [3, 1]]  0.947183     0.0625   0.0401024   
6      0.98  0.496622   [[294, 2], [4, 0]]  0.989899          0 -0.00896861   
9      0.93  0.471284  [[279, 17], [4, 0]]  0.963731          0  -0.0220636   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
0    0.189542         1  0.0487805  0.736486      1  
5    0.398563  0.993197   0.333333  0.986486    0.5  
1    0.179968  0.992754  0.0833333  0.925676    0.5  
7    0.211878  0.989831        0.2  0.986486   0.25  
4    0.161147  0.989726      0.125  0.976351   0.25  
3     0.14992  0.989691   0.111111  0.972973   0.25  
8    0.124577  0.989583  0.0833333  0.962838   0.25  
2   0.0626064  0.988971  0.0357143  0.908784   0.25  
6 -0.00952338  0.986577          0  0.993243      0  
9  -0.0284915  0.985866          0  0.942568      0  
Elapsed time 51.22 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv 
datetime: 2017-05-09 01:59:36.746000 
pca_target: 0 	 poly degree: 2 	 kselect: 80 
Imbalance: ClusterCentroids(estimator=None, n_jobs=1, random_state=None, ratio='auto') 
Extended target (count):  25141 325
('Total : Processed (count): ', (998L, 25425L), 13)
Final feature (count):  (998L, 25425L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.573 	0.074 	0.019 	0.660 	0.654 	0.436
[[169 127]
 [  1   3]]
             precision    recall  f1-score   support

        0.0       0.99      0.57      0.73       296
        1.0       0.02      0.75      0.04         4

avg / total       0.98      0.57      0.72       300


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=1, class_weight={1: 3}, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=4,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.463 	-0.009 	-0.002 	0.481 	0.481 	0.232
[[137 159]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      0.46      0.63       296
        1.0       0.01      0.50      0.02         4

avg / total       0.97      0.46      0.62       300


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.0001, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='constant', loss='perceptron', n_iter=5, n_jobs=4,
       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.327 	0.017 	0.003 	0.535 	0.491 	0.251
[[ 95 201]
 [  1   3]]
             precision    recall  f1-score   support

        0.0       0.99      0.32      0.48       296
        1.0       0.01      0.75      0.03         4

avg / total       0.98      0.33      0.48       300


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=8, max_features=0.33, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.243 	-0.004 	-0.000 	0.493 	0.421 	0.186
[[ 70 226]
 [  1   3]]
             precision    recall  f1-score   support

        0.0       0.99      0.24      0.38       296
        1.0       0.01      0.75      0.03         4

avg / total       0.97      0.24      0.38       300


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.150 	-0.114 	-0.011 	0.323 	0.270 	0.075
[[ 43 253]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.96      0.15      0.25       296
        1.0       0.01      0.50      0.02         4

avg / total       0.94      0.15      0.25       300


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.443 	-0.013 	-0.003 	0.471 	0.470 	0.223
[[131 165]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.98      0.44      0.61       296
        1.0       0.01      0.50      0.02         4

avg / total       0.97      0.44      0.60       300


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=0.5, n_estimators=15, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.037 	-0.150 	-0.006 	0.389 	0.142 	0.022
[[  8 288]
 [  1   3]]
             precision    recall  f1-score   support

        0.0       0.89      0.03      0.05       296
        1.0       0.01      0.75      0.02         4

avg / total       0.88      0.04      0.05       300


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.407 	0.036 	0.007 	0.576 	0.549 	0.312
[[119 177]
 [  1   3]]
             precision    recall  f1-score   support

        0.0       0.99      0.40      0.57       296
        1.0       0.02      0.75      0.03         4

avg / total       0.98      0.41      0.56       300


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.200 	0.056 	0.006 	0.595 	0.435 	0.205
[[ 56 240]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.19      0.32       296
        1.0       0.02      1.00      0.03         4

avg / total       0.99      0.20      0.31       300


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=1,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.210 	-0.013 	-0.002 	0.476 	0.390 	0.160
[[ 60 236]
 [  1   3]]
             precision    recall  f1-score   support

        0.0       0.98      0.20      0.34       296
        1.0       0.01      0.75      0.02         4

avg / total       0.97      0.21      0.33       300


                estimator min_score mean_score max_score   sd_score  \
0              GaussianNB  0.794967   0.794967  0.794967          0   
8        VotingClassifier  0.589933   0.769516  0.777778  0.0280959   
7                     SVC         0   0.474421  0.794967   0.303154   
2           SGDClassifier -0.222222   0.561714         1    0.22894   
3    ExtraTreesClassifier  0.906078    0.91547         1  0.0281766   
1      LogisticRegression         0   0.570088  0.906078   0.303454   
9    KNeighborsClassifier  0.607122   0.739348  0.812156  0.0846655   
5           MLPClassifier    0.2566   0.506371  0.624311   0.124754   
6      AdaBoostClassifier  0.333333   0.709884         1   0.163966   
4  RandomForestClassifier  0.496011   0.695061  0.906078   0.087266   

         acc       auc           conf_matrix     f1_c0      f1_c1  \
0   0.573333  0.660473  [[169, 127], [1, 3]]  0.725322  0.0447761   
8        0.2  0.594595   [[56, 240], [0, 4]]  0.318182  0.0322581   
7   0.406667  0.576014  [[119, 177], [1, 3]]  0.572115  0.0326087   
2   0.326667  0.535473   [[95, 201], [1, 3]]  0.484694  0.0288462   
3   0.243333  0.493243   [[70, 226], [1, 3]]  0.381471  0.0257511   
1   0.463333  0.481419  [[137, 159], [2, 2]]  0.629885  0.0242424   
9       0.21  0.476351   [[60, 236], [1, 3]]  0.336134  0.0246914   
5   0.443333  0.471284  [[131, 165], [2, 2]]  0.610723  0.0233918   
6  0.0366667  0.388514    [[8, 288], [1, 3]]  0.052459   0.020339   
4       0.15  0.322635   [[43, 253], [2, 2]]  0.252199   0.015444   

         kappa model_score   prec_c0     prec_c1    rec_c0 rec_c1  
0    0.0194076   0.0742868  0.994118   0.0230769  0.570946   0.75  
8   0.00618375   0.0556908         1   0.0163934  0.189189      1  
7   0.00669643   0.0355934  0.991667   0.0166667  0.402027   0.75  
2   0.00276461   0.0174443  0.989583   0.0147059  0.320946   0.75  
3 -0.000470118 -0.00364668  0.985915   0.0131004  0.236486   0.75  
1  -0.00182527 -0.00854784  0.985612   0.0124224  0.462838    0.5  
9  -0.00157773  -0.0134787  0.983607   0.0125523  0.202703   0.75  
5  -0.00272196  -0.0132602  0.984962    0.011976  0.442568    0.5  
6  -0.00612728    -0.14992  0.888889   0.0103093  0.027027   0.75  
4   -0.0111023   -0.113945  0.955556  0.00784314   0.14527    0.5  
Elapsed time 20.01 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv 
datetime: 2017-05-09 02:19:37.295000 
pca_target: 80 	 poly degree: 2 	 kselect: 40 
Imbalance: None 
Extended target (count):  25141 325
('Total : Processed (count): ', (998L, 25425L), 13)
Final feature (count):  (998L, 25425L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.923 	0.082 	0.059 	0.591 	0.483 	0.217
[[276  20]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.93      0.96       296
        1.0       0.05      0.25      0.08         4

avg / total       0.98      0.92      0.95       300


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.001, class_weight={1: 50}, dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.893 	0.058 	0.036 	0.576 	0.475 	0.211
[[267  29]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.90      0.94       296
        1.0       0.03      0.25      0.06         4

avg / total       0.98      0.89      0.93       300


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.5, average=False, class_weight={1: 50}, epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='constant', loss='modified_huber', n_iter=5, n_jobs=4,
       penalty='l1', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.737 	0.062 	0.023 	0.620 	0.608 	0.361
[[219  77]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      0.74      0.85       296
        1.0       0.03      0.50      0.05         4

avg / total       0.98      0.74      0.84       300


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 500}, criterion='gini',
           max_depth=8, max_features='auto', max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.990 	0.572 	0.566 	0.748 	0.706 	0.474
[[295   1]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       296
        1.0       0.67      0.50      0.57         4

avg / total       0.99      0.99      0.99       300


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	0.000 	0.000 	0.500 	0.000 	0.000
[[296   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       296
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       300


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(500,), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.983 	0.280 	0.277 	0.622 	0.498 	0.230
[[294   2]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       296
        1.0       0.33      0.25      0.29         4

avg / total       0.98      0.98      0.98       300


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 50}, criterion='entropy', max_depth=8,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=0.5, n_estimators=50, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	0.000 	0.000 	0.500 	0.000 	0.000
[[296   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       296
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       300


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.500 	0.113 	0.025 	0.747 	0.702 	0.518
[[146 150]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.49      0.66       296
        1.0       0.03      1.00      0.05         4

avg / total       0.99      0.50      0.65       300


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	0.000 	0.000 	0.500 	0.000 	0.000
[[296   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       296
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       300


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=1,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.983 	0.280 	0.277 	0.622 	0.498 	0.230
[[294   2]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       296
        1.0       0.33      0.25      0.29         4

avg / total       0.98      0.98      0.98       300


                estimator   min_score   mean_score   max_score     sd_score  \
3    ExtraTreesClassifier -0.00844608  9.10867e-05   0.0757034   0.00405876   
7                     SVC  -0.0248415  -0.00933383   0.0475448    0.0122291   
5           MLPClassifier  -0.0187034   -0.0121327 -0.00495491   0.00433069   
9    KNeighborsClassifier -0.00905133   0.00245307    0.063761    0.0161452   
2           SGDClassifier   -0.137174    0.0363679    0.218585    0.0501893   
0              GaussianNB    0.131132     0.131132    0.131132            0   
1      LogisticRegression  -0.0488242    0.0120639    0.179148    0.0498743   
4  RandomForestClassifier -0.00349117 -6.78839e-05           0  0.000387668   
6      AdaBoostClassifier  -0.0219523  -0.00264495    0.193612    0.0296942   
8        VotingClassifier  -0.0113529   -0.0026035           0   0.00290638   

        acc       auc           conf_matrix     f1_c0      f1_c1      kappa  \
3      0.99  0.748311    [[295, 1], [2, 2]]  0.994941   0.571429   0.566474   
7       0.5  0.746622  [[146, 150], [0, 4]]  0.660633  0.0506329  0.0252989   
5  0.983333  0.621622    [[294, 2], [3, 1]]  0.991568   0.285714   0.277457   
9  0.983333  0.621622    [[294, 2], [3, 1]]  0.991568   0.285714   0.277457   
2  0.736667  0.619932   [[219, 77], [2, 2]]  0.847195  0.0481928  0.0234053   
0  0.923333  0.591216   [[276, 20], [3, 1]]      0.96       0.08  0.0589198   
1  0.893333  0.576014   [[267, 29], [3, 1]]  0.943463  0.0588235  0.0361446   
4  0.986667       0.5    [[296, 0], [4, 0]]  0.993289          0          0   
6  0.986667       0.5    [[296, 0], [4, 0]]  0.993289          0          0   
8  0.986667       0.5    [[296, 0], [4, 0]]  0.993289          0          0   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
3    0.572483  0.993266   0.666667  0.996622    0.5  
7    0.113188         1   0.025974  0.493243      1  
5      0.2804  0.989899   0.333333  0.993243   0.25  
9      0.2804  0.989899   0.333333  0.993243   0.25  
2   0.0624644   0.99095  0.0253165  0.739865    0.5  
0   0.0820099  0.989247   0.047619  0.932432   0.25  
1   0.0581238  0.988889  0.0333333  0.902027   0.25  
4           0  0.986667          0         1      0  
6           0  0.986667          0         1      0  
8           0  0.986667          0         1      0  
Elapsed time 25.13 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv 
datetime: 2017-05-09 02:44:45.067000 
pca_target: 80 	 poly degree: 2 	 kselect: 40 
Imbalance: SMOTE(k=None, k_neighbors=5, kind='regular', m=None, m_neighbors=10, n_jobs=1,
   out_step=0.5, random_state=None, ratio='auto', svm_estimator=None) 
Extended target (count):  25141 325
('Total : Processed (count): ', (998L, 25425L), 13)
Final feature (count):  (998L, 25425L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	0.000 	0.000 	0.500 	0.000 	0.000
[[296   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       296
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       300


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=5, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.970 	0.320 	0.295 	0.738 	0.699 	0.465
[[289   7]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      0.98      0.98       296
        1.0       0.22      0.50      0.31         4

avg / total       0.98      0.97      0.98       300


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.0001, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='squared_hinge', n_iter=5, n_jobs=4,
       penalty='l2', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.983 	0.280 	0.277 	0.622 	0.498 	0.230
[[294   2]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       296
        1.0       0.33      0.25      0.29         4

avg / total       0.98      0.98      0.98       300


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=8, max_features=0.75, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	0.000 	0.000 	0.500 	0.000 	0.000
[[296   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       296
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       300


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	0.000 	0.000 	0.500 	0.000 	0.000
[[296   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       296
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       300


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	0.348 	0.327 	0.623 	0.499 	0.231
[[295   1]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       296
        1.0       0.50      0.25      0.33         4

avg / total       0.98      0.99      0.98       300


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=1.0, n_estimators=50, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	0.000 	0.000 	0.500 	0.000 	0.000
[[296   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       296
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       300


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.1, cache_size=200, class_weight={1: 50}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	0.000 	0.000 	0.500 	0.000 	0.000
[[296   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       296
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       300


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=1.0, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', R...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	0.493 	0.493 	0.747 	0.705 	0.472
[[294   2]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       296
        1.0       0.50      0.50      0.50         4

avg / total       0.99      0.99      0.99       300


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=4,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.957 	0.373 	0.301 	0.855 	0.848 	0.705
[[284  12]
 [  1   3]]
             precision    recall  f1-score   support

        0.0       1.00      0.96      0.98       296
        1.0       0.20      0.75      0.32         4

avg / total       0.99      0.96      0.97       300


                estimator min_score mean_score max_score    sd_score  \
9    KNeighborsClassifier  0.742293   0.842098   0.93405   0.0585397   
8        VotingClassifier  0.934082   0.976363   0.99278   0.0132623   
1      LogisticRegression  0.365648   0.877765  0.979916    0.134956   
5           MLPClassifier  0.975659   0.988223         1  0.00794516   
2           SGDClassifier -0.186198   0.691755  0.989948    0.290447   
0              GaussianNB  0.961659   0.961659  0.961659           0   
3    ExtraTreesClassifier  0.974446   0.999359         1  0.00163675   
4  RandomForestClassifier  0.995662   0.998301         1  0.00107734   
6      AdaBoostClassifier  0.941524   0.985734         1  0.00881887   
7                     SVC         0    0.84272         1    0.320555   

        acc       auc          conf_matrix     f1_c0     f1_c1     kappa  \
9  0.956667   0.85473  [[284, 12], [1, 3]]  0.977625  0.315789  0.301075   
8  0.986667  0.746622   [[294, 2], [2, 2]]  0.993243       0.5  0.493243   
1      0.97  0.738176   [[289, 7], [2, 2]]  0.984668  0.307692  0.294671   
5  0.986667  0.623311   [[295, 1], [3, 1]]  0.993266  0.333333  0.327354   
2  0.983333  0.621622   [[294, 2], [3, 1]]  0.991568  0.285714  0.277457   
0  0.986667       0.5   [[296, 0], [4, 0]]  0.993289         0         0   
3  0.986667       0.5   [[296, 0], [4, 0]]  0.993289         0         0   
4  0.986667       0.5   [[296, 0], [4, 0]]  0.993289         0         0   
6  0.986667       0.5   [[296, 0], [4, 0]]  0.993289         0         0   
7  0.986667       0.5   [[296, 0], [4, 0]]  0.993289         0         0   

  model_score   prec_c0   prec_c1    rec_c0 rec_c1  
9    0.373367  0.996491       0.2  0.959459   0.75  
8    0.493243  0.993243       0.5  0.993243    0.5  
1    0.320284  0.993127  0.222222  0.976351    0.5  
5    0.347603  0.989933       0.5  0.996622   0.25  
2      0.2804  0.989899  0.333333  0.993243   0.25  
0           0  0.986667         0         1      0  
3           0  0.986667         0         1      0  
4           0  0.986667         0         1      0  
6           0  0.986667         0         1      0  
7           0  0.986667         0         1      0  
Elapsed time 41.21 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv 
datetime: 2017-05-09 03:25:57.730000 
pca_target: 80 	 poly degree: 2 	 kselect: 40 
Imbalance: ClusterCentroids(estimator=None, n_jobs=1, random_state=None, ratio='auto') 
Extended target (count):  25141 325
('Total : Processed (count): ', (998L, 25425L), 13)
Final feature (count):  (998L, 25425L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	0.000 	0.000 	0.500 	0.000 	0.000
[[296   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       296
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       300


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.001, class_weight={1: 500}, dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.660 	0.039 	0.012 	0.581 	0.575 	0.326
[[196 100]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      0.66      0.79       296
        1.0       0.02      0.50      0.04         4

avg / total       0.98      0.66      0.78       300


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.0001, average=False, class_weight='balanced',
       epsilon=0.1, eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='squared_hinge', n_iter=5, n_jobs=4,
       penalty='l2', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.610 	-0.032 	-0.009 	0.432 	0.392 	0.148
[[182 114]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.98      0.61      0.76       296
        1.0       0.01      0.25      0.02         4

avg / total       0.97      0.61      0.75       300


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=8, max_features='auto', max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.183 	0.053 	0.006 	0.586 	0.415 	0.187
[[ 51 245]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.17      0.29       296
        1.0       0.02      1.00      0.03         4

avg / total       0.99      0.18      0.29       300


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features=0.33, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=30, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.333 	0.080 	0.013 	0.662 	0.569 	0.346
[[ 96 200]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.32      0.49       296
        1.0       0.02      1.00      0.04         4

avg / total       0.99      0.33      0.48       300


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.460 	0.104 	0.022 	0.726 	0.673 	0.477
[[134 162]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.45      0.62       296
        1.0       0.02      1.00      0.05         4

avg / total       0.99      0.46      0.62       300


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=8,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=0.5, n_estimators=80, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.283 	0.071 	0.010 	0.637 	0.523 	0.294
[[ 81 215]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.27      0.43       296
        1.0       0.02      1.00      0.04         4

avg / total       0.99      0.28      0.42       300


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=10, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.013 	0.000 	0.000 	0.500 	0.000 	0.000
[[  0 296]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       0.00      0.00      0.00       296
        1.0       0.01      1.00      0.03         4

avg / total       0.00      0.01      0.00       300


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', R...wski',
           metric_params=None, n_jobs=4, n_neighbors=4, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.460 	-0.009 	-0.002 	0.480 	0.479 	0.231
[[136 160]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      0.46      0.63       296
        1.0       0.01      0.50      0.02         4

avg / total       0.97      0.46      0.62       300


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=1,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.740 	0.127 	0.047 	0.745 	0.745 	0.555
[[219  77]
 [  1   3]]
             precision    recall  f1-score   support

        0.0       1.00      0.74      0.85       296
        1.0       0.04      0.75      0.07         4

avg / total       0.98      0.74      0.84       300


                estimator min_score mean_score max_score     sd_score  \
9    KNeighborsClassifier -0.589933   0.172038  0.906078     0.483533   
5           MLPClassifier    0.2566   0.521718  0.718234    0.0650653   
4  RandomForestClassifier  0.478822   0.843954         1    0.0921369   
6      AdaBoostClassifier    0.1283   0.774101         1     0.160606   
3    ExtraTreesClassifier  0.906078   0.906078  0.906078  1.11022e-16   
1      LogisticRegression         0   0.355844  0.718234     0.218039   
0              GaussianNB  0.888889   0.888889  0.888889            0   
7                     SVC         0   0.442845  0.812156     0.339255   
8        VotingClassifier  0.444444   0.623838  0.906078    0.0999517   
2           SGDClassifier -0.794967   0.322105  0.812156     0.249188   

         acc       auc           conf_matrix     f1_c0      f1_c1       kappa  \
9       0.74  0.744932   [[219, 77], [1, 3]]  0.848837  0.0714286   0.0472313   
5       0.46  0.726351  [[134, 162], [0, 4]]  0.623256  0.0470588   0.0215816   
4   0.333333  0.662162   [[96, 200], [0, 4]]  0.489796  0.0384615   0.0126382   
6   0.283333  0.636824   [[81, 215], [0, 4]]  0.429708  0.0358744  0.00994658   
3   0.183333  0.586149   [[51, 245], [0, 4]]  0.293948  0.0316206  0.00552038   
1       0.66  0.581081  [[196, 100], [2, 2]]  0.793522  0.0377358   0.0123935   
0   0.986667       0.5    [[296, 0], [4, 0]]  0.993289          0           0   
7  0.0133333       0.5    [[0, 296], [0, 4]]         0  0.0263158           0   
8       0.46   0.47973  [[136, 160], [2, 2]]  0.626728  0.0240964 -0.00197922   
2       0.61  0.432432  [[182, 114], [3, 1]]  0.756757  0.0168067 -0.00920069   

  model_score   prec_c0     prec_c1    rec_c0 rec_c1  
9    0.127056  0.995455      0.0375  0.739865   0.75  
5    0.104444         1   0.0240964  0.452703      1  
4   0.0797452         1   0.0196078  0.324324      1  
6   0.0706976         1   0.0182648  0.273649      1  
3   0.0526102         1   0.0160643  0.172297      1  
1   0.0392638  0.989899   0.0196078  0.662162    0.5  
0           0  0.986667           0         1      0  
7           0         0   0.0133333         0      1  
8 -0.00932971  0.985507   0.0123457  0.459459    0.5  
2  -0.0318793  0.983784  0.00869565  0.614865   0.25  
Elapsed time 18.73 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv 
datetime: 2017-05-09 03:44:41.559000 
pca_target: 80 	 poly degree: 2 	 kselect: 80 
Imbalance: None 
Extended target (count):  25141 325
('Total : Processed (count): ', (998L, 25425L), 13)
Final feature (count):  (998L, 25425L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.900 	0.063 	0.040 	0.579 	0.477 	0.212
[[269  27]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.91      0.95       296
        1.0       0.04      0.25      0.06         4

avg / total       0.98      0.90      0.94       300


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.001, class_weight={1: 50}, dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.900 	0.063 	0.040 	0.579 	0.477 	0.212
[[269  27]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.91      0.95       296
        1.0       0.04      0.25      0.06         4

avg / total       0.98      0.90      0.94       300


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.1, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='perceptron', n_iter=5, n_jobs=4,
       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	0.000 	0.000 	0.500 	0.000 	0.000
[[296   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       296
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       300


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 500}, criterion='gini',
           max_depth=8, max_features=0.33, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.977 	0.367 	0.353 	0.742 	0.701 	0.468
[[291   5]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      0.98      0.99       296
        1.0       0.29      0.50      0.36         4

avg / total       0.98      0.98      0.98       300


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	0.000 	0.000 	0.500 	0.000 	0.000
[[296   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       296
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       300


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.1, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(500,), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.980 	-0.010 	-0.009 	0.497 	0.000 	0.000
[[294   2]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       296
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.98       300


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight='balanced', criterion='entropy',
            max_depth=32, max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=2.0, n_estimators=15, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.977 	0.212 	0.211 	0.618 	0.497 	0.228
[[292   4]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       296
        1.0       0.20      0.25      0.22         4

avg / total       0.98      0.98      0.98       300


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.503 	0.114 	0.026 	0.748 	0.705 	0.522
[[147 149]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.50      0.66       296
        1.0       0.03      1.00      0.05         4

avg / total       0.99      0.50      0.66       300


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.990 	0.497 	0.397 	0.625 	0.500 	0.231
[[296   0]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       296
        1.0       1.00      0.25      0.40         4

avg / total       0.99      0.99      0.99       300


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=2,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	0.348 	0.327 	0.623 	0.499 	0.231
[[295   1]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       296
        1.0       0.50      0.25      0.33         4

avg / total       0.98      0.99      0.98       300


                estimator   min_score   mean_score   max_score     sd_score  \
7                     SVC   -0.023804  -0.00860018   0.0487922    0.0117262   
3    ExtraTreesClassifier -0.00700296  7.79592e-05   0.0762267   0.00408793   
8        VotingClassifier -0.00758727  -0.00152643           0   0.00163311   
9    KNeighborsClassifier -0.00787328    0.0103514   0.0913602    0.0300765   
6      AdaBoostClassifier    -0.02015  -0.00330503    0.242931    0.0281121   
0              GaussianNB    0.140741     0.140741    0.140741            0   
1      LogisticRegression  -0.0516025    0.0100016    0.177101    0.0484904   
2           SGDClassifier    -0.10544    0.0327511    0.197708    0.0469536   
4  RandomForestClassifier -0.00639803 -0.000128897           0  0.000630004   
5           MLPClassifier  -0.0165195   -0.0104303 -0.00204805   0.00341513   

        acc       auc           conf_matrix     f1_c0      f1_c1       kappa  \
7  0.503333  0.748311  [[147, 149], [0, 4]]  0.663657  0.0509554   0.0256343   
3  0.976667  0.741554    [[291, 5], [2, 2]]  0.988115   0.363636    0.352651   
8      0.99     0.625    [[296, 0], [3, 1]]  0.994958        0.4    0.396783   
9  0.986667  0.623311    [[295, 1], [3, 1]]  0.993266   0.333333    0.327354   
6  0.976667  0.618243    [[292, 4], [3, 1]]  0.988156   0.222222    0.210526   
0       0.9  0.579392   [[269, 27], [3, 1]]  0.947183     0.0625   0.0401024   
1       0.9  0.579392   [[269, 27], [3, 1]]  0.947183     0.0625   0.0401024   
2  0.986667       0.5    [[296, 0], [4, 0]]  0.993289          0           0   
4  0.986667       0.5    [[296, 0], [4, 0]]  0.993289          0           0   
5      0.98  0.496622    [[294, 2], [4, 0]]  0.989899          0 -0.00896861   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
7    0.113945         1  0.0261438  0.496622      1  
3     0.36706  0.993174   0.285714  0.983108    0.5  
8    0.497485  0.989967          1         1   0.25  
9    0.347603  0.989933        0.5  0.996622   0.25  
6    0.211878  0.989831        0.2  0.986486   0.25  
0   0.0626064  0.988971  0.0357143  0.908784   0.25  
1   0.0626064  0.988971  0.0357143  0.908784   0.25  
2           0  0.986667          0         1      0  
4           0  0.986667          0         1      0  
5 -0.00952338  0.986577          0  0.993243      0  
Elapsed time 28.75 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv 
datetime: 2017-05-09 04:13:26.401000 
pca_target: 80 	 poly degree: 2 	 kselect: 80 
Imbalance: SMOTE(k=None, k_neighbors=5, kind='regular', m=None, m_neighbors=10, n_jobs=1,
   out_step=0.5, random_state=None, ratio='auto', svm_estimator=None) 
Extended target (count):  25141 325
('Total : Processed (count): ', (998L, 25425L), 13)
Final feature (count):  (998L, 25425L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	0.000 	0.000 	0.500 	0.000 	0.000
[[296   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       296
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       300


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=10, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.970 	0.320 	0.295 	0.738 	0.699 	0.465
[[289   7]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      0.98      0.98       296
        1.0       0.22      0.50      0.31         4

avg / total       0.98      0.97      0.98       300


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.001, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='perceptron', n_iter=5, n_jobs=4,
       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	0.348 	0.327 	0.623 	0.499 	0.231
[[295   1]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       296
        1.0       0.50      0.25      0.33         4

avg / total       0.98      0.99      0.98       300


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=8, max_features=0.75, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=50, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	0.000 	0.000 	0.500 	0.000 	0.000
[[296   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       296
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       300


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	0.000 	0.000 	0.500 	0.000 	0.000
[[296   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       296
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       300


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	0.000 	0.000 	0.500 	0.000 	0.000
[[296   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       296
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       300


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=0.5, n_estimators=15, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	0.000 	0.000 	0.500 	0.000 	0.000
[[296   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       296
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       300


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.1, cache_size=200, class_weight={1: 50}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	0.000 	0.000 	0.500 	0.000 	0.000
[[296   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       296
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       300


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=10.0, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', ...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.990 	0.572 	0.566 	0.748 	0.706 	0.474
[[295   1]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       296
        1.0       0.67      0.50      0.57         4

avg / total       0.99      0.99      0.99       300


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=4,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.967 	0.421 	0.362 	0.860 	0.853 	0.711
[[287   9]
 [  1   3]]
             precision    recall  f1-score   support

        0.0       1.00      0.97      0.98       296
        1.0       0.25      0.75      0.38         4

avg / total       0.99      0.97      0.97       300


                estimator min_score mean_score max_score     sd_score  \
9    KNeighborsClassifier  0.791854   0.861904  0.935371    0.0479772   
8        VotingClassifier  0.927327   0.971659   0.99278     0.015556   
1      LogisticRegression  0.291279   0.878822  0.978568     0.135623   
2           SGDClassifier -0.145622   0.694709  0.994226     0.283213   
0              GaussianNB  0.926132   0.926132  0.926132            0   
3    ExtraTreesClassifier  0.967298   0.999412         1   0.00217099   
4  RandomForestClassifier  0.994236   0.999201         1  0.000972143   
5           MLPClassifier  0.975706   0.988276         1   0.00725819   
6      AdaBoostClassifier  0.906939   0.987954         1   0.00947196   
7                     SVC         0   0.830814         1     0.324123   

        acc       auc         conf_matrix     f1_c0     f1_c1     kappa  \
9  0.966667  0.859797  [[287, 9], [1, 3]]  0.982877     0.375  0.362245   
8      0.99  0.748311  [[295, 1], [2, 2]]  0.994941  0.571429  0.566474   
1      0.97  0.738176  [[289, 7], [2, 2]]  0.984668  0.307692  0.294671   
2  0.986667  0.623311  [[295, 1], [3, 1]]  0.993266  0.333333  0.327354   
0  0.986667       0.5  [[296, 0], [4, 0]]  0.993289         0         0   
3  0.986667       0.5  [[296, 0], [4, 0]]  0.993289         0         0   
4  0.986667       0.5  [[296, 0], [4, 0]]  0.993289         0         0   
5  0.986667       0.5  [[296, 0], [4, 0]]  0.993289         0         0   
6  0.986667       0.5  [[296, 0], [4, 0]]  0.993289         0         0   
7  0.986667       0.5  [[296, 0], [4, 0]]  0.993289         0         0   

  model_score   prec_c0   prec_c1    rec_c0 rec_c1  
9    0.421189  0.996528      0.25  0.969595   0.75  
8    0.572483  0.993266  0.666667  0.996622    0.5  
1    0.320284  0.993127  0.222222  0.976351    0.5  
2    0.347603  0.989933       0.5  0.996622   0.25  
0           0  0.986667         0         1      0  
3           0  0.986667         0         1      0  
4           0  0.986667         0         1      0  
5           0  0.986667         0         1      0  
6           0  0.986667         0         1      0  
7           0  0.986667         0         1      0  
Elapsed time 48.60 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv 
datetime: 2017-05-09 05:02:02.176000 
pca_target: 80 	 poly degree: 2 	 kselect: 80 
Imbalance: ClusterCentroids(estimator=None, n_jobs=1, random_state=None, ratio='auto') 
Extended target (count):  25141 325
('Total : Processed (count): ', (998L, 25425L), 13)
Final feature (count):  (998L, 25425L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	0.000 	0.000 	0.500 	0.000 	0.000
[[296   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       296
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       300


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.001, class_weight={1: 500}, dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.467 	0.049 	0.010 	0.606 	0.589 	0.357
[[137 159]
 [  1   3]]
             precision    recall  f1-score   support

        0.0       0.99      0.46      0.63       296
        1.0       0.02      0.75      0.04         4

avg / total       0.98      0.47      0.62       300


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.0001, average=False, class_weight={1: 500}, epsilon=0.1,
       eta0=0.001, fit_intercept=True, l1_ratio=0.15,
       learning_rate='invscaling', loss='modified_huber', n_iter=5,
       n_jobs=4, penalty='l1', power_t=0.5, random_state=None,
       shuffle=True, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.453 	0.046 	0.010 	0.600 	0.581 	0.347
[[133 163]
 [  1   3]]
             precision    recall  f1-score   support

        0.0       0.99      0.45      0.62       296
        1.0       0.02      0.75      0.04         4

avg / total       0.98      0.45      0.61       300


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=16, max_features=0.75, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.057 	0.025 	0.001 	0.522 	0.210 	0.048
[[ 13 283]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.04      0.08       296
        1.0       0.01      1.00      0.03         4

avg / total       0.99      0.06      0.08       300


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features=0.75, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=50, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.243 	0.064 	0.008 	0.617 	0.483 	0.251
[[ 69 227]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.23      0.38       296
        1.0       0.02      1.00      0.03         4

avg / total       0.99      0.24      0.37       300


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	0.000 	0.000 	0.500 	0.000 	0.000
[[296   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       296
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       300


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=1.0, n_estimators=50, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.280 	0.070 	0.010 	0.635 	0.520 	0.290
[[ 80 216]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.27      0.43       296
        1.0       0.02      1.00      0.04         4

avg / total       0.99      0.28      0.42       300


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.013 	0.000 	0.000 	0.500 	0.000 	0.000
[[  0 296]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       0.00      0.00      0.00       296
        1.0       0.01      1.00      0.03         4

avg / total       0.00      0.01      0.00       300


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...owski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='uniform'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.397 	-0.025 	-0.005 	0.448 	0.445 	0.200
[[117 179]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.98      0.40      0.56       296
        1.0       0.01      0.50      0.02         4

avg / total       0.97      0.40      0.56       300


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=3, p=1,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.707 	0.053 	0.018 	0.605 	0.596 	0.347
[[210  86]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      0.71      0.83       296
        1.0       0.02      0.50      0.04         4

avg / total       0.98      0.71      0.82       300


                estimator min_score mean_score max_score   sd_score  \
6      AdaBoostClassifier  0.222222     0.7065         1   0.177305   
4  RandomForestClassifier  0.589933   0.899093         1  0.0930892   
1      LogisticRegression         0   0.404914  0.701045   0.236573   
9    KNeighborsClassifier -0.145489   0.432206  0.794967   0.240686   
2           SGDClassifier   -0.5132   0.436465  0.906078   0.244328   
3    ExtraTreesClassifier  0.794967   0.906001         1  0.0377611   
0              GaussianNB  0.888889   0.888889  0.888889          0   
5           MLPClassifier  0.683856   0.746854  0.906078  0.0509702   
7                     SVC         0   0.608429         1   0.370532   
8        VotingClassifier  0.649478   0.731882         1  0.0957724   

         acc       auc           conf_matrix      f1_c0      f1_c1  \
6       0.28  0.635135   [[80, 216], [0, 4]]   0.425532  0.0357143   
4   0.243333  0.616554   [[69, 227], [0, 4]]   0.378082  0.0340426   
1   0.466667  0.606419  [[137, 159], [1, 3]]   0.631336  0.0361446   
9   0.706667   0.60473   [[210, 86], [2, 2]]   0.826772  0.0434783   
2   0.453333  0.599662  [[133, 163], [1, 3]]   0.618605  0.0352941   
3  0.0566667  0.521959   [[13, 283], [0, 4]]  0.0841424  0.0274914   
0   0.986667       0.5    [[296, 0], [4, 0]]   0.993289          0   
5   0.986667       0.5    [[296, 0], [4, 0]]   0.993289          0   
7  0.0133333       0.5    [[0, 296], [0, 4]]          0  0.0263158   
8   0.396667  0.447635  [[117, 179], [2, 2]]   0.563855  0.0216216   

        kappa model_score   prec_c0    prec_c1     rec_c0 rec_c1  
6  0.00977995      0.0701         1  0.0181818    0.27027      1  
4  0.00804055   0.0635335         1   0.017316   0.233108      1  
1   0.0103909    0.048981  0.992754  0.0185185   0.462838   0.75  
9   0.0184414   0.0527675  0.990566  0.0227273   0.709459    0.5  
2  0.00950234   0.0459864  0.992537  0.0180723   0.449324   0.75  
3  0.00122347   0.0247409         1  0.0139373  0.0439189      1  
0           0           0  0.986667          0          1      0  
5           0           0  0.986667          0          1      0  
7           0           0         0  0.0133333          0      1  
8 -0.00458817  -0.0245546  0.983193  0.0110497    0.39527    0.5  
Elapsed time 19.09 mins 

************************************************************







Standard, lagged (3,4)x2, filter(tukey), None, truncated








    pca = [0]
    poly = [2]
    ksel = [80]
    imb = [None, SMOTE(), ClusterCentroids() ]
	
	
	
	








pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv 
datetime: 2017-05-09 07:08:51.509000 
pca_target: 0 	 poly degree: 2 	 kselect: 80 
Imbalance: None 
Extended target (count):  25141 325
('Total : Processed (count): ', (998L, 24976L), 13)
Final feature (count):  (998L, 24976L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.873 	0.047 	0.027 	0.566 	0.470 	0.207
[[261  35]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.88      0.93       296
        1.0       0.03      0.25      0.05         4

avg / total       0.98      0.87      0.92       300


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.001, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='sag', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.940 	-0.026 	-0.021 	0.476 	0.000 	0.000
[[282  14]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.95      0.97       296
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.94      0.96       300


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.5, average=False, class_weight={1: 15}, epsilon=0.1,
       eta0=0.001, fit_intercept=True, l1_ratio=0.15,
       learning_rate='invscaling', loss='perceptron', n_iter=5, n_jobs=4,
       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.803 	0.089 	0.040 	0.654 	0.635 	0.391
[[239  57]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      0.81      0.89       296
        1.0       0.03      0.50      0.06         4

avg / total       0.98      0.80      0.88       300


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 50}, criterion='gini',
           max_depth=16, max_features=0.75, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=30, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.980 	-0.010 	-0.009 	0.497 	0.000 	0.000
[[294   2]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       296
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.98       300


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 500},
            criterion='gini', max_depth=8, max_features=0.33,
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=15, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.973 	-0.014 	-0.014 	0.493 	0.000 	0.000
[[292   4]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       296
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.97      0.97       300


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.5, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(500,), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	0.000 	0.000 	0.500 	0.000 	0.000
[[296   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       296
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       300


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 50}, criterion='gini', max_depth=32,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=0.5, n_estimators=80, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.963 	-0.018 	-0.017 	0.488 	0.000 	0.000
[[289   7]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.98      0.98       296
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.96      0.97       300


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.1, cache_size=200, class_weight={1: 50}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.963 	0.150 	0.138 	0.611 	0.493 	0.226
[[288   8]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.97      0.98       296
        1.0       0.11      0.25      0.15         4

avg / total       0.98      0.96      0.97       300


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	0.000 	0.000 	0.500 	0.000 	0.000
[[296   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       296
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       300


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=1,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.970 	-0.015 	-0.015 	0.492 	0.000 	0.000
[[291   5]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.98      0.98       296
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.97      0.97       300


                estimator  min_score   mean_score   max_score    sd_score  \
2           SGDClassifier  -0.278793    0.0280981    0.210929   0.0476425   
7                     SVC  -0.116351      -0.0192    0.096565   0.0424956   
0              GaussianNB   0.113616     0.113616    0.113616           0   
5           MLPClassifier -0.0200473   -0.0126905 -0.00434998  0.00390876   
8        VotingClassifier  -0.012878  -0.00296945           0  0.00385966   
3    ExtraTreesClassifier -0.0152946  0.000437195    0.137742   0.0170806   
4  RandomForestClassifier  -0.017236 -0.000656063   0.0381392  0.00267419   
9    KNeighborsClassifier -0.0167781  0.000735388   0.0692234   0.0187384   
6      AdaBoostClassifier -0.0217474  -0.00234036    0.191985   0.0276393   
1      LogisticRegression  -0.128986  -0.00204433    0.191807   0.0537551   

        acc       auc          conf_matrix     f1_c0      f1_c1       kappa  \
2  0.803333  0.653716  [[239, 57], [2, 2]]   0.89013  0.0634921   0.0395051   
7  0.963333  0.611486   [[288, 8], [3, 1]]  0.981261   0.153846    0.137931   
0  0.873333  0.565878  [[261, 35], [3, 1]]  0.932143       0.05   0.0266393   
5  0.986667       0.5   [[296, 0], [4, 0]]  0.993289          0           0   
8  0.986667       0.5   [[296, 0], [4, 0]]  0.993289          0           0   
3      0.98  0.496622   [[294, 2], [4, 0]]  0.989899          0 -0.00896861   
4  0.973333  0.493243   [[292, 4], [4, 0]]  0.986486          0  -0.0135135   
9      0.97  0.491554   [[291, 5], [4, 0]]  0.984772          0  -0.0150376   
6  0.963333  0.488176   [[289, 7], [4, 0]]  0.981324          0  -0.0172626   
1      0.94  0.476351  [[282, 14], [4, 0]]  0.969072          0    -0.02118   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
2   0.0887138  0.991701  0.0338983  0.807432    0.5  
7     0.14992  0.989691   0.111111  0.972973   0.25  
0   0.0465046  0.988636  0.0277778  0.881757   0.25  
5           0  0.986667          0         1      0  
8           0  0.986667          0         1      0  
3 -0.00952338  0.986577          0  0.993243      0  
4  -0.0135135  0.986486          0  0.986486      0  
9  -0.0151342  0.986441          0  0.983108      0  
6   -0.017968  0.986348          0  0.976351      0  
1  -0.0257197  0.986014          0  0.952703      0  
Elapsed time 28.06 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv 
datetime: 2017-05-09 07:36:55.237000 
pca_target: 0 	 poly degree: 2 	 kselect: 80 
Imbalance: SMOTE(k=None, k_neighbors=5, kind='regular', m=None, m_neighbors=10, n_jobs=1,
   out_step=0.5, random_state=None, ratio='auto', svm_estimator=None) 
Extended target (count):  25141 325
('Total : Processed (count): ', (998L, 24976L), 13)
Final feature (count):  (998L, 24976L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.790 	0.150 	0.063 	0.770 	0.770 	0.591
[[234  62]
 [  1   3]]
             precision    recall  f1-score   support

        0.0       1.00      0.79      0.88       296
        1.0       0.05      0.75      0.09         4

avg / total       0.98      0.79      0.87       300


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=10, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=5, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.930 	0.196 	0.141 	0.718 	0.684 	0.448
[[277  19]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      0.94      0.96       296
        1.0       0.10      0.50      0.16         4

avg / total       0.98      0.93      0.95       300


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.001, average=False, class_weight='balanced',
       epsilon=0.1, eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='invscaling', loss='modified_huber', n_iter=5,
       n_jobs=4, penalty='l1', power_t=0.5, random_state=None,
       shuffle=True, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.907 	0.252 	0.157 	0.829 	0.826 	0.671
[[269  27]
 [  1   3]]
             precision    recall  f1-score   support

        0.0       1.00      0.91      0.95       296
        1.0       0.10      0.75      0.18         4

avg / total       0.98      0.91      0.94       300


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 50},
           criterion='entropy', max_depth=None, max_features=0.75,
           max_leaf_nodes=None, min_impurity_split=1e-07,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=4,
           oob_score=False, random_state=None, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.963 	-0.018 	-0.017 	0.488 	0.000 	0.000
[[289   7]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.98      0.98       296
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.96      0.97       300


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 500},
            criterion='entropy', max_depth=None, max_features=0.33,
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.953 	0.125 	0.107 	0.606 	0.491 	0.224
[[285  11]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.96      0.98       296
        1.0       0.08      0.25      0.12         4

avg / total       0.98      0.95      0.96       300


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.1, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.970 	-0.015 	-0.015 	0.492 	0.000 	0.000
[[291   5]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.98      0.98       296
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.97      0.97       300


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='entropy', max_depth=8,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=1.0, n_estimators=80, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.950 	0.118 	0.099 	0.605 	0.490 	0.223
[[284  12]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.96      0.97       296
        1.0       0.08      0.25      0.12         4

avg / total       0.98      0.95      0.96       300


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=10, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.967 	-0.017 	-0.016 	0.490 	0.000 	0.000
[[290   6]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.98      0.98       296
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.97      0.97       300


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=10.0, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', ...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.950 	0.118 	0.099 	0.605 	0.490 	0.223
[[284  12]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.96      0.97       296
        1.0       0.08      0.25      0.12         4

avg / total       0.98      0.95      0.96       300


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=3,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.920 	0.079 	0.056 	0.590 	0.482 	0.216
[[275  21]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.93      0.96       296
        1.0       0.05      0.25      0.08         4

avg / total       0.98      0.92      0.95       300


                estimator min_score mean_score max_score    sd_score  \
2           SGDClassifier -0.128434   0.544457  0.888238    0.221231   
0              GaussianNB  0.545471   0.545471  0.545471           0   
1      LogisticRegression  0.414012   0.743734  0.932844     0.12939   
4  RandomForestClassifier  0.767232   0.922189  0.962959   0.0459708   
6      AdaBoostClassifier  0.738481    0.91503  0.968553   0.0337668   
8        VotingClassifier  0.846364   0.913326  0.953372   0.0251787   
9    KNeighborsClassifier  0.842956   0.890274  0.931328   0.0291338   
5           MLPClassifier  0.962954   0.969976   0.97851  0.00500502   
7                     SVC         0   0.780458   0.97848    0.207857   
3    ExtraTreesClassifier  0.616044   0.906387  0.969718   0.0826318   

        acc       auc          conf_matrix     f1_c0      f1_c1      kappa  \
2  0.906667  0.829392  [[269, 27], [1, 3]]   0.95053   0.176471   0.156627   
0      0.79   0.77027  [[234, 62], [1, 3]]  0.881356  0.0869565  0.0634291   
1      0.93  0.717905  [[277, 19], [2, 2]]  0.963478       0.16   0.140753   
4  0.953333  0.606419  [[285, 11], [3, 1]]  0.976027      0.125   0.107143   
6      0.95   0.60473  [[284, 12], [3, 1]]  0.974271   0.117647  0.0992794   
8      0.95   0.60473  [[284, 12], [3, 1]]  0.974271   0.117647  0.0992794   
9      0.92  0.589527  [[275, 21], [3, 1]]  0.958188  0.0769231  0.0556139   
5      0.97  0.491554   [[291, 5], [4, 0]]  0.984772          0 -0.0150376   
7  0.966667  0.489865   [[290, 6], [4, 0]]  0.983051          0 -0.0162602   
3  0.963333  0.488176   [[289, 7], [4, 0]]  0.981324          0 -0.0172626   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
2     0.25187  0.996296        0.1  0.908784   0.75  
0    0.150492  0.995745  0.0461538  0.790541   0.75  
1    0.195912  0.992832  0.0952381  0.935811    0.5  
4    0.124577  0.989583  0.0833333  0.962838   0.25  
6    0.117995  0.989547  0.0769231  0.959459   0.25  
8    0.117995  0.989547  0.0769231  0.959459   0.25  
9   0.0787819  0.989209  0.0454545  0.929054   0.25  
5  -0.0151342  0.986441          0  0.983108      0  
7  -0.0166068  0.986395          0   0.97973      0  
3   -0.017968  0.986348          0  0.976351      0  
Elapsed time 50.36 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv 
datetime: 2017-05-09 08:27:16.626000 
pca_target: 0 	 poly degree: 2 	 kselect: 80 
Imbalance: ClusterCentroids(estimator=None, n_jobs=1, random_state=None, ratio='auto') 
Extended target (count):  25141 325
('Total : Processed (count): ', (998L, 24976L), 13)
Final feature (count):  (998L, 24976L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.140 	-0.040 	-0.004 	0.441 	0.314 	0.105
[[ 39 257]
 [  1   3]]
             precision    recall  f1-score   support

        0.0       0.97      0.13      0.23       296
        1.0       0.01      0.75      0.02         4

avg / total       0.96      0.14      0.23       300


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=10, class_weight={1: 3}, dual=False, fit_intercept=True,
          intercept_scaling=0.1, max_iter=100, multi_class='ovr', n_jobs=4,
          penalty='l2', random_state=None, solver='sag', tol=0.0001,
          verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.560 	0.128 	0.032 	0.777 	0.744 	0.579
[[164 132]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.55      0.71       296
        1.0       0.03      1.00      0.06         4

avg / total       0.99      0.56      0.70       300


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.5, average=False, class_weight='balanced', epsilon=0.1,
       eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='perceptron', n_iter=5, n_jobs=4,
       penalty='l2', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.280 	-0.180 	-0.027 	0.142 	0.000 	0.000
[[ 84 212]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.95      0.28      0.44       296
        1.0       0.00      0.00      0.00         4

avg / total       0.94      0.28      0.43       300


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=8, max_features='auto', max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.237 	-0.006 	-0.001 	0.490 	0.415 	0.181
[[ 68 228]
 [  1   3]]
             precision    recall  f1-score   support

        0.0       0.99      0.23      0.37       296
        1.0       0.01      0.75      0.03         4

avg / total       0.97      0.24      0.37       300


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features=0.75, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.327 	0.079 	0.012 	0.659 	0.564 	0.339
[[ 94 202]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.32      0.48       296
        1.0       0.02      1.00      0.04         4

avg / total       0.99      0.33      0.48       300


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.470 	0.107 	0.022 	0.731 	0.680 	0.488
[[137 159]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.46      0.63       296
        1.0       0.02      1.00      0.05         4

avg / total       0.99      0.47      0.62       300


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=0.5, n_estimators=80, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.320 	0.077 	0.012 	0.655 	0.558 	0.332
[[ 92 204]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.31      0.47       296
        1.0       0.02      1.00      0.04         4

avg / total       0.99      0.32      0.47       300


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.5, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.100 	-0.063 	-0.005 	0.421 	0.262 	0.073
[[ 27 269]
 [  1   3]]
             precision    recall  f1-score   support

        0.0       0.96      0.09      0.17       296
        1.0       0.01      0.75      0.02         4

avg / total       0.95      0.10      0.16       300


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 500}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Ran...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.453 	0.046 	0.010 	0.600 	0.581 	0.347
[[133 163]
 [  1   3]]
             precision    recall  f1-score   support

        0.0       0.99      0.45      0.62       296
        1.0       0.02      0.75      0.04         4

avg / total       0.98      0.45      0.61       300


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=2,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.383 	-0.028 	-0.005 	0.441 	0.437 	0.193
[[113 183]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.98      0.38      0.55       296
        1.0       0.01      0.50      0.02         4

avg / total       0.97      0.38      0.54       300


                estimator min_score mean_score max_score     sd_score  \
1      LogisticRegression         0   0.573442         1     0.323808   
5           MLPClassifier  0.777778   0.859257  0.906078    0.0542258   
4  RandomForestClassifier  0.607122   0.904767         1     0.102821   
6      AdaBoostClassifier    0.1283   0.701668         1     0.191027   
8        VotingClassifier  0.589933     0.7035  0.812156    0.0451886   
3    ExtraTreesClassifier  0.812156   0.812156  0.812156  2.22045e-16   
0              GaussianNB  0.794967   0.794967  0.794967            0   
9    KNeighborsClassifier  0.478822   0.695776  0.812156    0.0956474   
7                     SVC         0   0.354164  0.812156     0.243303   
2           SGDClassifier   -0.1283   0.543192  0.812156     0.204872   

        acc       auc           conf_matrix     f1_c0      f1_c1        kappa  \
1      0.56  0.777027  [[164, 132], [0, 4]]  0.713043  0.0571429    0.0320688   
5      0.47  0.731419  [[137, 159], [0, 4]]  0.632794  0.0479042    0.0224609   
4  0.326667  0.658784   [[94, 202], [0, 4]]  0.482051  0.0380952    0.0122571   
6      0.32  0.655405   [[92, 204], [0, 4]]  0.474227  0.0377358    0.0118832   
8  0.453333  0.599662  [[133, 163], [1, 3]]  0.618605  0.0352941   0.00950234   
3  0.236667  0.489865   [[68, 228], [1, 3]]  0.372603  0.0255319 -0.000699178   
0      0.14  0.440878   [[39, 257], [1, 3]]  0.232143  0.0227273  -0.00363071   
9  0.383333  0.440878  [[113, 183], [2, 2]]  0.549878   0.021164  -0.00507063   
7       0.1  0.420608   [[27, 269], [1, 3]]  0.166667  0.0217391  -0.00466362   
2      0.28  0.141892   [[84, 212], [4, 0]]    0.4375          0   -0.0268763   

  model_score   prec_c0    prec_c1     rec_c0 rec_c1  
1    0.127655         1  0.0294118   0.554054      1  
5    0.106574         1  0.0245399   0.462838      1  
4   0.0785262         1  0.0194175   0.317568      1  
6   0.0773119         1  0.0192308   0.310811      1  
8   0.0459864  0.992537  0.0180723   0.449324   0.75  
3 -0.00552465  0.985507   0.012987    0.22973   0.75  
0  -0.0398966     0.975  0.0115385   0.131757   0.75  
9  -0.0278944  0.982609  0.0108108   0.381757    0.5  
7  -0.0626064  0.964286  0.0110294  0.0912162   0.75  
2   -0.180431  0.954545          0   0.283784      0  
Elapsed time 19.06 mins 

************************************************************







Standard, lagged (3,4)x2, filter(tukey), None, truncated







    pca = [0]
    poly = [0]
    ksel = [40, 80]
    imb = [None, SMOTE(), ClusterCentroids() ]
	
	
	

	

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv 
datetime: 2017-05-09 09:29:29.804000 
pca_target: 0 	 poly degree: 0 	 kselect: 40 
Imbalance: None 
Extended target (count):  25141 325
('Total : Processed (count): ', (998L, 222L), 13)
Final feature (count):  (998L, 222L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.743 	0.128 	0.048 	0.747 	0.747 	0.558
[[220  76]
 [  1   3]]
             precision    recall  f1-score   support

        0.0       1.00      0.74      0.85       296
        1.0       0.04      0.75      0.07         4

avg / total       0.98      0.74      0.84       300


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.001, class_weight={1: 50}, dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.853 	0.116 	0.060 	0.679 	0.655 	0.414
[[254  42]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      0.86      0.92       296
        1.0       0.05      0.50      0.08         4

avg / total       0.98      0.85      0.91       300


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.1, average=False, class_weight={1: 50}, epsilon=0.1,
       eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='constant', loss='squared_hinge', n_iter=5, n_jobs=4,
       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.560 	0.128 	0.032 	0.777 	0.744 	0.579
[[164 132]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.55      0.71       296
        1.0       0.03      1.00      0.06         4

avg / total       0.99      0.56      0.70       300


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 50}, criterion='gini',
           max_depth=8, max_features='auto', max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=30, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.980 	-0.010 	-0.009 	0.497 	0.000 	0.000
[[294   2]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       296
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.98       300


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 500},
            criterion='gini', max_depth=8, max_features=0.33,
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=15, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.983 	-0.007 	-0.005 	0.498 	0.000 	0.000
[[295   1]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       296
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.98       300


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.5, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(500,), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.990 	0.497 	0.397 	0.625 	0.500 	0.231
[[296   0]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       296
        1.0       1.00      0.25      0.40         4

avg / total       0.99      0.99      0.99       300


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight='balanced', criterion='gini', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=2.0, n_estimators=15, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.970 	-0.015 	-0.015 	0.492 	0.000 	0.000
[[291   5]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.98      0.98       296
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.97      0.97       300


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.1, cache_size=200, class_weight={1: 50}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.963 	0.150 	0.138 	0.611 	0.493 	0.226
[[288   8]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.97      0.98       296
        1.0       0.11      0.25      0.15         4

avg / total       0.98      0.96      0.97       300


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', R...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	0.000 	0.000 	0.500 	0.000 	0.000
[[296   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       296
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       300


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=3,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.973 	0.191 	0.187 	0.617 	0.496 	0.228
[[291   5]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.98      0.99       296
        1.0       0.17      0.25      0.20         4

avg / total       0.98      0.97      0.98       300


                estimator   min_score   mean_score   max_score    sd_score  \
2           SGDClassifier   -0.221897    0.0213853    0.171339   0.0378561   
0              GaussianNB   0.0360894    0.0360894   0.0360894           0   
1      LogisticRegression  -0.0627924   0.00905397    0.138772   0.0428232   
5           MLPClassifier   -0.017018  -0.00984408 -0.00349117   0.0030001   
9    KNeighborsClassifier -0.00349117    0.0422181    0.232275   0.0786555   
7                     SVC  -0.0420946  -0.00317333    0.146212   0.0329421   
8        VotingClassifier -0.00952097   0.00676205    0.141315   0.0315432   
4  RandomForestClassifier  -0.0202531 -0.000508022   0.0400653  0.00275329   
3    ExtraTreesClassifier  -0.0123162   0.00309576    0.141315   0.0197492   
6      AdaBoostClassifier   -0.020807  -0.00205001    0.206123   0.0263763   

        acc       auc           conf_matrix     f1_c0      f1_c1       kappa  \
2      0.56  0.777027  [[164, 132], [0, 4]]  0.713043  0.0571429   0.0320688   
0  0.743333  0.746622   [[220, 76], [1, 3]]  0.851064  0.0722892   0.0481292   
1  0.853333  0.679054   [[254, 42], [2, 2]]   0.92029  0.0833333   0.0603645   
5      0.99     0.625    [[296, 0], [3, 1]]  0.994958        0.4    0.396783   
9  0.973333  0.616554    [[291, 5], [3, 1]]  0.986441        0.2    0.186992   
7  0.963333  0.611486    [[288, 8], [3, 1]]  0.981261   0.153846    0.137931   
8  0.986667       0.5    [[296, 0], [4, 0]]  0.993289          0           0   
4  0.983333  0.498311    [[295, 1], [4, 0]]  0.991597          0 -0.00536193   
3      0.98  0.496622    [[294, 2], [4, 0]]  0.989899          0 -0.00896861   
6      0.97  0.491554    [[291, 5], [4, 0]]  0.984772          0  -0.0150376   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
2    0.127655         1  0.0294118  0.554054      1  
0    0.128448  0.995475  0.0379747  0.743243   0.75  
1    0.116103  0.992188  0.0454545  0.858108    0.5  
5    0.497485  0.989967          1         1   0.25  
9    0.190978  0.989796   0.166667  0.983108   0.25  
7     0.14992  0.989691   0.111111  0.972973   0.25  
8           0  0.986667          0         1      0  
4 -0.00672277  0.986622          0  0.996622      0  
3 -0.00952338  0.986577          0  0.993243      0  
6  -0.0151342  0.986441          0  0.983108      0  
Elapsed time 21.99 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv 
datetime: 2017-05-09 09:51:29.320000 
pca_target: 0 	 poly degree: 0 	 kselect: 40 
Imbalance: SMOTE(k=None, k_neighbors=5, kind='regular', m=None, m_neighbors=10, n_jobs=1,
   out_step=0.5, random_state=None, ratio='auto', svm_estimator=None) 
Extended target (count):  25141 325
('Total : Processed (count): ', (998L, 222L), 13)
Final feature (count):  (998L, 222L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.627 	0.146 	0.042 	0.811 	0.788 	0.645
[[184 112]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.62      0.77       296
        1.0       0.03      1.00      0.07         4

avg / total       0.99      0.63      0.76       300


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=10, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.877 	0.214 	0.118 	0.814 	0.812 	0.650
[[260  36]
 [  1   3]]
             precision    recall  f1-score   support

        0.0       1.00      0.88      0.93       296
        1.0       0.08      0.75      0.14         4

avg / total       0.98      0.88      0.92       300


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=1, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='invscaling', loss='modified_huber', n_iter=5,
       n_jobs=4, penalty='none', power_t=0.5, random_state=None,
       shuffle=True, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.803 	0.158 	0.069 	0.777 	0.777 	0.600
[[238  58]
 [  1   3]]
             precision    recall  f1-score   support

        0.0       1.00      0.80      0.89       296
        1.0       0.05      0.75      0.09         4

avg / total       0.98      0.80      0.88       300


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 500},
           criterion='entropy', max_depth=None, max_features=0.33,
           max_leaf_nodes=None, min_impurity_split=1e-07,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=4,
           oob_score=False, random_state=None, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	0.348 	0.327 	0.623 	0.499 	0.231
[[295   1]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       296
        1.0       0.50      0.25      0.33         4

avg / total       0.98      0.99      0.98       300


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight='balanced',
            criterion='entropy', max_depth=16, max_features='auto',
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.980 	-0.010 	-0.009 	0.497 	0.000 	0.000
[[294   2]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       296
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.98       300


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.1, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(500,), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.973 	0.342 	0.321 	0.740 	0.700 	0.466
[[290   6]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      0.98      0.99       296
        1.0       0.25      0.50      0.33         4

avg / total       0.98      0.97      0.98       300


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 50}, criterion='gini', max_depth=8,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=1.0, n_estimators=50, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.990 	0.572 	0.566 	0.748 	0.706 	0.474
[[295   1]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       296
        1.0       0.67      0.50      0.57         4

avg / total       0.99      0.99      0.99       300


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.5, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	0.000 	0.000 	0.500 	0.000 	0.000
[[296   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       296
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       300


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=10.0, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', ...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.960 	0.273 	0.235 	0.733 	0.695 	0.461
[[286  10]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      0.97      0.98       296
        1.0       0.17      0.50      0.25         4

avg / total       0.98      0.96      0.97       300


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=3,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.930 	0.089 	0.066 	0.595 	0.485 	0.219
[[278  18]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.94      0.96       296
        1.0       0.05      0.25      0.09         4

avg / total       0.98      0.93      0.95       300


                estimator min_score mean_score max_score   sd_score       acc  \
1      LogisticRegression         0   0.638272  0.869347   0.181188  0.876667   
0              GaussianNB  0.535891   0.535891  0.535891          0  0.626667   
2           SGDClassifier -0.274543   0.468409  0.785962   0.210845  0.803333   
6      AdaBoostClassifier  0.833054   0.950232  0.994226  0.0277319      0.99   
5           MLPClassifier  0.953216   0.967027   0.97855  0.0071791  0.973333   
8        VotingClassifier   0.84759   0.911781  0.949032  0.0229879      0.96   
3    ExtraTreesClassifier  0.545437   0.924499  0.991344  0.0995954  0.986667   
9    KNeighborsClassifier  0.820836   0.873732  0.928405  0.0331862      0.93   
7                     SVC         0   0.740524   0.99281   0.245819  0.986667   
4  RandomForestClassifier  0.747512   0.935303   0.98842  0.0567032      0.98   

        auc           conf_matrix     f1_c0      f1_c1       kappa  \
1  0.814189   [[260, 36], [1, 3]]  0.933573   0.139535    0.118208   
0  0.810811  [[184, 112], [0, 4]]  0.766667  0.0666667   0.0419708   
2  0.777027   [[238, 58], [1, 3]]   0.88972  0.0923077    0.069009   
6  0.748311    [[295, 1], [2, 2]]  0.994941   0.571429    0.566474   
5  0.739865    [[290, 6], [2, 2]]  0.986395   0.333333    0.321267   
8  0.733108   [[286, 10], [2, 2]]  0.979452       0.25    0.234694   
3  0.623311    [[295, 1], [3, 1]]  0.993266   0.333333    0.327354   
9  0.594595   [[278, 18], [3, 1]]  0.963605  0.0869565     0.06639   
7       0.5    [[296, 0], [4, 0]]  0.993289          0           0   
4  0.496622    [[294, 2], [4, 0]]  0.989899          0 -0.00896861   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
1    0.214311  0.996169  0.0769231  0.878378   0.75  
0    0.146408         1  0.0344828  0.621622      1  
2    0.157893  0.995816  0.0491803  0.804054   0.75  
6    0.572483  0.993266   0.666667  0.996622    0.5  
5    0.341536  0.993151       0.25   0.97973    0.5  
8    0.272883  0.993056   0.166667  0.966216    0.5  
3    0.347603  0.989933        0.5  0.996622   0.25  
9   0.0890927  0.989324  0.0526316  0.939189   0.25  
7           0  0.986667          0         1      0  
4 -0.00952338  0.986577          0  0.993243      0  
Elapsed time 42.17 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv 
datetime: 2017-05-09 10:33:39.304000 
pca_target: 0 	 poly degree: 0 	 kselect: 40 
Imbalance: ClusterCentroids(estimator=None, n_jobs=1, random_state=None, ratio='auto') 
Extended target (count):  25141 325
('Total : Processed (count): ', (998L, 222L), 13)
Final feature (count):  (998L, 222L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.533 	0.121 	0.029 	0.764 	0.726 	0.552
[[156 140]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.53      0.69       296
        1.0       0.03      1.00      0.05         4

avg / total       0.99      0.53      0.68       300


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=5, class_weight={1: 3}, dual=False, fit_intercept=True,
          intercept_scaling=0.1, max_iter=100, multi_class='ovr', n_jobs=4,
          penalty='l2', random_state=None, solver='lbfgs', tol=0.0001,
          verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.767 	0.139 	0.055 	0.758 	0.758 	0.574
[[227  69]
 [  1   3]]
             precision    recall  f1-score   support

        0.0       1.00      0.77      0.87       296
        1.0       0.04      0.75      0.08         4

avg / total       0.98      0.77      0.86       300


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.0001, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='perceptron', n_iter=5, n_jobs=4,
       penalty='l2', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.570 	0.130 	0.033 	0.782 	0.751 	0.589
[[167 129]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.56      0.72       296
        1.0       0.03      1.00      0.06         4

avg / total       0.99      0.57      0.71       300


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight='balanced',
           criterion='gini', max_depth=32, max_features=0.75,
           max_leaf_nodes=None, min_impurity_split=1e-07,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=4,
           oob_score=False, random_state=None, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.467 	0.106 	0.022 	0.730 	0.678 	0.484
[[136 160]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.46      0.63       296
        1.0       0.02      1.00      0.05         4

avg / total       0.99      0.47      0.62       300


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 50}, criterion='gini',
            max_depth=8, max_features=0.75, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.517 	0.117 	0.027 	0.755 	0.714 	0.535
[[151 145]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.51      0.68       296
        1.0       0.03      1.00      0.05         4

avg / total       0.99      0.52      0.67       300


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.1, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.807 	0.019 	0.009 	0.532 	0.451 	0.192
[[241  55]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.81      0.89       296
        1.0       0.02      0.25      0.03         4

avg / total       0.97      0.81      0.88       300


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 500}, criterion='gini', max_depth=8,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=0.5, n_estimators=80, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.427 	0.098 	0.019 	0.709 	0.647 	0.443
[[124 172]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.42      0.59       296
        1.0       0.02      1.00      0.04         4

avg / total       0.99      0.43      0.58       300


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=10, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.577 	0.075 	0.020 	0.662 	0.656 	0.438
[[170 126]
 [  1   3]]
             precision    recall  f1-score   support

        0.0       0.99      0.57      0.73       296
        1.0       0.02      0.75      0.05         4

avg / total       0.98      0.58      0.72       300


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=1.0, class_weight={1: 500}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Ran...owski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='uniform'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.630 	0.147 	0.043 	0.812 	0.791 	0.648
[[185 111]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.62      0.77       296
        1.0       0.03      1.00      0.07         4

avg / total       0.99      0.63      0.76       300


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=5, p=1,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.763 	0.006 	0.002 	0.510 	0.439 	0.183
[[228  68]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.77      0.87       296
        1.0       0.01      0.25      0.03         4

avg / total       0.97      0.76      0.85       300


                estimator min_score mean_score max_score   sd_score       acc  \
8        VotingClassifier  0.239411   0.493336  0.718234  0.0971737      0.63   
2           SGDClassifier -0.461633   0.248076  0.812156   0.154045      0.57   
0              GaussianNB  0.666667   0.666667  0.666667          0  0.533333   
1      LogisticRegression -0.145489   0.183426  0.589933     0.1773  0.766667   
4  RandomForestClassifier    0.1283   0.611441         1   0.157942  0.516667   
3    ExtraTreesClassifier  0.222222   0.530554  0.906078   0.104291  0.466667   
6      AdaBoostClassifier         0   0.514219  0.906078   0.174234  0.426667   
7                     SVC         0   0.303883  0.607122    0.20667  0.576667   
5           MLPClassifier  0.239411   0.489924  0.589933  0.0762752  0.806667   
9    KNeighborsClassifier         0   0.183664  0.367711   0.127665  0.763333   

        auc           conf_matrix     f1_c0      f1_c1       kappa  \
8    0.8125  [[185, 111], [0, 4]]  0.769231  0.0672269   0.0425532   
2  0.782095  [[167, 129], [0, 4]]  0.721382  0.0583942     0.03337   
0  0.763514  [[156, 140], [0, 4]]  0.690265  0.0540541   0.0288568   
1  0.758446   [[227, 69], [1, 3]]  0.866412  0.0789474   0.0550756   
4  0.755068  [[151, 145], [0, 4]]  0.675615  0.0522876   0.0270198   
3   0.72973  [[136, 160], [0, 4]]   0.62963   0.047619   0.0221643   
6  0.709459  [[124, 172], [0, 4]]  0.590476  0.0444444   0.0188622   
7  0.662162  [[170, 126], [1, 3]]  0.728051  0.0451128   0.0197592   
5  0.532095   [[241, 55], [3, 1]]  0.892593  0.0333333  0.00865998   
9  0.510135   [[228, 68], [3, 1]]  0.865275  0.0273973  0.00224845   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
8    0.147442         1  0.0347826     0.625      1  
2    0.130262         1  0.0300752  0.564189      1  
0    0.120994         1  0.0277778  0.527027      1  
1    0.138817  0.995614  0.0416667  0.766892   0.75  
4    0.117025         1  0.0268456  0.510135      1  
3     0.10586         1  0.0243902  0.459459      1  
6    0.097575         1  0.0227273  0.418919      1  
7   0.0751385  0.994152  0.0232558  0.574324   0.75  
5   0.0188951  0.987705  0.0178571  0.814189   0.25  
9  0.00552465  0.987013  0.0144928   0.77027   0.25  
Elapsed time 14.17 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv 
datetime: 2017-05-09 10:47:49.358000 
pca_target: 0 	 poly degree: 0 	 kselect: 80 
Imbalance: None 
Extended target (count):  25141 325
('Total : Processed (count): ', (998L, 222L), 13)
Final feature (count):  (998L, 222L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.710 	0.176 	0.060 	0.853 	0.840 	0.727
[[209  87]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.71      0.83       296
        1.0       0.04      1.00      0.08         4

avg / total       0.99      0.71      0.82       300


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.01, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=10, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='sag', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.793 	0.084 	0.036 	0.649 	0.631 	0.387
[[236  60]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      0.80      0.88       296
        1.0       0.03      0.50      0.06         4

avg / total       0.98      0.79      0.87       300


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.001, average=False, class_weight={1: 15}, epsilon=0.1,
       eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='constant', loss='modified_huber', n_iter=5, n_jobs=4,
       penalty='l2', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.930 	-0.028 	-0.022 	0.471 	0.000 	0.000
[[279  17]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.94      0.96       296
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.93      0.95       300


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight='balanced',
           criterion='gini', max_depth=8, max_features=0.75,
           max_leaf_nodes=None, min_impurity_split=1e-07,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=4,
           oob_score=False, random_state=None, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.983 	-0.007 	-0.005 	0.498 	0.000 	0.000
[[295   1]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       296
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.98       300


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	0.000 	0.000 	0.500 	0.000 	0.000
[[296   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       296
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       300


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.5, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(500,), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.983 	-0.007 	-0.005 	0.498 	0.000 	0.000
[[295   1]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       296
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.98       300


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight='balanced', criterion='gini', max_depth=8,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=2.0, n_estimators=15, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.963 	-0.018 	-0.017 	0.488 	0.000 	0.000
[[289   7]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.98      0.98       296
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.96      0.97       300


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.447 	0.102 	0.020 	0.720 	0.663 	0.464
[[130 166]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.44      0.61       296
        1.0       0.02      1.00      0.05         4

avg / total       0.99      0.45      0.60       300


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	0.000 	0.000 	0.500 	0.000 	0.000
[[296   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       296
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       300


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=1,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	0.000 	0.000 	0.500 	0.000 	0.000
[[296   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       296
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       300


                estimator   min_score   mean_score   max_score     sd_score  \
0              GaussianNB  0.00487843   0.00487843  0.00487843            0   
7                     SVC  -0.0285133   -0.0016994   0.0687354    0.0190485   
1      LogisticRegression   -0.108963    0.0221717    0.181202    0.0359531   
4  RandomForestClassifier  -0.0040961 -0.000259591           0  0.000733708   
8        VotingClassifier  -0.0105391  -0.00383916           0   0.00219281   
9    KNeighborsClassifier  -0.0140624  -0.00311404           0   0.00473443   
3    ExtraTreesClassifier  -0.0177462   0.00162465    0.131084    0.0149741   
5           MLPClassifier  -0.0167234   -0.0106303 -0.00581371   0.00243394   
6      AdaBoostClassifier  -0.0205904  -0.00258203    0.215494     0.023951   
2           SGDClassifier   -0.203892    0.0278719    0.143809    0.0380905   

        acc       auc           conf_matrix     f1_c0      f1_c1       kappa  \
0      0.71  0.853041   [[209, 87], [0, 4]]  0.827723  0.0842105   0.0602045   
7  0.446667  0.719595  [[130, 166], [0, 4]]  0.610329   0.045977   0.0204563   
1  0.793333  0.648649   [[236, 60], [2, 2]]  0.883895  0.0606061   0.0364691   
4  0.986667       0.5    [[296, 0], [4, 0]]  0.993289          0           0   
8  0.986667       0.5    [[296, 0], [4, 0]]  0.993289          0           0   
9  0.986667       0.5    [[296, 0], [4, 0]]  0.993289          0           0   
3  0.983333  0.498311    [[295, 1], [4, 0]]  0.991597          0 -0.00536193   
5  0.983333  0.498311    [[295, 1], [4, 0]]  0.991597          0 -0.00536193   
6  0.963333  0.488176    [[289, 7], [4, 0]]  0.981324          0  -0.0172626   
2      0.93  0.471284   [[279, 17], [4, 0]]  0.963731          0  -0.0220636   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
0    0.176172         1   0.043956  0.706081      1  
7    0.101656         1  0.0235294  0.439189      1  
1   0.0842136  0.991597  0.0322581  0.797297    0.5  
4           0  0.986667          0         1      0  
8           0  0.986667          0         1      0  
9           0  0.986667          0         1      0  
3 -0.00672277  0.986622          0  0.996622      0  
5 -0.00672277  0.986622          0  0.996622      0  
6   -0.017968  0.986348          0  0.976351      0  
2  -0.0284915  0.985866          0  0.942568      0  
Elapsed time 23.04 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv 
datetime: 2017-05-09 11:10:51.489000 
pca_target: 0 	 poly degree: 0 	 kselect: 80 
Imbalance: SMOTE(k=None, k_neighbors=5, kind='regular', m=None, m_neighbors=10, n_jobs=1,
   out_step=0.5, random_state=None, ratio='auto', svm_estimator=None) 
Extended target (count):  25141 325
('Total : Processed (count): ', (998L, 222L), 13)
Final feature (count):  (998L, 222L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.663 	0.158 	0.049 	0.829 	0.812 	0.681
[[195 101]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.66      0.79       296
        1.0       0.04      1.00      0.07         4

avg / total       0.99      0.66      0.78       300


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=10, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.970 	0.320 	0.295 	0.738 	0.699 	0.465
[[289   7]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      0.98      0.98       296
        1.0       0.22      0.50      0.31         4

avg / total       0.98      0.97      0.98       300


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.001, average=False, class_weight='balanced',
       epsilon=0.1, eta0=0.001, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='squared_hinge', n_iter=5, n_jobs=4,
       penalty='l1', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.950 	0.118 	0.099 	0.605 	0.490 	0.223
[[284  12]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.96      0.97       296
        1.0       0.08      0.25      0.12         4

avg / total       0.98      0.95      0.96       300


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=None, max_features='auto', max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=30, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.990 	0.497 	0.397 	0.625 	0.500 	0.231
[[296   0]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       296
        1.0       1.00      0.25      0.40         4

avg / total       0.99      0.99      0.99       300


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight='balanced',
            criterion='entropy', max_depth=32, max_features='auto',
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	0.000 	0.000 	0.500 	0.000 	0.000
[[296   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       296
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       300


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.01, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(500,), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	0.493 	0.493 	0.747 	0.705 	0.472
[[294   2]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       296
        1.0       0.50      0.50      0.50         4

avg / total       0.99      0.99      0.99       300


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=1.0, n_estimators=80, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	0.000 	0.000 	0.500 	0.000 	0.000
[[296   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       296
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       300


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.5, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.983 	-0.007 	-0.005 	0.498 	0.000 	0.000
[[295   1]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       296
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.98       300


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=10.0, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', ...owski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='uniform'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.983 	0.280 	0.277 	0.622 	0.498 	0.230
[[294   2]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       296
        1.0       0.33      0.25      0.29         4

avg / total       0.98      0.98      0.98       300


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=3,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.940 	0.102 	0.080 	0.600 	0.487 	0.221
[[281  15]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.95      0.97       296
        1.0       0.06      0.25      0.10         4

avg / total       0.98      0.94      0.96       300


                estimator min_score mean_score max_score    sd_score  \
0              GaussianNB  0.571059   0.571059  0.571059           0   
5           MLPClassifier  0.961641    0.97291  0.982788  0.00609338   
1      LogisticRegression         0   0.777652  0.957469    0.185167   
3    ExtraTreesClassifier  0.565603    0.95141         1   0.0831948   
8        VotingClassifier  0.888739   0.947418  0.975688   0.0203699   
2           SGDClassifier -0.113914   0.555794  0.961433    0.267127   
9    KNeighborsClassifier  0.830045   0.886172   0.93538    0.032407   
4  RandomForestClassifier  0.893696   0.968622  0.995672   0.0179068   
6      AdaBoostClassifier  0.904879   0.968328         1   0.0191035   
7                     SVC         0   0.801976  0.998554     0.31401   

        acc       auc           conf_matrix     f1_c0      f1_c1       kappa  \
0  0.663333  0.829392  [[195, 101], [0, 4]]  0.794297  0.0733945   0.0489642   
5  0.986667  0.746622    [[294, 2], [2, 2]]  0.993243        0.5    0.493243   
1      0.97  0.738176    [[289, 7], [2, 2]]  0.984668   0.307692    0.294671   
3      0.99     0.625    [[296, 0], [3, 1]]  0.994958        0.4    0.396783   
8  0.983333  0.621622    [[294, 2], [3, 1]]  0.991568   0.285714    0.277457   
2      0.95   0.60473   [[284, 12], [3, 1]]  0.974271   0.117647   0.0992794   
9      0.94  0.599662   [[281, 15], [3, 1]]  0.968966        0.1   0.0803815   
4  0.986667       0.5    [[296, 0], [4, 0]]  0.993289          0           0   
6  0.986667       0.5    [[296, 0], [4, 0]]  0.993289          0           0   
7  0.983333  0.498311    [[295, 1], [4, 0]]  0.991597          0 -0.00536193   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
0    0.158419         1  0.0380952  0.658784      1  
5    0.493243  0.993243        0.5  0.993243    0.5  
1    0.320284  0.993127   0.222222  0.976351    0.5  
3    0.497485  0.989967          1         1   0.25  
8      0.2804  0.989899   0.333333  0.993243   0.25  
2    0.117995  0.989547  0.0769231  0.959459   0.25  
9    0.101746  0.989437     0.0625  0.949324   0.25  
4           0  0.986667          0         1      0  
6           0  0.986667          0         1      0  
7 -0.00672277  0.986622          0  0.996622      0  
Elapsed time 48.90 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv 
datetime: 2017-05-09 11:59:45.761000 
pca_target: 0 	 poly degree: 0 	 kselect: 80 
Imbalance: ClusterCentroids(estimator=None, n_jobs=1, random_state=None, ratio='auto') 
Extended target (count):  25141 325
('Total : Processed (count): ', (998L, 222L), 13)
Final feature (count):  (998L, 222L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.503 	0.114 	0.026 	0.748 	0.705 	0.522
[[147 149]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.50      0.66       296
        1.0       0.03      1.00      0.05         4

avg / total       0.99      0.50      0.66       300


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.01, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.753 	0.068 	0.027 	0.628 	0.615 	0.369
[[224  72]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      0.76      0.86       296
        1.0       0.03      0.50      0.05         4

avg / total       0.98      0.75      0.85       300


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.5, average=False, class_weight='balanced', epsilon=0.1,
       eta0=0.001, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='squared_hinge', n_iter=5, n_jobs=4,
       penalty='l2', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.647 	-0.083 	-0.026 	0.328 	0.000 	0.000
[[194 102]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.98      0.66      0.79       296
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.65      0.77       300


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3},
           criterion='entropy', max_depth=32, max_features=0.33,
           max_leaf_nodes=None, min_impurity_split=1e-07,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=15, n_jobs=4,
           oob_score=False, random_state=None, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.447 	0.102 	0.020 	0.720 	0.663 	0.464
[[130 166]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.44      0.61       296
        1.0       0.02      1.00      0.05         4

avg / total       0.99      0.45      0.60       300


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 15},
            criterion='entropy', max_depth=None, max_features=0.75,
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=15, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.540 	0.123 	0.030 	0.767 	0.731 	0.559
[[158 138]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.53      0.70       296
        1.0       0.03      1.00      0.05         4

avg / total       0.99      0.54      0.69       300


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.717 	0.118 	0.041 	0.733 	0.733 	0.539
[[212  84]
 [  1   3]]
             precision    recall  f1-score   support

        0.0       1.00      0.72      0.83       296
        1.0       0.03      0.75      0.07         4

avg / total       0.98      0.72      0.82       300


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight='balanced', criterion='gini',
            max_depth=16, max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=0.5, n_estimators=15, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.563 	0.129 	0.032 	0.779 	0.747 	0.582
[[165 131]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.56      0.72       296
        1.0       0.03      1.00      0.06         4

avg / total       0.99      0.56      0.71       300


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.5, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='linear',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.843 	0.110 	0.055 	0.674 	0.651 	0.409
[[251  45]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      0.85      0.91       296
        1.0       0.04      0.50      0.08         4

avg / total       0.98      0.84      0.90       300


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=1.0, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', R...wski',
           metric_params=None, n_jobs=4, n_neighbors=4, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.830 	0.102 	0.049 	0.667 	0.646 	0.403
[[247  49]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      0.83      0.91       296
        1.0       0.04      0.50      0.07         4

avg / total       0.98      0.83      0.90       300


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=5, p=1,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.880 	0.050 	0.029 	0.569 	0.471 	0.208
[[263  33]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.89      0.94       296
        1.0       0.03      0.25      0.05         4

avg / total       0.98      0.88      0.92       300


                estimator  min_score mean_score max_score  sd_score       acc  \
6      AdaBoostClassifier          0   0.527684  0.906078  0.164164  0.563333   
4  RandomForestClassifier  0.0343779   0.483349  0.906078  0.175354      0.54   
0              GaussianNB   0.666667   0.666667  0.666667         0  0.503333   
5           MLPClassifier    -0.1283   0.246599  0.496011  0.130187  0.716667   
3    ExtraTreesClassifier   0.222222    0.55028  0.812156  0.128364  0.446667   
7                     SVC          0   0.296118  0.624311  0.252244  0.843333   
8        VotingClassifier -0.0171889   0.379761  0.777778  0.147109      0.83   
1      LogisticRegression    -0.2566   0.111053  0.461633  0.175717  0.753333   
9    KNeighborsClassifier    -0.1283   0.103528    0.3849  0.136549      0.88   
2           SGDClassifier  -0.496011    0.20285  0.718234  0.136993  0.646667   

        auc           conf_matrix     f1_c0      f1_c1      kappa model_score  \
6  0.778716  [[165, 131], [0, 4]]  0.715835   0.057554  0.0324963    0.128517   
4  0.766892  [[158, 138], [0, 4]]  0.696035  0.0547945  0.0296269    0.122622   
0  0.748311  [[147, 149], [0, 4]]  0.663657  0.0509554  0.0256343    0.113945   
5  0.733108   [[212, 84], [1, 3]]  0.833006  0.0659341  0.0414975    0.117846   
3  0.719595  [[130, 166], [0, 4]]  0.610329   0.045977  0.0204563    0.101656   
7  0.673986   [[251, 45], [2, 2]]   0.91439  0.0784314  0.0552131    0.109802   
8   0.66723   [[247, 49], [2, 2]]  0.906422  0.0727273   0.049217    0.102126   
1  0.628378   [[224, 72], [2, 2]]  0.858238  0.0512821  0.0266573   0.0683168   
9  0.569257   [[263, 33], [3, 1]]  0.935943  0.0526316  0.0294752   0.0501173   
2  0.327703  [[194, 102], [4, 0]]  0.785425          0 -0.0263362  -0.0834356   

    prec_c0    prec_c1    rec_c0 rec_c1  
6         1  0.0296296  0.557432      1  
4         1   0.028169  0.533784      1  
0         1  0.0261438  0.496622      1  
5  0.995305  0.0344828  0.716216   0.75  
3         1  0.0235294  0.439189      1  
7  0.992095  0.0425532  0.847973    0.5  
8  0.991968  0.0392157  0.834459    0.5  
1   0.99115   0.027027  0.756757    0.5  
9  0.988722  0.0294118  0.888514   0.25  
2  0.979798          0  0.655405      0  
Elapsed time 15.24 mins 

************************************************************






Standard, lagged (3,4)x1, filter(tukey), None, truncated







    pca = [0]
    poly = [0]
    ksel = [40, 80]
    imb = [None, SMOTE(), ClusterCentroids() ]
	
	

	

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv 
datetime: 2017-05-09 12:30:56.185000 
pca_target: 0 	 poly degree: 0 	 kselect: 40 
Imbalance: None 
Extended target (count):  25141 325
('Total : Processed (count): ', (998L, 220L), 13)
Final feature (count):  (998L, 220L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.743 	0.128 	0.048 	0.747 	0.747 	0.558
[[220  76]
 [  1   3]]
             precision    recall  f1-score   support

        0.0       1.00      0.74      0.85       296
        1.0       0.04      0.75      0.07         4

avg / total       0.98      0.74      0.84       300


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.001, class_weight={1: 50}, dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.853 	0.116 	0.060 	0.679 	0.655 	0.414
[[254  42]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      0.86      0.92       296
        1.0       0.05      0.50      0.08         4

avg / total       0.98      0.85      0.91       300


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=1, average=False, class_weight={1: 15}, epsilon=0.1,
       eta0=0.001, fit_intercept=True, l1_ratio=0.15,
       learning_rate='invscaling', loss='squared_hinge', n_iter=5,
       n_jobs=4, penalty='elasticnet', power_t=0.5, random_state=None,
       shuffle=True, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.880 	0.050 	0.029 	0.569 	0.471 	0.208
[[263  33]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.89      0.94       296
        1.0       0.03      0.25      0.05         4

avg / total       0.98      0.88      0.92       300


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 500},
           criterion='entropy', max_depth=8, max_features='auto',
           max_leaf_nodes=None, min_impurity_split=1e-07,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=4,
           oob_score=False, random_state=None, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.977 	-0.012 	-0.012 	0.495 	0.000 	0.000
[[293   3]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       296
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.98       300


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	0.000 	0.000 	0.500 	0.000 	0.000
[[296   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       296
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       300


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.5, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.983 	0.280 	0.277 	0.622 	0.498 	0.230
[[294   2]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       296
        1.0       0.33      0.25      0.29         4

avg / total       0.98      0.98      0.98       300


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 500}, criterion='gini', max_depth=32,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=0.5, n_estimators=50, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.983 	-0.007 	-0.005 	0.498 	0.000 	0.000
[[295   1]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       296
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.98       300


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.1, cache_size=200, class_weight={1: 50}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.963 	0.150 	0.138 	0.611 	0.493 	0.226
[[288   8]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.97      0.98       296
        1.0       0.11      0.25      0.15         4

avg / total       0.98      0.96      0.97       300


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', R...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.980 	-0.010 	-0.009 	0.497 	0.000 	0.000
[[294   2]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       296
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.98       300


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=3,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.973 	0.191 	0.187 	0.617 	0.496 	0.228
[[291   5]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.98      0.99       296
        1.0       0.17      0.25      0.20         4

avg / total       0.98      0.97      0.98       300


                estimator   min_score   mean_score  max_score    sd_score  \
0              GaussianNB   0.0360894    0.0360894  0.0360894           0   
1      LogisticRegression  -0.0582515    0.0107005   0.138772   0.0428098   
5           MLPClassifier  -0.0155874  -0.00583013  0.0934082   0.0174903   
9    KNeighborsClassifier -0.00349117    0.0422181   0.232275   0.0786555   
7                     SVC  -0.0420946  -0.00317333   0.146212   0.0329421   
2           SGDClassifier   -0.202271    0.0219935    0.15122   0.0378132   
4  RandomForestClassifier  -0.0257331 -0.000555132          0  0.00190672   
6      AdaBoostClassifier  -0.0256961  -0.00120126    0.15312   0.0276754   
8        VotingClassifier  -0.0101637   0.00544608   0.139267   0.0280642   
3    ExtraTreesClassifier    -0.01083   0.00547851   0.194661    0.026767   

        acc       auc          conf_matrix     f1_c0      f1_c1       kappa  \
0  0.743333  0.746622  [[220, 76], [1, 3]]  0.851064  0.0722892   0.0481292   
1  0.853333  0.679054  [[254, 42], [2, 2]]   0.92029  0.0833333   0.0603645   
5  0.983333  0.621622   [[294, 2], [3, 1]]  0.991568   0.285714    0.277457   
9  0.973333  0.616554   [[291, 5], [3, 1]]  0.986441        0.2    0.186992   
7  0.963333  0.611486   [[288, 8], [3, 1]]  0.981261   0.153846    0.137931   
2      0.88  0.569257  [[263, 33], [3, 1]]  0.935943  0.0526316   0.0294752   
4  0.986667       0.5   [[296, 0], [4, 0]]  0.993289          0           0   
6  0.983333  0.498311   [[295, 1], [4, 0]]  0.991597          0 -0.00536193   
8      0.98  0.496622   [[294, 2], [4, 0]]  0.989899          0 -0.00896861   
3  0.976667  0.494932   [[293, 3], [4, 0]]  0.988196          0  -0.0115607   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
0    0.128448  0.995475  0.0379747  0.743243   0.75  
1    0.116103  0.992188  0.0454545  0.858108    0.5  
5      0.2804  0.989899   0.333333  0.993243   0.25  
9    0.190978  0.989796   0.166667  0.983108   0.25  
7     0.14992  0.989691   0.111111  0.972973   0.25  
2   0.0501173  0.988722  0.0294118  0.888514   0.25  
4           0  0.986667          0         1      0  
6 -0.00672277  0.986622          0  0.996622      0  
8 -0.00952338  0.986577          0  0.993243      0  
3  -0.0116833  0.986532          0  0.989865      0  
Elapsed time 21.62 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv 
datetime: 2017-05-09 12:52:33.120000 
pca_target: 0 	 poly degree: 0 	 kselect: 40 
Imbalance: SMOTE(k=None, k_neighbors=5, kind='regular', m=None, m_neighbors=10, n_jobs=1,
   out_step=0.5, random_state=None, ratio='auto', svm_estimator=None) 
Extended target (count):  25141 325
('Total : Processed (count): ', (998L, 220L), 13)
Final feature (count):  (998L, 220L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.633 	0.148 	0.043 	0.814 	0.793 	0.652
[[186 110]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.63      0.77       296
        1.0       0.04      1.00      0.07         4

avg / total       0.99      0.63      0.76       300


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=10, class_weight={1: 3}, dual=False, fit_intercept=True,
          intercept_scaling=5, max_iter=100, multi_class='ovr', n_jobs=4,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.840 	0.182 	0.089 	0.796 	0.794 	0.625
[[249  47]
 [  1   3]]
             precision    recall  f1-score   support

        0.0       1.00      0.84      0.91       296
        1.0       0.06      0.75      0.11         4

avg / total       0.98      0.84      0.90       300


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.001, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='invscaling', loss='modified_huber', n_iter=5,
       n_jobs=4, penalty='none', power_t=0.5, random_state=None,
       shuffle=True, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.690 	0.108 	0.036 	0.720 	0.719 	0.520
[[204  92]
 [  1   3]]
             precision    recall  f1-score   support

        0.0       1.00      0.69      0.81       296
        1.0       0.03      0.75      0.06         4

avg / total       0.98      0.69      0.80       300


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 50},
           criterion='entropy', max_depth=32, max_features=0.75,
           max_leaf_nodes=None, min_impurity_split=1e-07,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=4,
           oob_score=False, random_state=None, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	0.000 	0.000 	0.500 	0.000 	0.000
[[296   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       296
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       300


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight='balanced',
            criterion='entropy', max_depth=None, max_features=0.33,
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	0.000 	0.000 	0.500 	0.000 	0.000
[[296   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       296
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       300


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.5, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(500,), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.973 	-0.014 	-0.014 	0.493 	0.000 	0.000
[[292   4]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       296
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.97      0.97       300


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 500}, criterion='entropy',
            max_depth=16, max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=1.0, n_estimators=50, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.980 	-0.010 	-0.009 	0.497 	0.000 	0.000
[[294   2]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       296
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.98       300


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.5, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	0.000 	0.000 	0.500 	0.000 	0.000
[[296   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       296
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       300


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=10.0, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', ...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.960 	0.273 	0.235 	0.733 	0.695 	0.461
[[286  10]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      0.97      0.98       296
        1.0       0.17      0.50      0.25         4

avg / total       0.98      0.96      0.97       300


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.930 	0.196 	0.141 	0.718 	0.684 	0.448
[[277  19]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      0.94      0.96       296
        1.0       0.10      0.50      0.16         4

avg / total       0.98      0.93      0.95       300


                estimator min_score mean_score max_score    sd_score  \
0              GaussianNB  0.512959   0.512959  0.512959           0   
1      LogisticRegression         0   0.623236   0.81388    0.175996   
8        VotingClassifier  0.847602   0.906685  0.940884   0.0218908   
2           SGDClassifier -0.210486   0.461229  0.786879    0.210674   
9    KNeighborsClassifier  0.826182   0.876875  0.924437   0.0318016   
3    ExtraTreesClassifier  0.543113   0.928625   0.99278   0.0984059   
4  RandomForestClassifier  0.746638   0.941363  0.991343   0.0562147   
7                     SVC         0   0.750051  0.991384     0.24979   
6      AdaBoostClassifier  0.874626   0.953675  0.991384   0.0258903   
5           MLPClassifier  0.946224   0.968317  0.984224  0.00951546   

        acc       auc           conf_matrix     f1_c0      f1_c1       kappa  \
0  0.633333  0.814189  [[186, 110], [0, 4]]  0.771784  0.0677966   0.0431454   
1      0.84  0.795608   [[249, 47], [1, 3]]  0.912088   0.111111   0.0886076   
8      0.96  0.733108   [[286, 10], [2, 2]]  0.979452       0.25    0.234694   
2      0.69  0.719595   [[204, 92], [1, 3]]  0.814371  0.0606061   0.0359364   
9      0.93  0.717905   [[277, 19], [2, 2]]  0.963478       0.16    0.140753   
3  0.986667       0.5    [[296, 0], [4, 0]]  0.993289          0           0   
4  0.986667       0.5    [[296, 0], [4, 0]]  0.993289          0           0   
7  0.986667       0.5    [[296, 0], [4, 0]]  0.993289          0           0   
6      0.98  0.496622    [[294, 2], [4, 0]]  0.989899          0 -0.00896861   
5  0.973333  0.493243    [[292, 4], [4, 0]]  0.986486          0  -0.0135135   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
0    0.148487         1  0.0350877  0.628378      1  
1    0.181956     0.996       0.06  0.841216   0.75  
8    0.272883  0.993056   0.166667  0.966216    0.5  
2     0.10829  0.995122  0.0315789  0.689189   0.75  
9    0.195912  0.992832  0.0952381  0.935811    0.5  
3           0  0.986667          0         1      0  
4           0  0.986667          0         1      0  
7           0  0.986667          0         1      0  
6 -0.00952338  0.986577          0  0.993243      0  
5  -0.0135135  0.986486          0  0.986486      0  
Elapsed time 40.32 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv 
datetime: 2017-05-09 13:32:52.176000 
pca_target: 0 	 poly degree: 0 	 kselect: 40 
Imbalance: ClusterCentroids(estimator=None, n_jobs=1, random_state=None, ratio='auto') 
Extended target (count):  25141 325
('Total : Processed (count): ', (998L, 220L), 13)
Final feature (count):  (998L, 220L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.363 	0.085 	0.014 	0.677 	0.596 	0.378
[[105 191]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.35      0.52       296
        1.0       0.02      1.00      0.04         4

avg / total       0.99      0.36      0.52       300


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=10, class_weight={1: 15}, dual=False, fit_intercept=True,
          intercept_scaling=5, max_iter=100, multi_class='ovr', n_jobs=4,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.740 	0.064 	0.024 	0.622 	0.610 	0.363
[[220  76]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      0.74      0.85       296
        1.0       0.03      0.50      0.05         4

avg / total       0.98      0.74      0.84       300


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.001, average=False, class_weight='balanced',
       epsilon=0.1, eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='modified_huber', n_iter=5, n_jobs=4,
       penalty='l2', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.653 	0.155 	0.047 	0.824 	0.805 	0.671
[[192 104]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.65      0.79       296
        1.0       0.04      1.00      0.07         4

avg / total       0.99      0.65      0.78       300


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight='balanced',
           criterion='gini', max_depth=None, max_features='auto',
           max_leaf_nodes=None, min_impurity_split=1e-07,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=4,
           oob_score=False, random_state=None, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.587 	0.135 	0.036 	0.791 	0.762 	0.605
[[172 124]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.58      0.74       296
        1.0       0.03      1.00      0.06         4

avg / total       0.99      0.59      0.73       300


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 50},
            criterion='entropy', max_depth=16, max_features=0.33,
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.540 	0.123 	0.030 	0.767 	0.731 	0.559
[[158 138]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.53      0.70       296
        1.0       0.03      1.00      0.05         4

avg / total       0.99      0.54      0.69       300


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.783 	0.080 	0.034 	0.644 	0.627 	0.382
[[233  63]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      0.79      0.88       296
        1.0       0.03      0.50      0.06         4

avg / total       0.98      0.78      0.87       300


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight='balanced', criterion='entropy',
            max_depth=32, max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=0.5, n_estimators=50, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.543 	0.123 	0.030 	0.769 	0.733 	0.562
[[159 137]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.54      0.70       296
        1.0       0.03      1.00      0.06         4

avg / total       0.99      0.54      0.69       300


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='linear',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.843 	0.033 	0.017 	0.551 	0.461 	0.200
[[252  44]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.85      0.91       296
        1.0       0.02      0.25      0.04         4

avg / total       0.98      0.84      0.90       300


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=10.0, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', ...owski',
           metric_params=None, n_jobs=4, n_neighbors=4, p=2,
           weights='uniform'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.810 	0.230 	0.101 	0.904 	0.899 	0.823
[[239  57]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.81      0.89       296
        1.0       0.07      1.00      0.12         4

avg / total       0.99      0.81      0.88       300


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=5, p=1,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.803 	0.089 	0.040 	0.654 	0.635 	0.391
[[239  57]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      0.81      0.89       296
        1.0       0.03      0.50      0.06         4

avg / total       0.98      0.80      0.88       300


                estimator min_score mean_score max_score   sd_score       acc  \
8        VotingClassifier    0.1283   0.343915  0.718234   0.132856      0.81   
2           SGDClassifier -0.145489   0.273853  0.718234   0.131483  0.653333   
3    ExtraTreesClassifier  0.222222   0.537324  0.906078    0.10605  0.586667   
6      AdaBoostClassifier  0.350522    0.63118         1   0.135733  0.543333   
4  RandomForestClassifier    0.1283   0.625128  0.906078    0.14199      0.54   
0              GaussianNB  0.666667   0.666667  0.666667          0  0.363333   
9    KNeighborsClassifier    0.1283   0.342197  0.589933  0.0987047  0.803333   
5           MLPClassifier  0.111111   0.408252  0.589933   0.112776  0.783333   
1      LogisticRegression   -0.1283   0.212512  0.718234     0.2006      0.74   
7                     SVC         0   0.356347  0.718234   0.236991  0.843333   

        auc           conf_matrix     f1_c0      f1_c1      kappa model_score  \
8  0.903716   [[239, 57], [0, 4]]  0.893458   0.123077   0.100568    0.230101   
2  0.824324  [[192, 104], [0, 4]]  0.786885  0.0714286  0.0469208    0.154997   
3  0.790541  [[172, 124], [0, 4]]  0.735043  0.0606061  0.0356698    0.134755   
6  0.768581  [[159, 137], [0, 4]]  0.698901  0.0551724  0.0300198    0.123445   
4  0.766892  [[158, 138], [0, 4]]  0.696035  0.0547945  0.0296269    0.122622   
0  0.677365  [[105, 191], [0, 4]]  0.523691   0.040201  0.0144479   0.0853024   
9  0.653716   [[239, 57], [2, 2]]   0.89013  0.0634921  0.0395051   0.0887138   
5  0.643581   [[233, 63], [2, 2]]  0.877589   0.057971  0.0336967   0.0799489   
1  0.621622   [[220, 76], [2, 2]]  0.849421  0.0487805   0.024024   0.0636052   
7  0.550676   [[252, 44], [3, 1]]  0.914701  0.0408163  0.0167364   0.0325559   

    prec_c0    prec_c1    rec_c0 rec_c1  
8         1  0.0655738  0.807432      1  
2         1   0.037037  0.648649      1  
3         1    0.03125  0.581081      1  
6         1  0.0283688  0.537162      1  
4         1   0.028169  0.533784      1  
0         1  0.0205128   0.35473      1  
9  0.991701  0.0338983  0.807432    0.5  
5  0.991489  0.0307692  0.787162    0.5  
1  0.990991   0.025641  0.743243    0.5  
7  0.988235  0.0222222  0.851351   0.25  
Elapsed time 14.20 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv 
datetime: 2017-05-09 13:47:03.932000 
pca_target: 0 	 poly degree: 0 	 kselect: 80 
Imbalance: None 
Extended target (count):  25141 325
('Total : Processed (count): ', (998L, 220L), 13)
Final feature (count):  (998L, 220L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.710 	0.176 	0.060 	0.853 	0.840 	0.727
[[209  87]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.71      0.83       296
        1.0       0.04      1.00      0.08         4

avg / total       0.99      0.71      0.82       300


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=1, class_weight={1: 50}, dual=False, fit_intercept=True,
          intercept_scaling=5, max_iter=100, multi_class='ovr', n_jobs=4,
          penalty='l2', random_state=None, solver='sag', tol=0.0001,
          verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.933 	-0.028 	-0.022 	0.473 	0.000 	0.000
[[280  16]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.95      0.97       296
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.93      0.95       300


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.1, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='modified_huber', n_iter=5, n_jobs=4,
       penalty='none', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.953 	-0.022 	-0.019 	0.483 	0.000 	0.000
[[286  10]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.97      0.98       296
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.95      0.96       300


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 500},
           criterion='entropy', max_depth=8, max_features=0.75,
           max_leaf_nodes=None, min_impurity_split=1e-07,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=4,
           oob_score=False, random_state=None, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.950 	-0.023 	-0.020 	0.481 	0.000 	0.000
[[285  11]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.96      0.97       296
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.95      0.96       300


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	0.000 	0.000 	0.500 	0.000 	0.000
[[296   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       296
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       300


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.1, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.990 	0.497 	0.397 	0.625 	0.500 	0.231
[[296   0]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       296
        1.0       1.00      0.25      0.40         4

avg / total       0.99      0.99      0.99       300


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 500}, criterion='entropy',
            max_depth=32, max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=2.0, n_estimators=50, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.977 	-0.012 	-0.012 	0.495 	0.000 	0.000
[[293   3]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       296
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.98       300


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.443 	0.101 	0.020 	0.718 	0.660 	0.460
[[129 167]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.44      0.61       296
        1.0       0.02      1.00      0.05         4

avg / total       0.99      0.44      0.60       300


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	0.000 	0.000 	0.500 	0.000 	0.000
[[296   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       296
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       300


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=1,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	0.000 	0.000 	0.500 	0.000 	0.000
[[296   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       296
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       300


                estimator   min_score   mean_score   max_score     sd_score  \
0              GaussianNB  0.00524003   0.00524003  0.00524003            0   
7                     SVC  -0.0289758  -0.00210343   0.0686694    0.0187501   
5           MLPClassifier  -0.0132907  -0.00974162 -0.00562118   0.00220144   
4  RandomForestClassifier -0.00409642 -0.000244032           0  0.000744267   
8        VotingClassifier -0.00852803  -0.00357453           0    0.0018543   
9    KNeighborsClassifier  -0.0147286  -0.00309289           0   0.00498203   
6      AdaBoostClassifier  -0.0250256  -0.00130855    0.161539    0.0252979   
2           SGDClassifier   -0.199003    0.0285631    0.166258     0.038046   
3    ExtraTreesClassifier  -0.0209823   0.00179749    0.127141    0.0141935   
1      LogisticRegression  -0.0463532    0.0123225    0.130019    0.0383891   

        acc       auc           conf_matrix     f1_c0      f1_c1      kappa  \
0      0.71  0.853041   [[209, 87], [0, 4]]  0.827723  0.0842105  0.0602045   
7  0.443333  0.717905  [[129, 167], [0, 4]]  0.607059  0.0457143  0.0201831   
5      0.99     0.625    [[296, 0], [3, 1]]  0.994958        0.4   0.396783   
4  0.986667       0.5    [[296, 0], [4, 0]]  0.993289          0          0   
8  0.986667       0.5    [[296, 0], [4, 0]]  0.993289          0          0   
9  0.986667       0.5    [[296, 0], [4, 0]]  0.993289          0          0   
6  0.976667  0.494932    [[293, 3], [4, 0]]  0.988196          0 -0.0115607   
2  0.953333  0.483108   [[286, 10], [4, 0]]  0.976109          0 -0.0194175   
3      0.95  0.481419   [[285, 11], [4, 0]]  0.974359          0 -0.0199456   
1  0.933333  0.472973   [[280, 16], [4, 0]]  0.965517          0 -0.0217984   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
0    0.176172         1   0.043956  0.706081      1  
7    0.100967         1  0.0233918  0.435811      1  
5    0.497485  0.989967          1         1   0.25  
4           0  0.986667          0         1      0  
8           0  0.986667          0         1      0  
9           0  0.986667          0         1      0  
6  -0.0116833  0.986532          0  0.989865      0  
2  -0.0215866  0.986207          0  0.966216      0  
3  -0.0226794  0.986159          0  0.962838      0  
1  -0.0275921  0.985915          0  0.945946      0  
Elapsed time 22.88 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv 
datetime: 2017-05-09 14:09:56.672000 
pca_target: 0 	 poly degree: 0 	 kselect: 80 
Imbalance: SMOTE(k=None, k_neighbors=5, kind='regular', m=None, m_neighbors=10, n_jobs=1,
   out_step=0.5, random_state=None, ratio='auto', svm_estimator=None) 
Extended target (count):  25141 325
('Total : Processed (count): ', (998L, 220L), 13)
Final feature (count):  (998L, 220L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.673 	0.162 	0.051 	0.834 	0.818 	0.691
[[198  98]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.67      0.80       296
        1.0       0.04      1.00      0.08         4

avg / total       0.99      0.67      0.79       300


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=10, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.967 	0.302 	0.272 	0.736 	0.697 	0.463
[[288   8]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      0.97      0.98       296
        1.0       0.20      0.50      0.29         4

avg / total       0.98      0.97      0.97       300


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.001, average=False, class_weight='balanced',
       epsilon=0.1, eta0=0.001, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='perceptron', n_iter=5, n_jobs=4,
       penalty='none', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.983 	0.439 	0.436 	0.745 	0.704 	0.471
[[293   3]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       296
        1.0       0.40      0.50      0.44         4

avg / total       0.99      0.98      0.98       300


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 15},
           criterion='entropy', max_depth=32, max_features=0.75,
           max_leaf_nodes=None, min_impurity_split=1e-07,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=15, n_jobs=4,
           oob_score=False, random_state=None, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.980 	-0.010 	-0.009 	0.497 	0.000 	0.000
[[294   2]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       296
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.98       300


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight='balanced',
            criterion='entropy', max_depth=None, max_features='auto',
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	0.000 	0.000 	0.500 	0.000 	0.000
[[296   0]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       296
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.99      0.98       300


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.977 	0.212 	0.211 	0.618 	0.497 	0.228
[[292   4]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       296
        1.0       0.20      0.25      0.22         4

avg / total       0.98      0.98      0.98       300


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=16,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=1.0, n_estimators=80, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.980 	-0.010 	-0.009 	0.497 	0.000 	0.000
[[294   2]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      0.99      0.99       296
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.98       300


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.5, cache_size=200, class_weight='balanced', coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.983 	-0.007 	-0.005 	0.498 	0.000 	0.000
[[295   1]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      0.99       296
        1.0       0.00      0.00      0.00         4

avg / total       0.97      0.98      0.98       300


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=10.0, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', ...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.993 	0.705 	0.664 	0.750 	0.707 	0.475
[[296   0]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      1.00      1.00       296
        1.0       1.00      0.50      0.67         4

avg / total       0.99      0.99      0.99       300


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=3,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.937 	0.097 	0.075 	0.598 	0.486 	0.220
[[280  16]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.95      0.97       296
        1.0       0.06      0.25      0.10         4

avg / total       0.98      0.94      0.96       300


                estimator  min_score mean_score max_score    sd_score  \
0              GaussianNB   0.614759   0.614759  0.614759           0   
8        VotingClassifier   0.880963   0.945375  0.977113   0.0224397   
2           SGDClassifier  -0.153562   0.581248  0.957477    0.265296   
1      LogisticRegression  0.0496859   0.772918  0.953249    0.180208   
5           MLPClassifier   0.964397   0.977745  0.991344  0.00614031   
9    KNeighborsClassifier    0.82757   0.884753  0.936784   0.0358099   
4  RandomForestClassifier   0.907937   0.970497  0.995662   0.0152652   
7                     SVC          0   0.807779         1    0.306267   
3    ExtraTreesClassifier   0.619467   0.949871  0.998554   0.0740064   
6      AdaBoostClassifier   0.896006    0.97012  0.998554   0.0182235   

        acc       auc          conf_matrix     f1_c0      f1_c1       kappa  \
0  0.673333  0.834459  [[198, 98], [0, 4]]  0.801619  0.0754717   0.0511232   
8  0.993333      0.75   [[296, 0], [2, 2]]  0.996633   0.666667    0.663677   
2  0.983333  0.744932   [[293, 3], [2, 2]]   0.99154   0.444444     0.43609   
1  0.966667  0.736486   [[288, 8], [2, 2]]  0.982935   0.285714    0.271845   
5  0.976667  0.618243   [[292, 4], [3, 1]]  0.988156   0.222222    0.210526   
9  0.936667  0.597973  [[280, 16], [3, 1]]  0.967185  0.0952381   0.0752758   
4  0.986667       0.5   [[296, 0], [4, 0]]  0.993289          0           0   
7  0.983333  0.498311   [[295, 1], [4, 0]]  0.991597          0 -0.00536193   
3      0.98  0.496622   [[294, 2], [4, 0]]  0.989899          0 -0.00896861   
6      0.98  0.496622   [[294, 2], [4, 0]]  0.989899          0 -0.00896861   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
0    0.161963         1  0.0392157  0.668919      1  
8     0.70473  0.993289          1         1    0.5  
2     0.43889   0.99322        0.4  0.989865    0.5  
1    0.302213  0.993103        0.2  0.972973    0.5  
5    0.211878  0.989831        0.2  0.986486   0.25  
9   0.0972063  0.989399  0.0588235  0.945946   0.25  
4           0  0.986667          0         1      0  
7 -0.00672277  0.986622          0  0.996622      0  
3 -0.00952338  0.986577          0  0.993243      0  
6 -0.00952338  0.986577          0  0.993243      0  
Elapsed time 46.99 mins 

************************************************************

pre/post: 25/0  win/stride: 200/25  label:start 
filename: stm_sb_modified.csv 
datetime: 2017-05-09 14:56:56.118000 
pca_target: 0 	 poly degree: 0 	 kselect: 80 
Imbalance: ClusterCentroids(estimator=None, n_jobs=1, random_state=None, ratio='auto') 
Extended target (count):  25141 325
('Total : Processed (count): ', (998L, 220L), 13)
Final feature (count):  (998L, 220L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.493 	0.112 	0.025 	0.743 	0.697 	0.511
[[144 152]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.49      0.65       296
        1.0       0.03      1.00      0.05         4

avg / total       0.99      0.49      0.65       300


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.01, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=5, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.630 	0.147 	0.043 	0.812 	0.791 	0.648
[[185 111]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.62      0.77       296
        1.0       0.03      1.00      0.07         4

avg / total       0.99      0.63      0.76       300


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.1, average=False, class_weight='balanced', epsilon=0.1,
       eta0=0.001, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='squared_hinge', n_iter=5, n_jobs=4,
       penalty='l2', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.517 	-0.109 	-0.027 	0.262 	0.000 	0.000
[[155 141]
 [  4   0]]
             precision    recall  f1-score   support

        0.0       0.97      0.52      0.68       296
        1.0       0.00      0.00      0.00         4

avg / total       0.96      0.52      0.67       300


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight='balanced',
           criterion='gini', max_depth=16, max_features=0.75,
           max_leaf_nodes=None, min_impurity_split=1e-07,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=4,
           oob_score=False, random_state=None, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.477 	0.108 	0.023 	0.735 	0.685 	0.495
[[139 157]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.47      0.64       296
        1.0       0.02      1.00      0.05         4

avg / total       0.99      0.48      0.63       300


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3},
            criterion='entropy', max_depth=None, max_features=0.33,
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=15, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.623 	0.088 	0.025 	0.686 	0.683 	0.472
[[184 112]
 [  1   3]]
             precision    recall  f1-score   support

        0.0       0.99      0.62      0.77       296
        1.0       0.03      0.75      0.05         4

avg / total       0.98      0.62      0.76       300


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.01, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(500,), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.827 	0.026 	0.013 	0.542 	0.457 	0.196
[[247  49]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.83      0.90       296
        1.0       0.02      0.25      0.04         4

avg / total       0.98      0.83      0.89       300


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight='balanced', criterion='entropy',
            max_depth=16, max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=2.0, n_estimators=80, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.447 	0.102 	0.020 	0.720 	0.663 	0.464
[[130 166]
 [  0   4]]
             precision    recall  f1-score   support

        0.0       1.00      0.44      0.61       296
        1.0       0.02      1.00      0.05         4

avg / total       0.99      0.45      0.60       300


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=1, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='linear',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.863 	0.123 	0.066 	0.684 	0.659 	0.418
[[257  39]
 [  2   2]]
             precision    recall  f1-score   support

        0.0       0.99      0.87      0.93       296
        1.0       0.05      0.50      0.09         4

avg / total       0.98      0.86      0.91       300


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 500}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Ran...owski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='uniform'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.563 	0.072 	0.018 	0.655 	0.649 	0.429
[[166 130]
 [  1   3]]
             precision    recall  f1-score   support

        0.0       0.99      0.56      0.72       296
        1.0       0.02      0.75      0.04         4

avg / total       0.98      0.56      0.71       300


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=3, p=2,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.870 	0.045 	0.025 	0.564 	0.469 	0.206
[[260  36]
 [  3   1]]
             precision    recall  f1-score   support

        0.0       0.99      0.88      0.93       296
        1.0       0.03      0.25      0.05         4

avg / total       0.98      0.87      0.92       300


                estimator    min_score mean_score max_score  sd_score  \
1      LogisticRegression    -0.367711   0.179103  0.478822  0.144594   
0              GaussianNB     0.666667   0.666667  0.666667         0   
3    ExtraTreesClassifier -2.46716e-17   0.447834  0.812156  0.157067   
6      AdaBoostClassifier       0.1283   0.556155         1  0.154665   
4  RandomForestClassifier    0.0939222   0.555457         1  0.194477   
7                     SVC            0   0.240605    0.5132  0.215655   
8        VotingClassifier       0.1283   0.415991  0.683856  0.111004   
9    KNeighborsClassifier   -0.0171889   0.144286  0.367711  0.113924   
5           MLPClassifier    -0.367711   0.387355  0.607122  0.216642   
2           SGDClassifier    -0.478822    0.13275  0.607122  0.146884   

        acc       auc           conf_matrix     f1_c0      f1_c1      kappa  \
1      0.63    0.8125  [[185, 111], [0, 4]]  0.769231  0.0672269  0.0425532   
0  0.493333  0.743243  [[144, 152], [0, 4]]  0.654545       0.05  0.0246407   
3  0.476667  0.734797  [[139, 157], [0, 4]]   0.63908  0.0484848  0.0230648   
6  0.446667  0.719595  [[130, 166], [0, 4]]  0.610329   0.045977  0.0204563   
4  0.623333  0.685811  [[184, 112], [1, 3]]  0.765073  0.0504202  0.0253019   
7  0.863333  0.684122   [[257, 39], [2, 2]]  0.926126  0.0888889   0.066201   
8  0.563333  0.655405  [[166, 130], [1, 3]]  0.717063  0.0437956  0.0183835   
9      0.87  0.564189   [[260, 36], [3, 1]]  0.930233  0.0487805  0.0253249   
5  0.826667   0.54223   [[247, 49], [3, 1]]  0.904762   0.037037  0.0126582   
2  0.516667  0.261824  [[155, 141], [4, 0]]  0.681319          0 -0.0266214   

  model_score   prec_c0    prec_c1    rec_c0 rec_c1  
1    0.147442         1  0.0347826     0.625      1  
0    0.111687         1   0.025641  0.486486      1  
3    0.108014         1  0.0248447  0.469595      1  
6    0.101656         1  0.0235294  0.439189      1  
4   0.0876682  0.994595   0.026087  0.621622   0.75  
7    0.122961  0.992278  0.0487805  0.868243    0.5  
8   0.0717609  0.994012  0.0225564  0.560811   0.75  
9   0.0447805  0.988593   0.027027  0.878378   0.25  
5   0.0259938     0.988       0.02  0.834459   0.25  
2    -0.10947  0.974843          0  0.523649      0  
Elapsed time 15.07 mins 

************************************************************

