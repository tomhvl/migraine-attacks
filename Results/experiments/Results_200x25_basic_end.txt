


Standard, NT+, lagged allx1, truncated fileid=2

    pca = [0]
    poly = [0]
    ksel = [0]
    imb = [ClusterCentroids(), SMOTE(), None]
    

	
	

pre/post: 0/25  win/stride: 200/25  label:end 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-05-01 07:55:53.213000 
pca_target: 0 	 poly degree: 0 	 kselect: 0 
Imbalance: ClusterCentroids(estimator=None, n_jobs=1, random_state=None, ratio='auto') 
Extended target (count):  25141 325
('Total : Processed (count): ', (998L, 38L), 12)
Final feature (count):  (998L, 38L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.620 	0.059 	0.015 	0.643 	0.643 	0.415
[[184 113]
 [  1   2]]
             precision    recall  f1-score   support

          0       0.99      0.62      0.76       297
          1       0.02      0.67      0.03         3

avg / total       0.98      0.62      0.76       300


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.001, class_weight={1: 3}, dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.410 	0.015 	0.002 	0.537 	0.521 	0.279
[[121 176]
 [  1   2]]
             precision    recall  f1-score   support

          0       0.99      0.41      0.58       297
          1       0.01      0.67      0.02         3

avg / total       0.98      0.41      0.57       300


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.0001, average=False, class_weight='balanced',
       epsilon=0.1, eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='invscaling', loss='modified_huber', n_iter=5,
       n_jobs=4, penalty='l1', power_t=0.5, random_state=None,
       shuffle=True, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.553 	0.044 	0.010 	0.609 	0.607 	0.372
[[164 133]
 [  1   2]]
             precision    recall  f1-score   support

          0       0.99      0.55      0.71       297
          1       0.01      0.67      0.03         3

avg / total       0.98      0.55      0.70       300


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 50},
           criterion='entropy', max_depth=16, max_features=0.75,
           max_leaf_nodes=None, min_impurity_split=1e-07,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=4,
           oob_score=False, random_state=None, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.720 	0.085 	0.027 	0.694 	0.693 	0.478
[[214  83]
 [  1   2]]
             precision    recall  f1-score   support

          0       1.00      0.72      0.84       297
          1       0.02      0.67      0.05         3

avg / total       0.99      0.72      0.83       300


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=50, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.643 	0.064 	0.017 	0.655 	0.655 	0.430
[[191 106]
 [  1   2]]
             precision    recall  f1-score   support

          0       0.99      0.64      0.78       297
          1       0.02      0.67      0.04         3

avg / total       0.99      0.64      0.77       300


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.733 	0.090 	0.029 	0.700 	0.700 	0.486
[[218  79]
 [  1   2]]
             precision    recall  f1-score   support

          0       1.00      0.73      0.84       297
          1       0.02      0.67      0.05         3

avg / total       0.99      0.73      0.84       300


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=2.0, n_estimators=80, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.610 	0.056 	0.014 	0.638 	0.637 	0.409
[[181 116]
 [  1   2]]
             precision    recall  f1-score   support

          0       0.99      0.61      0.76       297
          1       0.02      0.67      0.03         3

avg / total       0.98      0.61      0.75       300


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=1, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='linear',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.637 	0.063 	0.016 	0.652 	0.651 	0.426
[[189 108]
 [  1   2]]
             precision    recall  f1-score   support

          0       0.99      0.64      0.78       297
          1       0.02      0.67      0.04         3

avg / total       0.98      0.64      0.77       300


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.520 	0.037 	0.008 	0.593 	0.588 	0.351
[[154 143]
 [  1   2]]
             precision    recall  f1-score   support

          0       0.99      0.52      0.68       297
          1       0.01      0.67      0.03         3

avg / total       0.98      0.52      0.67       300


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=3, p=1,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.570 	0.047 	0.011 	0.618 	0.616 	0.383
[[169 128]
 [  1   2]]
             precision    recall  f1-score   support

          0       0.99      0.57      0.72       297
          1       0.02      0.67      0.03         3

avg / total       0.98      0.57      0.72       300


                estimator min_score  mean_score max_score  sd_score       acc  \
5           MLPClassifier   -0.1283   0.0433167    0.2566  0.120336  0.733333   
3    ExtraTreesClassifier    0.1283    0.564084  0.906078  0.131038      0.72   
4  RandomForestClassifier  0.111111    0.559889  0.812156  0.124777  0.643333   
7                     SVC -0.350522     0.11824    0.3849   0.18129  0.636667   
0              GaussianNB         1           1         1         0      0.62   
6      AdaBoostClassifier   -0.1283    0.555679  0.906078  0.132603      0.61   
9    KNeighborsClassifier -0.496011   -0.196862    0.2566  0.174553      0.57   
2           SGDClassifier -0.496011    0.285798  0.624311  0.187859  0.553333   
8        VotingClassifier -0.367711    0.270708    0.5132  0.180706      0.52   
1      LogisticRegression -0.718234 -0.00360537  0.478822  0.264234      0.41   

        auc           conf_matrix     f1_c0      f1_c1       kappa  \
5  0.700337   [[218, 79], [1, 2]]  0.844961   0.047619   0.0288905   
3  0.693603   [[214, 83], [1, 2]]  0.835938  0.0454545   0.0266512   
4  0.654882  [[191, 106], [1, 2]]  0.781186   0.036036   0.0169055   
7  0.651515  [[189, 108], [1, 2]]  0.776181  0.0353982   0.0162455   
0  0.643098  [[184, 113], [1, 2]]  0.763485  0.0338983   0.0146932   
6  0.638047  [[181, 116], [1, 2]]  0.755741  0.0330579   0.0138233   
9  0.617845  [[169, 128], [1, 2]]  0.723769  0.0300752   0.0107362   
2  0.609428  [[164, 133], [1, 2]]  0.709957  0.0289855  0.00960828   
8  0.592593  [[154, 143], [1, 2]]  0.681416   0.027027  0.00758098   
1  0.537037  [[121, 176], [1, 2]]  0.577566  0.0220994  0.00247971   

  model_score   prec_c0    prec_c1    rec_c0    rec_c1  
5   0.0897976  0.995434  0.0246914  0.734007  0.666667  
3   0.0854971  0.995349  0.0235294  0.720539  0.666667  
4   0.0642107  0.994792  0.0185185  0.643098  0.666667  
7   0.0625679  0.994737  0.0181818  0.636364  0.666667  
0   0.0585688  0.994595  0.0173913  0.619529  0.666667  
6   0.0562367  0.994505  0.0169492  0.609428  0.666667  
9   0.0473243  0.994118  0.0153846  0.569024  0.666667  
2    0.043771  0.993939  0.0148148  0.552189  0.666667  
8   0.0368719  0.993548  0.0137931  0.518519  0.666667  
1   0.0150043  0.991803   0.011236  0.407407  0.666667  
Elapsed time 15.28 mins 

************************************************************

pre/post: 0/25  win/stride: 200/25  label:end 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-05-01 08:11:10.019000 
pca_target: 0 	 poly degree: 0 	 kselect: 0 
Imbalance: SMOTE(k=None, k_neighbors=5, kind='regular', m=None, m_neighbors=10, n_jobs=1,
   out_step=0.5, random_state=None, ratio='auto', svm_estimator=None) 
Extended target (count):  25141 325
('Total : Processed (count): ', (998L, 38L), 12)
Final feature (count):  (998L, 38L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.713 	0.083 	0.026 	0.690 	0.690 	0.474
[[212  85]
 [  1   2]]
             precision    recall  f1-score   support

          0       1.00      0.71      0.83       297
          1       0.02      0.67      0.04         3

avg / total       0.99      0.71      0.82       300


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=10, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.927 	0.223 	0.139 	0.798 	0.787 	0.603
[[276  21]
 [  1   2]]
             precision    recall  f1-score   support

          0       1.00      0.93      0.96       297
          1       0.09      0.67      0.15         3

avg / total       0.99      0.93      0.95       300


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.001, average=False, class_weight='balanced',
       epsilon=0.1, eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='squared_hinge', n_iter=5, n_jobs=4,
       penalty='l1', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.953 	0.284 	0.209 	0.811 	0.798 	0.619
[[284  13]
 [  1   2]]
             precision    recall  f1-score   support

          0       1.00      0.96      0.98       297
          1       0.13      0.67      0.22         3

avg / total       0.99      0.95      0.97       300


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=32, max_features='auto', max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=30, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	0.327 	0.327 	0.663 	0.575 	0.309
[[295   2]
 [  2   1]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       297
          1       0.33      0.33      0.33         3

avg / total       0.99      0.99      0.99       300


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3},
            criterion='entropy', max_depth=None, max_features='auto',
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.977 	-0.012 	-0.012 	0.493 	0.000 	0.000
[[293   4]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       297
          1       0.00      0.00      0.00         3

avg / total       0.98      0.98      0.98       300


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.967 	-0.016 	-0.014 	0.488 	0.000 	0.000
[[290   7]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.98      0.98       297
          1       0.00      0.00      0.00         3

avg / total       0.98      0.97      0.97       300


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 500}, criterion='entropy',
            max_depth=16, max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=1.0, n_estimators=50, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.983 	-0.008 	-0.008 	0.497 	0.000 	0.000
[[295   2]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       297
          1       0.00      0.00      0.00         3

avg / total       0.98      0.98      0.98       300


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=1, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.993 	0.575 	0.497 	0.667 	0.577 	0.311
[[297   0]
 [  2   1]]
             precision    recall  f1-score   support

          0       0.99      1.00      1.00       297
          1       1.00      0.33      0.50         3

avg / total       0.99      0.99      0.99       300


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=10.0, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', ...owski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='uniform'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.963 	0.168 	0.141 	0.652 	0.569 	0.303
[[288   9]
 [  2   1]]
             precision    recall  f1-score   support

          0       0.99      0.97      0.98       297
          1       0.10      0.33      0.15         3

avg / total       0.98      0.96      0.97       300


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=1,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.957 	0.150 	0.119 	0.648 	0.567 	0.301
[[286  11]
 [  2   1]]
             precision    recall  f1-score   support

          0       0.99      0.96      0.98       297
          1       0.08      0.33      0.13         3

avg / total       0.98      0.96      0.97       300


                estimator min_score mean_score max_score    sd_score  \
2           SGDClassifier -0.185948   0.514552   0.92739    0.234311   
1      LogisticRegression  0.284745   0.680521  0.919379      0.1666   
0              GaussianNB  0.703521   0.703521  0.703521           0   
7                     SVC         0   0.784224  0.994226    0.244279   
3    ExtraTreesClassifier   0.73398   0.921169  0.988482   0.0689941   
8        VotingClassifier  0.855296   0.922408   0.96171   0.0270259   
9    KNeighborsClassifier  0.830163   0.886722  0.954711   0.0386726   
6      AdaBoostClassifier  0.884931    0.95391  0.988492   0.0208682   
4  RandomForestClassifier  0.886403    0.95114  0.978358   0.0231618   
5           MLPClassifier    0.9492   0.964578   0.97851  0.00671706   

        acc       auc          conf_matrix     f1_c0      f1_c1       kappa  \
2  0.953333  0.811448  [[284, 13], [1, 2]]  0.975945   0.222222     0.20904   
1  0.926667   0.79798  [[276, 21], [1, 2]]  0.961672   0.153846    0.138606   
0  0.713333  0.690236  [[212, 85], [1, 2]]  0.831373  0.0444444   0.0256062   
7  0.993333  0.666667   [[297, 0], [2, 1]]  0.996644        0.5    0.497487   
3  0.986667    0.6633   [[295, 2], [2, 1]]  0.993266   0.333333    0.326599   
8  0.963333  0.651515   [[288, 9], [2, 1]]  0.981261   0.153846    0.140625   
9  0.956667  0.648148  [[286, 11], [2, 1]]  0.977778   0.133333    0.119241   
6  0.983333  0.496633   [[295, 2], [3, 0]]  0.991597          0 -0.00806452   
4  0.976667  0.493266   [[293, 4], [3, 0]]  0.988196          0  -0.0115607   
5  0.966667  0.488215   [[290, 7], [3, 0]]  0.983051          0  -0.0141988   

  model_score   prec_c0    prec_c1    rec_c0    rec_c1  
2    0.284372  0.996491   0.133333  0.956229  0.666667  
1     0.22287   0.99639  0.0869565  0.929293  0.666667  
0   0.0834279  0.995305  0.0229885  0.713805  0.666667  
7    0.575416  0.993311          1         1  0.333333  
3    0.326599  0.993266   0.333333  0.993266  0.333333  
8    0.167968  0.993103        0.1  0.969697  0.333333  
9    0.150445  0.993056  0.0833333  0.962963  0.333333  
6 -0.00823359  0.989933          0  0.993266         0  
4  -0.0116833  0.989865          0  0.986532         0  
5  -0.0155345  0.989761          0  0.976431         0  
Elapsed time 40.12 mins 

************************************************************

pre/post: 0/25  win/stride: 200/25  label:end 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-05-01 08:51:17.125000 
pca_target: 0 	 poly degree: 0 	 kselect: 0 
Imbalance: None 
Extended target (count):  25141 325
('Total : Processed (count): ', (998L, 38L), 12)
Final feature (count):  (998L, 38L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.643 	0.064 	0.017 	0.655 	0.655 	0.430
[[191 106]
 [  1   2]]
             precision    recall  f1-score   support

          0       0.99      0.64      0.78       297
          1       0.02      0.67      0.04         3

avg / total       0.99      0.64      0.77       300


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=5, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=5, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='sag', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.727 	0.088 	0.028 	0.697 	0.696 	0.482
[[216  81]
 [  1   2]]
             precision    recall  f1-score   support

          0       1.00      0.73      0.84       297
          1       0.02      0.67      0.05         3

avg / total       0.99      0.73      0.83       300


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.001, average=False, class_weight={1: 15}, epsilon=0.1,
       eta0=0.001, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='squared_hinge', n_iter=5, n_jobs=4,
       penalty='l2', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.860 	-0.039 	-0.019 	0.434 	0.000 	0.000
[[258  39]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.87      0.92       297
          1       0.00      0.00      0.00         3

avg / total       0.98      0.86      0.92       300


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 500}, criterion='gini',
           max_depth=8, max_features='auto', max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.790 	0.031 	0.012 	0.564 	0.515 	0.253
[[236  61]
 [  2   1]]
             precision    recall  f1-score   support

          0       0.99      0.79      0.88       297
          1       0.02      0.33      0.03         3

avg / total       0.98      0.79      0.87       300


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.990 	0.000 	0.000 	0.500 	0.000 	0.000
[[297   0]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       297
          1       0.00      0.00      0.00         3

avg / total       0.98      0.99      0.99       300


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.5, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(500,), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	-0.006 	-0.005 	0.498 	0.000 	0.000
[[296   1]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       297
          1       0.00      0.00      0.00         3

avg / total       0.98      0.99      0.98       300


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='entropy', max_depth=8,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=2.0, n_estimators=15, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.973 	0.206 	0.189 	0.657 	0.571 	0.305
[[291   6]
 [  2   1]]
             precision    recall  f1-score   support

          0       0.99      0.98      0.99       297
          1       0.14      0.33      0.20         3

avg / total       0.98      0.97      0.98       300


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.1, cache_size=200, class_weight='balanced', coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='linear',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.753 	0.097 	0.033 	0.710 	0.709 	0.498
[[224  73]
 [  1   2]]
             precision    recall  f1-score   support

          0       1.00      0.75      0.86       297
          1       0.03      0.67      0.05         3

avg / total       0.99      0.75      0.85       300


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...wski',
           metric_params=None, n_jobs=4, n_neighbors=4, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.990 	0.000 	0.000 	0.500 	0.000 	0.000
[[297   0]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       297
          1       0.00      0.00      0.00         3

avg / total       0.98      0.99      0.99       300


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=4, p=1,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.990 	0.000 	0.000 	0.500 	0.000 	0.000
[[297   0]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       297
          1       0.00      0.00      0.00         3

avg / total       0.98      0.99      0.99       300


                estimator  min_score   mean_score   max_score    sd_score  \
7                     SVC -0.0330436    0.0346285    0.125765   0.0462166   
1      LogisticRegression -0.0450808    0.0423319    0.138987   0.0461378   
6      AdaBoostClassifier -0.0263079  -0.00541955    0.150503   0.0204607   
0              GaussianNB  0.0987775    0.0987775   0.0987775           0   
3    ExtraTreesClassifier -0.0291475  0.000407508   0.0957847   0.0156854   
4  RandomForestClassifier -0.0115122 -0.000705947           0  0.00180379   
8        VotingClassifier -0.0135443  -0.00416074           0  0.00274169   
9    KNeighborsClassifier -0.0140512  -0.00405405           0  0.00499108   
5           MLPClassifier -0.0202596   -0.0145982 -0.00553922  0.00319079   
2           SGDClassifier -0.0695819    0.0364077    0.185163   0.0422928   

        acc       auc           conf_matrix     f1_c0      f1_c1       kappa  \
7  0.753333  0.710438   [[224, 73], [1, 2]]  0.858238  0.0512821   0.0326797   
1  0.726667   0.69697   [[216, 81], [1, 2]]  0.840467  0.0465116   0.0277448   
6  0.973333  0.656566    [[291, 6], [2, 1]]  0.986441        0.2    0.188641   
0  0.643333  0.654882  [[191, 106], [1, 2]]  0.781186   0.036036   0.0169055   
3      0.79  0.563973   [[236, 61], [2, 1]]  0.882243  0.0307692   0.0119197   
4      0.99       0.5    [[297, 0], [3, 0]]  0.994975          0           0   
8      0.99       0.5    [[297, 0], [3, 0]]  0.994975          0           0   
9      0.99       0.5    [[297, 0], [3, 0]]  0.994975          0           0   
5  0.986667  0.498316    [[296, 1], [3, 0]]  0.993289          0 -0.00502513   
2      0.86  0.434343   [[258, 39], [3, 0]]  0.924731          0  -0.0189229   

  model_score   prec_c0    prec_c1    rec_c0    rec_c1  
7   0.0967098  0.995556  0.0266667  0.754209  0.666667  
1   0.0876192  0.995392  0.0240964  0.727273  0.666667  
6    0.206387  0.993174   0.142857  0.979798  0.333333  
0   0.0642107  0.994792  0.0185185  0.643098  0.666667  
3   0.0314399  0.991597   0.016129  0.794613  0.333333  
4           0      0.99          0         1         0  
8           0      0.99          0         1         0  
9           0      0.99          0         1         0  
5 -0.00581228  0.989967          0  0.996633         0  
2  -0.0388503  0.988506          0  0.868687         0  
Elapsed time 22.34 mins 

************************************************************

Finished.

Standard, NT+, lagged allx1



    pca = [0, 60]
    poly = [2]
    ksel = [0, 30, 60]
    imb = [ClusterCentroids(), SMOTE(), None]

	
	
pre/post: 0/25  win/stride: 200/25  label:end 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-05-01 10:10:27.761000 
pca_target: 0 	 poly degree: 2 	 kselect: 0 
Imbalance: ClusterCentroids(estimator=None, n_jobs=1, random_state=None, ratio='auto') 
Extended target (count):  25141 325
('Total : Processed (count): ', (998L, 780L), 12)
Final feature (count):  (998L, 780L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.703 	0.080 	0.024 	0.685 	0.685 	0.467
[[209  88]
 [  1   2]]
             precision    recall  f1-score   support

          0       1.00      0.70      0.82       297
          1       0.02      0.67      0.04         3

avg / total       0.99      0.70      0.82       300


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.1, class_weight={1: 50}, dual=False,
          fit_intercept=True, intercept_scaling=10, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='sag', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.480 	0.029 	0.005 	0.572 	0.565 	0.325
[[142 155]
 [  1   2]]
             precision    recall  f1-score   support

          0       0.99      0.48      0.65       297
          1       0.01      0.67      0.03         3

avg / total       0.98      0.48      0.64       300


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.001, average=False, class_weight='balanced',
       epsilon=0.1, eta0=0.001, fit_intercept=True, l1_ratio=0.15,
       learning_rate='constant', loss='perceptron', n_iter=5, n_jobs=4,
       penalty='l1', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.577 	0.115 	0.026 	0.786 	0.757 	0.597
[[170 127]
 [  0   3]]
             precision    recall  f1-score   support

          0       1.00      0.57      0.73       297
          1       0.02      1.00      0.05         3

avg / total       0.99      0.58      0.72       300


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=8, max_features=0.75, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.687 	0.076 	0.022 	0.677 	0.677 	0.457
[[204  93]
 [  1   2]]
             precision    recall  f1-score   support

          0       1.00      0.69      0.81       297
          1       0.02      0.67      0.04         3

avg / total       0.99      0.69      0.81       300


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight='balanced',
            criterion='gini', max_depth=8, max_features='auto',
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.587 	0.051 	0.012 	0.626 	0.625 	0.394
[[174 123]
 [  1   2]]
             precision    recall  f1-score   support

          0       0.99      0.59      0.74       297
          1       0.02      0.67      0.03         3

avg / total       0.98      0.59      0.73       300


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.803 	0.036 	0.014 	0.571 	0.519 	0.257
[[240  57]
 [  2   1]]
             precision    recall  f1-score   support

          0       0.99      0.81      0.89       297
          1       0.02      0.33      0.03         3

avg / total       0.98      0.80      0.88       300


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=16,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=2.0, n_estimators=15, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.753 	0.097 	0.033 	0.710 	0.709 	0.498
[[224  73]
 [  1   2]]
             precision    recall  f1-score   support

          0       1.00      0.75      0.86       297
          1       0.03      0.67      0.05         3

avg / total       0.99      0.75      0.85       300


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.5, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='linear',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.820 	0.126 	0.051 	0.744 	0.740 	0.539
[[244  53]
 [  1   2]]
             precision    recall  f1-score   support

          0       1.00      0.82      0.90       297
          1       0.04      0.67      0.07         3

avg / total       0.99      0.82      0.89       300


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 500}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Ran...wski',
           metric_params=None, n_jobs=4, n_neighbors=4, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.607 	0.055 	0.014 	0.636 	0.636 	0.406
[[180 117]
 [  1   2]]
             precision    recall  f1-score   support

          0       0.99      0.61      0.75       297
          1       0.02      0.67      0.03         3

avg / total       0.98      0.61      0.75       300


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=5, p=1,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.547 	0.042 	0.009 	0.606 	0.603 	0.368
[[162 135]
 [  1   2]]
             precision    recall  f1-score   support

          0       0.99      0.55      0.70       297
          1       0.01      0.67      0.03         3

avg / total       0.98      0.55      0.70       300


                estimator  min_score mean_score max_score  sd_score       acc  \
2           SGDClassifier  -0.572745  0.0755156    0.5132  0.194431  0.576667   
7                     SVC  -0.496011   -0.05658    0.1283  0.180521      0.82   
6      AdaBoostClassifier  -0.145489   0.539301  0.906078  0.159143  0.753333   
0              GaussianNB   0.607122   0.607122  0.607122         0  0.703333   
3    ExtraTreesClassifier   0.111111   0.627069  0.906078  0.244332  0.686667   
8        VotingClassifier  -0.478822 -0.0948432  0.350522  0.230414  0.606667   
4  RandomForestClassifier -0.0343779   0.531639  0.906078  0.168699  0.586667   
9    KNeighborsClassifier  -0.794967  -0.291219    0.3849  0.202812  0.546667   
1      LogisticRegression  -0.461633  0.0125232  0.461633  0.195079      0.48   
5           MLPClassifier  -0.701045  -0.299737         0  0.138472  0.803333   

        auc           conf_matrix     f1_c0      f1_c1       kappa  \
2  0.786195  [[170, 127], [0, 3]]  0.728051  0.0451128   0.0260736   
7  0.744108   [[244, 53], [1, 2]]  0.900369  0.0689655   0.0509666   
6  0.710438   [[224, 73], [1, 2]]  0.858238  0.0512821   0.0326797   
0  0.685185   [[209, 88], [1, 2]]  0.824458  0.0430108   0.0241228   
3  0.676768   [[204, 93], [1, 2]]  0.812749  0.0408163   0.0218522   
8  0.636364  [[180, 117], [1, 2]]  0.753138  0.0327869   0.0135429   
4  0.626263  [[174, 123], [1, 2]]  0.737288    0.03125   0.0119522   
9  0.606061  [[162, 135], [1, 2]]  0.704348  0.0285714  0.00917966   
1  0.572391  [[142, 155], [1, 2]]  0.645455      0.025   0.0054826   
5  0.570707   [[240, 57], [2, 1]]  0.890538  0.0327869   0.0140374   

  model_score   prec_c0    prec_c1    rec_c0    rec_c1  
2     0.11493         1  0.0230769  0.572391         1  
7    0.125541  0.995918  0.0363636  0.821549  0.666667  
6   0.0967098  0.995556  0.0266667  0.754209  0.666667  
0   0.0804163  0.995238  0.0222222  0.703704  0.666667  
3   0.0756194  0.995122  0.0210526  0.686869  0.666667  
8   0.0554696  0.994475  0.0168067  0.606061  0.666667  
4   0.0509647  0.994286      0.016  0.585859  0.666667  
9    0.042371  0.993865  0.0145985  0.545455  0.666667  
1   0.0288425  0.993007  0.0127389  0.478114  0.666667  
5   0.0356295  0.991736  0.0172414  0.808081  0.333333  
Elapsed time 37.77 mins 

************************************************************

pre/post: 0/25  win/stride: 200/25  label:end 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-05-01 10:48:13.716000 
pca_target: 0 	 poly degree: 2 	 kselect: 0 
Imbalance: SMOTE(k=None, k_neighbors=5, kind='regular', m=None, m_neighbors=10, n_jobs=1,
   out_step=0.5, random_state=None, ratio='auto', svm_estimator=None) 
Extended target (count):  25141 325
('Total : Processed (count): ', (998L, 780L), 12)
Final feature (count):  (998L, 780L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.787 	0.030 	0.011 	0.562 	0.514 	0.252
[[235  62]
 [  2   1]]
             precision    recall  f1-score   support

          0       0.99      0.79      0.88       297
          1       0.02      0.33      0.03         3

avg / total       0.98      0.79      0.87       300


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=5, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=10, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.947 	-0.021 	-0.017 	0.478 	0.000 	0.000
[[284  13]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.96      0.97       297
          1       0.00      0.00      0.00         3

avg / total       0.98      0.95      0.96       300


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.001, average=False, class_weight='balanced',
       epsilon=0.1, eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='modified_huber', n_iter=5, n_jobs=4,
       penalty='none', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.940 	0.120 	0.084 	0.640 	0.562 	0.296
[[281  16]
 [  2   1]]
             precision    recall  f1-score   support

          0       0.99      0.95      0.97       297
          1       0.06      0.33      0.10         3

avg / total       0.98      0.94      0.96       300


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=None, max_features='auto', max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=30, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	0.327 	0.327 	0.663 	0.575 	0.309
[[295   2]
 [  2   1]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       297
          1       0.33      0.33      0.33         3

avg / total       0.99      0.99      0.99       300


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight='balanced',
            criterion='gini', max_depth=32, max_features='auto',
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	-0.006 	-0.005 	0.498 	0.000 	0.000
[[296   1]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       297
          1       0.00      0.00      0.00         3

avg / total       0.98      0.99      0.98       300


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.977 	-0.012 	-0.012 	0.493 	0.000 	0.000
[[293   4]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       297
          1       0.00      0.00      0.00         3

avg / total       0.98      0.98      0.98       300


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=1.0, n_estimators=80, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.977 	-0.012 	-0.012 	0.493 	0.000 	0.000
[[293   4]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       297
          1       0.00      0.00      0.00         3

avg / total       0.98      0.98      0.98       300


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=10, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	0.327 	0.327 	0.663 	0.575 	0.309
[[295   2]
 [  2   1]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       297
          1       0.33      0.33      0.33         3

avg / total       0.99      0.99      0.99       300


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=10.0, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', ...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.980 	0.249 	0.241 	0.660 	0.573 	0.307
[[293   4]
 [  2   1]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       297
          1       0.20      0.33      0.25         3

avg / total       0.99      0.98      0.98       300


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=1,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.957 	0.150 	0.119 	0.648 	0.567 	0.301
[[286  11]
 [  2   1]]
             precision    recall  f1-score   support

          0       0.99      0.96      0.98       297
          1       0.08      0.33      0.13         3

avg / total       0.98      0.96      0.97       300


                estimator min_score mean_score max_score    sd_score  \
3    ExtraTreesClassifier  0.821343   0.957558  0.991354   0.0392799   
7                     SVC         0   0.763805  0.988482    0.335637   
8        VotingClassifier  0.906011   0.946299  0.971498   0.0155726   
9    KNeighborsClassifier  0.822649   0.888581  0.954826   0.0394141   
2           SGDClassifier -0.103092   0.562029  0.931387    0.238271   
0              GaussianNB  0.763306   0.763306  0.763306           0   
4  RandomForestClassifier   0.94073   0.970059  0.984154  0.00760853   
5           MLPClassifier  0.959222   0.970139  0.977199  0.00497697   
6      AdaBoostClassifier  0.903664   0.966999  0.991364    0.014267   
1      LogisticRegression  0.490871   0.791327  0.953734    0.135507   

        acc       auc          conf_matrix     f1_c0     f1_c1       kappa  \
3  0.986667    0.6633   [[295, 2], [2, 1]]  0.993266  0.333333    0.326599   
7  0.986667    0.6633   [[295, 2], [2, 1]]  0.993266  0.333333    0.326599   
8      0.98  0.659933   [[293, 4], [2, 1]]  0.989865      0.25    0.240506   
9  0.956667  0.648148  [[286, 11], [2, 1]]  0.977778  0.133333    0.119241   
2      0.94  0.639731  [[281, 16], [2, 1]]  0.968966       0.1   0.0844354   
0  0.786667   0.56229  [[235, 62], [2, 1]]   0.88015  0.030303   0.0114303   
4  0.986667  0.498316   [[296, 1], [3, 0]]  0.993289         0 -0.00502513   
5  0.976667  0.493266   [[293, 4], [3, 0]]  0.988196         0  -0.0115607   
6  0.976667  0.493266   [[293, 4], [3, 0]]  0.988196         0  -0.0115607   
1  0.946667  0.478114  [[284, 13], [3, 0]]  0.972603         0  -0.0165184   

  model_score   prec_c0    prec_c1    rec_c0    rec_c1  
3    0.326599  0.993266   0.333333  0.993266  0.333333  
7    0.326599  0.993266   0.333333  0.993266  0.333333  
8    0.248605   0.99322        0.2  0.986532  0.333333  
9    0.150445  0.993056  0.0833333  0.962963  0.333333  
2    0.120266  0.992933  0.0588235  0.946128  0.333333  
0   0.0304326  0.991561   0.015873  0.791246  0.333333  
4 -0.00581228  0.989967          0  0.996633         0  
5  -0.0116833  0.989865          0  0.986532         0  
6  -0.0116833  0.989865          0  0.986532         0  
1  -0.0213901  0.989547          0  0.956229         0  
Elapsed time 288.71 mins 

************************************************************

pre/post: 0/25  win/stride: 200/25  label:end 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-05-01 15:36:56.253000 
pca_target: 0 	 poly degree: 2 	 kselect: 0 
Imbalance: None 
Extended target (count):  25141 325
('Total : Processed (count): ', (998L, 780L), 12)
Final feature (count):  (998L, 780L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.723 	0.014 	0.004 	0.530 	0.492 	0.233
[[216  81]
 [  2   1]]
             precision    recall  f1-score   support

          0       0.99      0.73      0.84       297
          1       0.01      0.33      0.02         3

avg / total       0.98      0.72      0.83       300


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=1, class_weight={1: 500}, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=4,
          penalty='l2', random_state=None, solver='sag', tol=0.0001,
          verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.637 	0.063 	0.016 	0.652 	0.651 	0.426
[[189 108]
 [  1   2]]
             precision    recall  f1-score   support

          0       0.99      0.64      0.78       297
          1       0.02      0.67      0.04         3

avg / total       0.98      0.64      0.77       300


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.001, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='constant', loss='perceptron', n_iter=5, n_jobs=4,
       penalty='l2', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.967 	-0.016 	-0.014 	0.488 	0.000 	0.000
[[290   7]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.98      0.98       297
          1       0.00      0.00      0.00         3

avg / total       0.98      0.97      0.97       300


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 500}, criterion='gini',
           max_depth=8, max_features='auto', max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=30, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.840 	0.049 	0.022 	0.589 	0.531 	0.267
[[251  46]
 [  2   1]]
             precision    recall  f1-score   support

          0       0.99      0.85      0.91       297
          1       0.02      0.33      0.04         3

avg / total       0.98      0.84      0.90       300


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.990 	0.000 	0.000 	0.500 	0.000 	0.000
[[297   0]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       297
          1       0.00      0.00      0.00         3

avg / total       0.98      0.99      0.99       300


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.01, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.983 	0.280 	0.277 	0.662 	0.574 	0.308
[[294   3]
 [  2   1]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       297
          1       0.25      0.33      0.29         3

avg / total       0.99      0.98      0.98       300


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='entropy', max_depth=32,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=2.0, n_estimators=15, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.970 	-0.014 	-0.014 	0.490 	0.000 	0.000
[[291   6]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.98      0.98       297
          1       0.00      0.00      0.00         3

avg / total       0.98      0.97      0.97       300


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.01, cache_size=200, class_weight={1: 500}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.300 	0.064 	0.008 	0.646 	0.541 	0.314
[[ 87 210]
 [  0   3]]
             precision    recall  f1-score   support

          0       1.00      0.29      0.45       297
          1       0.01      1.00      0.03         3

avg / total       0.99      0.30      0.45       300


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...owski',
           metric_params=None, n_jobs=4, n_neighbors=4, p=2,
           weights='uniform'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.990 	0.000 	0.000 	0.500 	0.000 	0.000
[[297   0]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       297
          1       0.00      0.00      0.00         3

avg / total       0.98      0.99      0.99       300


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=3,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.990 	0.000 	0.000 	0.500 	0.000 	0.000
[[297   0]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       297
          1       0.00      0.00      0.00         3

avg / total       0.98      0.99      0.99       300


                estimator   min_score   mean_score   max_score     sd_score  \
5           MLPClassifier  -0.0194206   -0.0139289 -0.00639803   0.00258119   
1      LogisticRegression  -0.0531797   0.00539325    0.123691    0.0380062   
7                     SVC  -0.0278846  -0.00831894   0.0654893    0.0141154   
3    ExtraTreesClassifier  -0.0292389  -0.00485442   0.0607478   0.00872252   
0              GaussianNB   0.0746396    0.0746396   0.0746396            0   
4  RandomForestClassifier -0.00614447 -0.000388459           0  0.000918954   
8        VotingClassifier  -0.0114962  -0.00564171           0   0.00263986   
9    KNeighborsClassifier    -0.01083   -0.0032195           0   0.00451165   
6      AdaBoostClassifier  -0.0263632  -0.00606443    0.130936     0.017541   
2           SGDClassifier   -0.128392    0.0310205    0.154947    0.0404234   

        acc       auc           conf_matrix     f1_c0      f1_c1       kappa  \
5  0.983333  0.661616    [[294, 3], [2, 1]]  0.991568   0.285714    0.277457   
1  0.636667  0.651515  [[189, 108], [1, 2]]  0.776181  0.0353982   0.0162455   
7       0.3  0.646465   [[87, 210], [0, 3]]  0.453125  0.0277778  0.00821763   
3      0.84  0.589226   [[251, 46], [2, 1]]  0.912727       0.04   0.0216062   
0  0.723333  0.530303   [[216, 81], [2, 1]]  0.838835  0.0235294  0.00431862   
4      0.99       0.5    [[297, 0], [3, 0]]  0.994975          0           0   
8      0.99       0.5    [[297, 0], [3, 0]]  0.994975          0           0   
9      0.99       0.5    [[297, 0], [3, 0]]  0.994975          0           0   
6      0.97  0.489899    [[291, 6], [3, 0]]  0.984772          0  -0.0135135   
2  0.966667  0.488215    [[290, 7], [3, 0]]  0.983051          0  -0.0141988   

  model_score   prec_c0    prec_c1    rec_c0    rec_c1  
5      0.2804  0.993243       0.25  0.989899  0.333333  
1   0.0625679  0.994737  0.0181818  0.636364  0.666667  
7   0.0642321         1  0.0140845  0.292929         1  
3   0.0488483  0.992095  0.0212766  0.845118  0.333333  
0   0.0135307  0.990826  0.0121951  0.727273  0.333333  
4           0      0.99          0         1         0  
8           0      0.99          0         1         0  
9           0      0.99          0         1         0  
6  -0.0143577  0.989796          0  0.979798         0  
2  -0.0155345  0.989761          0  0.976431         0  
Elapsed time 95.27 mins 

************************************************************

pre/post: 0/25  win/stride: 200/25  label:end 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-05-01 17:12:12.208000 
pca_target: 0 	 poly degree: 2 	 kselect: 30 
Imbalance: ClusterCentroids(estimator=None, n_jobs=1, random_state=None, ratio='auto') 
Extended target (count):  25141 325
('Total : Processed (count): ', (998L, 780L), 12)
Final feature (count):  (998L, 780L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.600 	0.054 	0.013 	0.633 	0.632 	0.402
[[178 119]
 [  1   2]]
             precision    recall  f1-score   support

          0       0.99      0.60      0.75       297
          1       0.02      0.67      0.03         3

avg / total       0.98      0.60      0.74       300


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=10, class_weight={1: 15}, dual=False, fit_intercept=True,
          intercept_scaling=5, max_iter=100, multi_class='ovr', n_jobs=4,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.547 	0.042 	0.009 	0.606 	0.603 	0.368
[[162 135]
 [  1   2]]
             precision    recall  f1-score   support

          0       0.99      0.55      0.70       297
          1       0.01      0.67      0.03         3

avg / total       0.98      0.55      0.70       300


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.0001, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='invscaling', loss='modified_huber', n_iter=5,
       n_jobs=4, penalty='l2', power_t=0.5, random_state=None,
       shuffle=True, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.560 	0.045 	0.010 	0.613 	0.610 	0.377
[[166 131]
 [  1   2]]
             precision    recall  f1-score   support

          0       0.99      0.56      0.72       297
          1       0.02      0.67      0.03         3

avg / total       0.98      0.56      0.71       300


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 15}, criterion='gini',
           max_depth=16, max_features=0.75, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.617 	0.058 	0.014 	0.641 	0.641 	0.413
[[183 114]
 [  1   2]]
             precision    recall  f1-score   support

          0       0.99      0.62      0.76       297
          1       0.02      0.67      0.03         3

avg / total       0.98      0.62      0.75       300


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features=0.33, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=50, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.593 	0.052 	0.012 	0.630 	0.629 	0.398
[[176 121]
 [  1   2]]
             precision    recall  f1-score   support

          0       0.99      0.59      0.74       297
          1       0.02      0.67      0.03         3

avg / total       0.98      0.59      0.74       300


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.613 	0.057 	0.014 	0.640 	0.639 	0.411
[[182 115]
 [  1   2]]
             precision    recall  f1-score   support

          0       0.99      0.61      0.76       297
          1       0.02      0.67      0.03         3

avg / total       0.98      0.61      0.75       300


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=2.0, n_estimators=80, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.563 	0.046 	0.010 	0.614 	0.612 	0.379
[[167 130]
 [  1   2]]
             precision    recall  f1-score   support

          0       0.99      0.56      0.72       297
          1       0.02      0.67      0.03         3

avg / total       0.98      0.56      0.71       300


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.680 	0.074 	0.021 	0.673 	0.673 	0.453
[[202  95]
 [  1   2]]
             precision    recall  f1-score   support

          0       1.00      0.68      0.81       297
          1       0.02      0.67      0.04         3

avg / total       0.99      0.68      0.80       300


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', R...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.640 	0.063 	0.017 	0.653 	0.653 	0.428
[[190 107]
 [  1   2]]
             precision    recall  f1-score   support

          0       0.99      0.64      0.78       297
          1       0.02      0.67      0.04         3

avg / total       0.99      0.64      0.77       300


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=6, p=1,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.573 	0.048 	0.011 	0.620 	0.618 	0.385
[[170 127]
 [  1   2]]
             precision    recall  f1-score   support

          0       0.99      0.57      0.73       297
          1       0.02      0.67      0.03         3

avg / total       0.98      0.57      0.72       300


                estimator min_score mean_score max_score   sd_score       acc  \
7                     SVC   -0.3849   0.276512  0.607122   0.275814      0.68   
8        VotingClassifier  0.333333    0.57832  0.683856  0.0831927      0.64   
3    ExtraTreesClassifier  0.478822   0.788848         1  0.0933193  0.616667   
5           MLPClassifier  0.239411   0.506024  0.589933  0.0867278  0.613333   
0              GaussianNB         1          1         1          0       0.6   
4  RandomForestClassifier  0.461633   0.756421  0.906078  0.0967064  0.593333   
9    KNeighborsClassifier -0.239411   0.186477  0.572745   0.180945  0.573333   
6      AdaBoostClassifier  0.111111   0.794749         1   0.158486  0.563333   
2           SGDClassifier   -0.3849   0.331729  0.812156   0.152988      0.56   
1      LogisticRegression         0   0.364729  0.812156   0.228505  0.546667   

        auc           conf_matrix     f1_c0      f1_c1       kappa  \
7  0.673401   [[202, 95], [1, 2]]     0.808       0.04   0.0210075   
8  0.653199  [[190, 107], [1, 2]]  0.778689  0.0357143   0.0165726   
3  0.641414  [[183, 114], [1, 2]]  0.760915  0.0336134   0.0143984   
5  0.639731  [[182, 115], [1, 2]]  0.758333  0.0333333   0.0141084   
0  0.632997  [[178, 119], [1, 2]]  0.747899  0.0322581   0.0129956   
4   0.62963  [[176, 121], [1, 2]]  0.742616   0.031746   0.0124656   
9  0.619529  [[170, 127], [1, 2]]  0.726496   0.030303    0.010972   
6  0.614478  [[167, 130], [1, 2]]   0.71828  0.0296296    0.010275   
2  0.612795  [[166, 131], [1, 2]]  0.715517  0.0294118   0.0100495   
1  0.606061  [[162, 135], [1, 2]]  0.704348  0.0285714  0.00917966   

  model_score   prec_c0    prec_c1    rec_c0    rec_c1  
7    0.073771  0.995074  0.0206186  0.680135  0.666667  
8   0.0633861  0.994764  0.0183486  0.639731  0.666667  
3   0.0577862  0.994565  0.0172414  0.616162  0.666667  
5   0.0570088  0.994536   0.017094  0.612795  0.666667  
0   0.0539499  0.994413  0.0165289  0.599327  0.666667  
4   0.0524486   0.99435  0.0162602  0.592593  0.666667  
9    0.048045  0.994152  0.0155039  0.572391  0.666667  
6   0.0458933  0.994048  0.0151515   0.56229  0.666667  
2   0.0451828  0.994012  0.0150376  0.558923  0.666667  
1    0.042371  0.993865  0.0145985  0.545455  0.666667  
Elapsed time 15.02 mins 

************************************************************

pre/post: 0/25  win/stride: 200/25  label:end 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-05-01 17:27:13.265000 
pca_target: 0 	 poly degree: 2 	 kselect: 30 
Imbalance: SMOTE(k=None, k_neighbors=5, kind='regular', m=None, m_neighbors=10, n_jobs=1,
   out_step=0.5, random_state=None, ratio='auto', svm_estimator=None) 
Extended target (count):  25141 325
('Total : Processed (count): ', (998L, 780L), 12)
Final feature (count):  (998L, 780L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.737 	0.091 	0.029 	0.702 	0.701 	0.488
[[219  78]
 [  1   2]]
             precision    recall  f1-score   support

          0       1.00      0.74      0.85       297
          1       0.03      0.67      0.05         3

avg / total       0.99      0.74      0.84       300


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=10, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=5, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.880 	0.166 	0.083 	0.774 	0.767 	0.575
[[262  35]
 [  1   2]]
             precision    recall  f1-score   support

          0       1.00      0.88      0.94       297
          1       0.05      0.67      0.10         3

avg / total       0.99      0.88      0.93       300


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.001, average=False, class_weight='balanced',
       epsilon=0.1, eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='modified_huber', n_iter=5, n_jobs=4,
       penalty='none', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.923 	0.100 	0.064 	0.631 	0.557 	0.291
[[276  21]
 [  2   1]]
             precision    recall  f1-score   support

          0       0.99      0.93      0.96       297
          1       0.05      0.33      0.08         3

avg / total       0.98      0.92      0.95       300


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight='balanced',
           criterion='gini', max_depth=32, max_features='auto',
           max_leaf_nodes=None, min_impurity_split=1e-07,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=4,
           oob_score=False, random_state=None, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	0.327 	0.327 	0.663 	0.575 	0.309
[[295   2]
 [  2   1]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       297
          1       0.33      0.33      0.33         3

avg / total       0.99      0.99      0.99       300


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight='balanced',
            criterion='entropy', max_depth=32, max_features='auto',
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.980 	-0.010 	-0.010 	0.495 	0.000 	0.000
[[294   3]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       297
          1       0.00      0.00      0.00         3

avg / total       0.98      0.98      0.98       300


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.1, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	-0.006 	-0.005 	0.498 	0.000 	0.000
[[296   1]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       297
          1       0.00      0.00      0.00         3

avg / total       0.98      0.99      0.98       300


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=8,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=1.0, n_estimators=50, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.980 	-0.010 	-0.010 	0.495 	0.000 	0.000
[[294   3]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       297
          1       0.00      0.00      0.00         3

avg / total       0.98      0.98      0.98       300


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.5, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=10, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.990 	0.000 	0.000 	0.500 	0.000 	0.000
[[297   0]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       297
          1       0.00      0.00      0.00         3

avg / total       0.98      0.99      0.99       300


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=10.0, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', ...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.960 	0.159 	0.129 	0.650 	0.568 	0.302
[[287  10]
 [  2   1]]
             precision    recall  f1-score   support

          0       0.99      0.97      0.98       297
          1       0.09      0.33      0.14         3

avg / total       0.98      0.96      0.97       300


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=1,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.957 	0.150 	0.119 	0.648 	0.567 	0.301
[[286  11]
 [  2   1]]
             precision    recall  f1-score   support

          0       0.99      0.96      0.98       297
          1       0.08      0.33      0.13         3

avg / total       0.98      0.96      0.97       300


                estimator  min_score mean_score max_score    sd_score  \
1      LogisticRegression   0.442434   0.696437  0.883567    0.126238   
0              GaussianNB   0.745369   0.745369  0.745369           0   
3    ExtraTreesClassifier   0.805518   0.938354  0.987056   0.0530033   
8        VotingClassifier   0.896574   0.936734   0.96729   0.0168103   
9    KNeighborsClassifier   0.888902   0.922712  0.961514   0.0229293   
2           SGDClassifier -0.0408069   0.536978  0.890054    0.219138   
7                     SVC          0   0.795308  0.995662     0.19005   
5           MLPClassifier   0.964455   0.976058  0.984215  0.00398372   
4  RandomForestClassifier   0.939222   0.958744  0.969862  0.00712581   
6      AdaBoostClassifier   0.902568   0.959334  0.984234   0.0141535   

        acc       auc          conf_matrix     f1_c0      f1_c1       kappa  \
1      0.88  0.774411  [[262, 35], [1, 2]]  0.935714        0.1   0.0830362   
0  0.736667   0.70202  [[219, 78], [1, 2]]  0.847195  0.0481928    0.029484   
3  0.986667    0.6633   [[295, 2], [2, 1]]  0.993266   0.333333    0.326599   
8      0.96  0.649832  [[287, 10], [2, 1]]  0.979522   0.142857    0.129173   
9  0.956667  0.648148  [[286, 11], [2, 1]]  0.977778   0.133333    0.119241   
2  0.923333  0.631313  [[276, 21], [2, 1]]      0.96       0.08   0.0635179   
7      0.99       0.5   [[297, 0], [3, 0]]  0.994975          0           0   
5  0.986667  0.498316   [[296, 1], [3, 0]]  0.993289          0 -0.00502513   
4      0.98  0.494949   [[294, 3], [3, 0]]  0.989899          0   -0.010101   
6      0.98  0.494949   [[294, 3], [3, 0]]  0.989899          0   -0.010101   

  model_score   prec_c0    prec_c1    rec_c0    rec_c1  
1     0.16607  0.996198  0.0540541  0.882155  0.666667  
0   0.0909091  0.995455      0.025  0.737374  0.666667  
3    0.326599  0.993266   0.333333  0.993266  0.333333  
8    0.158645   0.99308  0.0909091   0.96633  0.333333  
9    0.150445  0.993056  0.0833333  0.962963  0.333333  
2    0.100241  0.992806  0.0454545  0.929293  0.333333  
7           0      0.99          0         1         0  
5 -0.00581228  0.989967          0  0.996633         0  
4   -0.010101  0.989899          0  0.989899         0  
6   -0.010101  0.989899          0  0.989899         0  
Elapsed time 38.55 mins 

************************************************************

pre/post: 0/25  win/stride: 200/25  label:end 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-05-01 18:05:46.173000 
pca_target: 0 	 poly degree: 2 	 kselect: 30 
Imbalance: None 
Extended target (count):  25141 325
('Total : Processed (count): ', (998L, 780L), 12)
Final feature (count):  (998L, 780L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.723 	0.087 	0.027 	0.695 	0.695 	0.480
[[215  82]
 [  1   2]]
             precision    recall  f1-score   support

          0       1.00      0.72      0.84       297
          1       0.02      0.67      0.05         3

avg / total       0.99      0.72      0.83       300


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=10, class_weight={1: 15}, dual=False, fit_intercept=True,
          intercept_scaling=0.01, max_iter=100, multi_class='ovr',
          n_jobs=4, penalty='l2', random_state=None, solver='liblinear',
          tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.700 	0.079 	0.024 	0.684 	0.683 	0.465
[[208  89]
 [  1   2]]
             precision    recall  f1-score   support

          0       1.00      0.70      0.82       297
          1       0.02      0.67      0.04         3

avg / total       0.99      0.70      0.81       300


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.1, average=False, class_weight={1: 50}, epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='perceptron', n_iter=5, n_jobs=4,
       penalty='l1', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.677 	0.003 	0.001 	0.507 	0.476 	0.219
[[202  95]
 [  2   1]]
             precision    recall  f1-score   support

          0       0.99      0.68      0.81       297
          1       0.01      0.33      0.02         3

avg / total       0.98      0.68      0.80       300


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 500}, criterion='gini',
           max_depth=8, max_features='auto', max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=30, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.823 	0.042 	0.018 	0.581 	0.525 	0.262
[[246  51]
 [  2   1]]
             precision    recall  f1-score   support

          0       0.99      0.83      0.90       297
          1       0.02      0.33      0.04         3

avg / total       0.98      0.82      0.89       300


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 500},
            criterion='gini', max_depth=8, max_features='auto',
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=15, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.963 	-0.017 	-0.015 	0.487 	0.000 	0.000
[[289   8]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.97      0.98       297
          1       0.00      0.00      0.00         3

avg / total       0.98      0.96      0.97       300


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	0.327 	0.327 	0.663 	0.575 	0.309
[[295   2]
 [  2   1]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       297
          1       0.33      0.33      0.33         3

avg / total       0.99      0.99      0.99       300


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 50}, criterion='gini', max_depth=16,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=1.0, n_estimators=15, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	-0.006 	-0.005 	0.498 	0.000 	0.000
[[296   1]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       297
          1       0.00      0.00      0.00         3

avg / total       0.98      0.99      0.98       300


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=1, cache_size=200, class_weight={1: 500}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.760 	0.099 	0.034 	0.714 	0.712 	0.503
[[226  71]
 [  1   2]]
             precision    recall  f1-score   support

          0       1.00      0.76      0.86       297
          1       0.03      0.67      0.05         3

avg / total       0.99      0.76      0.85       300


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=10.0, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', ...owski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='uniform'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.983 	-0.008 	-0.008 	0.497 	0.000 	0.000
[[295   2]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       297
          1       0.00      0.00      0.00         3

avg / total       0.98      0.98      0.98       300


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=1,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.980 	0.249 	0.241 	0.660 	0.573 	0.307
[[293   4]
 [  2   1]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       297
          1       0.20      0.33      0.25         3

avg / total       0.99      0.98      0.98       300


                estimator   min_score   mean_score  max_score    sd_score  \
7                     SVC  -0.0094165     0.040613   0.150788   0.0458506   
0              GaussianNB     0.15221      0.15221    0.15221           0   
1      LogisticRegression   -0.028234    0.0491538   0.162516   0.0462413   
5           MLPClassifier  -0.0138213    0.0568048   0.231559   0.0550632   
9    KNeighborsClassifier  -0.0040961    0.0132068  0.0604039   0.0242273   
3    ExtraTreesClassifier  -0.0285958   0.00486435   0.165987   0.0252365   
2           SGDClassifier   -0.112393    0.0389054   0.166738   0.0457786   
6      AdaBoostClassifier  -0.0202947   0.00407033   0.198234   0.0350032   
8        VotingClassifier  -0.0125823    0.0154832   0.137219   0.0408794   
4  RandomForestClassifier -0.00639803 -0.000123682  0.0926437  0.00500124   

        acc       auc          conf_matrix     f1_c0      f1_c1        kappa  \
7      0.76  0.713805  [[226, 71], [1, 2]]  0.862595  0.0526316    0.0340757   
0  0.723333  0.695286  [[215, 82], [1, 2]]  0.838207   0.045977    0.0271917   
1       0.7  0.683502  [[208, 89], [1, 2]]  0.822134  0.0425532    0.0236494   
5  0.986667    0.6633   [[295, 2], [2, 1]]  0.993266   0.333333     0.326599   
9      0.98  0.659933   [[293, 4], [2, 1]]  0.989865       0.25     0.240506   
3  0.823333  0.580808  [[246, 51], [2, 1]]  0.902752  0.0363636     0.017791   
2  0.676667  0.506734  [[202, 95], [2, 1]]  0.806387   0.020202  0.000824063   
6  0.986667  0.498316   [[296, 1], [3, 0]]  0.993289          0  -0.00502513   
8  0.983333  0.496633   [[295, 2], [3, 0]]  0.991597          0  -0.00806452   
4  0.963333  0.486532   [[289, 8], [3, 0]]  0.981324          0   -0.0147601   

  model_score   prec_c0    prec_c1    rec_c0    rec_c1  
7   0.0991543  0.995595  0.0273973  0.760943  0.666667  
0   0.0865514   0.99537  0.0238095  0.723906  0.666667  
1   0.0794356  0.995215   0.021978  0.700337  0.666667  
5    0.326599  0.993266   0.333333  0.993266  0.333333  
9    0.248605   0.99322        0.2  0.986532  0.333333  
3   0.0424811  0.991935  0.0192308  0.828283  0.333333  
2  0.00287271  0.990196  0.0104167  0.680135  0.333333  
6 -0.00581228  0.989967          0  0.996633         0  
8 -0.00823359  0.989933          0  0.993266         0  
4  -0.0166355  0.989726          0  0.973064         0  
Elapsed time 23.06 mins 

************************************************************

pre/post: 0/25  win/stride: 200/25  label:end 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-05-01 18:28:49.893000 
pca_target: 0 	 poly degree: 2 	 kselect: 60 
Imbalance: ClusterCentroids(estimator=None, n_jobs=1, random_state=None, ratio='auto') 
Extended target (count):  25141 325
('Total : Processed (count): ', (998L, 780L), 12)
Final feature (count):  (998L, 780L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.627 	0.060 	0.015 	0.646 	0.646 	0.419
[[186 111]
 [  1   2]]
             precision    recall  f1-score   support

          0       0.99      0.63      0.77       297
          1       0.02      0.67      0.03         3

avg / total       0.98      0.63      0.76       300


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=1, class_weight={1: 3}, dual=False, fit_intercept=True,
          intercept_scaling=0.1, max_iter=100, multi_class='ovr', n_jobs=4,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.533 	0.040 	0.008 	0.599 	0.596 	0.359
[[158 139]
 [  1   2]]
             precision    recall  f1-score   support

          0       0.99      0.53      0.69       297
          1       0.01      0.67      0.03         3

avg / total       0.98      0.53      0.69       300


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.001, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='constant', loss='squared_hinge', n_iter=5, n_jobs=4,
       penalty='l1', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.503 	0.034 	0.007 	0.584 	0.578 	0.340
[[149 148]
 [  1   2]]
             precision    recall  f1-score   support

          0       0.99      0.50      0.67       297
          1       0.01      0.67      0.03         3

avg / total       0.98      0.50      0.66       300


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=16, max_features=0.75, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.607 	0.055 	0.014 	0.636 	0.636 	0.406
[[180 117]
 [  1   2]]
             precision    recall  f1-score   support

          0       0.99      0.61      0.75       297
          1       0.02      0.67      0.03         3

avg / total       0.98      0.61      0.75       300


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 15}, criterion='gini',
            max_depth=8, max_features=0.33, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=30, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.683 	0.075 	0.021 	0.675 	0.675 	0.455
[[203  94]
 [  1   2]]
             precision    recall  f1-score   support

          0       1.00      0.68      0.81       297
          1       0.02      0.67      0.04         3

avg / total       0.99      0.68      0.80       300


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.5, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(500,), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.670 	0.071 	0.020 	0.668 	0.668 	0.447
[[199  98]
 [  1   2]]
             precision    recall  f1-score   support

          0       0.99      0.67      0.80       297
          1       0.02      0.67      0.04         3

avg / total       0.99      0.67      0.79       300


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=8,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=1.0, n_estimators=15, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.747 	0.094 	0.031 	0.707 	0.706 	0.494
[[222  75]
 [  1   2]]
             precision    recall  f1-score   support

          0       1.00      0.75      0.85       297
          1       0.03      0.67      0.05         3

avg / total       0.99      0.75      0.85       300


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=10, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.617 	0.058 	0.014 	0.641 	0.641 	0.413
[[183 114]
 [  1   2]]
             precision    recall  f1-score   support

          0       0.99      0.62      0.76       297
          1       0.02      0.67      0.03         3

avg / total       0.98      0.62      0.75       300


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=1.0, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', R...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.630 	0.061 	0.016 	0.648 	0.648 	0.421
[[187 110]
 [  1   2]]
             precision    recall  f1-score   support

          0       0.99      0.63      0.77       297
          1       0.02      0.67      0.03         3

avg / total       0.98      0.63      0.76       300


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=4, p=1,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.623 	0.059 	0.015 	0.645 	0.644 	0.417
[[185 112]
 [  1   2]]
             precision    recall  f1-score   support

          0       0.99      0.62      0.77       297
          1       0.02      0.67      0.03         3

avg / total       0.98      0.62      0.76       300


                estimator  min_score mean_score max_score  sd_score       acc  \
6      AdaBoostClassifier  0.0939222   0.742142         1  0.171912  0.746667   
4  RandomForestClassifier          0   0.611692  0.906078  0.150191  0.683333   
5           MLPClassifier  -0.205033   0.082809  0.461633  0.158636      0.67   
8        VotingClassifier     0.2566   0.560672  0.812156  0.112854      0.63   
0              GaussianNB          1          1         1         0  0.626667   
9    KNeighborsClassifier    -0.1283   0.299788  0.572745  0.137064  0.623333   
7                     SVC  -0.111111   0.270527  0.624311  0.242452  0.616667   
3    ExtraTreesClassifier   0.239411   0.631102  0.812156  0.105696  0.606667   
1      LogisticRegression          0   0.373542  0.718234  0.228144  0.533333   
2           SGDClassifier    -0.3849   0.349873  0.812156  0.162753  0.503333   

        auc           conf_matrix     f1_c0      f1_c1       kappa  \
6  0.707071   [[222, 75], [1, 2]]  0.853846       0.05   0.0313536   
4  0.675084   [[203, 94], [1, 2]]  0.810379   0.040404   0.0214256   
5   0.66835   [[199, 98], [1, 2]]  0.800805   0.038835    0.019802   
8  0.648148  [[187, 110], [1, 2]]  0.771134  0.0347826   0.0156084   
0  0.646465  [[186, 111], [1, 2]]  0.768595  0.0344828    0.015298   
9  0.644781  [[185, 112], [1, 2]]  0.766046   0.034188    0.014993   
7  0.641414  [[183, 114], [1, 2]]  0.760915  0.0336134   0.0143984   
3  0.636364  [[180, 117], [1, 2]]  0.753138  0.0327869   0.0135429   
1  0.599327  [[158, 139], [1, 2]]  0.692982  0.0277778  0.00835812   
2  0.584175  [[149, 148], [1, 2]]  0.666667  0.0261438  0.00666667   

  model_score   prec_c0    prec_c1    rec_c0    rec_c1  
6   0.0943387  0.995516   0.025974  0.747475  0.666667  
4   0.0746904  0.995098  0.0208333  0.683502  0.666667  
5   0.0710669     0.995       0.02  0.670034  0.666667  
8   0.0609505  0.994681  0.0178571   0.62963  0.666667  
0   0.0601508  0.994652  0.0176991  0.626263  0.666667  
9    0.059357  0.994624  0.0175439  0.622896  0.666667  
7   0.0577862  0.994565  0.0172414  0.616162  0.666667  
3   0.0554696  0.994475  0.0168067  0.606061  0.666667  
1   0.0396028  0.993711  0.0141844  0.531987  0.666667  
2   0.0335013  0.993333  0.0133333  0.501684  0.666667  
Elapsed time 15.92 mins 

************************************************************

pre/post: 0/25  win/stride: 200/25  label:end 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-05-01 18:44:44.939000 
pca_target: 0 	 poly degree: 2 	 kselect: 60 
Imbalance: SMOTE(k=None, k_neighbors=5, kind='regular', m=None, m_neighbors=10, n_jobs=1,
   out_step=0.5, random_state=None, ratio='auto', svm_estimator=None) 
Extended target (count):  25141 325
('Total : Processed (count): ', (998L, 780L), 12)
Final feature (count):  (998L, 780L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.753 	0.021 	0.007 	0.545 	0.503 	0.242
[[225  72]
 [  2   1]]
             precision    recall  f1-score   support

          0       0.99      0.76      0.86       297
          1       0.01      0.33      0.03         3

avg / total       0.98      0.75      0.85       300


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=10, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.923 	0.217 	0.133 	0.796 	0.786 	0.601
[[275  22]
 [  1   2]]
             precision    recall  f1-score   support

          0       1.00      0.93      0.96       297
          1       0.08      0.67      0.15         3

avg / total       0.99      0.92      0.95       300


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.001, average=False, class_weight='balanced',
       epsilon=0.1, eta0=0.001, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='perceptron', n_iter=5, n_jobs=4,
       penalty='none', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.920 	0.212 	0.127 	0.795 	0.784 	0.599
[[274  23]
 [  1   2]]
             precision    recall  f1-score   support

          0       1.00      0.92      0.96       297
          1       0.08      0.67      0.14         3

avg / total       0.99      0.92      0.95       300


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 500}, criterion='gini',
           max_depth=None, max_features='auto', max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=30, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	-0.006 	-0.005 	0.498 	0.000 	0.000
[[296   1]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       297
          1       0.00      0.00      0.00         3

avg / total       0.98      0.99      0.98       300


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight='balanced',
            criterion='entropy', max_depth=32, max_features='auto',
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	0.327 	0.327 	0.663 	0.575 	0.309
[[295   2]
 [  2   1]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       297
          1       0.33      0.33      0.33         3

avg / total       0.99      0.99      0.99       300


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.5, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.980 	0.249 	0.241 	0.660 	0.573 	0.307
[[293   4]
 [  2   1]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       297
          1       0.20      0.33      0.25         3

avg / total       0.99      0.98      0.98       300


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 500}, criterion='entropy',
            max_depth=16, max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=0.5, n_estimators=50, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.980 	-0.010 	-0.010 	0.495 	0.000 	0.000
[[294   3]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       297
          1       0.00      0.00      0.00         3

avg / total       0.98      0.98      0.98       300


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.5, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.990 	0.000 	0.000 	0.500 	0.000 	0.000
[[297   0]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       297
          1       0.00      0.00      0.00         3

avg / total       0.98      0.99      0.99       300


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=10.0, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', ...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.973 	0.206 	0.189 	0.657 	0.571 	0.305
[[291   6]
 [  2   1]]
             precision    recall  f1-score   support

          0       0.99      0.98      0.99       297
          1       0.14      0.33      0.20         3

avg / total       0.98      0.97      0.98       300


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=1,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.960 	0.159 	0.129 	0.650 	0.568 	0.302
[[287  10]
 [  2   1]]
             precision    recall  f1-score   support

          0       0.99      0.97      0.98       297
          1       0.09      0.33      0.14         3

avg / total       0.98      0.96      0.97       300


                estimator  min_score mean_score max_score    sd_score  \
1      LogisticRegression   0.448354   0.721489  0.904666    0.136752   
2           SGDClassifier -0.0479756   0.552248  0.906644    0.225469   
4  RandomForestClassifier   0.938085   0.963311  0.974212  0.00720396   
5           MLPClassifier   0.961634   0.973013  0.981343  0.00449078   
8        VotingClassifier   0.894044   0.934873  0.965844   0.0159216   
9    KNeighborsClassifier      0.875   0.913714  0.950664   0.0271273   
0              GaussianNB   0.753686   0.753686  0.753686           0   
7                     SVC          0    0.81383  0.994226    0.223879   
3    ExtraTreesClassifier   0.804073   0.943181  0.987106   0.0500432   
6      AdaBoostClassifier   0.896842   0.961947  0.988512   0.0149232   

        acc       auc          conf_matrix     f1_c0      f1_c1       kappa  \
1  0.923333  0.796296  [[275, 22], [1, 2]]   0.95986   0.148148     0.13273   
2      0.92  0.794613  [[274, 23], [1, 2]]  0.958042   0.142857    0.127273   
4  0.986667    0.6633   [[295, 2], [2, 1]]  0.993266   0.333333    0.326599   
5      0.98  0.659933   [[293, 4], [2, 1]]  0.989865       0.25    0.240506   
8  0.973333  0.656566   [[291, 6], [2, 1]]  0.986441        0.2    0.188641   
9      0.96  0.649832  [[287, 10], [2, 1]]  0.979522   0.142857    0.129173   
0  0.753333  0.545455  [[225, 72], [2, 1]]  0.858779  0.0263158  0.00724443   
7      0.99       0.5   [[297, 0], [3, 0]]  0.994975          0           0   
3  0.986667  0.498316   [[296, 1], [3, 0]]  0.993289          0 -0.00502513   
6      0.98  0.494949   [[294, 3], [3, 0]]  0.989899          0   -0.010101   

  model_score   prec_c0    prec_c1    rec_c0    rec_c1  
1    0.217338  0.996377  0.0833333  0.925926  0.666667  
2    0.212121  0.996364       0.08  0.922559  0.666667  
4    0.326599  0.993266   0.333333  0.993266  0.333333  
5    0.248605   0.99322        0.2  0.986532  0.333333  
8    0.206387  0.993174   0.142857  0.979798  0.333333  
9    0.158645   0.99308  0.0909091   0.96633  0.333333  
0   0.0210801  0.991189  0.0136986  0.757576  0.333333  
7           0      0.99          0         1         0  
3 -0.00581228  0.989967          0  0.996633         0  
6   -0.010101  0.989899          0  0.989899         0  
Elapsed time 48.98 mins 

************************************************************

pre/post: 0/25  win/stride: 200/25  label:end 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-05-01 19:33:43.862000 
pca_target: 0 	 poly degree: 2 	 kselect: 60 
Imbalance: None 
Extended target (count):  25141 325
('Total : Processed (count): ', (998L, 780L), 12)
Final feature (count):  (998L, 780L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.687 	0.076 	0.022 	0.677 	0.677 	0.457
[[204  93]
 [  1   2]]
             precision    recall  f1-score   support

          0       1.00      0.69      0.81       297
          1       0.02      0.67      0.04         3

avg / total       0.99      0.69      0.81       300


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=1, class_weight={1: 500}, dual=False, fit_intercept=True,
          intercept_scaling=0.01, max_iter=100, multi_class='ovr',
          n_jobs=4, penalty='l2', random_state=None, solver='sag',
          tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.600 	0.054 	0.013 	0.633 	0.632 	0.402
[[178 119]
 [  1   2]]
             precision    recall  f1-score   support

          0       0.99      0.60      0.75       297
          1       0.02      0.67      0.03         3

avg / total       0.98      0.60      0.74       300


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.0001, average=False, class_weight='balanced',
       epsilon=0.1, eta0=0.001, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='squared_hinge', n_iter=5, n_jobs=4,
       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.557 	0.044 	0.010 	0.611 	0.609 	0.374
[[165 132]
 [  1   2]]
             precision    recall  f1-score   support

          0       0.99      0.56      0.71       297
          1       0.01      0.67      0.03         3

avg / total       0.98      0.56      0.71       300


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 500}, criterion='gini',
           max_depth=8, max_features='auto', max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=50, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.813 	0.039 	0.016 	0.576 	0.522 	0.260
[[243  54]
 [  2   1]]
             precision    recall  f1-score   support

          0       0.99      0.82      0.90       297
          1       0.02      0.33      0.03         3

avg / total       0.98      0.81      0.89       300


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.990 	0.000 	0.000 	0.500 	0.000 	0.000
[[297   0]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       297
          1       0.00      0.00      0.00         3

avg / total       0.98      0.99      0.99       300


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.973 	-0.013 	-0.013 	0.492 	0.000 	0.000
[[292   5]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.98      0.99       297
          1       0.00      0.00      0.00         3

avg / total       0.98      0.97      0.98       300


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='entropy', max_depth=16,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=1.0, n_estimators=50, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.980 	-0.010 	-0.010 	0.495 	0.000 	0.000
[[294   3]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       297
          1       0.00      0.00      0.00         3

avg / total       0.98      0.98      0.98       300


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.1, cache_size=200, class_weight={1: 500}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.687 	0.076 	0.022 	0.677 	0.677 	0.457
[[204  93]
 [  1   2]]
             precision    recall  f1-score   support

          0       1.00      0.69      0.81       297
          1       0.02      0.67      0.04         3

avg / total       0.99      0.69      0.81       300


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	-0.006 	-0.005 	0.498 	0.000 	0.000
[[296   1]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       297
          1       0.00      0.00      0.00         3

avg / total       0.98      0.99      0.98       300


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=1,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	-0.006 	-0.005 	0.498 	0.000 	0.000
[[296   1]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       297
          1       0.00      0.00      0.00         3

avg / total       0.98      0.99      0.98       300


                estimator   min_score   mean_score  max_score     sd_score  \
0              GaussianNB    0.140609     0.140609   0.140609            0   
7                     SVC  -0.0311312    0.0184977   0.119654    0.0364872   
1      LogisticRegression   -0.054029    0.0304118    0.13975    0.0435743   
2           SGDClassifier   -0.113603    0.0400417   0.157036    0.0458175   
3    ExtraTreesClassifier  -0.0320316   0.00187837   0.167281    0.0232291   
4  RandomForestClassifier -0.00813919 -0.000396666          0  0.000814203   
8        VotingClassifier  -0.0152233  -0.00517409          0   0.00449934   
9    KNeighborsClassifier  -0.0132363   -0.0034184          0   0.00506608   
6      AdaBoostClassifier  -0.0203464  -0.00558034   0.134312    0.0188646   
5           MLPClassifier  -0.0172801   -0.0098853  0.0696137    0.0164807   

        acc       auc           conf_matrix     f1_c0      f1_c1       kappa  \
0  0.686667  0.676768   [[204, 93], [1, 2]]  0.812749  0.0408163   0.0218522   
7  0.686667  0.676768   [[204, 93], [1, 2]]  0.812749  0.0408163   0.0218522   
1       0.6  0.632997  [[178, 119], [1, 2]]  0.747899  0.0322581   0.0129956   
2  0.556667  0.611111  [[165, 132], [1, 2]]  0.712743  0.0291971  0.00982728   
3  0.813333  0.575758   [[243, 54], [2, 1]]  0.896679  0.0344828   0.0158172   
4      0.99       0.5    [[297, 0], [3, 0]]  0.994975          0           0   
8  0.986667  0.498316    [[296, 1], [3, 0]]  0.993289          0 -0.00502513   
9  0.986667  0.498316    [[296, 1], [3, 0]]  0.993289          0 -0.00502513   
6      0.98  0.494949    [[294, 3], [3, 0]]  0.989899          0   -0.010101   
5  0.973333  0.491582    [[292, 5], [3, 0]]  0.986486          0  -0.0126582   

  model_score   prec_c0    prec_c1    rec_c0    rec_c1  
0   0.0756194  0.995122  0.0210526  0.686869  0.666667  
7   0.0756194  0.995122  0.0210526  0.686869  0.666667  
1   0.0539499  0.994413  0.0165289  0.599327  0.666667  
2   0.0444754  0.993976  0.0149254  0.555556  0.666667  
3    0.038961  0.991837  0.0181818  0.818182  0.333333  
4           0      0.99          0         1         0  
8 -0.00581228  0.989967          0  0.996633         0  
9 -0.00581228  0.989967          0  0.996633         0  
6   -0.010101  0.989899          0  0.989899         0  
5  -0.0130845  0.989831          0  0.983165         0  
Elapsed time 24.48 mins 

************************************************************

pre/post: 0/25  win/stride: 200/25  label:end 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-05-01 19:58:12.888000 
pca_target: 60 	 poly degree: 2 	 kselect: 0 
Imbalance: ClusterCentroids(estimator=None, n_jobs=1, random_state=None, ratio='auto') 
Extended target (count):  25141 325
('Total : Processed (count): ', (998L, 780L), 12)
Final feature (count):  (998L, 780L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.990 	0.000 	0.000 	0.500 	0.000 	0.000
[[297   0]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       297
          1       0.00      0.00      0.00         3

avg / total       0.98      0.99      0.99       300


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.1, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='sag', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.460 	-0.041 	-0.008 	0.397 	0.392 	0.152
[[137 160]
 [  2   1]]
             precision    recall  f1-score   support

          0       0.99      0.46      0.63       297
          1       0.01      0.33      0.01         3

avg / total       0.98      0.46      0.62       300


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.1, average=False, class_weight='balanced', epsilon=0.1,
       eta0=0.001, fit_intercept=True, l1_ratio=0.15,
       learning_rate='constant', loss='perceptron', n_iter=5, n_jobs=4,
       penalty='l1', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.720 	0.085 	0.027 	0.694 	0.693 	0.478
[[214  83]
 [  1   2]]
             precision    recall  f1-score   support

          0       1.00      0.72      0.84       297
          1       0.02      0.67      0.05         3

avg / total       0.99      0.72      0.83       300


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 500},
           criterion='entropy', max_depth=8, max_features='auto',
           max_leaf_nodes=None, min_impurity_split=1e-07,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=4,
           oob_score=False, random_state=None, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.953 	-0.020 	-0.016 	0.481 	0.000 	0.000
[[286  11]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.96      0.98       297
          1       0.00      0.00      0.00         3

avg / total       0.98      0.95      0.97       300


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3},
            criterion='entropy', max_depth=32, max_features='auto',
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.847 	0.052 	0.023 	0.593 	0.533 	0.269
[[253  44]
 [  2   1]]
             precision    recall  f1-score   support

          0       0.99      0.85      0.92       297
          1       0.02      0.33      0.04         3

avg / total       0.98      0.85      0.91       300


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.01, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(500,), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.527 	-0.028 	-0.006 	0.431 	0.420 	0.173
[[157 140]
 [  2   1]]
             precision    recall  f1-score   support

          0       0.99      0.53      0.69       297
          1       0.01      0.33      0.01         3

avg / total       0.98      0.53      0.68       300


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 50}, criterion='gini', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=0.5, n_estimators=80, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.913 	-0.029 	-0.018 	0.461 	0.000 	0.000
[[274  23]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.92      0.95       297
          1       0.00      0.00      0.00         3

avg / total       0.98      0.91      0.95       300


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=10, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.010 	0.000 	0.000 	0.500 	0.000 	0.000
[[  0 297]
 [  0   3]]
             precision    recall  f1-score   support

          0       0.00      0.00      0.00       297
          1       0.01      1.00      0.02         3

avg / total       0.00      0.01      0.00       300


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 500}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Ran...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.447 	-0.110 	-0.020 	0.226 	0.000 	0.000
[[134 163]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.98      0.45      0.62       297
          1       0.00      0.00      0.00         3

avg / total       0.97      0.45      0.61       300


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=4, p=1,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.900 	0.080 	0.045 	0.620 	0.549 	0.285
[[269  28]
 [  2   1]]
             precision    recall  f1-score   support

          0       0.99      0.91      0.95       297
          1       0.03      0.33      0.06         3

avg / total       0.98      0.90      0.94       300


                estimator min_score  mean_score max_score   sd_score  \
2           SGDClassifier   -0.5132    0.144533  0.607122   0.144598   
9    KNeighborsClassifier   -0.2566   0.0423829  0.496011   0.234093   
4  RandomForestClassifier -0.367711    0.170746  0.718234   0.182715   
0              GaussianNB  0.701045    0.701045  0.701045          0   
7                     SVC   -0.1283   0.0834793  0.316144   0.104455   
3    ExtraTreesClassifier -0.496011    0.234434  0.812156   0.251802   
6      AdaBoostClassifier -0.333333    0.435849  0.812156   0.212183   
5           MLPClassifier -0.350522   0.0548651  0.367711   0.144791   
1      LogisticRegression   -0.3849  0.00977419  0.239411  0.0805739   
8        VotingClassifier -0.496011  0.00772176  0.367711   0.199901   

        acc       auc           conf_matrix     f1_c0      f1_c1       kappa  \
2      0.72  0.693603   [[214, 83], [1, 2]]  0.835938  0.0454545   0.0266512   
9       0.9  0.619529   [[269, 28], [2, 1]]  0.947183     0.0625   0.0451941   
4  0.846667  0.592593   [[253, 44], [2, 1]]  0.916667  0.0416667   0.0233546   
0      0.99       0.5    [[297, 0], [3, 0]]  0.994975          0           0   
7      0.01       0.5    [[0, 297], [0, 3]]         0   0.019802           0   
3  0.953333  0.481481   [[286, 11], [3, 0]]  0.976109          0  -0.0159652   
6  0.913333  0.461279   [[274, 23], [3, 0]]  0.954704          0   -0.018011   
5  0.526667  0.430976  [[157, 140], [2, 1]]  0.688596  0.0138889 -0.00580819   
1      0.46  0.397306  [[137, 160], [2, 1]]   0.62844  0.0121951 -0.00758801   
8  0.446667  0.225589  [[134, 163], [3, 0]]  0.617512          0   -0.020032   

  model_score   prec_c0     prec_c1    rec_c0    rec_c1  
2   0.0854971  0.995349   0.0235294  0.720539  0.666667  
9   0.0804928   0.99262   0.0344828  0.905724  0.333333  
4   0.0516023  0.992157   0.0222222  0.851852  0.333333  
0           0      0.99           0         1         0  
7           0         0        0.01         0         1  
3  -0.0196078  0.989619           0  0.962963         0  
6  -0.0289605   0.98917           0  0.922559         0  
5  -0.0275206  0.987421   0.0070922   0.52862  0.333333  
1  -0.0409819  0.985612  0.00621118  0.461279  0.333333  
8   -0.109627  0.978102           0  0.451178         0  
Elapsed time 13.79 mins 

************************************************************

pre/post: 0/25  win/stride: 200/25  label:end 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-05-01 20:12:00.393000 
pca_target: 60 	 poly degree: 2 	 kselect: 0 
Imbalance: SMOTE(k=None, k_neighbors=5, kind='regular', m=None, m_neighbors=10, n_jobs=1,
   out_step=0.5, random_state=None, ratio='auto', svm_estimator=None) 
Extended target (count):  25141 325
('Total : Processed (count): ', (998L, 780L), 12)
Final feature (count):  (998L, 780L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.973 	-0.013 	-0.013 	0.492 	0.000 	0.000
[[292   5]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.98      0.99       297
          1       0.00      0.00      0.00         3

avg / total       0.98      0.97      0.98       300


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=5, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.947 	0.265 	0.186 	0.808 	0.796 	0.615
[[282  15]
 [  1   2]]
             precision    recall  f1-score   support

          0       1.00      0.95      0.97       297
          1       0.12      0.67      0.20         3

avg / total       0.99      0.95      0.96       300


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.001, average=False, class_weight='balanced',
       epsilon=0.1, eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='modified_huber', n_iter=5, n_jobs=4,
       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.973 	0.206 	0.189 	0.657 	0.571 	0.305
[[291   6]
 [  2   1]]
             precision    recall  f1-score   support

          0       0.99      0.98      0.99       297
          1       0.14      0.33      0.20         3

avg / total       0.98      0.97      0.98       300


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=16, max_features='auto', max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=50, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.990 	0.000 	0.000 	0.500 	0.000 	0.000
[[297   0]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       297
          1       0.00      0.00      0.00         3

avg / total       0.98      0.99      0.99       300


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.990 	0.000 	0.000 	0.500 	0.000 	0.000
[[297   0]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       297
          1       0.00      0.00      0.00         3

avg / total       0.98      0.99      0.99       300


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.990 	0.000 	0.000 	0.500 	0.000 	0.000
[[297   0]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       297
          1       0.00      0.00      0.00         3

avg / total       0.98      0.99      0.99       300


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=1.0, n_estimators=50, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.990 	0.000 	0.000 	0.500 	0.000 	0.000
[[297   0]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       297
          1       0.00      0.00      0.00         3

avg / total       0.98      0.99      0.99       300


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.1, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.990 	0.000 	0.000 	0.500 	0.000 	0.000
[[297   0]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       297
          1       0.00      0.00      0.00         3

avg / total       0.98      0.99      0.99       300


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=10.0, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Ran...owski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='uniform'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	0.327 	0.327 	0.663 	0.575 	0.309
[[295   2]
 [  2   1]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       297
          1       0.33      0.33      0.33         3

avg / total       0.99      0.99      0.99       300


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.977 	0.225 	0.212 	0.658 	0.572 	0.306
[[292   5]
 [  2   1]]
             precision    recall  f1-score   support

          0       0.99      0.98      0.99       297
          1       0.17      0.33      0.22         3

avg / total       0.98      0.98      0.98       300


                estimator min_score mean_score max_score    sd_score  \
1      LogisticRegression         0   0.793743   0.94266    0.267071   
8        VotingClassifier  0.958971   0.978539   0.99278  0.00799883   
9    KNeighborsClassifier  0.904457   0.945265  0.980016   0.0250716   
2           SGDClassifier   -0.1177     0.6486  0.982758    0.313513   
3    ExtraTreesClassifier  0.827915   0.993965         1   0.0197294   
4  RandomForestClassifier  0.995662   0.999727         1    0.000678   
5           MLPClassifier  0.942384   0.969568  0.995672   0.0175113   
6      AdaBoostClassifier   0.91849   0.986305         1   0.0115274   
7                     SVC         0   0.837867  0.998554    0.294667   
0              GaussianNB  0.994226   0.994226  0.994226           0   

        acc       auc          conf_matrix     f1_c0     f1_c1      kappa  \
1  0.946667  0.808081  [[282, 15], [1, 2]]  0.972414       0.2   0.186165   
8  0.986667    0.6633   [[295, 2], [2, 1]]  0.993266  0.333333   0.326599   
9  0.976667  0.658249   [[292, 5], [2, 1]]  0.988156  0.222222   0.211712   
2  0.973333  0.656566   [[291, 6], [2, 1]]  0.986441       0.2   0.188641   
3      0.99       0.5   [[297, 0], [3, 0]]  0.994975         0          0   
4      0.99       0.5   [[297, 0], [3, 0]]  0.994975         0          0   
5      0.99       0.5   [[297, 0], [3, 0]]  0.994975         0          0   
6      0.99       0.5   [[297, 0], [3, 0]]  0.994975         0          0   
7      0.99       0.5   [[297, 0], [3, 0]]  0.994975         0          0   
0  0.973333  0.491582   [[292, 5], [3, 0]]  0.986486         0 -0.0126582   

  model_score   prec_c0   prec_c1    rec_c0    rec_c1  
1    0.265165  0.996466  0.117647  0.949495  0.666667  
8    0.326599  0.993266  0.333333  0.993266  0.333333  
9    0.224937  0.993197  0.166667  0.983165  0.333333  
2    0.206387  0.993174  0.142857  0.979798  0.333333  
3           0      0.99         0         1         0  
4           0      0.99         0         1         0  
5           0      0.99         0         1         0  
6           0      0.99         0         1         0  
7           0      0.99         0         1         0  
0  -0.0130845  0.989831         0  0.983165         0  
Elapsed time 28.09 mins 

************************************************************

pre/post: 0/25  win/stride: 200/25  label:end 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-05-01 20:40:06.034000 
pca_target: 60 	 poly degree: 2 	 kselect: 0 
Imbalance: None 
Extended target (count):  25141 325
('Total : Processed (count): ', (998L, 780L), 12)
Final feature (count):  (998L, 780L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.967 	0.337 	0.274 	0.818 	0.804 	0.627
[[288   9]
 [  1   2]]
             precision    recall  f1-score   support

          0       1.00      0.97      0.98       297
          1       0.18      0.67      0.29         3

avg / total       0.99      0.97      0.98       300


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.001, class_weight={1: 500}, dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.567 	0.047 	0.011 	0.616 	0.614 	0.381
[[168 129]
 [  1   2]]
             precision    recall  f1-score   support

          0       0.99      0.57      0.72       297
          1       0.02      0.67      0.03         3

avg / total       0.98      0.57      0.71       300


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=1, average=False, class_weight='balanced', epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='constant', loss='squared_hinge', n_iter=5, n_jobs=4,
       penalty='l2', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.620 	0.059 	0.015 	0.643 	0.643 	0.415
[[184 113]
 [  1   2]]
             precision    recall  f1-score   support

          0       0.99      0.62      0.76       297
          1       0.02      0.67      0.03         3

avg / total       0.98      0.62      0.76       300


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 500},
           criterion='entropy', max_depth=8, max_features='auto',
           max_leaf_nodes=None, min_impurity_split=1e-07,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=4,
           oob_score=False, random_state=None, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.937 	0.116 	0.079 	0.638 	0.561 	0.295
[[280  17]
 [  2   1]]
             precision    recall  f1-score   support

          0       0.99      0.94      0.97       297
          1       0.06      0.33      0.10         3

avg / total       0.98      0.94      0.96       300


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.990 	0.000 	0.000 	0.500 	0.000 	0.000
[[297   0]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       297
          1       0.00      0.00      0.00         3

avg / total       0.98      0.99      0.99       300


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.1, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(500,), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	0.327 	0.327 	0.663 	0.575 	0.309
[[295   2]
 [  2   1]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       297
          1       0.33      0.33      0.33         3

avg / total       0.99      0.99      0.99       300


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='entropy', max_depth=32,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=0.5, n_estimators=15, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.943 	0.125 	0.090 	0.641 	0.563 	0.297
[[282  15]
 [  2   1]]
             precision    recall  f1-score   support

          0       0.99      0.95      0.97       297
          1       0.06      0.33      0.11         3

avg / total       0.98      0.94      0.96       300


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.1, cache_size=200, class_weight={1: 500}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.940 	0.249 	0.167 	0.805 	0.793 	0.611
[[280  17]
 [  1   2]]
             precision    recall  f1-score   support

          0       1.00      0.94      0.97       297
          1       0.11      0.67      0.18         3

avg / total       0.99      0.94      0.96       300


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...wski',
           metric_params=None, n_jobs=4, n_neighbors=4, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.990 	0.000 	0.000 	0.500 	0.000 	0.000
[[297   0]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       297
          1       0.00      0.00      0.00         3

avg / total       0.98      0.99      0.99       300


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=1,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.990 	0.000 	0.000 	0.500 	0.000 	0.000
[[297   0]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       297
          1       0.00      0.00      0.00         3

avg / total       0.98      0.99      0.99       300


                estimator   min_score   mean_score  max_score     sd_score  \
0              GaussianNB   0.0793043    0.0793043  0.0793043            0   
7                     SVC   -0.035599  -0.00927658  0.0190749    0.0150341   
5           MLPClassifier  -0.0228031   -0.0159775 -0.0079231   0.00430211   
2           SGDClassifier  -0.0797998   0.00145457   0.112558    0.0285229   
6      AdaBoostClassifier  -0.0242064   0.00788271   0.134251    0.0356752   
3    ExtraTreesClassifier  -0.0280129 -0.000249378  0.0665366   0.00805008   
1      LogisticRegression  -0.0767112   -0.0135104  0.0850117    0.0243027   
4  RandomForestClassifier -0.00357313 -0.000302031          0  0.000668436   
8        VotingClassifier   -0.013379  -0.00560475          0   0.00403326   
9    KNeighborsClassifier  -0.0147174  -0.00346001          0   0.00548926   

        acc       auc           conf_matrix     f1_c0      f1_c1      kappa  \
0  0.966667  0.818182    [[288, 9], [1, 2]]  0.982935   0.285714   0.274311   
7      0.94  0.804714   [[280, 17], [1, 2]]  0.968858   0.181818   0.167438   
5  0.986667    0.6633    [[295, 2], [2, 1]]  0.993266   0.333333   0.326599   
2      0.62  0.643098  [[184, 113], [1, 2]]  0.763485  0.0338983  0.0146932   
6  0.943333  0.641414   [[282, 15], [2, 1]]   0.97074   0.105263  0.0899358   
3  0.936667  0.638047   [[280, 17], [2, 1]]  0.967185  0.0952381  0.0794574   
1  0.566667  0.616162  [[168, 129], [1, 2]]   0.72103  0.0298507  0.0105039   
4      0.99       0.5    [[297, 0], [3, 0]]  0.994975          0          0   
8      0.99       0.5    [[297, 0], [3, 0]]  0.994975          0          0   
9      0.99       0.5    [[297, 0], [3, 0]]  0.994975          0          0   

  model_score   prec_c0    prec_c1    rec_c0    rec_c1  
0    0.336898   0.99654   0.181818  0.969697  0.666667  
7    0.248961  0.996441   0.105263  0.942761  0.666667  
5    0.326599  0.993266   0.333333  0.993266  0.333333  
2   0.0585688  0.994595  0.0173913  0.619529  0.666667  
6     0.12524  0.992958     0.0625  0.949495  0.333333  
3    0.115674  0.992908  0.0555556  0.942761  0.333333  
1   0.0466071  0.994083  0.0152672  0.565657  0.666667  
4           0      0.99          0         1         0  
8           0      0.99          0         1         0  
9           0      0.99          0         1         0  
Elapsed time 21.59 mins 

************************************************************

pre/post: 0/25  win/stride: 200/25  label:end 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-05-01 21:01:41.254000 
pca_target: 60 	 poly degree: 2 	 kselect: 30 
Imbalance: ClusterCentroids(estimator=None, n_jobs=1, random_state=None, ratio='auto') 
Extended target (count):  25141 325
('Total : Processed (count): ', (998L, 780L), 12)
Final feature (count):  (998L, 780L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.990 	0.000 	0.000 	0.500 	0.000 	0.000
[[297   0]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       297
          1       0.00      0.00      0.00         3

avg / total       0.98      0.99      0.99       300


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.1, class_weight={1: 3}, dual=False, fit_intercept=True,
          intercept_scaling=0.1, max_iter=100, multi_class='ovr', n_jobs=4,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.437 	-0.112 	-0.020 	0.221 	0.000 	0.000
[[131 166]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.98      0.44      0.61       297
          1       0.00      0.00      0.00         3

avg / total       0.97      0.44      0.60       300


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.1, average=False, class_weight='balanced', epsilon=0.1,
       eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='invscaling', loss='modified_huber', n_iter=5,
       n_jobs=4, penalty='l1', power_t=0.5, random_state=None,
       shuffle=True, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.543 	0.042 	0.009 	0.604 	0.601 	0.366
[[161 136]
 [  1   2]]
             precision    recall  f1-score   support

          0       0.99      0.54      0.70       297
          1       0.01      0.67      0.03         3

avg / total       0.98      0.54      0.69       300


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=8, max_features='auto', max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=30, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.797 	0.034 	0.013 	0.567 	0.517 	0.255
[[238  59]
 [  2   1]]
             precision    recall  f1-score   support

          0       0.99      0.80      0.89       297
          1       0.02      0.33      0.03         3

avg / total       0.98      0.80      0.88       300


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight='balanced',
            criterion='entropy', max_depth=16, max_features=0.33,
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.553 	0.044 	0.010 	0.609 	0.607 	0.372
[[164 133]
 [  1   2]]
             precision    recall  f1-score   support

          0       0.99      0.55      0.71       297
          1       0.01      0.67      0.03         3

avg / total       0.98      0.55      0.70       300


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.01, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.523 	0.103 	0.021 	0.759 	0.720 	0.543
[[154 143]
 [  0   3]]
             precision    recall  f1-score   support

          0       1.00      0.52      0.68       297
          1       0.02      1.00      0.04         3

avg / total       0.99      0.52      0.68       300


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=8,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=0.5, n_estimators=80, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.803 	0.036 	0.014 	0.571 	0.519 	0.257
[[240  57]
 [  2   1]]
             precision    recall  f1-score   support

          0       0.99      0.81      0.89       297
          1       0.02      0.33      0.03         3

avg / total       0.98      0.80      0.88       300


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=1, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.990 	0.000 	0.000 	0.500 	0.000 	0.000
[[297   0]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       297
          1       0.00      0.00      0.00         3

avg / total       0.98      0.99      0.99       300


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', R...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.517 	0.036 	0.007 	0.591 	0.586 	0.349
[[153 144]
 [  1   2]]
             precision    recall  f1-score   support

          0       0.99      0.52      0.68       297
          1       0.01      0.67      0.03         3

avg / total       0.98      0.52      0.67       300


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=1,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.827 	0.044 	0.018 	0.582 	0.527 	0.263
[[247  50]
 [  2   1]]
             precision    recall  f1-score   support

          0       0.99      0.83      0.90       297
          1       0.02      0.33      0.04         3

avg / total       0.98      0.83      0.90       300


                estimator  min_score mean_score max_score   sd_score  \
5           MLPClassifier     0.2566   0.624988  0.812156   0.115132   
4  RandomForestClassifier   0.239411   0.737155         1   0.135944   
2           SGDClassifier  -0.367711   0.386398  0.906078   0.159821   
8        VotingClassifier     0.2566   0.496073  0.718234  0.0768386   
9    KNeighborsClassifier   0.111111   0.293726  0.461633   0.101411   
6      AdaBoostClassifier -0.0171889   0.656468         1     0.1897   
3    ExtraTreesClassifier   0.444444   0.844921  0.906078  0.0910131   
0              GaussianNB   0.906078   0.906078  0.906078          0   
7                     SVC          0   0.221874  0.701045   0.164614   
1      LogisticRegression          0   0.292667  0.624311   0.183183   

        acc       auc           conf_matrix     f1_c0      f1_c1       kappa  \
5  0.523333  0.759259  [[154, 143], [0, 3]]  0.682927  0.0402685   0.0210843   
4  0.553333  0.609428  [[164, 133], [1, 2]]  0.709957  0.0289855  0.00960828   
2  0.543333  0.604377  [[161, 136], [1, 2]]  0.701525  0.0283688  0.00896991   
8  0.516667  0.590909  [[153, 144], [1, 2]]  0.678492  0.0268456  0.00739321   
9  0.826667  0.582492   [[247, 50], [2, 1]]  0.904762   0.037037   0.0184975   
6  0.803333  0.570707   [[240, 57], [2, 1]]  0.890538  0.0327869   0.0140374   
3  0.796667   0.56734   [[238, 59], [2, 1]]  0.886406   0.031746    0.012945   
0      0.99       0.5    [[297, 0], [3, 0]]  0.994975          0           0   
7      0.99       0.5    [[297, 0], [3, 0]]  0.994975          0           0   
1  0.436667  0.220539  [[131, 166], [3, 0]]  0.607889          0  -0.0200386   

  model_score   prec_c0    prec_c1    rec_c0    rec_c1  
5    0.103221         1  0.0205479  0.518519         1  
4    0.043771  0.993939  0.0148148  0.552189  0.666667  
2   0.0416751  0.993827  0.0144928  0.542088  0.666667  
8   0.0361942  0.993506  0.0136986  0.515152  0.666667  
9   0.0437012  0.991968  0.0196078   0.83165  0.333333  
6   0.0356295  0.991736  0.0172414  0.808081  0.333333  
3   0.0335013  0.991667  0.0166667  0.801347  0.333333  
0           0      0.99          0         1         0  
7           0      0.99          0         1         0  
1   -0.111862  0.977612          0  0.441077         0  
Elapsed time 14.09 mins 

************************************************************

pre/post: 0/25  win/stride: 200/25  label:end 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-05-01 21:15:46.768000 
pca_target: 60 	 poly degree: 2 	 kselect: 30 
Imbalance: SMOTE(k=None, k_neighbors=5, kind='regular', m=None, m_neighbors=10, n_jobs=1,
   out_step=0.5, random_state=None, ratio='auto', svm_estimator=None) 
Extended target (count):  25141 325
('Total : Processed (count): ', (998L, 780L), 12)
Final feature (count):  (998L, 780L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.983 	0.280 	0.277 	0.662 	0.574 	0.308
[[294   3]
 [  2   1]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       297
          1       0.25      0.33      0.29         3

avg / total       0.99      0.98      0.98       300


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=10, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.957 	0.295 	0.222 	0.813 	0.800 	0.621
[[285  12]
 [  1   2]]
             precision    recall  f1-score   support

          0       1.00      0.96      0.98       297
          1       0.14      0.67      0.24         3

avg / total       0.99      0.96      0.97       300


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.001, average=False, class_weight='balanced',
       epsilon=0.1, eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='squared_hinge', n_iter=5, n_jobs=4,
       penalty='none', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.970 	0.191 	0.170 	0.655 	0.571 	0.305
[[290   7]
 [  2   1]]
             precision    recall  f1-score   support

          0       0.99      0.98      0.98       297
          1       0.12      0.33      0.18         3

avg / total       0.98      0.97      0.98       300


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=16, max_features=0.75, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=30, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.990 	0.000 	0.000 	0.500 	0.000 	0.000
[[297   0]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       297
          1       0.00      0.00      0.00         3

avg / total       0.98      0.99      0.99       300


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=50, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.990 	0.000 	0.000 	0.500 	0.000 	0.000
[[297   0]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       297
          1       0.00      0.00      0.00         3

avg / total       0.98      0.99      0.99       300


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.01, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.983 	-0.008 	-0.008 	0.497 	0.000 	0.000
[[295   2]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       297
          1       0.00      0.00      0.00         3

avg / total       0.98      0.98      0.98       300


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=1.0, n_estimators=50, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.990 	0.000 	0.000 	0.500 	0.000 	0.000
[[297   0]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       297
          1       0.00      0.00      0.00         3

avg / total       0.98      0.99      0.99       300


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.5, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.990 	0.000 	0.000 	0.500 	0.000 	0.000
[[297   0]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       297
          1       0.00      0.00      0.00         3

avg / total       0.98      0.99      0.99       300


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=10.0, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', ...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.980 	-0.010 	-0.010 	0.495 	0.000 	0.000
[[294   3]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       297
          1       0.00      0.00      0.00         3

avg / total       0.98      0.98      0.98       300


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.973 	-0.013 	-0.013 	0.492 	0.000 	0.000
[[292   5]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.98      0.99       297
          1       0.00      0.00      0.00         3

avg / total       0.98      0.97      0.98       300


                estimator min_score mean_score max_score    sd_score  \
1      LogisticRegression  0.463238   0.835214  0.950716     0.13754   
0              GaussianNB  0.982799   0.982799  0.982799           0   
2           SGDClassifier -0.312648   0.680692  0.975718    0.275636   
3    ExtraTreesClassifier  0.931672   0.994419         1   0.0121939   
4  RandomForestClassifier  0.994226   0.998956         1  0.00121396   
6      AdaBoostClassifier  0.928039   0.987227         1  0.00995979   
7                     SVC         0    0.84557         1    0.289374   
5           MLPClassifier  0.945151   0.972057  0.995662   0.0165133   
8        VotingClassifier  0.949132   0.972265  0.988492  0.00914314   
9    KNeighborsClassifier  0.898002   0.940159  0.975709   0.0262904   

        acc       auc          conf_matrix     f1_c0     f1_c1       kappa  \
1  0.956667  0.813131  [[285, 12], [1, 2]]  0.977702  0.235294    0.222488   
0  0.983333  0.661616   [[294, 3], [2, 1]]  0.991568  0.285714    0.277457   
2      0.97  0.654882   [[290, 7], [2, 1]]   0.98472  0.181818    0.169742   
3      0.99       0.5   [[297, 0], [3, 0]]  0.994975         0           0   
4      0.99       0.5   [[297, 0], [3, 0]]  0.994975         0           0   
6      0.99       0.5   [[297, 0], [3, 0]]  0.994975         0           0   
7      0.99       0.5   [[297, 0], [3, 0]]  0.994975         0           0   
5  0.983333  0.496633   [[295, 2], [3, 0]]  0.991597         0 -0.00806452   
8      0.98  0.494949   [[294, 3], [3, 0]]  0.989899         0   -0.010101   
9  0.973333  0.491582   [[292, 5], [3, 0]]  0.986486         0  -0.0126582   

  model_score   prec_c0   prec_c1    rec_c0    rec_c1  
1    0.295426  0.996503  0.142857  0.959596  0.666667  
0      0.2804  0.993243      0.25  0.989899  0.333333  
2    0.191308  0.993151     0.125  0.976431  0.333333  
3           0      0.99         0         1         0  
4           0      0.99         0         1         0  
6           0      0.99         0         1         0  
7           0      0.99         0         1         0  
5 -0.00823359  0.989933         0  0.993266         0  
8   -0.010101  0.989899         0  0.989899         0  
9  -0.0130845  0.989831         0  0.983165         0  
Elapsed time 35.10 mins 

************************************************************

pre/post: 0/25  win/stride: 200/25  label:end 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-05-01 21:50:53.014000 
pca_target: 60 	 poly degree: 2 	 kselect: 30 
Imbalance: None 
Extended target (count):  25141 325
('Total : Processed (count): ', (998L, 780L), 12)
Final feature (count):  (998L, 780L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.810 	0.120 	0.047 	0.739 	0.736 	0.533
[[241  56]
 [  1   2]]
             precision    recall  f1-score   support

          0       1.00      0.81      0.89       297
          1       0.03      0.67      0.07         3

avg / total       0.99      0.81      0.89       300


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.001, class_weight={1: 50}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.583 	0.050 	0.012 	0.625 	0.623 	0.392
[[173 124]
 [  1   2]]
             precision    recall  f1-score   support

          0       0.99      0.58      0.73       297
          1       0.02      0.67      0.03         3

avg / total       0.98      0.58      0.73       300


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.5, average=False, class_weight={1: 500}, epsilon=0.1,
       eta0=0.001, fit_intercept=True, l1_ratio=0.15,
       learning_rate='constant', loss='squared_hinge', n_iter=5, n_jobs=4,
       penalty='none', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.540 	0.041 	0.009 	0.603 	0.599 	0.364
[[160 137]
 [  1   2]]
             precision    recall  f1-score   support

          0       0.99      0.54      0.70       297
          1       0.01      0.67      0.03         3

avg / total       0.98      0.54      0.69       300


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 500}, criterion='gini',
           max_depth=8, max_features='auto', max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.907 	0.085 	0.050 	0.623 	0.552 	0.287
[[271  26]
 [  2   1]]
             precision    recall  f1-score   support

          0       0.99      0.91      0.95       297
          1       0.04      0.33      0.07         3

avg / total       0.98      0.91      0.94       300


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.990 	0.000 	0.000 	0.500 	0.000 	0.000
[[297   0]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       297
          1       0.00      0.00      0.00         3

avg / total       0.98      0.99      0.99       300


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.01, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.990 	0.403 	0.395 	0.665 	0.576 	0.310
[[296   1]
 [  2   1]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       297
          1       0.50      0.33      0.40         3

avg / total       0.99      0.99      0.99       300


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=16,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=2.0, n_estimators=80, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.983 	0.280 	0.277 	0.662 	0.574 	0.308
[[294   3]
 [  2   1]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       297
          1       0.25      0.33      0.29         3

avg / total       0.99      0.98      0.98       300


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.01, cache_size=200, class_weight={1: 500}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.470 	0.027 	0.005 	0.567 	0.559 	0.318
[[139 158]
 [  1   2]]
             precision    recall  f1-score   support

          0       0.99      0.47      0.64       297
          1       0.01      0.67      0.02         3

avg / total       0.98      0.47      0.63       300


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...wski',
           metric_params=None, n_jobs=4, n_neighbors=4, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.990 	0.000 	0.000 	0.500 	0.000 	0.000
[[297   0]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       297
          1       0.00      0.00      0.00         3

avg / total       0.98      0.99      0.99       300


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=1,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.990 	0.000 	0.000 	0.500 	0.000 	0.000
[[297   0]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       297
          1       0.00      0.00      0.00         3

avg / total       0.98      0.99      0.99       300


                estimator   min_score   mean_score   max_score    sd_score  \
0              GaussianNB    0.107982     0.107982    0.107982           0   
5           MLPClassifier  -0.0192984   -0.0147584 -0.00870709  0.00330015   
6      AdaBoostClassifier  -0.0211017  -0.00436004    0.131128   0.0189774   
1      LogisticRegression  -0.0574264  8.54742e-05    0.129768    0.041311   
3    ExtraTreesClassifier  -0.0259528  -0.00119651   0.0841647   0.0088727   
2           SGDClassifier   -0.102929    0.0188436    0.132771   0.0480965   
7                     SVC  -0.0333267   -0.0115384     0.10374    0.016934   
4  RandomForestClassifier -0.00349117 -0.000370656           0  0.00070946   
8        VotingClassifier  -0.0168382   -0.0071278           0  0.00416756   
9    KNeighborsClassifier  -0.0120641  -0.00316439           0  0.00468228   

        acc       auc           conf_matrix     f1_c0      f1_c1       kappa  \
0      0.81  0.739057   [[241, 56], [1, 2]]  0.894249  0.0655738   0.0474599   
5      0.99  0.664983    [[296, 1], [2, 1]]  0.994958        0.4    0.395161   
6  0.983333  0.661616    [[294, 3], [2, 1]]  0.991568   0.285714    0.277457   
1  0.583333  0.624579  [[173, 124], [1, 2]]  0.734607  0.0310078   0.0117015   
3  0.906667  0.622896   [[271, 26], [2, 1]]  0.950877  0.0666667   0.0495587   
2      0.54  0.602694  [[160, 137], [1, 2]]   0.69869   0.028169  0.00876311   
7      0.47   0.56734  [[139, 158], [1, 2]]  0.636156  0.0245399  0.00500626   
4      0.99       0.5    [[297, 0], [3, 0]]  0.994975          0           0   
8      0.99       0.5    [[297, 0], [3, 0]]  0.994975          0           0   
9      0.99       0.5    [[297, 0], [3, 0]]  0.994975          0           0   

  model_score   prec_c0    prec_c1    rec_c0    rec_c1  
0    0.120462  0.995868  0.0344828  0.811448  0.666667  
5    0.403446  0.993289        0.5  0.996633  0.333333  
6      0.2804  0.993243       0.25  0.989899  0.333333  
1    0.050229  0.994253   0.015873  0.582492  0.666667  
3   0.0854559  0.992674   0.037037  0.912458  0.333333  
2   0.0409819  0.993789  0.0143885  0.538721  0.666667  
7   0.0268608  0.992857     0.0125  0.468013  0.666667  
4           0      0.99          0         1         0  
8           0      0.99          0         1         0  
9           0      0.99          0         1         0  
Elapsed time 23.84 mins 

************************************************************

pre/post: 0/25  win/stride: 200/25  label:end 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-05-01 22:14:43.377000 
pca_target: 60 	 poly degree: 2 	 kselect: 60 
Imbalance: ClusterCentroids(estimator=None, n_jobs=1, random_state=None, ratio='auto') 
Extended target (count):  25141 325
('Total : Processed (count): ', (998L, 780L), 12)
Final feature (count):  (998L, 780L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.990 	0.000 	0.000 	0.500 	0.000 	0.000
[[297   0]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       297
          1       0.00      0.00      0.00         3

avg / total       0.98      0.99      0.99       300


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=5, class_weight={1: 15}, dual=False, fit_intercept=True,
          intercept_scaling=0.1, max_iter=100, multi_class='ovr', n_jobs=4,
          penalty='l2', random_state=None, solver='sag', tol=0.0001,
          verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.483 	0.030 	0.006 	0.574 	0.567 	0.327
[[143 154]
 [  1   2]]
             precision    recall  f1-score   support

          0       0.99      0.48      0.65       297
          1       0.01      0.67      0.03         3

avg / total       0.98      0.48      0.64       300


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.0001, average=False, class_weight='balanced',
       epsilon=0.1, eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='invscaling', loss='squared_hinge', n_iter=5,
       n_jobs=4, penalty='l2', power_t=0.5, random_state=None,
       shuffle=True, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.597 	0.053 	0.013 	0.631 	0.630 	0.400
[[177 120]
 [  1   2]]
             precision    recall  f1-score   support

          0       0.99      0.60      0.75       297
          1       0.02      0.67      0.03         3

avg / total       0.98      0.60      0.74       300


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=8, max_features=0.75, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=50, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.613 	0.057 	0.014 	0.640 	0.639 	0.411
[[182 115]
 [  1   2]]
             precision    recall  f1-score   support

          0       0.99      0.61      0.76       297
          1       0.02      0.67      0.03         3

avg / total       0.98      0.61      0.75       300


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 50}, criterion='gini',
            max_depth=32, max_features=0.75, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=30, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.647 	0.065 	0.017 	0.657 	0.656 	0.432
[[192 105]
 [  1   2]]
             precision    recall  f1-score   support

          0       0.99      0.65      0.78       297
          1       0.02      0.67      0.04         3

avg / total       0.99      0.65      0.78       300


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.01, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.497 	0.032 	0.006 	0.581 	0.574 	0.336
[[147 150]
 [  1   2]]
             precision    recall  f1-score   support

          0       0.99      0.49      0.66       297
          1       0.01      0.67      0.03         3

avg / total       0.98      0.50      0.65       300


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=32,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=2.0, n_estimators=15, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.550 	0.043 	0.009 	0.608 	0.605 	0.370
[[163 134]
 [  1   2]]
             precision    recall  f1-score   support

          0       0.99      0.55      0.71       297
          1       0.01      0.67      0.03         3

avg / total       0.98      0.55      0.70       300


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=1, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.990 	0.000 	0.000 	0.500 	0.000 	0.000
[[297   0]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       297
          1       0.00      0.00      0.00         3

avg / total       0.98      0.99      0.99       300


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', R...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.423 	0.018 	0.003 	0.544 	0.530 	0.287
[[125 172]
 [  1   2]]
             precision    recall  f1-score   support

          0       0.99      0.42      0.59       297
          1       0.01      0.67      0.02         3

avg / total       0.98      0.42      0.59       300


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=6, p=1,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.750 	0.020 	0.007 	0.544 	0.501 	0.241
[[224  73]
 [  2   1]]
             precision    recall  f1-score   support

          0       0.99      0.75      0.86       297
          1       0.01      0.33      0.03         3

avg / total       0.98      0.75      0.85       300


                estimator  min_score  mean_score max_score   sd_score  \
4  RandomForestClassifier   0.111111    0.675078         1    0.14637   
3    ExtraTreesClassifier   0.111111    0.679236  0.906078   0.117079   
2           SGDClassifier  -0.402089    0.312851  0.718234   0.169498   
6      AdaBoostClassifier  -0.145489    0.541989         1   0.196924   
5           MLPClassifier  0.0939222    0.204357  0.496011   0.120228   
1      LogisticRegression          0    0.326081  0.624311   0.186528   
8        VotingClassifier     0.2566    0.528799  0.701045  0.0915455   
9    KNeighborsClassifier    -0.1283    0.209932  0.683856   0.235213   
0              GaussianNB   0.906078    0.906078  0.906078          0   
7                     SVC  -0.812156  0.00702874  0.461633   0.282718   

        acc       auc           conf_matrix     f1_c0      f1_c1       kappa  \
4  0.646667  0.656566  [[192, 105], [1, 2]]  0.783673  0.0363636   0.0172446   
3  0.613333  0.639731  [[182, 115], [1, 2]]  0.758333  0.0333333   0.0141084   
2  0.596667  0.631313  [[177, 120], [1, 2]]  0.745263      0.032   0.0127285   
6      0.55  0.607744  [[163, 134], [1, 2]]  0.707158   0.028777  0.00939243   
5  0.496667  0.580808  [[147, 150], [1, 2]]  0.660674  0.0258065  0.00631745   
1  0.483333  0.574074  [[143, 154], [1, 2]]  0.648526  0.0251572  0.00564537   
8  0.423333  0.543771  [[125, 172], [1, 2]]  0.591017  0.0225989  0.00299677   
9      0.75  0.543771   [[224, 73], [2, 1]]  0.856597   0.025974  0.00688559   
0      0.99       0.5    [[297, 0], [3, 0]]  0.994975          0           0   
7      0.99       0.5    [[297, 0], [3, 0]]  0.994975          0           0   

  model_score   prec_c0    prec_c1    rec_c0    rec_c1  
4   0.0650421  0.994819  0.0186916  0.646465  0.666667  
3   0.0570088  0.994536   0.017094  0.612795  0.666667  
2    0.053197  0.994382  0.0163934   0.59596  0.666667  
6   0.0430696  0.993902  0.0147059  0.548822  0.666667  
5   0.0321641  0.993243  0.0131579  0.494949  0.666667  
1   0.0295047  0.993056  0.0128205  0.481481  0.666667  
8    0.017648  0.992063  0.0114943  0.420875  0.666667  
9   0.0202062   0.99115  0.0135135  0.754209  0.333333  
0           0      0.99          0         1         0  
7           0      0.99          0         1         0  
Elapsed time 15.03 mins 

************************************************************

pre/post: 0/25  win/stride: 200/25  label:end 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-05-01 22:29:44.943000 
pca_target: 60 	 poly degree: 2 	 kselect: 60 
Imbalance: SMOTE(k=None, k_neighbors=5, kind='regular', m=None, m_neighbors=10, n_jobs=1,
   out_step=0.5, random_state=None, ratio='auto', svm_estimator=None) 
Extended target (count):  25141 325
('Total : Processed (count): ', (998L, 780L), 12)
Final feature (count):  (998L, 780L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.977 	0.225 	0.212 	0.658 	0.572 	0.306
[[292   5]
 [  2   1]]
             precision    recall  f1-score   support

          0       0.99      0.98      0.99       297
          1       0.17      0.33      0.22         3

avg / total       0.98      0.98      0.98       300


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=10, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.957 	0.295 	0.222 	0.813 	0.800 	0.621
[[285  12]
 [  1   2]]
             precision    recall  f1-score   support

          0       1.00      0.96      0.98       297
          1       0.14      0.67      0.24         3

avg / total       0.99      0.96      0.97       300


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.0001, average=False, class_weight='balanced',
       epsilon=0.1, eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='squared_hinge', n_iter=5, n_jobs=4,
       penalty='l1', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.967 	0.337 	0.274 	0.818 	0.804 	0.627
[[288   9]
 [  1   2]]
             precision    recall  f1-score   support

          0       1.00      0.97      0.98       297
          1       0.18      0.67      0.29         3

avg / total       0.99      0.97      0.98       300


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=8, max_features=0.75, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	-0.006 	-0.005 	0.498 	0.000 	0.000
[[296   1]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       297
          1       0.00      0.00      0.00         3

avg / total       0.98      0.99      0.98       300


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.990 	0.000 	0.000 	0.500 	0.000 	0.000
[[297   0]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       297
          1       0.00      0.00      0.00         3

avg / total       0.98      0.99      0.99       300


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.01, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	0.327 	0.327 	0.663 	0.575 	0.309
[[295   2]
 [  2   1]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       297
          1       0.33      0.33      0.33         3

avg / total       0.99      0.99      0.99       300


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=0.5, n_estimators=15, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.990 	0.000 	0.000 	0.500 	0.000 	0.000
[[297   0]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       297
          1       0.00      0.00      0.00         3

avg / total       0.98      0.99      0.99       300


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.1, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.990 	0.000 	0.000 	0.500 	0.000 	0.000
[[297   0]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       297
          1       0.00      0.00      0.00         3

avg / total       0.98      0.99      0.99       300


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=10.0, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Ran...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.983 	0.464 	0.437 	0.827 	0.811 	0.637
[[293   4]
 [  1   2]]
             precision    recall  f1-score   support

          0       1.00      0.99      0.99       297
          1       0.33      0.67      0.44         3

avg / total       0.99      0.98      0.99       300


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=3,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.973 	-0.013 	-0.013 	0.492 	0.000 	0.000
[[292   5]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.98      0.99       297
          1       0.00      0.00      0.00         3

avg / total       0.98      0.97      0.98       300


                estimator  min_score mean_score max_score     sd_score  \
8        VotingClassifier   0.943608   0.970151  0.987096   0.00925377   
2           SGDClassifier -0.0497431   0.673367   0.97432     0.273578   
1      LogisticRegression   0.473781   0.835482  0.949319     0.136011   
5           MLPClassifier   0.943736   0.972308  0.998554    0.0154034   
0              GaussianNB   0.971575   0.971575  0.971575            0   
4  RandomForestClassifier   0.995651   0.999478         1  0.000845138   
6      AdaBoostClassifier   0.919974   0.987617         1   0.00898578   
7                     SVC          0   0.844133  0.998554     0.290365   
3    ExtraTreesClassifier   0.919419   0.993844         1    0.0144204   
9    KNeighborsClassifier   0.891453   0.935676  0.974313    0.0281104   

        acc       auc          conf_matrix     f1_c0     f1_c1       kappa  \
8  0.983333  0.826599   [[293, 4], [1, 2]]   0.99154  0.444444    0.436937   
2  0.966667  0.818182   [[288, 9], [1, 2]]  0.982935  0.285714    0.274311   
1  0.956667  0.813131  [[285, 12], [1, 2]]  0.977702  0.235294    0.222488   
5  0.986667    0.6633   [[295, 2], [2, 1]]  0.993266  0.333333    0.326599   
0  0.976667  0.658249   [[292, 5], [2, 1]]  0.988156  0.222222    0.211712   
4      0.99       0.5   [[297, 0], [3, 0]]  0.994975         0           0   
6      0.99       0.5   [[297, 0], [3, 0]]  0.994975         0           0   
7      0.99       0.5   [[297, 0], [3, 0]]  0.994975         0           0   
3  0.986667  0.498316   [[296, 1], [3, 0]]  0.993289         0 -0.00502513   
9  0.973333  0.491582   [[292, 5], [3, 0]]  0.986486         0  -0.0126582   

  model_score   prec_c0   prec_c1    rec_c0    rec_c1  
8    0.464232  0.996599  0.333333  0.986532  0.666667  
2    0.336898   0.99654  0.181818  0.969697  0.666667  
1    0.295426  0.996503  0.142857  0.959596  0.666667  
5    0.326599  0.993266  0.333333  0.993266  0.333333  
0    0.224937  0.993197  0.166667  0.983165  0.333333  
4           0      0.99         0         1         0  
6           0      0.99         0         1         0  
7           0      0.99         0         1         0  
3 -0.00581228  0.989967         0  0.996633         0  
9  -0.0130845  0.989831         0  0.983165         0  
Elapsed time 42.51 mins 

************************************************************

pre/post: 0/25  win/stride: 200/25  label:end 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-05-01 23:12:15.276000 
pca_target: 60 	 poly degree: 2 	 kselect: 60 
Imbalance: None 
Extended target (count):  25141 325
('Total : Processed (count): ', (998L, 780L), 12)
Final feature (count):  (998L, 780L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.730 	0.089 	0.028 	0.699 	0.698 	0.484
[[217  80]
 [  1   2]]
             precision    recall  f1-score   support

          0       1.00      0.73      0.84       297
          1       0.02      0.67      0.05         3

avg / total       0.99      0.73      0.83       300


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.01, class_weight={1: 500}, dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='sag', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.540 	0.041 	0.009 	0.603 	0.599 	0.364
[[160 137]
 [  1   2]]
             precision    recall  f1-score   support

          0       0.99      0.54      0.70       297
          1       0.01      0.67      0.03         3

avg / total       0.98      0.54      0.69       300


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.001, average=False, class_weight={1: 50}, epsilon=0.1,
       eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='constant', loss='perceptron', n_iter=5, n_jobs=4,
       penalty='l1', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.760 	0.099 	0.034 	0.714 	0.712 	0.503
[[226  71]
 [  1   2]]
             precision    recall  f1-score   support

          0       1.00      0.76      0.86       297
          1       0.03      0.67      0.05         3

avg / total       0.99      0.76      0.85       300


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 500}, criterion='gini',
           max_depth=8, max_features='auto', max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=50, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.850 	0.143 	0.064 	0.759 	0.754 	0.557
[[253  44]
 [  1   2]]
             precision    recall  f1-score   support

          0       1.00      0.85      0.92       297
          1       0.04      0.67      0.08         3

avg / total       0.99      0.85      0.91       300


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.990 	0.000 	0.000 	0.500 	0.000 	0.000
[[297   0]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       297
          1       0.00      0.00      0.00         3

avg / total       0.98      0.99      0.99       300


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.983 	0.280 	0.277 	0.662 	0.574 	0.308
[[294   3]
 [  2   1]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       297
          1       0.25      0.33      0.29         3

avg / total       0.99      0.98      0.98       300


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='entropy', max_depth=8,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=0.5, n_estimators=80, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	-0.006 	-0.005 	0.498 	0.000 	0.000
[[296   1]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       297
          1       0.00      0.00      0.00         3

avg / total       0.98      0.99      0.98       300


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.01, cache_size=200, class_weight={1: 500}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.490 	0.031 	0.006 	0.577 	0.571 	0.331
[[145 152]
 [  1   2]]
             precision    recall  f1-score   support

          0       0.99      0.49      0.65       297
          1       0.01      0.67      0.03         3

avg / total       0.98      0.49      0.65       300


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...wski',
           metric_params=None, n_jobs=4, n_neighbors=4, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.990 	0.000 	0.000 	0.500 	0.000 	0.000
[[297   0]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       297
          1       0.00      0.00      0.00         3

avg / total       0.98      0.99      0.99       300


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=1,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.990 	0.000 	0.000 	0.500 	0.000 	0.000
[[297   0]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       297
          1       0.00      0.00      0.00         3

avg / total       0.98      0.99      0.99       300


                estimator   min_score   mean_score   max_score     sd_score  \
3    ExtraTreesClassifier  -0.0280078  -0.00188943   0.0950039    0.0103448   
2           SGDClassifier   -0.083945    0.0192567    0.145482    0.0475668   
0              GaussianNB    0.130704     0.130704    0.130704            0   
5           MLPClassifier  -0.0196506   -0.0141758 -0.00813919   0.00322937   
1      LogisticRegression  -0.0596238 -0.000462118    0.123973    0.0402205   
7                     SVC  -0.0396078   -0.0120347    0.106326    0.0179341   
4  RandomForestClassifier -0.00581371 -0.000395798           0  0.000778366   
8        VotingClassifier  -0.0173441   -0.0066441           0   0.00458489   
9    KNeighborsClassifier  -0.0141122  -0.00331722           0   0.00528112   
6      AdaBoostClassifier  -0.0197618  -0.00636622    0.139267     0.017043   

        acc       auc           conf_matrix     f1_c0      f1_c1       kappa  \
3      0.85  0.759259   [[253, 44], [1, 2]]   0.91833  0.0816327   0.0640599   
2      0.76  0.713805   [[226, 71], [1, 2]]  0.862595  0.0526316   0.0340757   
0      0.73  0.698653   [[217, 80], [1, 2]]  0.842718  0.0470588   0.0283109   
5  0.983333  0.661616    [[294, 3], [2, 1]]  0.991568   0.285714    0.277457   
1      0.54  0.602694  [[160, 137], [1, 2]]   0.69869   0.028169  0.00876311   
7      0.49  0.577441  [[145, 152], [1, 2]]  0.654628  0.0254777  0.00597713   
4      0.99       0.5    [[297, 0], [3, 0]]  0.994975          0           0   
8      0.99       0.5    [[297, 0], [3, 0]]  0.994975          0           0   
9      0.99       0.5    [[297, 0], [3, 0]]  0.994975          0           0   
6  0.986667  0.498316    [[296, 1], [3, 0]]  0.993289          0 -0.00502513   

  model_score   prec_c0    prec_c1    rec_c0    rec_c1  
3    0.143188  0.996063  0.0434783  0.851852  0.666667  
2   0.0991543  0.995595  0.0273973  0.760943  0.666667  
0   0.0887011  0.995413  0.0243902   0.73064  0.666667  
5      0.2804  0.993243       0.25  0.989899  0.333333  
1   0.0409819  0.993789  0.0143885  0.538721  0.666667  
7   0.0308321  0.993151   0.012987  0.488215  0.666667  
4           0      0.99          0         1         0  
8           0      0.99          0         1         0  
9           0      0.99          0         1         0  
6 -0.00581228  0.989967          0  0.996633         0  
Elapsed time 26.59 mins 

************************************************************




Standard, NT+, lagged(3,4)x2, truncated fileid=2


    pca = [0, 60]
    poly = [0]
    ksel = [0, 20]
    imb = [ClusterCentroids(), SMOTE(), None]





pre/post: 0/25  win/stride: 200/25  label:end 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-05-02 11:03:20.337000 
pca_target: 0 	 poly degree: 0 	 kselect: 0 
Imbalance: ClusterCentroids(estimator=None, n_jobs=1, random_state=None, ratio='auto') 
Extended target (count):  25141 325
('Total : Processed (count): ', (998L, 24L), 12)
Final feature (count):  (998L, 24L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.567 	0.047 	0.011 	0.616 	0.614 	0.381
[[168 129]
 [  1   2]]
             precision    recall  f1-score   support

          0       0.99      0.57      0.72       297
          1       0.02      0.67      0.03         3

avg / total       0.98      0.57      0.71       300


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.001, class_weight={1: 3}, dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.403 	0.014 	0.002 	0.534 	0.517 	0.274
[[119 178]
 [  1   2]]
             precision    recall  f1-score   support

          0       0.99      0.40      0.57       297
          1       0.01      0.67      0.02         3

avg / total       0.98      0.40      0.57       300


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.0001, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='squared_hinge', n_iter=5, n_jobs=4,
       penalty='none', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.413 	0.016 	0.003 	0.539 	0.523 	0.281
[[122 175]
 [  1   2]]
             precision    recall  f1-score   support

          0       0.99      0.41      0.58       297
          1       0.01      0.67      0.02         3

avg / total       0.98      0.41      0.58       300


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3},
           criterion='entropy', max_depth=16, max_features=0.75,
           max_leaf_nodes=None, min_impurity_split=1e-07,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=15, n_jobs=4,
           oob_score=False, random_state=None, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.600 	0.054 	0.013 	0.633 	0.632 	0.402
[[178 119]
 [  1   2]]
             precision    recall  f1-score   support

          0       0.99      0.60      0.75       297
          1       0.02      0.67      0.03         3

avg / total       0.98      0.60      0.74       300


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=16, max_features=0.75, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=30, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.480 	0.029 	0.005 	0.572 	0.565 	0.325
[[142 155]
 [  1   2]]
             precision    recall  f1-score   support

          0       0.99      0.48      0.65       297
          1       0.01      0.67      0.03         3

avg / total       0.98      0.48      0.64       300


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.743 	0.093 	0.031 	0.705 	0.704 	0.492
[[221  76]
 [  1   2]]
             precision    recall  f1-score   support

          0       1.00      0.74      0.85       297
          1       0.03      0.67      0.05         3

avg / total       0.99      0.74      0.84       300


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='entropy', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=2.0, n_estimators=50, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.747 	0.094 	0.031 	0.707 	0.706 	0.494
[[222  75]
 [  1   2]]
             precision    recall  f1-score   support

          0       1.00      0.75      0.85       297
          1       0.03      0.67      0.05         3

avg / total       0.99      0.75      0.85       300


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='linear',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.340 	0.071 	0.010 	0.667 	0.577 	0.356
[[ 99 198]
 [  0   3]]
             precision    recall  f1-score   support

          0       1.00      0.33      0.50       297
          1       0.01      1.00      0.03         3

avg / total       0.99      0.34      0.50       300


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...owski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='uniform'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.473 	0.028 	0.005 	0.569 	0.561 	0.320
[[140 157]
 [  1   2]]
             precision    recall  f1-score   support

          0       0.99      0.47      0.64       297
          1       0.01      0.67      0.02         3

avg / total       0.98      0.47      0.63       300


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=3, p=1,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.563 	-0.020 	-0.005 	0.449 	0.434 	0.184
[[168 129]
 [  2   1]]
             precision    recall  f1-score   support

          0       0.99      0.57      0.72       297
          1       0.01      0.33      0.02         3

avg / total       0.98      0.56      0.71       300


                estimator  min_score  mean_score  max_score   sd_score  \
6      AdaBoostClassifier   0.111111    0.659407   0.906078   0.140164   
5           MLPClassifier  -0.367711   -0.135167  0.0171889  0.0854916   
7                     SVC  -0.812156  0.00570927   0.478822    0.29584   
3    ExtraTreesClassifier  -0.239411    0.476547   0.906078   0.212939   
0              GaussianNB   0.906078    0.906078   0.906078          0   
4  RandomForestClassifier  0.0939222    0.544515   0.906078   0.151598   
8        VotingClassifier    -0.1283    0.288442   0.589933   0.154438   
2           SGDClassifier  -0.496011    0.190672   0.496011   0.162197   
1      LogisticRegression  -0.624311    0.141858   0.496011    0.20991   
9    KNeighborsClassifier  -0.572745   -0.185122   0.350522   0.232783   

        acc       auc           conf_matrix     f1_c0      f1_c1       kappa  \
6  0.746667  0.707071   [[222, 75], [1, 2]]  0.853846       0.05   0.0313536   
5  0.743333  0.705387   [[221, 76], [1, 2]]  0.851638  0.0493827    0.030715   
7      0.34  0.666667   [[99, 198], [0, 3]]       0.5  0.0294118  0.00990099   
3       0.6  0.632997  [[178, 119], [1, 2]]  0.747899  0.0322581   0.0129956   
0  0.566667  0.616162  [[168, 129], [1, 2]]   0.72103  0.0298507   0.0105039   
4      0.48  0.572391  [[142, 155], [1, 2]]  0.645455      0.025   0.0054826   
8  0.473333  0.569024  [[140, 157], [1, 2]]  0.639269  0.0246914  0.00516308   
2  0.413333  0.538721  [[122, 175], [1, 2]]  0.580952  0.0222222  0.00260682   
1  0.403333   0.53367  [[119, 178], [1, 2]]  0.570743  0.0218579  0.00222965   
9  0.563333  0.449495  [[168, 129], [2, 1]]  0.719486  0.0150376 -0.00460123   

  model_score   prec_c0     prec_c1    rec_c0    rec_c1  
6   0.0943387  0.995516    0.025974  0.747475  0.666667  
5   0.0931791  0.995495    0.025641  0.744108  0.666667  
7   0.0705346         1   0.0149254  0.333333         1  
3   0.0539499  0.994413   0.0165289  0.599327  0.666667  
0   0.0466071  0.994083   0.0152672  0.565657  0.666667  
4   0.0288425  0.993007   0.0127389  0.478114  0.666667  
8   0.0275206  0.992908   0.0125786   0.47138  0.666667  
2   0.0156665   0.99187   0.0112994  0.410774  0.666667  
1   0.0136768  0.991667   0.0111111  0.400673  0.666667  
9  -0.0202818  0.988235  0.00769231  0.565657  0.333333  
Elapsed time 14.96 mins 

************************************************************

pre/post: 0/25  win/stride: 200/25  label:end 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-05-02 11:18:17.645000 
pca_target: 0 	 poly degree: 0 	 kselect: 0 
Imbalance: SMOTE(k=None, k_neighbors=5, kind='regular', m=None, m_neighbors=10, n_jobs=1,
   out_step=0.5, random_state=None, ratio='auto', svm_estimator=None) 
Extended target (count):  25141 325
('Total : Processed (count): ', (998L, 24L), 12)
Final feature (count):  (998L, 24L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.610 	0.056 	0.014 	0.638 	0.637 	0.409
[[181 116]
 [  1   2]]
             precision    recall  f1-score   support

          0       0.99      0.61      0.76       297
          1       0.02      0.67      0.03         3

avg / total       0.98      0.61      0.75       300


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=10, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.893 	0.179 	0.095 	0.781 	0.773 	0.583
[[266  31]
 [  1   2]]
             precision    recall  f1-score   support

          0       1.00      0.90      0.94       297
          1       0.06      0.67      0.11         3

avg / total       0.99      0.89      0.93       300


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.001, average=False, class_weight='balanced',
       epsilon=0.1, eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='perceptron', n_iter=5, n_jobs=4,
       penalty='none', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.937 	0.242 	0.159 	0.803 	0.791 	0.609
[[279  18]
 [  1   2]]
             precision    recall  f1-score   support

          0       1.00      0.94      0.97       297
          1       0.10      0.67      0.17         3

avg / total       0.99      0.94      0.96       300


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight='balanced',
           criterion='gini', max_depth=32, max_features=0.75,
           max_leaf_nodes=None, min_impurity_split=1e-07,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=4,
           oob_score=False, random_state=None, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.980 	-0.010 	-0.010 	0.495 	0.000 	0.000
[[294   3]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       297
          1       0.00      0.00      0.00         3

avg / total       0.98      0.98      0.98       300


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight='balanced',
            criterion='gini', max_depth=32, max_features='auto',
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.973 	-0.013 	-0.013 	0.492 	0.000 	0.000
[[292   5]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.98      0.99       297
          1       0.00      0.00      0.00         3

avg / total       0.98      0.97      0.98       300


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.983 	0.280 	0.277 	0.662 	0.574 	0.308
[[294   3]
 [  2   1]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       297
          1       0.25      0.33      0.29         3

avg / total       0.99      0.98      0.98       300


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 50}, criterion='entropy', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=1.0, n_estimators=80, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.983 	0.280 	0.277 	0.662 	0.574 	0.308
[[294   3]
 [  2   1]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       297
          1       0.25      0.33      0.29         3

avg / total       0.99      0.98      0.98       300


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=10, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.990 	0.403 	0.395 	0.665 	0.576 	0.310
[[296   1]
 [  2   1]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       297
          1       0.50      0.33      0.40         3

avg / total       0.99      0.99      0.99       300


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=10.0, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', ...owski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='uniform'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.963 	0.168 	0.141 	0.652 	0.569 	0.303
[[288   9]
 [  2   1]]
             precision    recall  f1-score   support

          0       0.99      0.97      0.98       297
          1       0.10      0.33      0.15         3

avg / total       0.98      0.96      0.97       300


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=1,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.957 	0.150 	0.119 	0.648 	0.567 	0.301
[[286  11]
 [  2   1]]
             precision    recall  f1-score   support

          0       0.99      0.96      0.98       297
          1       0.08      0.33      0.13         3

avg / total       0.98      0.96      0.97       300


                estimator  min_score mean_score max_score    sd_score  \
2           SGDClassifier -0.0933142   0.502659  0.898074    0.227386   
1      LogisticRegression    0.14364   0.649253  0.886172    0.169129   
7                     SVC          0   0.758305  0.989948    0.242731   
5           MLPClassifier   0.964416   0.975176  0.984215  0.00556225   
6      AdaBoostClassifier   0.879184   0.954107  0.984184   0.0212468   
8        VotingClassifier   0.864358   0.922113  0.958894   0.0224719   
9    KNeighborsClassifier   0.840446   0.900554  0.958978   0.0339912   
0              GaussianNB   0.667934   0.667934  0.667934           0   
3    ExtraTreesClassifier   0.702575   0.910464   0.98562   0.0793518   
4  RandomForestClassifier   0.870462   0.943969  0.972701   0.0251016   

        acc       auc           conf_matrix     f1_c0      f1_c1      kappa  \
2  0.936667   0.80303   [[279, 18], [1, 2]]  0.967071   0.173913   0.159292   
1  0.893333  0.781145   [[266, 31], [1, 2]]  0.943262   0.111111  0.0945105   
7      0.99  0.664983    [[296, 1], [2, 1]]  0.994958        0.4   0.395161   
5  0.983333  0.661616    [[294, 3], [2, 1]]  0.991568   0.285714   0.277457   
6  0.983333  0.661616    [[294, 3], [2, 1]]  0.991568   0.285714   0.277457   
8  0.963333  0.651515    [[288, 9], [2, 1]]  0.981261   0.153846   0.140625   
9  0.956667  0.648148   [[286, 11], [2, 1]]  0.977778   0.133333   0.119241   
0      0.61  0.638047  [[181, 116], [1, 2]]  0.755741  0.0330579  0.0138233   
3      0.98  0.494949    [[294, 3], [3, 0]]  0.989899          0  -0.010101   
4  0.973333  0.491582    [[292, 5], [3, 0]]  0.986486          0 -0.0126582   

  model_score   prec_c0    prec_c1    rec_c0    rec_c1  
2    0.241747  0.996429        0.1  0.939394  0.666667  
1    0.178808  0.996255  0.0606061  0.895623  0.666667  
7    0.403446  0.993289        0.5  0.996633  0.333333  
5      0.2804  0.993243       0.25  0.989899  0.333333  
6      0.2804  0.993243       0.25  0.989899  0.333333  
8    0.167968  0.993103        0.1  0.969697  0.333333  
9    0.150445  0.993056  0.0833333  0.962963  0.333333  
0   0.0562367  0.994505  0.0169492  0.609428  0.666667  
3   -0.010101  0.989899          0  0.989899         0  
4  -0.0130845  0.989831          0  0.983165         0  
Elapsed time 35.08 mins 

************************************************************

pre/post: 0/25  win/stride: 200/25  label:end 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-05-02 11:53:22.652000 
pca_target: 0 	 poly degree: 0 	 kselect: 0 
Imbalance: None 
Extended target (count):  25141 325
('Total : Processed (count): ', (998L, 24L), 12)
Final feature (count):  (998L, 24L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.583 	0.050 	0.012 	0.625 	0.623 	0.392
[[173 124]
 [  1   2]]
             precision    recall  f1-score   support

          0       0.99      0.58      0.73       297
          1       0.02      0.67      0.03         3

avg / total       0.98      0.58      0.73       300


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=10, class_weight={1: 500}, dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.747 	0.094 	0.031 	0.707 	0.706 	0.494
[[222  75]
 [  1   2]]
             precision    recall  f1-score   support

          0       1.00      0.75      0.85       297
          1       0.03      0.67      0.05         3

avg / total       0.99      0.75      0.85       300


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.0001, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='perceptron', n_iter=5, n_jobs=4,
       penalty='none', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.947 	0.265 	0.186 	0.808 	0.796 	0.615
[[282  15]
 [  1   2]]
             precision    recall  f1-score   support

          0       1.00      0.95      0.97       297
          1       0.12      0.67      0.20         3

avg / total       0.99      0.95      0.96       300


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 500}, criterion='gini',
           max_depth=8, max_features=0.33, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.773 	0.104 	0.037 	0.721 	0.719 	0.511
[[230  67]
 [  1   2]]
             precision    recall  f1-score   support

          0       1.00      0.77      0.87       297
          1       0.03      0.67      0.06         3

avg / total       0.99      0.77      0.86       300


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 500},
            criterion='gini', max_depth=8, max_features='auto',
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=15, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.950 	-0.021 	-0.016 	0.480 	0.000 	0.000
[[285  12]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.96      0.97       297
          1       0.00      0.00      0.00         3

avg / total       0.98      0.95      0.96       300


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.980 	-0.010 	-0.010 	0.495 	0.000 	0.000
[[294   3]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       297
          1       0.00      0.00      0.00         3

avg / total       0.98      0.98      0.98       300


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=16,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=1.0, n_estimators=80, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.977 	-0.012 	-0.012 	0.493 	0.000 	0.000
[[293   4]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       297
          1       0.00      0.00      0.00         3

avg / total       0.98      0.98      0.98       300


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.5, cache_size=200, class_weight='balanced', coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='linear',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.793 	0.113 	0.042 	0.731 	0.728 	0.523
[[236  61]
 [  1   2]]
             precision    recall  f1-score   support

          0       1.00      0.79      0.88       297
          1       0.03      0.67      0.06         3

avg / total       0.99      0.79      0.88       300


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.990 	0.000 	0.000 	0.500 	0.000 	0.000
[[297   0]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       297
          1       0.00      0.00      0.00         3

avg / total       0.98      0.99      0.99       300


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=1,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.990 	0.000 	0.000 	0.500 	0.000 	0.000
[[297   0]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       297
          1       0.00      0.00      0.00         3

avg / total       0.98      0.99      0.99       300


                estimator  min_score   mean_score  max_score    sd_score  \
2           SGDClassifier  -0.063253    0.0373898   0.210462   0.0415896   
7                     SVC -0.0321279    0.0348274   0.143106   0.0472546   
3    ExtraTreesClassifier -0.0480755   0.00073045    0.11999   0.0171827   
1      LogisticRegression -0.0405719    0.0431243   0.168378    0.045804   
0              GaussianNB   0.138914     0.138914   0.138914           0   
8        VotingClassifier -0.0129715  -0.00334844          0  0.00386262   
9    KNeighborsClassifier   -0.01257  -0.00298488          0  0.00484817   
5           MLPClassifier -0.0178842  -0.00901858  0.0675991   0.0119221   
6      AdaBoostClassifier -0.0218973 -0.000984914   0.159528   0.0263236   
4  RandomForestClassifier -0.0178066  0.000145687  0.0619111  0.00584299   

        acc       auc           conf_matrix     f1_c0      f1_c1      kappa  \
2  0.946667  0.808081   [[282, 15], [1, 2]]  0.972414        0.2   0.186165   
7  0.793333   0.73064   [[236, 61], [1, 2]]  0.883895  0.0606061  0.0423231   
3  0.773333  0.720539   [[230, 67], [1, 2]]  0.871212  0.0555556     0.0371   
1  0.746667  0.707071   [[222, 75], [1, 2]]  0.853846       0.05  0.0313536   
0  0.583333  0.624579  [[173, 124], [1, 2]]  0.734607  0.0310078  0.0117015   
8      0.99       0.5    [[297, 0], [3, 0]]  0.994975          0          0   
9      0.99       0.5    [[297, 0], [3, 0]]  0.994975          0          0   
5      0.98  0.494949    [[294, 3], [3, 0]]  0.989899          0  -0.010101   
6  0.976667  0.493266    [[293, 4], [3, 0]]  0.988196          0 -0.0115607   
4      0.95  0.479798   [[285, 12], [3, 0]]  0.974359          0 -0.0162602   

  model_score   prec_c0    prec_c1    rec_c0    rec_c1  
2    0.265165  0.996466   0.117647  0.949495  0.666667  
7    0.112683  0.995781   0.031746  0.794613  0.666667  
3    0.104285  0.995671  0.0289855  0.774411  0.666667  
1   0.0943387  0.995516   0.025974  0.747475  0.666667  
0    0.050229  0.994253   0.015873  0.582492  0.666667  
8           0      0.99          0         1         0  
9           0      0.99          0         1         0  
5   -0.010101  0.989899          0  0.989899         0  
6  -0.0116833  0.989865          0  0.986532         0  
4  -0.0205152  0.989583          0  0.959596         0  
Elapsed time 21.81 mins 

************************************************************

pre/post: 0/25  win/stride: 200/25  label:end 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-05-02 12:15:11.253000 
pca_target: 0 	 poly degree: 0 	 kselect: 20 
Imbalance: ClusterCentroids(estimator=None, n_jobs=1, random_state=None, ratio='auto') 
Extended target (count):  25141 325
('Total : Processed (count): ', (998L, 24L), 12)
Final feature (count):  (998L, 24L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.570 	0.047 	0.011 	0.618 	0.616 	0.383
[[169 128]
 [  1   2]]
             precision    recall  f1-score   support

          0       0.99      0.57      0.72       297
          1       0.02      0.67      0.03         3

avg / total       0.98      0.57      0.72       300


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.01, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=10, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.490 	0.031 	0.006 	0.577 	0.571 	0.331
[[145 152]
 [  1   2]]
             precision    recall  f1-score   support

          0       0.99      0.49      0.65       297
          1       0.01      0.67      0.03         3

avg / total       0.98      0.49      0.65       300


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.1, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.001, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='modified_huber', n_iter=5, n_jobs=4,
       penalty='l1', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.763 	0.024 	0.008 	0.551 	0.506 	0.245
[[228  69]
 [  2   1]]
             precision    recall  f1-score   support

          0       0.99      0.77      0.87       297
          1       0.01      0.33      0.03         3

avg / total       0.98      0.76      0.86       300


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight='balanced',
           criterion='gini', max_depth=None, max_features='auto',
           max_leaf_nodes=None, min_impurity_split=1e-07,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=15, n_jobs=4,
           oob_score=False, random_state=None, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.647 	-0.004 	-0.001 	0.492 	0.465 	0.210
[[193 104]
 [  2   1]]
             precision    recall  f1-score   support

          0       0.99      0.65      0.78       297
          1       0.01      0.33      0.02         3

avg / total       0.98      0.65      0.78       300


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3},
            criterion='entropy', max_depth=16, max_features=0.75,
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.530 	0.039 	0.008 	0.598 	0.594 	0.357
[[157 140]
 [  1   2]]
             precision    recall  f1-score   support

          0       0.99      0.53      0.69       297
          1       0.01      0.67      0.03         3

avg / total       0.98      0.53      0.68       300


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.717 	0.012 	0.004 	0.527 	0.490 	0.231
[[214  83]
 [  2   1]]
             precision    recall  f1-score   support

          0       0.99      0.72      0.83       297
          1       0.01      0.33      0.02         3

avg / total       0.98      0.72      0.83       300


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=16,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=0.5, n_estimators=15, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.597 	0.053 	0.013 	0.631 	0.630 	0.400
[[177 120]
 [  1   2]]
             precision    recall  f1-score   support

          0       0.99      0.60      0.75       297
          1       0.02      0.67      0.03         3

avg / total       0.98      0.60      0.74       300


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='linear',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.337 	0.070 	0.010 	0.665 	0.574 	0.352
[[ 98 199]
 [  0   3]]
             precision    recall  f1-score   support

          0       1.00      0.33      0.50       297
          1       0.01      1.00      0.03         3

avg / total       0.99      0.34      0.49       300


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', R...owski',
           metric_params=None, n_jobs=4, n_neighbors=4, p=2,
           weights='uniform'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.680 	0.074 	0.021 	0.673 	0.673 	0.453
[[202  95]
 [  1   2]]
             precision    recall  f1-score   support

          0       1.00      0.68      0.81       297
          1       0.02      0.67      0.04         3

avg / total       0.99      0.68      0.80       300


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=4, p=1,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.677 	0.073 	0.021 	0.672 	0.672 	0.451
[[201  96]
 [  1   2]]
             precision    recall  f1-score   support

          0       1.00      0.68      0.81       297
          1       0.02      0.67      0.04         3

avg / total       0.99      0.68      0.80       300


                estimator  min_score  mean_score  max_score  sd_score  \
8        VotingClassifier          0    0.278322     0.5132  0.122191   
9    KNeighborsClassifier  -0.718234   -0.321364  0.0171889  0.148546   
7                     SVC  -0.496011  0.00796118     0.2566  0.187926   
6      AdaBoostClassifier   0.222222    0.681007   0.906078   0.12598   
0              GaussianNB   0.888889    0.888889   0.888889         0   
4  RandomForestClassifier  0.0171889    0.498829   0.906078  0.151798   
1      LogisticRegression          0    0.306355   0.607122  0.199254   
2           SGDClassifier  -0.607122    0.163047   0.589933  0.155316   
5           MLPClassifier  -0.239411   0.0253225   0.239411  0.135572   
3    ExtraTreesClassifier   0.222222    0.623377   0.906078  0.133689   

        acc       auc           conf_matrix     f1_c0      f1_c1        kappa  \
8      0.68  0.673401   [[202, 95], [1, 2]]     0.808       0.04    0.0210075   
9  0.676667  0.671717   [[201, 96], [1, 2]]  0.805611   0.039604    0.0205977   
7  0.336667  0.664983   [[98, 199], [0, 3]]  0.496203  0.0292683   0.00975318   
6  0.596667  0.631313  [[177, 120], [1, 2]]  0.745263      0.032    0.0127285   
0      0.57  0.617845  [[169, 128], [1, 2]]  0.723769  0.0300752    0.0107362   
4      0.53  0.597643  [[157, 140], [1, 2]]   0.69011  0.0275862   0.00815982   
1      0.49  0.577441  [[145, 152], [1, 2]]  0.654628  0.0254777   0.00597713   
2  0.763333  0.550505   [[228, 69], [2, 1]]  0.865275  0.0273973   0.00837989   
5  0.716667  0.526936   [[214, 83], [2, 1]]  0.834308  0.0229885   0.00375059   
3  0.646667  0.491582  [[193, 104], [2, 1]]  0.784553  0.0185185 -0.000944287   

  model_score   prec_c0     prec_c1    rec_c0    rec_c1  
8    0.073771  0.995074   0.0206186  0.680135  0.666667  
9   0.0728608   0.99505   0.0204082  0.676768  0.666667  
7   0.0700035         1   0.0148515  0.329966         1  
6    0.053197  0.994382   0.0163934   0.59596  0.666667  
0   0.0473243  0.994118   0.0153846  0.569024  0.666667  
4   0.0389169  0.993671   0.0140845   0.52862  0.666667  
1   0.0308321  0.993151    0.012987  0.488215  0.666667  
2   0.0237624  0.991304   0.0142857  0.767677  0.333333  
5   0.0119381  0.990741   0.0119048  0.720539  0.333333  
3 -0.00351189  0.989744  0.00952381  0.649832  0.333333  
Elapsed time 14.86 mins 

************************************************************

pre/post: 0/25  win/stride: 200/25  label:end 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-05-02 12:30:03.094000 
pca_target: 0 	 poly degree: 0 	 kselect: 20 
Imbalance: SMOTE(k=None, k_neighbors=5, kind='regular', m=None, m_neighbors=10, n_jobs=1,
   out_step=0.5, random_state=None, ratio='auto', svm_estimator=None) 
Extended target (count):  25141 325
('Total : Processed (count): ', (998L, 24L), 12)
Final feature (count):  (998L, 24L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.613 	0.057 	0.014 	0.640 	0.639 	0.411
[[182 115]
 [  1   2]]
             precision    recall  f1-score   support

          0       0.99      0.61      0.76       297
          1       0.02      0.67      0.03         3

avg / total       0.98      0.61      0.75       300


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=10, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.893 	0.179 	0.095 	0.781 	0.773 	0.583
[[266  31]
 [  1   2]]
             precision    recall  f1-score   support

          0       1.00      0.90      0.94       297
          1       0.06      0.67      0.11         3

avg / total       0.99      0.89      0.93       300


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.001, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='modified_huber', n_iter=5, n_jobs=4,
       penalty='l1', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.907 	0.194 	0.109 	0.788 	0.778 	0.591
[[270  27]
 [  1   2]]
             precision    recall  f1-score   support

          0       1.00      0.91      0.95       297
          1       0.07      0.67      0.12         3

avg / total       0.99      0.91      0.94       300


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 15}, criterion='gini',
           max_depth=None, max_features=0.75, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=30, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.977 	0.225 	0.212 	0.658 	0.572 	0.306
[[292   5]
 [  2   1]]
             precision    recall  f1-score   support

          0       0.99      0.98      0.99       297
          1       0.17      0.33      0.22         3

avg / total       0.98      0.98      0.98       300


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3},
            criterion='entropy', max_depth=None, max_features=0.33,
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.950 	-0.021 	-0.016 	0.480 	0.000 	0.000
[[285  12]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.96      0.97       297
          1       0.00      0.00      0.00         3

avg / total       0.98      0.95      0.96       300


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.5, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.960 	0.159 	0.129 	0.650 	0.568 	0.302
[[287  10]
 [  2   1]]
             precision    recall  f1-score   support

          0       0.99      0.97      0.98       297
          1       0.09      0.33      0.14         3

avg / total       0.98      0.96      0.97       300


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 50}, criterion='entropy',
            max_depth=16, max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=1.0, n_estimators=50, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.967 	0.179 	0.154 	0.653 	0.570 	0.304
[[289   8]
 [  2   1]]
             precision    recall  f1-score   support

          0       0.99      0.97      0.98       297
          1       0.11      0.33      0.17         3

avg / total       0.98      0.97      0.97       300


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.5, cache_size=200, class_weight={1: 50}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=10, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.990 	0.000 	0.000 	0.500 	0.000 	0.000
[[297   0]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       297
          1       0.00      0.00      0.00         3

avg / total       0.98      0.99      0.99       300


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=10.0, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', ...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.967 	0.179 	0.154 	0.653 	0.570 	0.304
[[289   8]
 [  2   1]]
             precision    recall  f1-score   support

          0       0.99      0.97      0.98       297
          1       0.11      0.33      0.17         3

avg / total       0.98      0.97      0.97       300


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=1,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.947 	0.131 	0.096 	0.643 	0.564 	0.298
[[283  14]
 [  2   1]]
             precision    recall  f1-score   support

          0       0.99      0.95      0.97       297
          1       0.07      0.33      0.11         3

avg / total       0.98      0.95      0.96       300


                estimator  min_score mean_score max_score    sd_score  \
2           SGDClassifier -0.0367727   0.506239  0.891474    0.221088   
1      LogisticRegression   0.150448   0.638472  0.877191    0.165287   
3    ExtraTreesClassifier   0.711738   0.899448  0.981333   0.0806046   
6      AdaBoostClassifier   0.856366   0.936212   0.97426   0.0248582   
8        VotingClassifier    0.83511   0.891831  0.931319    0.022216   
5           MLPClassifier   0.951932   0.965181  0.977094  0.00545786   
9    KNeighborsClassifier   0.822814   0.876278   0.93433   0.0326066   
0              GaussianNB   0.665687   0.665687  0.665687           0   
7                     SVC          0   0.737686  0.984133    0.238638   
4  RandomForestClassifier   0.870412    0.92725  0.964075   0.0260521   

        acc       auc           conf_matrix     f1_c0      f1_c1      kappa  \
2  0.906667  0.787879   [[270, 27], [1, 2]]  0.950704      0.125   0.108848   
1  0.893333  0.781145   [[266, 31], [1, 2]]  0.943262   0.111111  0.0945105   
3  0.976667  0.658249    [[292, 5], [2, 1]]  0.988156   0.222222   0.211712   
6  0.966667  0.653199    [[289, 8], [2, 1]]  0.982993   0.166667   0.153976   
8  0.966667  0.653199    [[289, 8], [2, 1]]  0.982993   0.166667   0.153976   
5      0.96  0.649832   [[287, 10], [2, 1]]  0.979522   0.142857   0.129173   
9  0.946667  0.643098   [[283, 14], [2, 1]]  0.972509   0.111111  0.0960452   
0  0.613333  0.639731  [[182, 115], [1, 2]]  0.758333  0.0333333  0.0141084   
7      0.99       0.5    [[297, 0], [3, 0]]  0.994975          0          0   
4      0.95  0.479798   [[285, 12], [3, 0]]  0.974359          0 -0.0162602   

  model_score   prec_c0    prec_c1    rec_c0    rec_c1  
2    0.193863   0.99631  0.0689655  0.909091  0.666667  
1    0.178808  0.996255  0.0606061  0.895623  0.666667  
3    0.224937  0.993197   0.166667  0.983165  0.333333  
6    0.178713  0.993127   0.111111  0.973064  0.333333  
8    0.178713  0.993127   0.111111  0.973064  0.333333  
5    0.158645   0.99308  0.0909091   0.96633  0.333333  
9    0.130657  0.992982  0.0666667  0.952862  0.333333  
0   0.0570088  0.994536   0.017094  0.612795  0.666667  
7           0      0.99          0         1         0  
4  -0.0205152  0.989583          0  0.959596         0  
Elapsed time 40.04 mins 

************************************************************

pre/post: 0/25  win/stride: 200/25  label:end 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-05-02 13:10:05.523000 
pca_target: 0 	 poly degree: 0 	 kselect: 20 
Imbalance: None 
Extended target (count):  25141 325
('Total : Processed (count): ', (998L, 24L), 12)
Final feature (count):  (998L, 24L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.580 	0.049 	0.011 	0.623 	0.621 	0.389
[[172 125]
 [  1   2]]
             precision    recall  f1-score   support

          0       0.99      0.58      0.73       297
          1       0.02      0.67      0.03         3

avg / total       0.98      0.58      0.72       300


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=1, class_weight={1: 500}, dual=False, fit_intercept=True,
          intercept_scaling=0.1, max_iter=100, multi_class='ovr', n_jobs=4,
          penalty='l2', random_state=None, solver='lbfgs', tol=0.0001,
          verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.703 	0.080 	0.024 	0.685 	0.685 	0.467
[[209  88]
 [  1   2]]
             precision    recall  f1-score   support

          0       1.00      0.70      0.82       297
          1       0.02      0.67      0.04         3

avg / total       0.99      0.70      0.82       300


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.0001, average=False, class_weight={1: 15}, epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='constant', loss='perceptron', n_iter=5, n_jobs=4,
       penalty='l1', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.577 	0.049 	0.011 	0.621 	0.620 	0.387
[[171 126]
 [  1   2]]
             precision    recall  f1-score   support

          0       0.99      0.58      0.73       297
          1       0.02      0.67      0.03         3

avg / total       0.98      0.58      0.72       300


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 500}, criterion='gini',
           max_depth=8, max_features=0.75, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=30, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.837 	0.048 	0.021 	0.588 	0.530 	0.266
[[250  47]
 [  2   1]]
             precision    recall  f1-score   support

          0       0.99      0.84      0.91       297
          1       0.02      0.33      0.04         3

avg / total       0.98      0.84      0.90       300


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 500},
            criterion='gini', max_depth=8, max_features='auto',
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.930 	-0.025 	-0.017 	0.470 	0.000 	0.000
[[279  18]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.94      0.96       297
          1       0.00      0.00      0.00         3

avg / total       0.98      0.93      0.95       300


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.5, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(500,), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.990 	0.000 	0.000 	0.500 	0.000 	0.000
[[297   0]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       297
          1       0.00      0.00      0.00         3

avg / total       0.98      0.99      0.99       300


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 50}, criterion='entropy',
            max_depth=32, max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=0.5, n_estimators=80, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	-0.006 	-0.005 	0.498 	0.000 	0.000
[[296   1]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       297
          1       0.00      0.00      0.00         3

avg / total       0.98      0.99      0.98       300


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.5, cache_size=200, class_weight='balanced', coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='linear',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.757 	0.098 	0.033 	0.712 	0.711 	0.500
[[225  72]
 [  1   2]]
             precision    recall  f1-score   support

          0       1.00      0.76      0.86       297
          1       0.03      0.67      0.05         3

avg / total       0.99      0.76      0.85       300


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.990 	0.000 	0.000 	0.500 	0.000 	0.000
[[297   0]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       297
          1       0.00      0.00      0.00         3

avg / total       0.98      0.99      0.99       300


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=1,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.990 	0.000 	0.000 	0.500 	0.000 	0.000
[[297   0]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       297
          1       0.00      0.00      0.00         3

avg / total       0.98      0.99      0.99       300


                estimator   min_score   mean_score   max_score    sd_score  \
7                     SVC  -0.0513159    0.0397072    0.150401   0.0540199   
1      LogisticRegression  -0.0530153    0.0450454     0.15042   0.0496735   
0              GaussianNB     0.13814      0.13814     0.13814           0   
2           SGDClassifier  -0.0656043    0.0398381    0.211271   0.0421081   
3    ExtraTreesClassifier  -0.0262645  0.000422526    0.103172   0.0155077   
5           MLPClassifier  -0.0176804   -0.0122108 -0.00290686  0.00353751   
8        VotingClassifier  -0.0164202  -0.00407067           0  0.00510573   
9    KNeighborsClassifier  -0.0147785  -0.00367564           0  0.00609778   
6      AdaBoostClassifier   -0.022878  0.000442664    0.212977   0.0302361   
4  RandomForestClassifier -0.00614415   0.00100147   0.0627417  0.00743681   

        acc       auc           conf_matrix     f1_c0      f1_c1       kappa  \
7  0.756667  0.712121   [[225, 72], [1, 2]]  0.860421  0.0519481   0.0333686   
1  0.703333  0.685185   [[209, 88], [1, 2]]  0.824458  0.0430108   0.0241228   
0      0.58  0.622896  [[172, 125], [1, 2]]  0.731915  0.0307692   0.0114546   
2  0.576667  0.621212  [[171, 126], [1, 2]]  0.729211  0.0305344   0.0112115   
3  0.836667  0.587542   [[250, 47], [2, 1]]  0.910747  0.0392157   0.0207834   
5      0.99       0.5    [[297, 0], [3, 0]]  0.994975          0           0   
8      0.99       0.5    [[297, 0], [3, 0]]  0.994975          0           0   
9      0.99       0.5    [[297, 0], [3, 0]]  0.994975          0           0   
6  0.986667  0.498316    [[296, 1], [3, 0]]  0.993289          0 -0.00502513   
4      0.93  0.469697   [[279, 18], [3, 0]]  0.963731          0  -0.0174419   

  model_score   prec_c0    prec_c1    rec_c0    rec_c1  
7   0.0979226  0.995575   0.027027  0.757576  0.666667  
1   0.0804163  0.995238  0.0222222  0.703704  0.666667  
0   0.0494972   0.99422   0.015748  0.579125  0.666667  
2   0.0487692  0.994186   0.015625  0.575758  0.666667  
3   0.0475187  0.992063  0.0208333  0.841751  0.333333  
5           0      0.99          0         1         0  
8           0      0.99          0         1         0  
9           0      0.99          0         1         0  
6 -0.00581228  0.989967          0  0.996633         0  
4  -0.0253918  0.989362          0  0.939394         0  
Elapsed time 23.89 mins 

************************************************************




Standard, lagged(3,4)x1, NT+



    pca = [0, 60]
    poly = [3]
    ksel = [20, 60]
    imb = [ClusterCentroids(), None]
	


	
pre/post: 0/25  win/stride: 200/25  label:end 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-05-02 22:17:04.659000 
pca_target: 0 	 poly degree: 3 	 kselect: 20 
Imbalance: ClusterCentroids(estimator=None, n_jobs=1, random_state=None, ratio='auto') 
Extended target (count):  25141 325
('Total : Processed (count): ', (998L, 2300L), 12)
Final feature (count):  (998L, 2300L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.603 	0.055 	0.013 	0.635 	0.634 	0.404
[[179 118]
 [  1   2]]
             precision    recall  f1-score   support

          0       0.99      0.60      0.75       297
          1       0.02      0.67      0.03         3

avg / total       0.98      0.60      0.74       300


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=5, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.610 	0.056 	0.014 	0.638 	0.637 	0.409
[[181 116]
 [  1   2]]
             precision    recall  f1-score   support

          0       0.99      0.61      0.76       297
          1       0.02      0.67      0.03         3

avg / total       0.98      0.61      0.75       300


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.001, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='invscaling', loss='squared_hinge', n_iter=5,
       n_jobs=4, penalty='none', power_t=0.5, random_state=None,
       shuffle=True, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.647 	0.065 	0.017 	0.657 	0.656 	0.432
[[192 105]
 [  1   2]]
             precision    recall  f1-score   support

          0       0.99      0.65      0.78       297
          1       0.02      0.67      0.04         3

avg / total       0.99      0.65      0.78       300


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=8, max_features=0.75, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.637 	0.063 	0.016 	0.652 	0.651 	0.426
[[189 108]
 [  1   2]]
             precision    recall  f1-score   support

          0       0.99      0.64      0.78       297
          1       0.02      0.67      0.04         3

avg / total       0.98      0.64      0.77       300


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3},
            criterion='entropy', max_depth=16, max_features=0.33,
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=15, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.620 	0.059 	0.015 	0.643 	0.643 	0.415
[[184 113]
 [  1   2]]
             precision    recall  f1-score   support

          0       0.99      0.62      0.76       297
          1       0.02      0.67      0.03         3

avg / total       0.98      0.62      0.76       300


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.567 	0.047 	0.011 	0.616 	0.614 	0.381
[[168 129]
 [  1   2]]
             precision    recall  f1-score   support

          0       0.99      0.57      0.72       297
          1       0.02      0.67      0.03         3

avg / total       0.98      0.57      0.71       300


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=0.5, n_estimators=15, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.557 	0.044 	0.010 	0.611 	0.609 	0.374
[[165 132]
 [  1   2]]
             precision    recall  f1-score   support

          0       0.99      0.56      0.71       297
          1       0.01      0.67      0.03         3

avg / total       0.98      0.56      0.71       300


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.5, cache_size=200, class_weight='balanced', coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='linear',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.603 	0.055 	0.013 	0.635 	0.634 	0.404
[[179 118]
 [  1   2]]
             precision    recall  f1-score   support

          0       0.99      0.60      0.75       297
          1       0.02      0.67      0.03         3

avg / total       0.98      0.60      0.74       300


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=10.0, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', ...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.617 	0.058 	0.014 	0.641 	0.641 	0.413
[[183 114]
 [  1   2]]
             precision    recall  f1-score   support

          0       0.99      0.62      0.76       297
          1       0.02      0.67      0.03         3

avg / total       0.98      0.62      0.75       300


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.763 	0.024 	0.008 	0.551 	0.506 	0.245
[[228  69]
 [  2   1]]
             precision    recall  f1-score   support

          0       0.99      0.77      0.87       297
          1       0.01      0.33      0.03         3

avg / total       0.98      0.76      0.86       300


                estimator min_score mean_score max_score   sd_score       acc  \
2           SGDClassifier   -0.1283   0.467182  0.906078   0.212088  0.646667   
3    ExtraTreesClassifier  0.777778   0.924767         1  0.0391693  0.636667   
4  RandomForestClassifier  0.683856   0.887056         1  0.0547359      0.62   
8        VotingClassifier  0.478822   0.620831  0.794967    0.06695  0.616667   
1      LogisticRegression         0   0.391701  0.777778   0.238873      0.61   
0              GaussianNB         1          1         1          0  0.603333   
7                     SVC         0   0.494587  0.906078   0.291964  0.603333   
5           MLPClassifier  0.444444   0.782459  0.888889    0.09888  0.566667   
6      AdaBoostClassifier  0.461633   0.901454         1  0.0929036  0.556667   
9    KNeighborsClassifier    0.2566   0.620052  0.906078   0.206572  0.763333   

        auc           conf_matrix     f1_c0      f1_c1       kappa  \
2  0.656566  [[192, 105], [1, 2]]  0.783673  0.0363636   0.0172446   
3  0.651515  [[189, 108], [1, 2]]  0.776181  0.0353982   0.0162455   
4  0.643098  [[184, 113], [1, 2]]  0.763485  0.0338983   0.0146932   
8  0.641414  [[183, 114], [1, 2]]  0.760915  0.0336134   0.0143984   
1  0.638047  [[181, 116], [1, 2]]  0.755741  0.0330579   0.0138233   
0   0.63468  [[179, 118], [1, 2]]  0.750524  0.0325203    0.013267   
7   0.63468  [[179, 118], [1, 2]]  0.750524  0.0325203    0.013267   
5  0.616162  [[168, 129], [1, 2]]   0.72103  0.0298507   0.0105039   
6  0.611111  [[165, 132], [1, 2]]  0.712743  0.0291971  0.00982728   
9  0.550505   [[228, 69], [2, 1]]  0.865275  0.0273973  0.00837989   

  model_score   prec_c0    prec_c1    rec_c0    rec_c1  
2   0.0650421  0.994819  0.0186916  0.646465  0.666667  
3   0.0625679  0.994737  0.0181818  0.636364  0.666667  
4   0.0585688  0.994595  0.0173913  0.619529  0.666667  
8   0.0577862  0.994565  0.0172414  0.616162  0.666667  
1   0.0562367  0.994505  0.0169492  0.609428  0.666667  
0   0.0547073  0.994444  0.0166667  0.602694  0.666667  
7   0.0547073  0.994444  0.0166667  0.602694  0.666667  
5   0.0466071  0.994083  0.0152672  0.565657  0.666667  
6   0.0444754  0.993976  0.0149254  0.555556  0.666667  
9   0.0237624  0.991304  0.0142857  0.767677  0.333333  
Elapsed time 14.66 mins 

************************************************************

pre/post: 0/25  win/stride: 200/25  label:end 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-05-02 22:31:44.048000 
pca_target: 0 	 poly degree: 3 	 kselect: 20 
Imbalance: None 
Extended target (count):  25141 325
('Total : Processed (count): ', (998L, 2300L), 12)
Final feature (count):  (998L, 2300L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.687 	0.076 	0.022 	0.677 	0.677 	0.457
[[204  93]
 [  1   2]]
             precision    recall  f1-score   support

          0       1.00      0.69      0.81       297
          1       0.02      0.67      0.04         3

avg / total       0.99      0.69      0.81       300


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.01, class_weight={1: 50}, dual=False,
          fit_intercept=True, intercept_scaling=10, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='sag', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.720 	0.013 	0.004 	0.529 	0.491 	0.232
[[215  82]
 [  2   1]]
             precision    recall  f1-score   support

          0       0.99      0.72      0.84       297
          1       0.01      0.33      0.02         3

avg / total       0.98      0.72      0.83       300


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.5, average=False, class_weight={1: 50}, epsilon=0.1,
       eta0=0.001, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='modified_huber', n_iter=5, n_jobs=4,
       penalty='l2', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.743 	0.018 	0.006 	0.540 	0.499 	0.239
[[222  75]
 [  2   1]]
             precision    recall  f1-score   support

          0       0.99      0.75      0.85       297
          1       0.01      0.33      0.03         3

avg / total       0.98      0.74      0.84       300


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 500},
           criterion='entropy', max_depth=8, max_features='auto',
           max_leaf_nodes=None, min_impurity_split=1e-07,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=15, n_jobs=4,
           oob_score=False, random_state=None, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.830 	0.045 	0.019 	0.584 	0.528 	0.264
[[248  49]
 [  2   1]]
             precision    recall  f1-score   support

          0       0.99      0.84      0.91       297
          1       0.02      0.33      0.04         3

avg / total       0.98      0.83      0.90       300


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=30, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.990 	0.000 	0.000 	0.500 	0.000 	0.000
[[297   0]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       297
          1       0.00      0.00      0.00         3

avg / total       0.98      0.99      0.99       300


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.1, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.980 	-0.010 	-0.010 	0.495 	0.000 	0.000
[[294   3]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       297
          1       0.00      0.00      0.00         3

avg / total       0.98      0.98      0.98       300


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 50}, criterion='gini', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=2.0, n_estimators=15, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.973 	-0.013 	-0.013 	0.492 	0.000 	0.000
[[292   5]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.98      0.99       297
          1       0.00      0.00      0.00         3

avg / total       0.98      0.97      0.98       300


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=1, cache_size=200, class_weight={1: 500}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.763 	0.024 	0.008 	0.551 	0.506 	0.245
[[228  69]
 [  2   1]]
             precision    recall  f1-score   support

          0       0.99      0.77      0.87       297
          1       0.01      0.33      0.03         3

avg / total       0.98      0.76      0.86       300


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 500}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Ran...owski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='uniform'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.973 	-0.013 	-0.013 	0.492 	0.000 	0.000
[[292   5]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.98      0.99       297
          1       0.00      0.00      0.00         3

avg / total       0.98      0.97      0.98       300


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=1,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.980 	0.249 	0.241 	0.660 	0.573 	0.307
[[293   4]
 [  2   1]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       297
          1       0.20      0.33      0.25         3

avg / total       0.99      0.98      0.98       300


                estimator  min_score   mean_score  max_score    sd_score  \
0              GaussianNB   0.118706     0.118706   0.118706           0   
9    KNeighborsClassifier -0.0148444 -0.000507186  0.0466387   0.0133395   
3    ExtraTreesClassifier -0.0237682   0.00480489   0.151566   0.0267948   
7                     SVC -0.0155874    0.0541384   0.161039   0.0538518   
2           SGDClassifier -0.0796455    0.0410957   0.224442   0.0475273   
1      LogisticRegression -0.0375728    0.0435117   0.157047   0.0542316   
4  RandomForestClassifier -0.0160744 -0.000428321          0  0.00183975   
5           MLPClassifier -0.0169271  -0.00494345  0.0589402   0.0202065   
6      AdaBoostClassifier -0.0192172   0.00182711   0.314993   0.0329664   
8        VotingClassifier -0.0158784    -0.005318  0.0466272  0.00593553   

        acc       auc          conf_matrix     f1_c0      f1_c1       kappa  \
0  0.686667  0.676768  [[204, 93], [1, 2]]  0.812749  0.0408163   0.0218522   
9      0.98  0.659933   [[293, 4], [2, 1]]  0.989865       0.25    0.240506   
3      0.83  0.584175  [[248, 49], [2, 1]]  0.906764  0.0377358   0.0192308   
7  0.763333  0.550505  [[228, 69], [2, 1]]  0.865275  0.0273973  0.00837989   
2  0.743333  0.540404  [[222, 75], [2, 1]]  0.852207  0.0253165  0.00619515   
1      0.72   0.52862  [[215, 82], [2, 1]]  0.836576  0.0232558   0.0040313   
4      0.99       0.5   [[297, 0], [3, 0]]  0.994975          0           0   
5      0.98  0.494949   [[294, 3], [3, 0]]  0.989899          0   -0.010101   
6  0.973333  0.491582   [[292, 5], [3, 0]]  0.986486          0  -0.0126582   
8  0.973333  0.491582   [[292, 5], [3, 0]]  0.986486          0  -0.0126582   

  model_score   prec_c0    prec_c1    rec_c0    rec_c1  
0   0.0756194  0.995122  0.0210526  0.686869  0.666667  
9    0.248605   0.99322        0.2  0.986532  0.333333  
3   0.0449467     0.992       0.02  0.835017  0.333333  
7   0.0237624  0.991304  0.0142857  0.767677  0.333333  
2   0.0184868  0.991071  0.0131579  0.747475  0.333333  
1    0.012731  0.990783  0.0120482  0.723906  0.333333  
4           0      0.99          0         1         0  
5   -0.010101  0.989899          0  0.989899         0  
6  -0.0130845  0.989831          0  0.983165         0  
8  -0.0130845  0.989831          0  0.983165         0  
Elapsed time 24.36 mins 

************************************************************

pre/post: 0/25  win/stride: 200/25  label:end 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-05-02 22:56:05.638000 
pca_target: 0 	 poly degree: 3 	 kselect: 60 
Imbalance: ClusterCentroids(estimator=None, n_jobs=1, random_state=None, ratio='auto') 
Extended target (count):  25141 325
('Total : Processed (count): ', (998L, 2300L), 12)
Final feature (count):  (998L, 2300L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.637 	0.063 	0.016 	0.652 	0.651 	0.426
[[189 108]
 [  1   2]]
             precision    recall  f1-score   support

          0       0.99      0.64      0.78       297
          1       0.02      0.67      0.04         3

avg / total       0.98      0.64      0.77       300


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=5, class_weight={1: 3}, dual=False, fit_intercept=True,
          intercept_scaling=0.1, max_iter=100, multi_class='ovr', n_jobs=4,
          penalty='l2', random_state=None, solver='lbfgs', tol=0.0001,
          verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.597 	0.053 	0.013 	0.631 	0.630 	0.400
[[177 120]
 [  1   2]]
             precision    recall  f1-score   support

          0       0.99      0.60      0.75       297
          1       0.02      0.67      0.03         3

avg / total       0.98      0.60      0.74       300


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.0001, average=False, class_weight={1: 15}, epsilon=0.1,
       eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='modified_huber', n_iter=5, n_jobs=4,
       penalty='l1', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.480 	0.029 	0.005 	0.572 	0.565 	0.325
[[142 155]
 [  1   2]]
             precision    recall  f1-score   support

          0       0.99      0.48      0.65       297
          1       0.01      0.67      0.03         3

avg / total       0.98      0.48      0.64       300


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=8, max_features=0.75, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=30, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.647 	0.065 	0.017 	0.657 	0.656 	0.432
[[192 105]
 [  1   2]]
             precision    recall  f1-score   support

          0       0.99      0.65      0.78       297
          1       0.02      0.67      0.04         3

avg / total       0.99      0.65      0.78       300


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 15},
            criterion='entropy', max_depth=None, max_features=0.33,
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=15, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.590 	0.052 	0.012 	0.628 	0.627 	0.396
[[175 122]
 [  1   2]]
             precision    recall  f1-score   support

          0       0.99      0.59      0.74       297
          1       0.02      0.67      0.03         3

avg / total       0.98      0.59      0.73       300


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.657 	0.068 	0.018 	0.662 	0.662 	0.438
[[195 102]
 [  1   2]]
             precision    recall  f1-score   support

          0       0.99      0.66      0.79       297
          1       0.02      0.67      0.04         3

avg / total       0.99      0.66      0.78       300


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=0.5, n_estimators=15, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.613 	0.057 	0.014 	0.640 	0.639 	0.411
[[182 115]
 [  1   2]]
             precision    recall  f1-score   support

          0       0.99      0.61      0.76       297
          1       0.02      0.67      0.03         3

avg / total       0.98      0.61      0.75       300


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.733 	0.016 	0.005 	0.535 	0.496 	0.236
[[219  78]
 [  2   1]]
             precision    recall  f1-score   support

          0       0.99      0.74      0.85       297
          1       0.01      0.33      0.02         3

avg / total       0.98      0.73      0.84       300


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.630 	0.061 	0.016 	0.648 	0.648 	0.421
[[187 110]
 [  1   2]]
             precision    recall  f1-score   support

          0       0.99      0.63      0.77       297
          1       0.02      0.67      0.03         3

avg / total       0.98      0.63      0.76       300


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=4,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.750 	0.020 	0.007 	0.544 	0.501 	0.241
[[224  73]
 [  2   1]]
             precision    recall  f1-score   support

          0       0.99      0.75      0.86       297
          1       0.01      0.33      0.03         3

avg / total       0.98      0.75      0.85       300


                estimator  min_score mean_score max_score  sd_score       acc  \
5           MLPClassifier   0.496011   0.672001  0.906078  0.092904  0.656667   
3    ExtraTreesClassifier   0.555556   0.901095         1  0.046501  0.646667   
0              GaussianNB          1          1         1         0  0.636667   
8        VotingClassifier   0.444444   0.636889  0.794967  0.111198      0.63   
6      AdaBoostClassifier -0.0343779   0.588283  0.906078  0.143439  0.613333   
1      LogisticRegression          0   0.429252  0.812156  0.267425  0.596667   
4  RandomForestClassifier   0.555556   0.769803         1  0.100622      0.59   
2           SGDClassifier  -0.239411   0.380517  0.906078  0.191969      0.48   
9    KNeighborsClassifier   0.239411   0.520681  0.718234   0.14765      0.75   
7                     SVC          0   0.381611  0.906078  0.279169  0.733333   

        auc           conf_matrix     f1_c0      f1_c1       kappa  \
5  0.661616  [[195, 102], [1, 2]]  0.791075  0.0373832   0.0182997   
3  0.656566  [[192, 105], [1, 2]]  0.783673  0.0363636   0.0172446   
0  0.651515  [[189, 108], [1, 2]]  0.776181  0.0353982   0.0162455   
8  0.648148  [[187, 110], [1, 2]]  0.771134  0.0347826   0.0156084   
6  0.639731  [[182, 115], [1, 2]]  0.758333  0.0333333   0.0141084   
1  0.631313  [[177, 120], [1, 2]]  0.745263      0.032   0.0127285   
4  0.627946  [[175, 122], [1, 2]]  0.739958  0.0314961   0.0122069   
2  0.572391  [[142, 155], [1, 2]]  0.645455      0.025   0.0054826   
9  0.543771   [[224, 73], [2, 1]]  0.856597   0.025974  0.00688559   
7  0.535354   [[219, 78], [2, 1]]   0.84556  0.0243902  0.00522258   

  model_score   prec_c0    prec_c1    rec_c0    rec_c1  
5   0.0675786  0.994898  0.0192308  0.656566  0.666667  
3   0.0650421  0.994819  0.0186916  0.646465  0.666667  
0   0.0625679  0.994737  0.0181818  0.636364  0.666667  
8   0.0609505  0.994681  0.0178571   0.62963  0.666667  
6   0.0570088  0.994536   0.017094  0.612795  0.666667  
1    0.053197  0.994382  0.0163934   0.59596  0.666667  
4   0.0517046  0.994318   0.016129  0.589226  0.666667  
2   0.0288425  0.993007  0.0127389  0.478114  0.666667  
9   0.0202062   0.99115  0.0135135  0.754209  0.333333  
7   0.0159732   0.99095  0.0126582  0.737374  0.333333  
Elapsed time 15.91 mins 

************************************************************

pre/post: 0/25  win/stride: 200/25  label:end 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-05-02 23:12:00.484000 
pca_target: 0 	 poly degree: 3 	 kselect: 60 
Imbalance: None 
Extended target (count):  25141 325
('Total : Processed (count): ', (998L, 2300L), 12)
Final feature (count):  (998L, 2300L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.683 	0.075 	0.021 	0.675 	0.675 	0.455
[[203  94]
 [  1   2]]
             precision    recall  f1-score   support

          0       1.00      0.68      0.81       297
          1       0.02      0.67      0.04         3

avg / total       0.99      0.68      0.80       300


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.1, class_weight={1: 500}, dual=False,
          fit_intercept=True, intercept_scaling=0.01, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='sag', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.530 	0.039 	0.008 	0.598 	0.594 	0.357
[[157 140]
 [  1   2]]
             precision    recall  f1-score   support

          0       0.99      0.53      0.69       297
          1       0.01      0.67      0.03         3

avg / total       0.98      0.53      0.68       300


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=1, average=False, class_weight={1: 15}, epsilon=0.1,
       eta0=0.001, fit_intercept=True, l1_ratio=0.15,
       learning_rate='constant', loss='squared_hinge', n_iter=5, n_jobs=4,
       penalty='none', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.940 	-0.023 	-0.017 	0.475 	0.000 	0.000
[[282  15]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.95      0.97       297
          1       0.00      0.00      0.00         3

avg / total       0.98      0.94      0.96       300


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight='balanced',
           criterion='gini', max_depth=8, max_features=0.33,
           max_leaf_nodes=None, min_impurity_split=1e-07,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=15, n_jobs=4,
           oob_score=False, random_state=None, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.947 	-0.021 	-0.017 	0.478 	0.000 	0.000
[[284  13]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.96      0.97       297
          1       0.00      0.00      0.00         3

avg / total       0.98      0.95      0.96       300


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=30, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.990 	0.000 	0.000 	0.500 	0.000 	0.000
[[297   0]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       297
          1       0.00      0.00      0.00         3

avg / total       0.98      0.99      0.99       300


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(500,), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.977 	-0.012 	-0.012 	0.493 	0.000 	0.000
[[293   4]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       297
          1       0.00      0.00      0.00         3

avg / total       0.98      0.98      0.98       300


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight='balanced', criterion='gini', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=2.0, n_estimators=50, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.983 	-0.008 	-0.008 	0.497 	0.000 	0.000
[[295   2]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       297
          1       0.00      0.00      0.00         3

avg / total       0.98      0.98      0.98       300


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.1, cache_size=200, class_weight={1: 500}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.733 	0.016 	0.005 	0.535 	0.496 	0.236
[[219  78]
 [  2   1]]
             precision    recall  f1-score   support

          0       0.99      0.74      0.85       297
          1       0.01      0.33      0.02         3

avg / total       0.98      0.73      0.84       300


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 500}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Ran...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.977 	-0.012 	-0.012 	0.493 	0.000 	0.000
[[293   4]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       297
          1       0.00      0.00      0.00         3

avg / total       0.98      0.98      0.98       300


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=1,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.977 	-0.012 	-0.012 	0.493 	0.000 	0.000
[[293   4]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       297
          1       0.00      0.00      0.00         3

avg / total       0.98      0.98      0.98       300


                estimator   min_score  mean_score  max_score    sd_score  \
0              GaussianNB    0.118196    0.118196   0.118196           0   
1      LogisticRegression   -0.031514   0.0357743   0.135697    0.044686   
7                     SVC  -0.0325548   0.0256243   0.143367   0.0426276   
4  RandomForestClassifier -0.00700328 -0.00064783          0  0.00116987   
6      AdaBoostClassifier  -0.0219856  -0.0012158   0.171214   0.0291367   
5           MLPClassifier  -0.0155762 -0.00793102  0.0912458   0.0185866   
8        VotingClassifier    -0.01491  -0.0073528  0.0502464  0.00626692   
9    KNeighborsClassifier   -0.013093  0.00634371  0.0451956   0.0189919   
3    ExtraTreesClassifier  -0.0232482  0.00429608    0.16111   0.0280045   
2           SGDClassifier   -0.141315   0.0422589    0.23236   0.0463781   

        acc       auc           conf_matrix     f1_c0      f1_c1       kappa  \
0  0.683333  0.675084   [[203, 94], [1, 2]]  0.810379   0.040404   0.0214256   
1      0.53  0.597643  [[157, 140], [1, 2]]   0.69011  0.0275862  0.00815982   
7  0.733333  0.535354   [[219, 78], [2, 1]]   0.84556  0.0243902  0.00522258   
4      0.99       0.5    [[297, 0], [3, 0]]  0.994975          0           0   
6  0.983333  0.496633    [[295, 2], [3, 0]]  0.991597          0 -0.00806452   
5  0.976667  0.493266    [[293, 4], [3, 0]]  0.988196          0  -0.0115607   
8  0.976667  0.493266    [[293, 4], [3, 0]]  0.988196          0  -0.0115607   
9  0.976667  0.493266    [[293, 4], [3, 0]]  0.988196          0  -0.0115607   
3  0.946667  0.478114   [[284, 13], [3, 0]]  0.972603          0  -0.0165184   
2      0.94  0.474747   [[282, 15], [3, 0]]  0.969072          0  -0.0169492   

  model_score   prec_c0    prec_c1    rec_c0    rec_c1  
0   0.0746904  0.995098  0.0208333  0.683502  0.666667  
1   0.0389169  0.993671  0.0140845   0.52862  0.666667  
7   0.0159732   0.99095  0.0126582  0.737374  0.333333  
4           0      0.99          0         1         0  
6 -0.00823359  0.989933          0  0.993266         0  
5  -0.0116833  0.989865          0  0.986532         0  
8  -0.0116833  0.989865          0  0.986532         0  
9  -0.0116833  0.989865          0  0.986532         0  
3  -0.0213901  0.989547          0  0.956229         0  
2  -0.0230571  0.989474          0  0.949495         0  
Elapsed time 26.01 mins 

************************************************************

pre/post: 0/25  win/stride: 200/25  label:end 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-05-02 23:38:00.841000 
pca_target: 60 	 poly degree: 3 	 kselect: 20 
Imbalance: ClusterCentroids(estimator=None, n_jobs=1, random_state=None, ratio='auto') 
Extended target (count):  25141 325
('Total : Processed (count): ', (998L, 2300L), 12)
Final feature (count):  (998L, 2300L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.990 	0.000 	0.000 	0.500 	0.000 	0.000
[[297   0]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       297
          1       0.00      0.00      0.00         3

avg / total       0.98      0.99      0.99       300


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.001, class_weight={1: 3}, dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.510 	0.035 	0.007 	0.588 	0.582 	0.344
[[151 146]
 [  1   2]]
             precision    recall  f1-score   support

          0       0.99      0.51      0.67       297
          1       0.01      0.67      0.03         3

avg / total       0.98      0.51      0.67       300


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.0001, average=False, class_weight='balanced',
       epsilon=0.1, eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='modified_huber', n_iter=5, n_jobs=4,
       penalty='none', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.570 	-0.019 	-0.004 	0.453 	0.437 	0.186
[[170 127]
 [  2   1]]
             precision    recall  f1-score   support

          0       0.99      0.57      0.72       297
          1       0.01      0.33      0.02         3

avg / total       0.98      0.57      0.72       300


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=16, max_features='auto', max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=30, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.570 	0.047 	0.011 	0.618 	0.616 	0.383
[[169 128]
 [  1   2]]
             precision    recall  f1-score   support

          0       0.99      0.57      0.72       297
          1       0.02      0.67      0.03         3

avg / total       0.98      0.57      0.72       300


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=30, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.617 	0.058 	0.014 	0.641 	0.641 	0.413
[[183 114]
 [  1   2]]
             precision    recall  f1-score   support

          0       0.99      0.62      0.76       297
          1       0.02      0.67      0.03         3

avg / total       0.98      0.62      0.75       300


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.540 	0.041 	0.009 	0.603 	0.599 	0.364
[[160 137]
 [  1   2]]
             precision    recall  f1-score   support

          0       0.99      0.54      0.70       297
          1       0.01      0.67      0.03         3

avg / total       0.98      0.54      0.69       300


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=0.5, n_estimators=50, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.647 	-0.004 	-0.001 	0.492 	0.465 	0.210
[[193 104]
 [  2   1]]
             precision    recall  f1-score   support

          0       0.99      0.65      0.78       297
          1       0.01      0.33      0.02         3

avg / total       0.98      0.65      0.78       300


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.1, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='linear',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.443 	0.022 	0.004 	0.554 	0.542 	0.301
[[131 166]
 [  1   2]]
             precision    recall  f1-score   support

          0       0.99      0.44      0.61       297
          1       0.01      0.67      0.02         3

avg / total       0.98      0.44      0.60       300


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=1.0, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.577 	0.115 	0.026 	0.786 	0.757 	0.597
[[170 127]
 [  0   3]]
             precision    recall  f1-score   support

          0       1.00      0.57      0.73       297
          1       0.02      1.00      0.05         3

avg / total       0.99      0.58      0.72       300


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=2,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.990 	0.000 	0.000 	0.500 	0.000 	0.000
[[297   0]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       297
          1       0.00      0.00      0.00         3

avg / total       0.98      0.99      0.99       300


                estimator min_score mean_score max_score   sd_score       acc  \
8        VotingClassifier  0.367711    0.60798  0.794967  0.0780627  0.576667   
4  RandomForestClassifier  0.205033   0.597143  0.906078   0.132107  0.616667   
3    ExtraTreesClassifier  0.111111   0.763934  0.906078   0.107033      0.57   
5           MLPClassifier    0.3849   0.566006  0.812156   0.100614      0.54   
1      LogisticRegression         0   0.443389  0.718234    0.24773      0.51   
7                     SVC         0   0.431366  0.683856   0.268772  0.443333   
0              GaussianNB         1          1         1          0      0.99   
9    KNeighborsClassifier         0   0.386511  0.701045   0.186776      0.99   
6      AdaBoostClassifier  0.205033   0.811211         1   0.173037  0.646667   
2           SGDClassifier   -0.2566   0.406058  0.812156   0.173299      0.57   

        auc           conf_matrix     f1_c0      f1_c1        kappa  \
8  0.786195  [[170, 127], [0, 3]]  0.728051  0.0451128    0.0260736   
4  0.641414  [[183, 114], [1, 2]]  0.760915  0.0336134    0.0143984   
3  0.617845  [[169, 128], [1, 2]]  0.723769  0.0300752    0.0107362   
5  0.602694  [[160, 137], [1, 2]]   0.69869   0.028169   0.00876311   
1  0.587542  [[151, 146], [1, 2]]  0.672606  0.0264901   0.00702513   
7  0.553872  [[131, 166], [1, 2]]  0.610723  0.0233918    0.0038177   
0       0.5    [[297, 0], [3, 0]]  0.994975          0            0   
9       0.5    [[297, 0], [3, 0]]  0.994975          0            0   
6  0.491582  [[193, 104], [2, 1]]  0.784553  0.0185185 -0.000944287   
2  0.452862  [[170, 127], [2, 1]]  0.724947  0.0152672  -0.00436001   

  model_score   prec_c0     prec_c1    rec_c0    rec_c1  
8     0.11493         1   0.0230769  0.572391         1  
4   0.0577862  0.994565   0.0172414  0.616162  0.666667  
3   0.0473243  0.994118   0.0153846  0.569024  0.666667  
5   0.0409819  0.993789   0.0143885  0.538721  0.666667  
1   0.0348444  0.993421   0.0135135  0.508418  0.666667  
7   0.0215969  0.992424   0.0119048  0.441077  0.666667  
0           0      0.99           0         1         0  
9           0      0.99           0         1         0  
6 -0.00351189  0.989744  0.00952381  0.649832  0.333333  
2  -0.0189658  0.988372   0.0078125  0.572391  0.333333  
Elapsed time 14.37 mins 

************************************************************

pre/post: 0/25  win/stride: 200/25  label:end 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-05-02 23:52:23.308000 
pca_target: 60 	 poly degree: 3 	 kselect: 20 
Imbalance: None 
Extended target (count):  25141 325
('Total : Processed (count): ', (998L, 2300L), 12)
Final feature (count):  (998L, 2300L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.793 	0.113 	0.042 	0.731 	0.728 	0.523
[[236  61]
 [  1   2]]
             precision    recall  f1-score   support

          0       1.00      0.79      0.88       297
          1       0.03      0.67      0.06         3

avg / total       0.99      0.79      0.88       300


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.001, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=10, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.713 	0.083 	0.026 	0.690 	0.690 	0.474
[[212  85]
 [  1   2]]
             precision    recall  f1-score   support

          0       1.00      0.71      0.83       297
          1       0.02      0.67      0.04         3

avg / total       0.99      0.71      0.82       300


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.0001, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='constant', loss='modified_huber', n_iter=5, n_jobs=4,
       penalty='l2', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.937 	0.116 	0.079 	0.638 	0.561 	0.295
[[280  17]
 [  2   1]]
             precision    recall  f1-score   support

          0       0.99      0.94      0.97       297
          1       0.06      0.33      0.10         3

avg / total       0.98      0.94      0.96       300


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 500}, criterion='gini',
           max_depth=8, max_features='auto', max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=30, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.863 	0.153 	0.072 	0.766 	0.760 	0.565
[[257  40]
 [  1   2]]
             precision    recall  f1-score   support

          0       1.00      0.87      0.93       297
          1       0.05      0.67      0.09         3

avg / total       0.99      0.86      0.92       300


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.990 	0.000 	0.000 	0.500 	0.000 	0.000
[[297   0]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       297
          1       0.00      0.00      0.00         3

avg / total       0.98      0.99      0.99       300


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.5, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(500,), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.980 	-0.010 	-0.010 	0.495 	0.000 	0.000
[[294   3]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       297
          1       0.00      0.00      0.00         3

avg / total       0.98      0.98      0.98       300


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=16,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=0.5, n_estimators=80, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.980 	0.249 	0.241 	0.660 	0.573 	0.307
[[293   4]
 [  2   1]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       297
          1       0.20      0.33      0.25         3

avg / total       0.99      0.98      0.98       300


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.01, cache_size=200, class_weight={1: 500}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.530 	0.105 	0.022 	0.763 	0.725 	0.550
[[156 141]
 [  0   3]]
             precision    recall  f1-score   support

          0       1.00      0.53      0.69       297
          1       0.02      1.00      0.04         3

avg / total       0.99      0.53      0.68       300


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...wski',
           metric_params=None, n_jobs=4, n_neighbors=4, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.990 	0.000 	0.000 	0.500 	0.000 	0.000
[[297   0]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       297
          1       0.00      0.00      0.00         3

avg / total       0.98      0.99      0.99       300


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=1,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.990 	0.000 	0.000 	0.500 	0.000 	0.000
[[297   0]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       297
          1       0.00      0.00      0.00         3

avg / total       0.98      0.99      0.99       300


                estimator   min_score   mean_score  max_score     sd_score  \
3    ExtraTreesClassifier  -0.0325018  -0.00104158   0.090745    0.0110716   
7                     SVC  -0.0282184  -0.00417563   0.113673    0.0231154   
0              GaussianNB    0.139465     0.139465   0.139465            0   
1      LogisticRegression  -0.0459192   0.00736696   0.136976    0.0428878   
6      AdaBoostClassifier  -0.0195734  -0.00266069   0.133646    0.0298556   
2           SGDClassifier  -0.0769756     0.023839    0.15119    0.0493991   
4  RandomForestClassifier -0.00357313 -0.000245912          0  0.000629741   
8        VotingClassifier  -0.0162537  -0.00713596          0   0.00449334   
9    KNeighborsClassifier  -0.0167731  -0.00396945          0   0.00644925   
5           MLPClassifier  -0.0215557   -0.0166277 -0.0111889   0.00232875   

        acc       auc           conf_matrix     f1_c0      f1_c1      kappa  \
3  0.863333  0.765993   [[257, 40], [1, 2]]  0.926126  0.0888889   0.071558   
7      0.53  0.762626  [[156, 141], [0, 3]]  0.688742  0.0408163  0.0216486   
0  0.793333   0.73064   [[236, 61], [1, 2]]  0.883895  0.0606061  0.0423231   
1  0.713333  0.690236   [[212, 85], [1, 2]]  0.831373  0.0444444  0.0256062   
6      0.98  0.659933    [[293, 4], [2, 1]]  0.989865       0.25   0.240506   
2  0.936667  0.638047   [[280, 17], [2, 1]]  0.967185  0.0952381  0.0794574   
4      0.99       0.5    [[297, 0], [3, 0]]  0.994975          0          0   
8      0.99       0.5    [[297, 0], [3, 0]]  0.994975          0          0   
9      0.99       0.5    [[297, 0], [3, 0]]  0.994975          0          0   
5      0.98  0.494949    [[294, 3], [3, 0]]  0.989899          0  -0.010101   

  model_score   prec_c0    prec_c1    rec_c0    rec_c1  
3    0.152547  0.996124   0.047619   0.86532  0.666667  
7    0.104608         1  0.0208333  0.525253         1  
0    0.112683  0.995781   0.031746  0.794613  0.666667  
1   0.0834279  0.995305  0.0229885  0.713805  0.666667  
6    0.248605   0.99322        0.2  0.986532  0.333333  
2    0.115674  0.992908  0.0555556  0.942761  0.333333  
4           0      0.99          0         1         0  
8           0      0.99          0         1         0  
9           0      0.99          0         1         0  
5   -0.010101  0.989899          0  0.989899         0  
Elapsed time 23.07 mins 

************************************************************

pre/post: 0/25  win/stride: 200/25  label:end 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-05-03 00:15:27.718000 
pca_target: 60 	 poly degree: 3 	 kselect: 60 
Imbalance: ClusterCentroids(estimator=None, n_jobs=1, random_state=None, ratio='auto') 
Extended target (count):  25141 325
('Total : Processed (count): ', (998L, 2300L), 12)
Final feature (count):  (998L, 2300L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.990 	0.000 	0.000 	0.500 	0.000 	0.000
[[297   0]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       297
          1       0.00      0.00      0.00         3

avg / total       0.98      0.99      0.99       300


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.01, class_weight={1: 3}, dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.587 	0.051 	0.012 	0.626 	0.625 	0.394
[[174 123]
 [  1   2]]
             precision    recall  f1-score   support

          0       0.99      0.59      0.74       297
          1       0.02      0.67      0.03         3

avg / total       0.98      0.59      0.73       300


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.0001, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='constant', loss='squared_hinge', n_iter=5, n_jobs=4,
       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.547 	-0.024 	-0.005 	0.441 	0.428 	0.179
[[163 134]
 [  2   1]]
             precision    recall  f1-score   support

          0       0.99      0.55      0.71       297
          1       0.01      0.33      0.01         3

avg / total       0.98      0.55      0.70       300


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=8, max_features=0.75, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.640 	0.063 	0.017 	0.653 	0.653 	0.428
[[190 107]
 [  1   2]]
             precision    recall  f1-score   support

          0       0.99      0.64      0.78       297
          1       0.02      0.67      0.04         3

avg / total       0.99      0.64      0.77       300


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=None, max_features=0.75, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=50, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.583 	0.050 	0.012 	0.625 	0.623 	0.392
[[173 124]
 [  1   2]]
             precision    recall  f1-score   support

          0       0.99      0.58      0.73       297
          1       0.02      0.67      0.03         3

avg / total       0.98      0.58      0.73       300


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.573 	0.114 	0.026 	0.785 	0.754 	0.594
[[169 128]
 [  0   3]]
             precision    recall  f1-score   support

          0       1.00      0.57      0.73       297
          1       0.02      1.00      0.04         3

avg / total       0.99      0.57      0.72       300


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=32,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=0.5, n_estimators=50, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.617 	0.058 	0.014 	0.641 	0.641 	0.413
[[183 114]
 [  1   2]]
             precision    recall  f1-score   support

          0       0.99      0.62      0.76       297
          1       0.02      0.67      0.03         3

avg / total       0.98      0.62      0.75       300


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.1, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='linear',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.463 	0.026 	0.005 	0.564 	0.555 	0.314
[[137 160]
 [  1   2]]
             precision    recall  f1-score   support

          0       0.99      0.46      0.63       297
          1       0.01      0.67      0.02         3

avg / total       0.98      0.46      0.62       300


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', R...wski',
           metric_params=None, n_jobs=4, n_neighbors=4, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.510 	-0.031 	-0.006 	0.423 	0.413 	0.168
[[152 145]
 [  2   1]]
             precision    recall  f1-score   support

          0       0.99      0.51      0.67       297
          1       0.01      0.33      0.01         3

avg / total       0.98      0.51      0.67       300


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=4,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.563 	0.046 	0.010 	0.614 	0.612 	0.379
[[167 130]
 [  1   2]]
             precision    recall  f1-score   support

          0       0.99      0.56      0.72       297
          1       0.02      0.67      0.03         3

avg / total       0.98      0.56      0.71       300


                estimator  min_score mean_score max_score   sd_score  \
5           MLPClassifier   0.273789   0.465612  0.812156   0.093359   
3    ExtraTreesClassifier   0.555556   0.885215         1  0.0734007   
6      AdaBoostClassifier  -0.145489   0.722851         1   0.201498   
1      LogisticRegression          0   0.371531  0.701045   0.183646   
4  RandomForestClassifier   0.333333   0.754115         1   0.115078   
9    KNeighborsClassifier  0.0171889   0.362749    0.5132  0.0944961   
7                     SVC  -0.367711   0.244828  0.461633   0.243593   
0              GaussianNB          1          1         1          0   
2           SGDClassifier    -0.3849   0.427614  0.812156   0.207693   
8        VotingClassifier   0.461633   0.586742  0.812156  0.0653166   

        acc       auc           conf_matrix     f1_c0      f1_c1       kappa  \
5  0.573333  0.784512  [[169, 128], [0, 3]]  0.725322  0.0447761   0.0257269   
3      0.64  0.653199  [[190, 107], [1, 2]]  0.778689  0.0357143   0.0165726   
6  0.616667  0.641414  [[183, 114], [1, 2]]  0.760915  0.0336134   0.0143984   
1  0.586667  0.626263  [[174, 123], [1, 2]]  0.737288    0.03125   0.0119522   
4  0.583333  0.624579  [[173, 124], [1, 2]]  0.734607  0.0310078   0.0117015   
9  0.563333  0.614478  [[167, 130], [1, 2]]   0.71828  0.0296296    0.010275   
7  0.463333  0.563973  [[137, 160], [1, 2]]  0.629885  0.0242424  0.00469832   
0      0.99       0.5    [[297, 0], [3, 0]]  0.994975          0           0   
2  0.546667  0.441077  [[163, 134], [2, 1]]  0.705628  0.0144928 -0.00517369   
8      0.51  0.422559  [[152, 145], [2, 1]]  0.674058  0.0134228 -0.00629792   

  model_score   prec_c0     prec_c1    rec_c0    rec_c1  
5    0.114154         1   0.0229008  0.569024         1  
3   0.0633861  0.994764   0.0183486  0.639731  0.666667  
6   0.0577862  0.994565   0.0172414  0.616162  0.666667  
1   0.0509647  0.994286       0.016  0.585859  0.666667  
4    0.050229  0.994253    0.015873  0.582492  0.666667  
9   0.0458933  0.994048   0.0151515   0.56229  0.666667  
7   0.0255428  0.992754   0.0123457  0.461279  0.666667  
0           0      0.99           0         1         0  
2   -0.023569  0.987879  0.00740741  0.548822  0.333333  
8  -0.0308321  0.987013  0.00684932  0.511785  0.333333  
Elapsed time 15.21 mins 

************************************************************

pre/post: 0/25  win/stride: 200/25  label:end 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-05-03 00:30:40.475000 
pca_target: 60 	 poly degree: 3 	 kselect: 60 
Imbalance: None 
Extended target (count):  25141 325
('Total : Processed (count): ', (998L, 2300L), 12)
Final feature (count):  (998L, 2300L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.717 	0.084 	0.026 	0.692 	0.691 	0.476
[[213  84]
 [  1   2]]
             precision    recall  f1-score   support

          0       1.00      0.72      0.83       297
          1       0.02      0.67      0.04         3

avg / total       0.99      0.72      0.83       300


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.01, class_weight={1: 500}, dual=False,
          fit_intercept=True, intercept_scaling=0.1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='sag', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.557 	0.044 	0.010 	0.611 	0.609 	0.374
[[165 132]
 [  1   2]]
             precision    recall  f1-score   support

          0       0.99      0.56      0.71       297
          1       0.01      0.67      0.03         3

avg / total       0.98      0.56      0.71       300


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.0001, average=False, class_weight={1: 15}, epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='perceptron', n_iter=5, n_jobs=4,
       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.753 	0.097 	0.033 	0.710 	0.709 	0.498
[[224  73]
 [  1   2]]
             precision    recall  f1-score   support

          0       1.00      0.75      0.86       297
          1       0.03      0.67      0.05         3

avg / total       0.99      0.75      0.85       300


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 500}, criterion='gini',
           max_depth=8, max_features=0.75, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.937 	0.116 	0.079 	0.638 	0.561 	0.295
[[280  17]
 [  2   1]]
             precision    recall  f1-score   support

          0       0.99      0.94      0.97       297
          1       0.06      0.33      0.10         3

avg / total       0.98      0.94      0.96       300


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.990 	0.000 	0.000 	0.500 	0.000 	0.000
[[297   0]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       297
          1       0.00      0.00      0.00         3

avg / total       0.98      0.99      0.99       300


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.01, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(240, 40), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	0.510 	0.494 	0.828 	0.812 	0.639
[[294   3]
 [  1   2]]
             precision    recall  f1-score   support

          0       1.00      0.99      0.99       297
          1       0.40      0.67      0.50         3

avg / total       0.99      0.99      0.99       300


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 500}, criterion='gini', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=2.0, n_estimators=80, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.970 	-0.014 	-0.014 	0.490 	0.000 	0.000
[[291   6]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.98      0.98       297
          1       0.00      0.00      0.00         3

avg / total       0.98      0.97      0.97       300


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.01, cache_size=200, class_weight={1: 500}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.517 	0.036 	0.007 	0.591 	0.586 	0.349
[[153 144]
 [  1   2]]
             precision    recall  f1-score   support

          0       0.99      0.52      0.68       297
          1       0.01      0.67      0.03         3

avg / total       0.98      0.52      0.67       300


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...wski',
           metric_params=None, n_jobs=4, n_neighbors=4, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.990 	0.000 	0.000 	0.500 	0.000 	0.000
[[297   0]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       297
          1       0.00      0.00      0.00         3

avg / total       0.98      0.99      0.99       300


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=1,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.990 	0.000 	0.000 	0.500 	0.000 	0.000
[[297   0]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       297
          1       0.00      0.00      0.00         3

avg / total       0.98      0.99      0.99       300


                estimator   min_score   mean_score  max_score    sd_score  \
5           MLPClassifier  -0.0189259   -0.0148073  0.0390192  0.00802683   
2           SGDClassifier  -0.0843176    0.0228985   0.133775   0.0474374   
0              GaussianNB    0.106959     0.106959   0.106959           0   
3    ExtraTreesClassifier  -0.0295787  -0.00196893  0.0807713   0.0104957   
1      LogisticRegression  -0.0489286   0.00398638    0.12415   0.0394723   
7                     SVC  -0.0270827  -0.00308267   0.117886   0.0245214   
4  RandomForestClassifier -0.00495491 -0.000396568          0  0.00082486   
8        VotingClassifier  -0.0139529  -0.00709823          0  0.00386266   
9    KNeighborsClassifier  -0.0156373  -0.00362307          0  0.00577554   
6      AdaBoostClassifier  -0.0191039  0.000198224      0.165   0.0303306   

        acc       auc           conf_matrix     f1_c0      f1_c1       kappa  \
5  0.986667  0.828283    [[294, 3], [1, 2]]  0.993243        0.5    0.493671   
2  0.753333  0.710438   [[224, 73], [1, 2]]  0.858238  0.0512821   0.0326797   
0  0.716667  0.691919   [[213, 84], [1, 2]]  0.833659  0.0449438   0.0261228   
3  0.936667  0.638047   [[280, 17], [2, 1]]  0.967185  0.0952381   0.0794574   
1  0.556667  0.611111  [[165, 132], [1, 2]]  0.712743  0.0291971  0.00982728   
7  0.516667  0.590909  [[153, 144], [1, 2]]  0.678492  0.0268456  0.00739321   
4      0.99       0.5    [[297, 0], [3, 0]]  0.994975          0           0   
8      0.99       0.5    [[297, 0], [3, 0]]  0.994975          0           0   
9      0.99       0.5    [[297, 0], [3, 0]]  0.994975          0           0   
6      0.97  0.489899    [[291, 6], [3, 0]]  0.984772          0  -0.0135135   

  model_score   prec_c0    prec_c1    rec_c0    rec_c1  
5    0.510295   0.99661        0.4  0.989899  0.666667  
2   0.0967098  0.995556  0.0266667  0.754209  0.666667  
0   0.0844561  0.995327  0.0232558  0.717172  0.666667  
3    0.115674  0.992908  0.0555556  0.942761  0.333333  
1   0.0444754  0.993976  0.0149254  0.555556  0.666667  
7   0.0361942  0.993506  0.0136986  0.515152  0.666667  
4           0      0.99          0         1         0  
8           0      0.99          0         1         0  
9           0      0.99          0         1         0  
6  -0.0143577  0.989796          0  0.979798         0  
Elapsed time 27.43 mins 

************************************************************


Standard, NT+, lagged(3,4)x1, filter(tukey & hp), truncated fileid=2




    pca = [0]
    poly = [0]
    ksel = [0, 60]
    imb = [ClusterCentroids(), None]
	
	
	
pre/post: 0/25  win/stride: 200/25  label:end 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-05-03 08:31:57.479000 
pca_target: 0 	 poly degree: 0 	 kselect: 0 
Imbalance: ClusterCentroids(estimator=None, n_jobs=1, random_state=None, ratio='auto') 
Extended target (count):  25141 325
('Total : Processed (count): ', (998L, 22L), 12)
Final feature (count):  (998L, 22L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.583 	0.050 	0.012 	0.625 	0.623 	0.392
[[173 124]
 [  1   2]]
             precision    recall  f1-score   support

          0       0.99      0.58      0.73       297
          1       0.02      0.67      0.03         3

avg / total       0.98      0.58      0.73       300


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.001, class_weight={1: 3}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.440 	0.021 	0.004 	0.552 	0.540 	0.298
[[130 167]
 [  1   2]]
             precision    recall  f1-score   support

          0       0.99      0.44      0.61       297
          1       0.01      0.67      0.02         3

avg / total       0.98      0.44      0.60       300


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.001, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='invscaling', loss='squared_hinge', n_iter=5,
       n_jobs=4, penalty='none', power_t=0.5, random_state=None,
       shuffle=True, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.520 	0.037 	0.008 	0.593 	0.588 	0.351
[[154 143]
 [  1   2]]
             precision    recall  f1-score   support

          0       0.99      0.52      0.68       297
          1       0.01      0.67      0.03         3

avg / total       0.98      0.52      0.67       300


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=8, max_features=0.75, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.563 	0.046 	0.010 	0.614 	0.612 	0.379
[[167 130]
 [  1   2]]
             precision    recall  f1-score   support

          0       0.99      0.56      0.72       297
          1       0.02      0.67      0.03         3

avg / total       0.98      0.56      0.71       300


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features=0.75, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.337 	0.000 	0.000 	0.500 	0.471 	0.230
[[ 99 198]
 [  1   2]]
             precision    recall  f1-score   support

          0       0.99      0.33      0.50       297
          1       0.01      0.67      0.02         3

avg / total       0.98      0.34      0.49       300


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.1, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(500,), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.680 	0.074 	0.021 	0.673 	0.673 	0.453
[[202  95]
 [  1   2]]
             precision    recall  f1-score   support

          0       1.00      0.68      0.81       297
          1       0.02      0.67      0.04         3

avg / total       0.99      0.68      0.80       300


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=4,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=2.0, n_estimators=80, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.337 	0.000 	0.000 	0.500 	0.471 	0.230
[[ 99 198]
 [  1   2]]
             precision    recall  f1-score   support

          0       0.99      0.33      0.50       297
          1       0.01      0.67      0.02         3

avg / total       0.98      0.34      0.49       300


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='linear',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.477 	0.028 	0.005 	0.571 	0.563 	0.323
[[141 156]
 [  1   2]]
             precision    recall  f1-score   support

          0       0.99      0.47      0.64       297
          1       0.01      0.67      0.02         3

avg / total       0.98      0.48      0.64       300


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', R...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.627 	0.060 	0.015 	0.646 	0.646 	0.419
[[186 111]
 [  1   2]]
             precision    recall  f1-score   support

          0       0.99      0.63      0.77       297
          1       0.02      0.67      0.03         3

avg / total       0.98      0.63      0.76       300


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=6, p=2,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.613 	0.057 	0.014 	0.640 	0.639 	0.411
[[182 115]
 [  1   2]]
             precision    recall  f1-score   support

          0       0.99      0.61      0.76       297
          1       0.02      0.67      0.03         3

avg / total       0.98      0.61      0.75       300


                estimator  min_score mean_score max_score   sd_score  \
5           MLPClassifier     0.1283   0.328219  0.624311   0.132328   
8        VotingClassifier   0.239411    0.46517  0.589933  0.0707179   
9    KNeighborsClassifier  -0.145489   0.159416  0.367711    0.12445   
0              GaussianNB   0.906078   0.906078  0.906078          0   
3    ExtraTreesClassifier     0.2566    0.75021  0.906078   0.153165   
2           SGDClassifier  -0.350522   0.389864  0.718234   0.191372   
7                     SVC  -0.145489   0.173803  0.496011   0.226223   
1      LogisticRegression -0.0171889   0.273015  0.624311   0.196154   
4  RandomForestClassifier   0.478822   0.807758  0.906078   0.104834   
6      AdaBoostClassifier   0.187844   0.863278         1   0.102079   

        acc       auc           conf_matrix     f1_c0      f1_c1       kappa  \
5      0.68  0.673401   [[202, 95], [1, 2]]     0.808       0.04   0.0210075   
8  0.626667  0.646465  [[186, 111], [1, 2]]  0.768595  0.0344828    0.015298   
9  0.613333  0.639731  [[182, 115], [1, 2]]  0.758333  0.0333333   0.0141084   
0  0.583333  0.624579  [[173, 124], [1, 2]]  0.734607  0.0310078   0.0117015   
3  0.563333  0.614478  [[167, 130], [1, 2]]   0.71828  0.0296296    0.010275   
2      0.52  0.592593  [[154, 143], [1, 2]]  0.681416   0.027027  0.00758098   
7  0.476667  0.570707  [[141, 156], [1, 2]]  0.642369  0.0248447  0.00532184   
1      0.44  0.552189  [[130, 167], [1, 2]]  0.607477  0.0232558  0.00367691   
4  0.336667       0.5   [[99, 198], [1, 2]]  0.498741  0.0197044           0   
6  0.336667       0.5   [[99, 198], [1, 2]]  0.498741  0.0197044           0   

   model_score   prec_c0    prec_c1    rec_c0    rec_c1  
5     0.073771  0.995074  0.0206186  0.680135  0.666667  
8    0.0601508  0.994652  0.0176991  0.626263  0.666667  
9    0.0570088  0.994536   0.017094  0.612795  0.666667  
0     0.050229  0.994253   0.015873  0.582492  0.666667  
3    0.0458933  0.994048  0.0151515   0.56229  0.666667  
2    0.0368719  0.993548  0.0137931  0.518519  0.666667  
7    0.0281812  0.992958  0.0126582  0.474747  0.666667  
1    0.0209394  0.992366  0.0118343   0.43771  0.666667  
4  2.46563e-18      0.99       0.01  0.333333  0.666667  
6  2.46563e-18      0.99       0.01  0.333333  0.666667  
Elapsed time 14.88 mins 

************************************************************

pre/post: 0/25  win/stride: 200/25  label:end 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-05-03 08:46:50.579000 
pca_target: 0 	 poly degree: 0 	 kselect: 0 
Imbalance: None 
Extended target (count):  25141 325
('Total : Processed (count): ', (998L, 22L), 12)
Final feature (count):  (998L, 22L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.607 	0.055 	0.014 	0.636 	0.636 	0.406
[[180 117]
 [  1   2]]
             precision    recall  f1-score   support

          0       0.99      0.61      0.75       297
          1       0.02      0.67      0.03         3

avg / total       0.98      0.61      0.75       300


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.1, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=0.01, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='sag', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.670 	0.071 	0.020 	0.668 	0.668 	0.447
[[199  98]
 [  1   2]]
             precision    recall  f1-score   support

          0       0.99      0.67      0.80       297
          1       0.02      0.67      0.04         3

avg / total       0.99      0.67      0.79       300


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.5, average=False, class_weight={1: 15}, epsilon=0.1,
       eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='squared_hinge', n_iter=5, n_jobs=4,
       penalty='none', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.867 	-0.038 	-0.019 	0.438 	0.000 	0.000
[[260  37]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.88      0.93       297
          1       0.00      0.00      0.00         3

avg / total       0.98      0.87      0.92       300


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 500}, criterion='gini',
           max_depth=8, max_features='auto', max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=30, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.787 	0.110 	0.040 	0.727 	0.725 	0.519
[[234  63]
 [  1   2]]
             precision    recall  f1-score   support

          0       1.00      0.79      0.88       297
          1       0.03      0.67      0.06         3

avg / total       0.99      0.79      0.87       300


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=32, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=30, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.990 	0.000 	0.000 	0.500 	0.000 	0.000
[[297   0]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       297
          1       0.00      0.00      0.00         3

avg / total       0.98      0.99      0.99       300


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.5, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(500,), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.990 	0.000 	0.000 	0.500 	0.000 	0.000
[[297   0]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       297
          1       0.00      0.00      0.00         3

avg / total       0.98      0.99      0.99       300


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 500}, criterion='gini', max_depth=32,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=1.0, n_estimators=50, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.980 	-0.010 	-0.010 	0.495 	0.000 	0.000
[[294   3]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       297
          1       0.00      0.00      0.00         3

avg / total       0.98      0.98      0.98       300


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.610 	0.056 	0.014 	0.638 	0.637 	0.409
[[181 116]
 [  1   2]]
             precision    recall  f1-score   support

          0       0.99      0.61      0.76       297
          1       0.02      0.67      0.03         3

avg / total       0.98      0.61      0.75       300


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.990 	0.000 	0.000 	0.500 	0.000 	0.000
[[297   0]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       297
          1       0.00      0.00      0.00         3

avg / total       0.98      0.99      0.99       300


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=1,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.990 	0.000 	0.000 	0.500 	0.000 	0.000
[[297   0]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       297
          1       0.00      0.00      0.00         3

avg / total       0.98      0.99      0.99       300


                estimator  min_score  mean_score  max_score    sd_score  \
3    ExtraTreesClassifier -0.0295217  0.00158201   0.111113   0.0162023   
1      LogisticRegression -0.0474411    0.030679   0.123072   0.0397985   
7                     SVC -0.0249323   0.0191873   0.115896   0.0306786   
0              GaussianNB  0.0948314   0.0948314  0.0948314           0   
4  RandomForestClassifier -0.0180642 -0.00137583          0  0.00268311   
5           MLPClassifier -0.0152571 -0.00940562          0  0.00458511   
8        VotingClassifier -0.0167121  -0.0047275          0  0.00535154   
9    KNeighborsClassifier -0.0187543 -0.00497422          0  0.00732114   
6      AdaBoostClassifier -0.0201888  -0.0060825    0.12711   0.0166026   
2           SGDClassifier  -0.160201    0.034827   0.158975   0.0393721   

        acc       auc           conf_matrix     f1_c0      f1_c1      kappa  \
3  0.786667  0.727273   [[234, 63], [1, 2]]  0.879699  0.0588235  0.0404798   
1      0.67   0.66835   [[199, 98], [1, 2]]  0.800805   0.038835   0.019802   
7      0.61  0.638047  [[181, 116], [1, 2]]  0.755741  0.0330579  0.0138233   
0  0.606667  0.636364  [[180, 117], [1, 2]]  0.753138  0.0327869  0.0135429   
4      0.99       0.5    [[297, 0], [3, 0]]  0.994975          0          0   
5      0.99       0.5    [[297, 0], [3, 0]]  0.994975          0          0   
8      0.99       0.5    [[297, 0], [3, 0]]  0.994975          0          0   
9      0.99       0.5    [[297, 0], [3, 0]]  0.994975          0          0   
6      0.98  0.494949    [[294, 3], [3, 0]]  0.989899          0  -0.010101   
2  0.866667   0.43771   [[260, 37], [3, 0]]  0.928571          0 -0.0188487   

  model_score   prec_c0    prec_c1    rec_c0    rec_c1  
3    0.109781  0.995745  0.0307692  0.787879  0.666667  
1   0.0710669     0.995       0.02  0.670034  0.666667  
7   0.0562367  0.994505  0.0169492  0.609428  0.666667  
0   0.0554696  0.994475  0.0168067  0.606061  0.666667  
4           0      0.99          0         1         0  
5           0      0.99          0         1         0  
8           0      0.99          0         1         0  
9           0      0.99          0         1         0  
6   -0.010101  0.989899          0  0.989899         0  
2  -0.0376969  0.988593          0  0.875421         0  
Elapsed time 22.62 mins 

************************************************************


Standard, NT+, lagged(3,4)x1, filter(tukey & hp), truncated fileid=2


    pca = [0]
    poly = [0]
    ksel = [0, 20]
    imb = [SMOTETomek(smote=SMOTE(m_neighbors=100, k_neighbors=3, kind='regular'))]
    




pre/post: 0/25  win/stride: 200/25  label:end 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-05-03 10:09:39.246000 
pca_target: 0 	 poly degree: 0 	 kselect: 0 
Imbalance: SMOTETomek(k=None, kind_smote=None, m=None, n_jobs=None, out_step=None,
      random_state=None, ratio='auto',
      smote=SMOTE(k=None, k_neighbors=3, kind='regular', m=None, m_neighbors=100,
   n_jobs=1, out_step=0.5, random_state=None, ratio='auto',
   svm_estimator=None),
      tomek=None) 
Extended target (count):  25141 325
('Total : Processed (count): ', (998L, 22L), 12)
Final feature (count):  (998L, 22L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.653 	0.067 	0.018 	0.660 	0.660 	0.436
[[194 103]
 [  1   2]]
             precision    recall  f1-score   support

          0       0.99      0.65      0.79       297
          1       0.02      0.67      0.04         3

avg / total       0.99      0.65      0.78       300


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=10, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=5, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.833 	0.133 	0.056 	0.751 	0.746 	0.547
[[248  49]
 [  1   2]]
             precision    recall  f1-score   support

          0       1.00      0.84      0.91       297
          1       0.04      0.67      0.07         3

avg / total       0.99      0.83      0.90       300


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=1, average=False, class_weight={1: 15}, epsilon=0.1,
       eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='invscaling', loss='squared_hinge', n_iter=5,
       n_jobs=4, penalty='none', power_t=0.5, random_state=None,
       shuffle=True, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.880 	0.068 	0.035 	0.609 	0.543 	0.279
[[263  34]
 [  2   1]]
             precision    recall  f1-score   support

          0       0.99      0.89      0.94       297
          1       0.03      0.33      0.05         3

avg / total       0.98      0.88      0.93       300


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 50}, criterion='gini',
           max_depth=None, max_features=0.33, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=50, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.980 	-0.010 	-0.010 	0.495 	0.000 	0.000
[[294   3]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       297
          1       0.00      0.00      0.00         3

avg / total       0.98      0.98      0.98       300


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight='balanced',
            criterion='gini', max_depth=None, max_features='auto',
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.983 	-0.008 	-0.008 	0.497 	0.000 	0.000
[[295   2]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       297
          1       0.00      0.00      0.00         3

avg / total       0.98      0.98      0.98       300


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.5, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.973 	0.206 	0.189 	0.657 	0.571 	0.305
[[291   6]
 [  2   1]]
             precision    recall  f1-score   support

          0       0.99      0.98      0.99       297
          1       0.14      0.33      0.20         3

avg / total       0.98      0.97      0.98       300


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='gini', max_depth=8,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=1.0, n_estimators=80, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	0.327 	0.327 	0.663 	0.575 	0.309
[[295   2]
 [  2   1]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       297
          1       0.33      0.33      0.33         3

avg / total       0.99      0.99      0.99       300


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.5, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=10, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.990 	0.000 	0.000 	0.500 	0.000 	0.000
[[297   0]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       297
          1       0.00      0.00      0.00         3

avg / total       0.98      0.99      0.99       300


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=10.0, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', ...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.940 	-0.023 	-0.017 	0.475 	0.000 	0.000
[[282  15]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.95      0.97       297
          1       0.00      0.00      0.00         3

avg / total       0.98      0.94      0.96       300


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=3,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.940 	-0.023 	-0.017 	0.475 	0.000 	0.000
[[282  15]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.95      0.97       297
          1       0.00      0.00      0.00         3

avg / total       0.98      0.94      0.96       300


                estimator min_score mean_score max_score    sd_score  \
1      LogisticRegression  0.199823   0.624947  0.821338    0.127169   
6      AdaBoostClassifier  0.840646   0.952912  0.988492   0.0236258   
0              GaussianNB  0.670967   0.670967  0.670967           0   
5           MLPClassifier  0.945056   0.963797  0.978676  0.00732472   
2           SGDClassifier -0.171072   0.495249  0.825723    0.202347   
7                     SVC         0   0.726223  0.994226    0.237959   
4  RandomForestClassifier  0.844693   0.933541  0.977014   0.0429583   
3    ExtraTreesClassifier  0.702431   0.923722  0.989938    0.083906   
8        VotingClassifier  0.857705   0.903842  0.942281   0.0206728   
9    KNeighborsClassifier  0.850174   0.897214  0.943709   0.0294507   

        acc       auc           conf_matrix     f1_c0      f1_c1       kappa  \
1  0.833333  0.750842   [[248, 49], [1, 2]]  0.908425  0.0740741   0.0562476   
6  0.986667    0.6633    [[295, 2], [2, 1]]  0.993266   0.333333    0.326599   
0  0.653333  0.659933  [[194, 103], [1, 2]]  0.788618   0.037037   0.0179415   
5  0.973333  0.656566    [[291, 6], [2, 1]]  0.986441        0.2    0.188641   
2      0.88  0.609428   [[263, 34], [2, 1]]  0.935943  0.0526316   0.0348525   
7      0.99       0.5    [[297, 0], [3, 0]]  0.994975          0           0   
4  0.983333  0.496633    [[295, 2], [3, 0]]  0.991597          0 -0.00806452   
3      0.98  0.494949    [[294, 3], [3, 0]]  0.989899          0   -0.010101   
8      0.94  0.474747   [[282, 15], [3, 0]]  0.969072          0  -0.0169492   
9      0.94  0.474747   [[282, 15], [3, 0]]  0.969072          0  -0.0169492   

  model_score   prec_c0    prec_c1    rec_c0    rec_c1  
1    0.132887  0.995984  0.0392157  0.835017  0.666667  
6    0.326599  0.993266   0.333333  0.993266  0.333333  
0   0.0667258  0.994872  0.0190476  0.653199  0.666667  
5    0.206387  0.993174   0.142857  0.979798  0.333333  
2   0.0678327  0.992453  0.0285714  0.885522  0.333333  
7           0      0.99          0         1         0  
4 -0.00823359  0.989933          0  0.993266         0  
3   -0.010101  0.989899          0  0.989899         0  
8  -0.0230571  0.989474          0  0.949495         0  
9  -0.0230571  0.989474          0  0.949495         0  
Elapsed time 36.86 mins 

************************************************************

pre/post: 0/25  win/stride: 200/25  label:end 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-05-03 10:46:30.938000 
pca_target: 0 	 poly degree: 0 	 kselect: 20 
Imbalance: SMOTETomek(k=None, kind_smote=None, m=None, n_jobs=None, out_step=None,
      random_state=None, ratio='auto',
      smote=SMOTE(k=None, k_neighbors=3, kind='regular', m=None, m_neighbors=100,
   n_jobs=1, out_step=0.5, random_state=None, ratio='auto',
   svm_estimator=None),
      tomek=None) 
Extended target (count):  25141 325
('Total : Processed (count): ', (998L, 22L), 12)
Final feature (count):  (998L, 22L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.643 	0.064 	0.017 	0.655 	0.655 	0.430
[[191 106]
 [  1   2]]
             precision    recall  f1-score   support

          0       0.99      0.64      0.78       297
          1       0.02      0.67      0.04         3

avg / total       0.99      0.64      0.77       300


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=10, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=5, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.817 	0.040 	0.016 	0.577 	0.523 	0.260
[[244  53]
 [  2   1]]
             precision    recall  f1-score   support

          0       0.99      0.82      0.90       297
          1       0.02      0.33      0.04         3

avg / total       0.98      0.82      0.89       300


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.001, average=False, class_weight={1: 15}, epsilon=0.1,
       eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='invscaling', loss='squared_hinge', n_iter=5,
       n_jobs=4, penalty='elasticnet', power_t=0.5, random_state=None,
       shuffle=True, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.813 	0.039 	0.016 	0.576 	0.522 	0.260
[[243  54]
 [  2   1]]
             precision    recall  f1-score   support

          0       0.99      0.82      0.90       297
          1       0.02      0.33      0.03         3

avg / total       0.98      0.81      0.89       300


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=32, max_features=0.75, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=50, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.977 	-0.012 	-0.012 	0.493 	0.000 	0.000
[[293   4]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       297
          1       0.00      0.00      0.00         3

avg / total       0.98      0.98      0.98       300


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3},
            criterion='entropy', max_depth=32, max_features='auto',
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=4,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.973 	-0.013 	-0.013 	0.492 	0.000 	0.000
[[292   5]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.98      0.99       297
          1       0.00      0.00      0.00         3

avg / total       0.98      0.97      0.98       300


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(500,), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.977 	0.225 	0.212 	0.658 	0.572 	0.306
[[292   5]
 [  2   1]]
             precision    recall  f1-score   support

          0       0.99      0.98      0.99       297
          1       0.17      0.33      0.22         3

avg / total       0.98      0.98      0.98       300


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 5}, criterion='entropy', max_depth=8,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='best'),
          learning_rate=1.0, n_estimators=50, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.980 	0.249 	0.241 	0.660 	0.573 	0.307
[[293   4]
 [  2   1]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       297
          1       0.20      0.33      0.25         3

avg / total       0.99      0.98      0.98       300


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.5, cache_size=200, class_weight={1: 3}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=10, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.990 	0.000 	0.000 	0.500 	0.000 	0.000
[[297   0]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       297
          1       0.00      0.00      0.00         3

avg / total       0.98      0.99      0.99       300


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=10.0, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', ...owski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='uniform'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.933 	0.111 	0.075 	0.636 	0.560 	0.294
[[279  18]
 [  2   1]]
             precision    recall  f1-score   support

          0       0.99      0.94      0.97       297
          1       0.05      0.33      0.09         3

avg / total       0.98      0.93      0.96       300


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=3,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.933 	0.111 	0.075 	0.636 	0.560 	0.294
[[279  18]
 [  2   1]]
             precision    recall  f1-score   support

          0       0.99      0.94      0.97       297
          1       0.05      0.33      0.09         3

avg / total       0.98      0.93      0.96       300


                estimator min_score mean_score max_score    sd_score  \
6      AdaBoostClassifier  0.820882   0.949484  0.984214     0.02724   
5           MLPClassifier    0.9547   0.967193  0.980117  0.00679511   
0              GaussianNB  0.627379   0.627379  0.627379           0   
8        VotingClassifier  0.861827   0.900159  0.935622   0.0196787   
9    KNeighborsClassifier  0.846426   0.892481  0.934152   0.0299372   
1      LogisticRegression  0.128025    0.59135  0.736757    0.116848   
2           SGDClassifier -0.173019   0.476592  0.772123    0.193137   
7                     SVC         0   0.697936  0.987026     0.23535   
3    ExtraTreesClassifier  0.691952   0.915408  0.989948   0.0906108   
4  RandomForestClassifier  0.814269    0.93338  0.982793   0.0507596   

        acc       auc           conf_matrix     f1_c0      f1_c1      kappa  \
6      0.98  0.659933    [[293, 4], [2, 1]]  0.989865       0.25   0.240506   
5  0.976667  0.658249    [[292, 5], [2, 1]]  0.988156   0.222222   0.211712   
0  0.643333  0.654882  [[191, 106], [1, 2]]  0.781186   0.036036  0.0169055   
8  0.933333  0.636364   [[279, 18], [2, 1]]  0.965398  0.0909091  0.0749306   
9  0.933333  0.636364   [[279, 18], [2, 1]]  0.965398  0.0909091  0.0749306   
1  0.816667  0.577441   [[244, 53], [2, 1]]  0.898711  0.0350877  0.0164521   
2  0.813333  0.575758   [[243, 54], [2, 1]]  0.896679  0.0344828  0.0158172   
7      0.99       0.5    [[297, 0], [3, 0]]  0.994975          0          0   
3  0.976667  0.493266    [[293, 4], [3, 0]]  0.988196          0 -0.0115607   
4  0.973333  0.491582    [[292, 5], [3, 0]]  0.986486          0 -0.0126582   

  model_score   prec_c0    prec_c1    rec_c0    rec_c1  
6    0.248605   0.99322        0.2  0.986532  0.333333  
5    0.224937  0.993197   0.166667  0.983165  0.333333  
0   0.0642107  0.994792  0.0185185  0.643098  0.666667  
8    0.111413  0.992883  0.0526316  0.939394  0.333333  
9    0.111413  0.992883  0.0526316  0.939394  0.333333  
1   0.0401121   0.99187  0.0185185  0.821549  0.333333  
2    0.038961  0.991837  0.0181818  0.818182  0.333333  
7           0      0.99          0         1         0  
3  -0.0116833  0.989865          0  0.986532         0  
4  -0.0130845  0.989831          0  0.983165         0  
Elapsed time 35.37 mins 

************************************************************

[4;33mReloaded modules[24m: migraine_processing, classifiers[0m
Finished.




    pca = [0]
    poly = [2]
    ksel = [0, 40]
    imb = [None, InstanceHardnessThreshold()]
	
	
	

pre/post: 0/25  win/stride: 200/25  label:end 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-05-03 16:04:24.118000 
pca_target: 0 	 poly degree: 2 	 kselect: 0 
Imbalance: None 
Extended target (count):  25141 325
('Total : Processed (count): ', (998L, 276L), 12)
Final feature (count):  (998L, 276L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.653 	0.067 	0.018 	0.660 	0.660 	0.436
[[194 103]
 [  1   2]]
             precision    recall  f1-score   support

          0       0.99      0.65      0.79       297
          1       0.02      0.67      0.04         3

avg / total       0.99      0.65      0.78       300


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.01, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=5, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='sag', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.600 	0.054 	0.013 	0.633 	0.632 	0.402
[[178 119]
 [  1   2]]
             precision    recall  f1-score   support

          0       0.99      0.60      0.75       297
          1       0.02      0.67      0.03         3

avg / total       0.98      0.60      0.74       300


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.1, average=False, class_weight={1: 3}, epsilon=0.1,
       eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='squared_hinge', n_iter=5, n_jobs=4,
       penalty='none', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.943 	0.125 	0.090 	0.641 	0.563 	0.297
[[282  15]
 [  2   1]]
             precision    recall  f1-score   support

          0       0.99      0.95      0.97       297
          1       0.06      0.33      0.11         3

avg / total       0.98      0.94      0.96       300


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 500}, criterion='gini',
           max_depth=8, max_features='auto', max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=50, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.793 	0.032 	0.012 	0.566 	0.516 	0.254
[[237  60]
 [  2   1]]
             precision    recall  f1-score   support

          0       0.99      0.80      0.88       297
          1       0.02      0.33      0.03         3

avg / total       0.98      0.79      0.88       300


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.990 	0.000 	0.000 	0.500 	0.000 	0.000
[[297   0]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       297
          1       0.00      0.00      0.00         3

avg / total       0.98      0.99      0.99       300


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='relu', alpha=0.1, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(500,), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.980 	0.249 	0.241 	0.660 	0.573 	0.307
[[293   4]
 [  2   1]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       297
          1       0.20      0.33      0.25         3

avg / total       0.99      0.98      0.98       300


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight='balanced', criterion='gini', max_depth=8,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=2.0, n_estimators=80, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.920 	-0.028 	-0.018 	0.465 	0.000 	0.000
[[276  21]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.93      0.96       297
          1       0.00      0.00      0.00         3

avg / total       0.98      0.92      0.95       300


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.01, cache_size=200, class_weight={1: 500}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.457 	0.024 	0.004 	0.561 	0.550 	0.309
[[135 162]
 [  1   2]]
             precision    recall  f1-score   support

          0       0.99      0.45      0.62       297
          1       0.01      0.67      0.02         3

avg / total       0.98      0.46      0.62       300


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	-0.006 	-0.005 	0.498 	0.000 	0.000
[[296   1]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       297
          1       0.00      0.00      0.00         3

avg / total       0.98      0.99      0.98       300


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=1,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.990 	0.000 	0.000 	0.500 	0.000 	0.000
[[297   0]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       297
          1       0.00      0.00      0.00         3

avg / total       0.98      0.99      0.99       300


                estimator   min_score   mean_score  max_score    sd_score  \
0              GaussianNB   0.0868476    0.0868476  0.0868476           0   
5           MLPClassifier  -0.0156373  -0.00837385 -0.0040961  0.00292646   
2           SGDClassifier  -0.0932136    0.0393092   0.173972   0.0411282   
1      LogisticRegression   -0.032097    0.0314999   0.141293   0.0344659   
3    ExtraTreesClassifier  -0.0457512  -0.00619532  0.0665511   0.0113461   
7                     SVC  -0.0278759   0.00552084  0.0837269   0.0211094   
4  RandomForestClassifier -0.00909626 -0.000766256          0  0.00158741   
9    KNeighborsClassifier  -0.0158784  -0.00366745          0   0.0061281   
8        VotingClassifier  -0.0147174  -0.00351814          0  0.00378889   
6      AdaBoostClassifier  -0.0222219  -0.00718689  0.0923531   0.0123789   

        acc       auc           conf_matrix     f1_c0      f1_c1       kappa  \
0  0.653333  0.659933  [[194, 103], [1, 2]]  0.788618   0.037037   0.0179415   
5      0.98  0.659933    [[293, 4], [2, 1]]  0.989865       0.25    0.240506   
2  0.943333  0.641414   [[282, 15], [2, 1]]   0.97074   0.105263   0.0899358   
1       0.6  0.632997  [[178, 119], [1, 2]]  0.747899  0.0322581   0.0129956   
3  0.793333  0.565657   [[237, 60], [2, 1]]  0.884328    0.03125   0.0124243   
7  0.456667  0.560606  [[135, 162], [1, 2]]  0.623557  0.0239521  0.00439775   
4      0.99       0.5    [[297, 0], [3, 0]]  0.994975          0           0   
9      0.99       0.5    [[297, 0], [3, 0]]  0.994975          0           0   
8  0.986667  0.498316    [[296, 1], [3, 0]]  0.993289          0 -0.00502513   
6      0.92  0.464646   [[276, 21], [3, 0]]  0.958333          0  -0.0178117   

  model_score   prec_c0    prec_c1    rec_c0    rec_c1  
0   0.0667258  0.994872  0.0190476  0.653199  0.666667  
5    0.248605   0.99322        0.2  0.986532  0.333333  
2     0.12524  0.992958     0.0625  0.949495  0.333333  
1   0.0539499  0.994413  0.0165289  0.599327  0.666667  
3   0.0324626  0.991632  0.0163934   0.79798  0.333333  
7   0.0242267  0.992647  0.0121951  0.454545  0.666667  
4           0      0.99          0         1         0  
9           0      0.99          0         1         0  
8 -0.00581228  0.989967          0  0.996633         0  
6  -0.0275734  0.989247          0  0.929293         0  
Elapsed time 44.12 mins 

************************************************************

pre/post: 0/25  win/stride: 200/25  label:end 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-05-03 16:48:31.537000 
pca_target: 0 	 poly degree: 2 	 kselect: 0 
Imbalance: InstanceHardnessThreshold(cv=5, estimator=None, n_jobs=1, random_state=None,
             ratio='auto', return_indices=False) 
Extended target (count):  25141 325
('Total : Processed (count): ', (998L, 276L), 12)
Final feature (count):  (998L, 276L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.650 	0.066 	0.018 	0.658 	0.658 	0.434
[[193 104]
 [  1   2]]
             precision    recall  f1-score   support

          0       0.99      0.65      0.79       297
          1       0.02      0.67      0.04         3

avg / total       0.99      0.65      0.78       300


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.01, class_weight={1: 3}, dual=False,
          fit_intercept=True, intercept_scaling=0.01, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.650 	0.066 	0.018 	0.658 	0.658 	0.434
[[193 104]
 [  1   2]]
             precision    recall  f1-score   support

          0       0.99      0.65      0.79       297
          1       0.02      0.67      0.04         3

avg / total       0.99      0.65      0.78       300


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.5, average=False, class_weight='balanced', epsilon=0.1,
       eta0=0.001, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='perceptron', n_iter=5, n_jobs=4,
       penalty='none', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.623 	0.059 	0.015 	0.645 	0.644 	0.417
[[185 112]
 [  1   2]]
             precision    recall  f1-score   support

          0       0.99      0.62      0.77       297
          1       0.02      0.67      0.03         3

avg / total       0.98      0.62      0.76       300


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 15}, criterion='gini',
           max_depth=8, max_features=0.33, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=50, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.980 	-0.010 	-0.010 	0.495 	0.000 	0.000
[[294   3]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       297
          1       0.00      0.00      0.00         3

avg / total       0.98      0.98      0.98       300


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.983 	-0.008 	-0.008 	0.497 	0.000 	0.000
[[295   2]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       297
          1       0.00      0.00      0.00         3

avg / total       0.98      0.98      0.98       300


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(500,), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.960 	-0.018 	-0.015 	0.485 	0.000 	0.000
[[288   9]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.97      0.98       297
          1       0.00      0.00      0.00         3

avg / total       0.98      0.96      0.97       300


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 50}, criterion='entropy',
            max_depth=32, max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=2.0, n_estimators=50, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.980 	-0.010 	-0.010 	0.495 	0.000 	0.000
[[294   3]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       297
          1       0.00      0.00      0.00         3

avg / total       0.98      0.98      0.98       300


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.01, cache_size=200, class_weight={1: 500}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.433 	0.020 	0.003 	0.549 	0.536 	0.294
[[128 169]
 [  1   2]]
             precision    recall  f1-score   support

          0       0.99      0.43      0.60       297
          1       0.01      0.67      0.02         3

avg / total       0.98      0.43      0.60       300


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 15}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Rand...wski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='distance'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.990 	0.000 	0.000 	0.500 	0.000 	0.000
[[297   0]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       297
          1       0.00      0.00      0.00         3

avg / total       0.98      0.99      0.99       300


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=1,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.937 	-0.024 	-0.017 	0.473 	0.000 	0.000
[[281  16]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.95      0.97       297
          1       0.00      0.00      0.00         3

avg / total       0.98      0.94      0.96       300


                estimator  min_score   mean_score  max_score    sd_score  \
0              GaussianNB  0.0999066    0.0999066  0.0999066           0   
1      LogisticRegression -0.0398706    0.0381505   0.154426   0.0558995   
2           SGDClassifier  -0.104079    0.0519955   0.166258   0.0487074   
7                     SVC -0.0351017  -0.00105769  0.0907666   0.0254757   
8        VotingClassifier -0.0133889  -0.00427935          0  0.00294044   
4  RandomForestClassifier -0.0122195 -0.000575636          0  0.00138728   
3    ExtraTreesClassifier  -0.047026   0.00405366   0.141299   0.0306445   
6      AdaBoostClassifier -0.0262329    0.0102288   0.175175    0.040055   
5           MLPClassifier -0.0165876  -0.00887199  0.0701325   0.0118895   
9    KNeighborsClassifier -0.0145712   0.00462343  0.0583857   0.0195686   

        acc       auc           conf_matrix     f1_c0      f1_c1       kappa  \
0      0.65  0.658249  [[193, 104], [1, 2]]  0.786151  0.0366972   0.0175898   
1      0.65  0.658249  [[193, 104], [1, 2]]  0.786151  0.0366972   0.0175898   
2  0.623333  0.644781  [[185, 112], [1, 2]]  0.766046   0.034188    0.014993   
7  0.433333  0.548822  [[128, 169], [1, 2]]  0.600939  0.0229885  0.00340016   
8      0.99       0.5    [[297, 0], [3, 0]]  0.994975          0           0   
4  0.983333  0.496633    [[295, 2], [3, 0]]  0.991597          0 -0.00806452   
3      0.98  0.494949    [[294, 3], [3, 0]]  0.989899          0   -0.010101   
6      0.98  0.494949    [[294, 3], [3, 0]]  0.989899          0   -0.010101   
5      0.96  0.484848    [[288, 9], [3, 0]]  0.979592          0  -0.0152284   
9  0.936667  0.473064   [[281, 16], [3, 0]]  0.967298          0  -0.0171306   

  model_score   prec_c0    prec_c1    rec_c0    rec_c1  
0   0.0658804  0.994845  0.0188679  0.649832  0.666667  
1   0.0658804  0.994845  0.0188679  0.649832  0.666667  
2    0.059357  0.994624  0.0175439  0.622896  0.666667  
7    0.019624  0.992248  0.0116959  0.430976  0.666667  
8           0      0.99          0         1         0  
4 -0.00823359  0.989933          0  0.993266         0  
3   -0.010101  0.989899          0  0.989899         0  
6   -0.010101  0.989899          0  0.989899         0  
5  -0.0176749  0.989691          0  0.969697         0  
9  -0.0238552  0.989437          0  0.946128         0  
Elapsed time 38.86 mins 

************************************************************

pre/post: 0/25  win/stride: 200/25  label:end 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-05-03 17:27:22.852000 
pca_target: 0 	 poly degree: 2 	 kselect: 40 
Imbalance: None 
Extended target (count):  25141 325
('Total : Processed (count): ', (998L, 276L), 12)
Final feature (count):  (998L, 276L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.687 	0.076 	0.022 	0.677 	0.677 	0.457
[[204  93]
 [  1   2]]
             precision    recall  f1-score   support

          0       1.00      0.69      0.81       297
          1       0.02      0.67      0.04         3

avg / total       0.99      0.69      0.81       300


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=0.01, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='sag', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.667 	0.001 	0.000 	0.502 	0.473 	0.216
[[199  98]
 [  2   1]]
             precision    recall  f1-score   support

          0       0.99      0.67      0.80       297
          1       0.01      0.33      0.02         3

avg / total       0.98      0.67      0.79       300


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.1, average=False, class_weight={1: 50}, epsilon=0.1,
       eta0=0.001, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='squared_hinge', n_iter=5, n_jobs=4,
       penalty='none', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.663 	-0.000 	0.000 	0.500 	0.471 	0.215
[[198  99]
 [  2   1]]
             precision    recall  f1-score   support

          0       0.99      0.67      0.80       297
          1       0.01      0.33      0.02         3

avg / total       0.98      0.66      0.79       300


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 500},
           criterion='entropy', max_depth=8, max_features=0.33,
           max_leaf_nodes=None, min_impurity_split=1e-07,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=4,
           oob_score=False, random_state=None, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.813 	0.122 	0.049 	0.741 	0.737 	0.535
[[242  55]
 [  1   2]]
             precision    recall  f1-score   support

          0       1.00      0.81      0.90       297
          1       0.04      0.67      0.07         3

avg / total       0.99      0.81      0.89       300


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=15, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.990 	0.000 	0.000 	0.500 	0.000 	0.000
[[297   0]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       297
          1       0.00      0.00      0.00         3

avg / total       0.98      0.99      0.99       300


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.01, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(500,), learning_rate='adaptive',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.977 	-0.012 	-0.012 	0.493 	0.000 	0.000
[[293   4]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       297
          1       0.00      0.00      0.00         3

avg / total       0.98      0.98      0.98       300


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 500}, criterion='entropy',
            max_depth=4, max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=2.0, n_estimators=50, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.980 	-0.010 	-0.010 	0.495 	0.000 	0.000
[[294   3]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       297
          1       0.00      0.00      0.00         3

avg / total       0.98      0.98      0.98       300


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.5, cache_size=200, class_weight='balanced', coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.677 	0.073 	0.021 	0.672 	0.672 	0.451
[[201  96]
 [  1   2]]
             precision    recall  f1-score   support

          0       1.00      0.68      0.81       297
          1       0.02      0.67      0.04         3

avg / total       0.99      0.68      0.80       300


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', R...owski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=2,
           weights='uniform'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.990 	0.000 	0.000 	0.500 	0.000 	0.000
[[297   0]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       297
          1       0.00      0.00      0.00         3

avg / total       0.98      0.99      0.99       300


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=2, p=1,
           weights='uniform')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.990 	0.000 	0.000 	0.500 	0.000 	0.000
[[297   0]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       297
          1       0.00      0.00      0.00         3

avg / total       0.98      0.99      0.99       300


                estimator  min_score  mean_score  max_score    sd_score  \
3    ExtraTreesClassifier -0.0335967 -0.00414234  0.0837526   0.0142009   
0              GaussianNB  0.0818392   0.0818392  0.0818392           0   
7                     SVC -0.0236442    0.028703   0.124496   0.0399033   
1      LogisticRegression -0.0460421   0.0399829   0.147149   0.0491766   
2           SGDClassifier -0.0623525   0.0470328   0.155784   0.0467644   
4  RandomForestClassifier -0.0389853 -0.00112046          0  0.00490614   
8        VotingClassifier -0.0140057 -0.00126952  0.0783567   0.0112306   
9    KNeighborsClassifier -0.0142128 -0.00396639          0  0.00596653   
6      AdaBoostClassifier -0.0211583 -0.00282559   0.250462   0.0251852   
5           MLPClassifier -0.0197618 -0.00638654  0.0511052   0.0165258   

        acc       auc          conf_matrix     f1_c0      f1_c1       kappa  \
3  0.813333  0.740741  [[242, 55], [1, 2]]  0.896296  0.0666667   0.0485899   
0  0.686667  0.676768  [[204, 93], [1, 2]]  0.812749  0.0408163   0.0218522   
7  0.676667  0.671717  [[201, 96], [1, 2]]  0.805611   0.039604   0.0205977   
1  0.666667  0.501684  [[199, 98], [2, 1]]  0.799197  0.0196078  0.00019996   
2  0.663333       0.5  [[198, 99], [2, 1]]  0.796781  0.0194175           0   
4      0.99       0.5   [[297, 0], [3, 0]]  0.994975          0           0   
8      0.99       0.5   [[297, 0], [3, 0]]  0.994975          0           0   
9      0.99       0.5   [[297, 0], [3, 0]]  0.994975          0           0   
6      0.98  0.494949   [[294, 3], [3, 0]]  0.989899          0   -0.010101   
5  0.976667  0.493266   [[293, 4], [3, 0]]  0.988196          0  -0.0115607   

   model_score   prec_c0    prec_c1    rec_c0    rec_c1  
3     0.122117  0.995885  0.0350877  0.814815  0.666667  
0    0.0756194  0.995122  0.0210526  0.686869  0.666667  
7    0.0728608   0.99505  0.0204082  0.676768  0.666667  
1   0.00071247   0.99005   0.010101  0.670034  0.333333  
2 -1.08488e-17      0.99       0.01  0.666667  0.333333  
4            0      0.99          0         1         0  
8            0      0.99          0         1         0  
9            0      0.99          0         1         0  
6    -0.010101  0.989899          0  0.989899         0  
5   -0.0116833  0.989865          0  0.986532         0  
Elapsed time 25.64 mins 

************************************************************

pre/post: 0/25  win/stride: 200/25  label:end 
filename: stm_sb_modified.csv (feature set prepared earlier) 
datetime: 2017-05-03 17:53:00.992000 
pca_target: 0 	 poly degree: 2 	 kselect: 40 
Imbalance: InstanceHardnessThreshold(cv=5, estimator=None, n_jobs=1, random_state=None,
             ratio='auto', return_indices=False) 
Extended target (count):  25141 325
('Total : Processed (count): ', (998L, 276L), 12)
Final feature (count):  (998L, 276L)
Running GridSearchCV for GaussianNB.
Fitting 5 folds for each of 1 candidates, totalling 5 fits
BEST: GaussianNB(priors=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.657 	0.068 	0.018 	0.662 	0.662 	0.438
[[195 102]
 [  1   2]]
             precision    recall  f1-score   support

          0       0.99      0.66      0.79       297
          1       0.02      0.67      0.04         3

avg / total       0.99      0.66      0.78       300


Running GridSearchCV for LogisticRegression.
Fitting 5 folds for each of 450 candidates, totalling 2250 fits
BEST: LogisticRegression(C=1, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=5, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='sag', tol=0.0001, verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.573 	0.048 	0.011 	0.620 	0.618 	0.385
[[170 127]
 [  1   2]]
             precision    recall  f1-score   support

          0       0.99      0.57      0.73       297
          1       0.02      0.67      0.03         3

avg / total       0.98      0.57      0.72       300


Running GridSearchCV for SGDClassifier.
Fitting 5 folds for each of 2700 candidates, totalling 13500 fits
BEST: SGDClassifier(alpha=0.0001, average=False, class_weight={1: 50}, epsilon=0.1,
       eta0=0.5, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='squared_hinge', n_iter=5, n_jobs=4,
       penalty='l2', power_t=0.5, random_state=None, shuffle=True,
       verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.743 	0.093 	0.031 	0.705 	0.704 	0.492
[[221  76]
 [  1   2]]
             precision    recall  f1-score   support

          0       1.00      0.74      0.85       297
          1       0.03      0.67      0.05         3

avg / total       0.99      0.74      0.84       300


Running GridSearchCV for ExtraTreesClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: ExtraTreesClassifier(bootstrap=False, class_weight={1: 3}, criterion='gini',
           max_depth=16, max_features=0.33, max_leaf_nodes=None,
           min_impurity_split=1e-07, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=30, n_jobs=4, oob_score=False, random_state=None,
           verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.973 	-0.013 	-0.013 	0.492 	0.000 	0.000
[[292   5]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.98      0.99       297
          1       0.00      0.00      0.00         3

avg / total       0.98      0.97      0.98       300


Running GridSearchCV for RandomForestClassifier.
Fitting 5 folds for each of 360 candidates, totalling 1800 fits
BEST: RandomForestClassifier(bootstrap=True, class_weight={1: 3}, criterion='gini',
            max_depth=8, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=30, n_jobs=4, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.987 	-0.006 	-0.005 	0.498 	0.000 	0.000
[[296   1]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      1.00      0.99       297
          1       0.00      0.00      0.00         3

avg / total       0.98      0.99      0.98       300


Running GridSearchCV for MLPClassifier.
Fitting 5 folds for each of 48 candidates, totalling 240 fits
BEST: MLPClassifier(activation='tanh', alpha=0.001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(60, 20, 10), learning_rate='invscaling',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.957 	-0.019 	-0.016 	0.483 	0.000 	0.000
[[287  10]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.97      0.98       297
          1       0.00      0.00      0.00         3

avg / total       0.98      0.96      0.97       300


Running GridSearchCV for AdaBoostClassifier.
Fitting 5 folds for each of 576 candidates, totalling 2880 fits
BEST: AdaBoostClassifier(algorithm='SAMME.R',
          base_estimator=DecisionTreeClassifier(class_weight={1: 50}, criterion='gini', max_depth=16,
            max_features=None, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=None, splitter='random'),
          learning_rate=2.0, n_estimators=15, random_state=None)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.973 	-0.013 	-0.013 	0.492 	0.000 	0.000
[[292   5]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.98      0.99       297
          1       0.00      0.00      0.00         3

avg / total       0.98      0.97      0.98       300


Running GridSearchCV for SVC.
Fitting 5 folds for each of 160 candidates, totalling 800 fits
BEST: SVC(C=0.5, cache_size=200, class_weight={1: 500}, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.677 	0.073 	0.021 	0.672 	0.672 	0.451
[[201  96]
 [  1   2]]
             precision    recall  f1-score   support

          0       1.00      0.68      0.81       297
          1       0.02      0.67      0.04         3

avg / total       0.99      0.68      0.80       300


Running GridSearchCV for VotingClassifier.
Fitting 5 folds for each of 216 candidates, totalling 1080 fits
BEST: VotingClassifier(estimators=[('lr', LogisticRegression(C=0.1, class_weight={1: 500}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=4, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)), ('rf', Ran...owski',
           metric_params=None, n_jobs=4, n_neighbors=4, p=2,
           weights='uniform'))],
         n_jobs=4, voting='soft', weights=[1, 1, 1])
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.983 	-0.008 	-0.008 	0.497 	0.000 	0.000
[[295   2]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       297
          1       0.00      0.00      0.00         3

avg / total       0.98      0.98      0.98       300


Running GridSearchCV for KNeighborsClassifier.
Fitting 5 folds for each of 96 candidates, totalling 480 fits
BEST: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=4, n_neighbors=1, p=4,
           weights='distance')
	 ACC 	 MCC 	 KAP 	 AUC 	 GEOM 	 IBA
	0.973 	-0.013 	-0.013 	0.492 	0.000 	0.000
[[292   5]
 [  3   0]]
             precision    recall  f1-score   support

          0       0.99      0.98      0.99       297
          1       0.00      0.00      0.00         3

avg / total       0.98      0.97      0.98       300


                estimator  min_score  mean_score  max_score    sd_score  \
2           SGDClassifier -0.0650142   0.0773932   0.207212   0.0580564   
7                     SVC -0.0506593    0.048412   0.157259   0.0560209   
0              GaussianNB   0.128549    0.128549   0.128549           0   
1      LogisticRegression -0.0381456   0.0693102   0.190617    0.061747   
4  RandomForestClassifier -0.0350515 -0.00117621          0  0.00453315   
8        VotingClassifier -0.0194085 -0.00279067   0.195657   0.0208672   
3    ExtraTreesClassifier -0.0339905  0.00130852   0.141055   0.0231168   
6      AdaBoostClassifier -0.0259839   0.0233794   0.291591   0.0591025   
9    KNeighborsClassifier -0.0142014  0.00258854  0.0831895   0.0213993   
5           MLPClassifier -0.0194636 -0.00871714  0.0642238   0.0122584   

        acc       auc           conf_matrix     f1_c0      f1_c1       kappa  \
2  0.743333  0.705387   [[221, 76], [1, 2]]  0.851638  0.0493827    0.030715   
7  0.676667  0.671717   [[201, 96], [1, 2]]  0.805611   0.039604   0.0205977   
0  0.656667  0.661616  [[195, 102], [1, 2]]  0.791075  0.0373832   0.0182997   
1  0.573333  0.619529  [[170, 127], [1, 2]]  0.726496   0.030303    0.010972   
4  0.986667  0.498316    [[296, 1], [3, 0]]  0.993289          0 -0.00502513   
8  0.983333  0.496633    [[295, 2], [3, 0]]  0.991597          0 -0.00806452   
3  0.973333  0.491582    [[292, 5], [3, 0]]  0.986486          0  -0.0126582   
6  0.973333  0.491582    [[292, 5], [3, 0]]  0.986486          0  -0.0126582   
9  0.973333  0.491582    [[292, 5], [3, 0]]  0.986486          0  -0.0126582   
5  0.956667  0.483165   [[287, 10], [3, 0]]  0.977853          0   -0.015625   

  model_score   prec_c0    prec_c1    rec_c0    rec_c1  
2   0.0931791  0.995495   0.025641  0.744108  0.666667  
7   0.0728608   0.99505  0.0204082  0.676768  0.666667  
0   0.0675786  0.994898  0.0192308  0.656566  0.666667  
1    0.048045  0.994152  0.0155039  0.572391  0.666667  
4 -0.00581228  0.989967          0  0.996633         0  
8 -0.00823359  0.989933          0  0.993266         0  
3  -0.0130845  0.989831          0  0.983165         0  
6  -0.0130845  0.989831          0  0.983165         0  
9  -0.0130845  0.989831          0  0.983165         0  
5  -0.0186631  0.989655          0   0.96633         0  
Elapsed time 23.77 mins 

************************************************************










[4;33mReloaded modules[24m: migraine_processing, classifiers[0m
